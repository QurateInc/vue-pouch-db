{"version":3,"sources":["webpack:///webpack/universalModuleDefinition","webpack:///build.js","webpack:///webpack/bootstrap 6ca1a8b5d6575cb0f2d0","webpack:///(webpack)/buildin/global.js","webpack:///./~/lodash.merge/index.js","webpack:///./~/immediate/lib/browser.js","webpack:///./src/utils/index.js","webpack:///./~/pouchdb-browser/lib/index.js","webpack:///./~/argsarray/index.js","webpack:///./~/debug/src/browser.js","webpack:///./~/debug/src/debug.js","webpack:///./~/events/events.js","webpack:///./~/inherits/inherits_browser.js","webpack:///./~/lie/lib/browser.js","webpack:///./~/ms/index.js","webpack:///./~/process/browser.js","webpack:///./~/scope-eval/scope_eval.js","webpack:///./~/sift/sift.js","webpack:///./~/spark-md5/spark-md5.js","webpack:///./~/vuvuzela/index.js","webpack:///(webpack)/buildin/module.js","webpack:///./src/index.js"],"names":["root","factory","exports","module","define","amd","this","modules","__webpack_require__","moduleId","installedModules","i","l","call","m","c","value","d","name","getter","o","Object","defineProperty","configurable","enumerable","get","n","__esModule","object","property","prototype","hasOwnProperty","p","s","g","Function","eval","e","window","global","addMapEntry","map","pair","set","addSetEntry","add","apply","func","thisArg","args","length","arrayEach","array","iteratee","index","arrayPush","values","offset","arrayReduce","accumulator","initAccum","baseTimes","result","Array","baseUnary","getValue","key","undefined","isHostObject","toString","mapToArray","size","forEach","overArg","transform","arg","setToArray","Hash","entries","clear","entry","hashClear","__data__","nativeCreate","hashDelete","has","hashGet","data","HASH_UNDEFINED","hashHas","hashSet","ListCache","listCacheClear","listCacheDelete","assocIndexOf","lastIndex","pop","splice","listCacheGet","listCacheHas","listCacheSet","push","MapCache","mapCacheClear","hash","Map","string","mapCacheDelete","getMapData","mapCacheGet","mapCacheHas","mapCacheSet","Stack","stackClear","stackDelete","stackGet","stackHas","stackSet","cache","pairs","LARGE_ARRAY_SIZE","arrayLikeKeys","inherited","isArray","isArguments","String","skipIndexes","isIndex","assignMergeValue","eq","assignValue","objValue","baseAssign","source","copyObject","keys","baseClone","isDeep","isFull","customizer","stack","isObject","isArr","initCloneArray","copyArray","tag","getTag","isFunc","funcTag","genTag","isBuffer","cloneBuffer","objectTag","argsTag","initCloneObject","copySymbols","cloneableTags","initCloneByTag","stacked","props","getAllKeys","subValue","baseCreate","proto","objectCreate","baseGetAllKeys","keysFunc","symbolsFunc","baseGetTag","objectToString","baseIsNative","isMasked","pattern","isFunction","reIsNative","reIsHostCtor","test","toSource","baseIsTypedArray","isObjectLike","isLength","typedArrayTags","baseKeys","isPrototype","nativeKeys","baseKeysIn","nativeKeysIn","isProto","baseMerge","srcIndex","isTypedArray","srcValue","baseMergeDeep","newValue","mergeFunc","isCommon","isArrayLikeObject","isPlainObject","toPlainObject","baseRest","start","nativeMax","arguments","otherArgs","buffer","slice","constructor","copy","cloneArrayBuffer","arrayBuffer","byteLength","Uint8Array","cloneDataView","dataView","byteOffset","cloneMap","cloneFunc","cloneRegExp","regexp","reFlags","exec","cloneSet","cloneSymbol","symbol","symbolValueOf","cloneTypedArray","typedArray","getSymbols","createAssigner","assigner","sources","guard","isIterateeCall","isKeyable","getNative","input","getPrototype","Ctor","arrayBufferTag","boolTag","dateTag","dataViewTag","float32Tag","float64Tag","int8Tag","int16Tag","int32Tag","uint8Tag","uint8ClampedTag","uint16Tag","uint32Tag","mapTag","numberTag","stringTag","regexpTag","setTag","symbolTag","MAX_SAFE_INTEGER","reIsUint","type","isArrayLike","maskSrcKey","objectProto","funcToString","other","propertyIsEnumerable","objectCtorString","keysIn","stubArray","stubFalse","arrayTag","errorTag","promiseTag","weakMapTag","reRegExpChar","freeGlobal","freeSelf","self","freeExports","nodeType","freeModule","moduleExports","freeProcess","process","nodeUtil","binding","nodeIsTypedArray","arrayProto","funcProto","coreJsData","uid","IE_PROTO","RegExp","replace","Buffer","Symbol","getPrototypeOf","create","nativeGetSymbols","getOwnPropertySymbols","nativeIsBuffer","Math","max","DataView","Promise","Set","WeakMap","dataViewCtorString","mapCtorString","promiseCtorString","setCtorString","weakMapCtorString","symbolProto","valueOf","ArrayBuffer","resolve","ctorString","merge","nextTick","draining","oldQueue","len","queue","immediate","task","scheduleDrain","Mutation","MutationObserver","WebKitMutationObserver","called","observer","element","document","createTextNode","observe","characterData","setImmediate","MessageChannel","createElement","scriptEl","onreadystatechange","parentNode","removeChild","documentElement","appendChild","setTimeout","channel","port1","onmessage","port2","postMessage","__webpack_exports__","_defineProperty","obj","writable","__WEBPACK_IMPORTED_MODULE_0_sift__","__WEBPACK_IMPORTED_MODULE_0_sift___default","__WEBPACK_IMPORTED_MODULE_1_lodash_merge__","__WEBPACK_IMPORTED_MODULE_1_lodash_merge___default","noop","expand","mapQueries","binarySearch","fn","context","queries","reduce","db","$dbsetup","Error","$bucket","state","filter","arr","docId","low","high","mid","_id","_interopDefault","ex","isBinaryObject","Blob","buff","target","targetArray","sourceArray","cloneBinaryObject","webkitSlice","clone","newObject","Date","toISOString","once","fun","getArguments","toPromise","usedCB","promise","PouchPromise$1","fulfill","reject","resp","callback","err","mesg","then","adapterFun","logApiCall","log","enabled","logArgs","origCallback","res","responseArgs","concat","_closed","_destroyed","taskqueue","isReady","addTask","failed","pick","prop","mangle","unmangle","substring","Map$1","_store","Set$1","supportsMapAndSet","getOwnPropertyDescriptor","species","identityFunction","x","formatResultForOpenRevsGet","ok","bulkGet","opts","collapseResultsAndFinish","results","perDocResults","docs","info","id","checkDone","numDone","numDocs","gotResult","docIndex","nextBatch","allRequests","upTo","min","MAX_NUM_CONCURRENT_REQUESTS","batch","processBatch","j","docIdx","docRequests","requestsById","docOpts","open_revs","request","rev","formatResult","param","error","requests","ExportedMap","isChromeApp","chrome","storage","local","hasLocalStorage","hasLocal","attachBrowserEvents","onChanged","addListener","db_name","emit","dbName","addEventListener","attachEvent","Changes","events","EventEmitter","_listeners","guardedConsole","method","console","randomNumber","maxTimeout","parseInt","ratio","random","range","defaultBackOff","explainError","status","str","PouchError","reason","message","createError","CustomPouchError","generateErrorFromResponse","UNKNOWN_ERROR","tryFilter","doc","req","msg","BAD_REQUEST","filterChange","hasFilter","query","query_params","change","filterReturn","include_docs","attachments","att","_attachments","stub","flatten","arrs","f","invalidIdError","INVALID_ID","RESERVED_ID","MISSING_ID","listenerCount","ee","parseDesignDocFunctionName","parts","split","normalizeDesignDocFunctionName","normalized","join","parseUri","parser","uri","encoded","indexOf","decodeURIComponent","qName","qParser","$0","$1","$2","upsert","diffFun","docRev","_rev","newDoc","tryAndPut","updated","put","radix","uuid","chars","out","winningRev","metadata","winningId","winningPos","winningDeleted","node","toVisit","rev_tree","tree","ids","branches","pos","deleted","traverseRevTree","revs","newCtx","ctx","sortByPos","a","b","collectLeaves","leaves","isLeaf","acc","sort","reverse","collectConflicts","win","conflicts","leaf","compactTree","revHash","rootToLeaf","paths","history","sortByPos$1","item","comparator","insertSorted","idx","pathToTree","path","numStemmed","currentLeaf","compareTree","mergeTree","in_tree1","in_tree2","tree1","tree2","merged","doMerge","dontExpand","restree","branch","t1","t2","diff","candidateParents","trees","parent","parentIdx","elements","elementsLen","el","stem","depth","maybeStem","stemmed","stemmedNode","newTree","stemmedRevs","revExists","splitRev","targetPos","targetId","getTrees","isDeleted","isLocalId","latest","historyNode","historyRev","evalFilter","scopedEval","evalView","code","tryCatchInChangeListener","Changes$2","onDestroy","cancel","complete","removeAllListeners","removeListener","on","onChange","isCancelled","bind","doChanges","processChange","changeList","style","changes","_conflicts","compare","left","right","yankError","cleanDocs","_deleted","atts","compareByIdThenRev","idCompare","aStart","_revisions","bStart","computeHeight","height","edges","prnt","from","to","edge","allDocsKeysQuery","api","skip","limit","descending","_allDocs","finalResults","all","subOpts","assign$1","optKey","total_rows","rows","doNextCompaction","_compactionQueue","catch","last_seq","_compact","shift","attachmentNameError","charAt","AbstractPouchDB","TaskQueue$1","parseAdapter","match","adapter","adapters","PouchDB$3","preferredAdapters","prefix","adapterName","localStorage","usePrefix","use_prefix","prepareForDestruction","onDestroyed","onClosed","onConstructorDestroyed","destructionListeners","delete","_destructionListeners","__opts","auto_compaction","prefixedName","backend","_adapter","debug","valid","fail","ready","setUpEventEmitter","Pouch","eventEmitter","destructListeners","toObject","parseRevisionInfo","INVALID_REV","makeRevTreeFromRevisions","revisions","revisionIds","parseDoc","newEdits","nRevNum","newRevId","revInfo","toLowerCase","_rev_tree","specialKey","reservedWords","DOC_VALIDATION","dataWords","createBlob","properties","Builder","BlobBuilder","MSBlobBuilder","MozBlobBuilder","WebKitBlobBuilder","builder","append","getBlob","binaryStringToArrayBuffer","bin","buf","charCodeAt","binStringToBluffer","binString","b64ToBluffer","b64","thisAtob","arrayBufferToBinaryString","binary","bytes","fromCharCode","readAsBinaryString","blob","FileReader","FileReaderSync","readAsArrayBuffer","reader","hasBinaryString","onloadend","blobToBinaryString","blobOrBuffer","blobToBase64","base64","thisBtoa","rawToBase64","raw","sliceBlob","blob$$1","end","appendBlob","appendString","appendBinary","binaryMd5","next","setImmediateShim","loadNextChunk","done","destroy","currentChunk","chunkSize","chunks","inputIsString","MD5_CHUNK_SIZE","ceil","Md5","stringMd5","parseBase64","BAD_ARG","preprocessString","blobType","asBinary","content_type","digest","preprocessBlob","md5","preprocessAttachment","preprocessAttachments","docInfos","docv","overallErr","docInfo","processedAttachment","recv","updateDoc","revLimit","prev","cb","writeDoc","previousWinningRev","previouslyDeleted","isRoot","inConflict","REV_CONFLICT","newRev","rev_map","newRevIsDeleted","winningRev$$1","winningRevIsDeleted","delta","rootIsMissing","processDocs","fetchedDocs","tx","overallCallback","insertDoc","resultsIdx","MISSING_DOC","checkAllDocsDone","docsDone","docsToDo","new_edits","idsToDocs","currentDoc","docWritten","nextDoc","safeJsonParse","JSON","parse","vuvuzela","safeJsonStringify","json","stringify","idbError","evt","IDB_ERROR","encodeMetadata","deletedOrLocal","seq","decodeMetadata","storedObject","decodeDoc","_doc_id_rev","lastIndexOf","readBlobData","body","asBlob","fetchAttachmentsIfNecessary","txn","fetchAttachment","attObj","objectStore","ATTACH_STORE","onsuccess","postProcessAttachments","row","attNames","compactRevs","count","deleteOrphanedAttachments","possiblyOrphanedDigests","countReq","attAndSeqStore","IDBKeyRange","bound","attStore","seqStore","BY_SEQ_STORE","ATTACH_AND_SEQ_STORE","getKey","cursor","openCursor","only","event","digestSeq","primaryKey","continue","openTransactionSafely","idb","stores","mode","transaction","idbBulkDocs","dbOpts","startTransaction","DOC_STORE","LOCAL_STORE","META_STORE","txnResult","onabort","ontimeout","oncomplete","docStore","bySeqStore","attachStore","attachAndSeqStore","metaStore","metaDoc","updateDocCountIfReady","verifyAttachments","preconditionErrored","fetchExistingDocs","onAllDocsProcessed","allDocsProcessed","idbProcessDocs","revs_limit","docCount","docCountDelta","numFetched","readMetadata","changesHandler$$1","notify","_meta","verifyAttachment","MISSING_STUB","finish","digests","filename","attErr","isUpdate","hasAttachments","writeAttachments","finishDoc","afterPutDoc","revsToDelete","metadataToStore","metaDataReq","afterPutMetadata","afterPutDocError","preventDefault","stopPropagation","getKeyReq","putReq","insertAttachmentMappings","onerror","collectResults","attachmentSaved","revpos","saveAttachment","attsAdded","attsToAdd","newAtt","docInfoError","blobSupport","runBatchedCursor","keyRange","batchSize","onBatch","onGetAll","valuesBatch","keysBatch","pseudoCursor","onGetAllKeys","continuePseudoCursor","newKeyRange","lastKey","upper","upperOpen","lowerBound","getAll","onCursor","useGetAll","onSuccess","createKeyRange","inclusiveEnd","upperBound","idbAllDocs","fetchDocAsynchronously","docIdRevIndex","allDocsInner","batchValues","batchValue","batchKeys","onResultsReady","onTxnComplete","startkey","endkey","inclusive_end","keyRangeError","checkBlobSupport","DETECT_BLOB_SUPPORT_STORE","matchedChrome","navigator","userAgent","matchedEdge","countDocs","tryCode","PouchDB","applyNext","running","enqueueTask","action","processMetadataAndWinningDoc","winningDoc","lastSeq","filtered","numResults","returnDocs","onBatchDone","winningDocs","metadatas","fetchWinningDocAndMetadata","onGetMetadata","docIdRev","docIds","docIdsToMetadata","continuous","doc_ids","ExportedSet","since","return_docs","objectStores","IdbPouch","thisCallback","init","createSchema","createObjectStore","keyPath","autoIncrement","createIndex","unique","addDeletedOrLocalIndex","createLocalStoreSchema","migrateLocalStore","localStore","seqCursor","addAttachAndSeqStore","migrateAttsAndSeqs","digestMap","migrateMetadata","decodeMetadataCompat","fetchMetadataSeq","metadataSeq","onGetMetadataSeq","instanceId","_bulkDocs","reqOpts","_get","_getAttachment","attachId","attachment","blobData","_info","updateSeq","doc_count","update_seq","idb_attachment_format","_changes","_close","close","cachedDBs","_getRevisionTree","_doCompaction","_getLocal","_putLocal","oldRev","ret","oStore","oldDoc","_removeLocal","_destroy","openReq","openReqList","indexedDB","deleteDatabase","cached","tryStorageOption","open","ADAPTER_VERSION","onupgradeneeded","migration","migrations","oldVersion","currentTarget","completeSetup","storedMetaDoc","storeMetaDocIfReady","instanceKey","onversionchange","blobSupportPromise","val","version","decodeUtf8","escape","hexToInt","charCode","parseHexUtf8","parseHexUtf16","parseHexString","encoding","quote","escapeBlob","unescapeBlob","stringifyDoc","unstringifyDoc","qMarks","num","select","selector","table","joiner","where","orderBy","compactRevs$1","deleteOrphans","seqs","sql","ATTACH_AND_SEQ_STORE$1","executeSql","digestsToCheck","nonOrphanedDigests","ATTACH_STORE$1","BY_SEQ_STORE$1","websqlError","errorNameMatch","errorName","errorReason","WSQ_ERROR","getSize","isAndroid","websqlBulkDocs","websqlChanges","_name","cnt","sqlArgs","deletedInt","insertId","dataWritten","fetchSql","attachmentErr","revsToCompact","DOC_STORE$1","metadataStr","params","websqlProcessDocs","userDocs","docInfoErrors","openDatabaseWithOpts","websql","description","openDBSafely","openDB$1","cachedResult","cachedDatabases","fetchAttachmentsIfNecessary$1","attOpts","_","WebSqlPouch$1","dbCreated","runMigration2","DOC_STORE_WINNINGSEQ_INDEX_SQL","BY_SEQ_STORE_DELETED_INDEX_SQL","runMigration3","LOCAL_STORE$1","doNext","runMigration4","updateRows","doc_id_rev","hex","doc_id","BY_SEQ_STORE_DOC_ID_REV_INDEX_SQL","runMigration5","nextPage","SELECT_DOCS","DOC_STORE_AND_BY_SEQ_JOINER","pageSize","addDigestSeq","digestSeqs","digestSeqPairs","attachAndRev","ATTACH_AND_SEQ_STORE_ATTACH_INDEX_SQL","ATTACH_AND_SEQ_STORE_SEQ_INDEX_SQL","runMigration6","runMigration7","checkEncoding","onGetInstanceId","idRequests","idCallback","onGetVersion","dbVersion","meta","META_STORE$1","attach","initSeq","initSeqArgs","ADAPTER_VERSION$1","setupDone","migrated","dbid","tasks","nextMigration","setup","fetchVersion","db_version","getMaxSeq","latest$$1","websqlOpts","POUCH_VERSION","openDBResult","readTransaction","theSeq","theDocCount","websql_encoding","latestRev","missingErr","deletedErr","totalRows","criteria","fetchChanges","selectStmt","view","reportChange","maxSeq","escaped","putLocal","rowsAffected","removeLocal","store","canOpenTestDB","openDatabase","isValidWebSQL","hasLS","localStorageKey","openedTestDB","openDB","WebSQLPouch","_opts","wrappedFetch","wrappedPromise","fetch","response","fetchRequest","options","timer","headers","Headers","fetchOptions","credentials","processData","url","timeout","fetchResponse","statusCode","clearTimeout","text","abort","xhRequest","xhr","timedout","abortReq","cleanUp","timeoutReq","onprogress","upload","XMLHttpRequest","exception","withCredentials","Accept","responseType","setRequestHeader","readyState","getResponseHeader","responseText","send","testXhr","ajax$1","hasXhr","defaultBody","ajaxCore$1","v","missing","res$2","defaultOptions","ajax","ua","isSafari","isIE","isEdge","shouldCacheBust","isBlobUrl","hasArgs","now","pool","promiseFactories","runNext","current","onError","runNextBatch","thisErr","readAttachmentsAsBlobOrBuffer","encodeDocId","encodeURIComponent","preprocessAttachments$2","hasUrlPrefix","protocol","getHost","substr","user","password","auth","username","genDBUrl","genUrl","pathDel","host","port","paramsToStr","k","HttpPouch","ajax$$1","userOpts","reqAjax","ajaxOpts","log$1","_ajax","ajaxPromise","adapterFun$$1","skipSetup","skip_setup","setupPromise","checkExists","dbUrl","encodeAttachmentId","attachmentId","nAuth","token","unescape","Authorization","uuid$$1","compact","ping","compact_running","interval","doBulkGet","doBulkGetShim","onResult","batchNum","numBatches","MAX_SIMULTANEOUS_REVS","supportsBulkGet","supportsBulkGetMap","fetchAttachments","filenames","fetchAllAttachments","docOrDocs","revs_info","remove","docOrId","optsOrRev","getAttachment","removeAttachment","putAttachment","Content-Type","_put","allDocs","start_key","end_key","paramStr","batch_size","CHANGES_BATCH_SIZE","leftToFetch","feed","heartbeat","param_name","lastFetchedSeq","aborted","xhrOpts","fetched","raw_results_length","finished","revsDiff","pad","padWith","upToLength","padding","targetLength","padLeft","collate","normalizeKey","ai","collationIndex","bi","stringCollate","arrayCollate","objectCollate","Infinity","isNaN","origKey","toJSON","indexify","numToIndexableString","toIndexableString","objKey","zero","SEP","parseNumber","originalIdx","neg","numAsString","magAsString","MAGNITUDE_DIGITS","magnitude","MIN_MAGNITUDE","ch","parseFloat","metaStack","lastMetaElement","lastElementIndex","parseIndexableString","parsedNum","parsedStr","arrayElement","objElement","ak","bk","expFormat","toExponential","magForComparison","magString","factor","abs","factorStr","toFixed","TaskQueue$2","createView","cachedViews","sourceDB","viewName","mapFun","reduceFun","temporary","viewSignature","_cachedViews","promiseForView","diffFunction","views","fullViewName","depDbs","depDbName","registerDependentDatabase","lastSeqDoc","QueryParseError","captureStackTrace","NotFoundError","BuiltInError","createBuiltInError","sum","jLen","jNum","evalFunctionWithEval","log$2","promisedCallback","callbackify","fin","finalPromiseFactory","sequentialize","promiseFactory","that","uniq","theSet","mapToKeysArray","parseViewName","isGenOne","emitError","tryMap","tryReduce","rereduce","output","sortByKeyThenValue","y","keyCompare","sliceResults","rowToDocId","readAttachmentsAsBlobOrBuffer$1","postprocessAttachments","addHttpParam","paramName","asJson","coerceInteger","integerCandidate","asNumber","Number","coerceOptions","group_level","checkPositiveInteger","number","checkQueryParseError","startkeyName","endkeyName","group","optionName","httpQuery","MAX_URL_LENGTH","keysAsString","customQuery","_query","customViewCleanup","_viewCleanup","defaultsTo","getDocsToPersist","docIdsToChangesAndEmits","getMetaDoc","defaultMetaDoc","metaDocId","getKeyValueDocs","processKeyValueDocs","kvDocsRes","kvDocs","oldKeys","indexableKeysToKeyValues","keyValue","newKeys","kvDoc","docData","saveKeyValues","seqDocId","listOfDocsToPersist","docsToPersist","bulkDocs","getQueue","persistentQueues","updateView","updateViewInQueue","mapResults","processNextBatch","currentSeq","CHANGES_BATCH_SIZE$1","createDocIdsToChangesAndEmits","createIndexableKeysToKeyValues","emittedKeyValue","complexKey","origMap","reduceView","shouldGroup","builtInReduce","groups","lvl","POSITIVE_INFINITY","last","groupKey","reduceTry","queryView","queryViewInQueue","fetchFromView","viewOpts","expectedKeys","parsedKeyAndDocId","onMapResultsReady","shouldReduce","allDocsRes","docIdsToDocs","fetchPromises","keyStart","keyEnd","httpViewCleanup","localViewCleanup","docsToViews","designDocName","viewsToStatus","ddocName","viewDBNames","statusIsGood","viewDBName","dbsToDelete","destroyPromises","queryPromised","createViewOpts","tempViewQueue","cleanup","stale","isGenOne$1","fileHasChanged","localDoc","remoteDoc","getDocAttachments","getDocAttachmentsFromTargetOrSource","src","doCheckForLocalAttachments","createBulkGetOpts","diffs","missingRevs","missingRev","getDocs","getAllDocs","bulkGetOpts","bulkGetResponse","cancelled","bulkGetInfo","resultDocs","Boolean","hasConflicts","fetchRevisionOneDocs","getRevisionOneDocs","returnResult","updateCheckpoint","checkpoint","session","returnValue","session_id","replicator","REPLICATOR","CHECKPOINT_VERSION","unshift","CHECKPOINT_HISTORY_SIZE","Checkpointer","compareReplicationLogs","srcDoc","tgtDoc","compareReplicationHistory","sourceHistory","targetHistory","S","sourceRest","T","targetRest","LOWEST_SEQ","sourceId","hasSessionId","sessionId","rest","isForbiddenError","floor","backOff","retry","back_off_function","backOffSet","current_back_off","STARTING_BACK_OFF","removeBackOffSetter","sortObjectPropertiesByKey","queryParams","generateReplicationId","filterFun","filterViewName","queryData","md5sum","replicate","initCheckpointer","checkpointer","repId","writeDocs","changedDocs","currentBatch","bulkOpts","completeReplication","errorsById","errorsNo","doc_write_failures","docs_written","errors","finishBatch","outResult","writingCheckpoint","writeCheckpoint","getChanges","onCheckpointError","getDiffs","getBatchDocs","got","docs_read","startNextBatch","batches","processPendingBatch","abortReplication","pendingBatch","changesOpts","live","changesCompleted","replicationCompleted","fatalError","end_time","onChangesComplete","changesPending","onChangesError","abortChanges","batches_limit","_abortChanges","startChanges","getCheckpoint","start_time","_addedListeners","Replication","toPouch","PouchConstructor","replicateWrapper","replicateRet","srcPouch","targetPouch","sync$1","Sync","pullChange","direction","pushChange","pushDenied","pullDenied","pushPaused","pullPaused","pushActive","pullActive","removeAll","isChange","isDenied","isPaused","isActive","removed","addOneListener","listener","listeners","canceled","optsPush","optsPull","pull","success","replication","sync","lie","inherits","mangled","setItem","getItem","eventFunction","inprogress","notifyLocalWindows","assign","nextSource","nextKey","MISSING_BULK_DOCS","QUERY_PARSE_ERROR","NOT_AN_OBJECT","hasName","filterChanges","newPromise","ddoc","filterName","filters","post","createAttachment","prevrevpos","was_delete","addToMissing","revId","processDoc","missingForId","missingObj","compactDocument","maxHeight","revTree","candidates","promises","onComplete","finishOpenRevs","existing","splittedRev","revNo","currentPath","hashIndex","hashFoundAtRevPos","indexOfRev","howMany","_revs_info","TypeError","incompatibleOpt","_type","attachmentError","dependentDb","dependentDbs","depDB","destroyDb","deletedMap","trueName","execute","addToPreferredAdapters","plugin","defaults","defaultOpts","PouchAlt","__defaults","atob","btoa","platform","IDBPouch","WebSqlPouch","HttpPouch$1","_sum","_count","_stats","sumsqr","_sumsqr","viewCleanup","mapreduce","updateTarget","updateSource","readOnlySource","comparisons","targetDoc","sourceDoc","1","_readyCalled","argsArray","useColors","firebug","formatArgs","namespace","humanize","color","lastC","save","namespaces","removeItem","load","NODE_ENV","DEBUG","localstorage","colors","formatters","enable","selectColor","createDebug","curr","ms","prevTime","coerce","format","formatter","logFn","skips","names","disable","default","_events","_maxListeners","isNumber","isUndefined","defaultMaxListeners","setMaxListeners","er","handler","newListener","warned","trace","fired","list","position","evlistener","emitter","ctor","superCtor","super_","TempCtor","INTERNAL","resolver","PENDING","outcome","safelyResolveThenable","QueueItem","onFulfilled","onRejected","callFulfilled","otherCallFulfilled","callRejected","otherCallRejected","unwrap","handlers","getThen","thenable","tryToUnwrap","tryCatch","iterable","allResolver","resolveFromAll","outValue","resolved","race","REJECTED","FULFILLED","h","fmtShort","round","fmtLong","plural","long","defaultSetTimout","defaultClearTimeout","runTimeout","cachedSetTimeout","runClearTimeout","marker","cachedClearTimeout","cleanUpNextTick","currentQueue","queueIndex","drainQueue","run","Item","title","browser","env","argv","versions","off","cwd","chdir","dir","umask","hasProp","scope","comparable","getTime","or","validator","and","validate","search","createValidator","nestedValidator","findValues","nv","keypath","createNestedValidator","$eq","validators","operator","prepare","$and","createRootValidator","sift","$ne","$or","$gt","$gte","$lt","$lte","$mod","$in","$nin","$not","$type","$all","$size","$nor","$regex","$where","$elemMatch","$exists","$options","use","md5cycle","md5blk","md5blks","md5blk_array","md51","tail","tmp","lo","hi","md51_array","subarray","rhex","hex_chr","toUtf8","utf8Str2ArrayBuffer","returnUInt8Array","arrayBuffer2Utf8Str","concatenateArrayBuffers","first","second","hexToBinaryString","SparkMD5","reset","add32","lsw","msw","clamp","begin","contents","_buff","_length","_hash","_finish","getState","setState","hashBinary","content","arrayPrefix","objPrefix","numChar","parsedString","lastCh","numConsecutiveSlashes","webpackPolyfill","deprecate","children","_classCallCheck","instance","Constructor","__WEBPACK_IMPORTED_MODULE_0_pouchdb_browser__","__WEBPACK_IMPORTED_MODULE_0_pouchdb_browser___default","__WEBPACK_IMPORTED_MODULE_2__utils__","_createClass","defineProperties","descriptor","protoProps","staticProps","Vue","Bucket","_this","schema","ignoredKeys","_config","config","_dbs","_watch","_state","actions","plugins","dbname","_initDB","docID","remote","_this2","remoteOnly","_initChanges","_this3","dbChanges","_upsert","onChanges","onPaused","onActive","onDenied","_this4","install","$Vue","_this5","dbsetup","bucketInit","bucket","defineReactive","dbDestroy","closedb","util","usesInit","_lifecycleHooks","mixin","created","beforeDestroy","beforeCreate","activated","deactivated","_init"],"mappings":"CAAA,SAAAA,EAAAC,GACA,gBAAAC,UAAA,gBAAAC,QACAA,OAAAD,QAAAD,IACA,kBAAAG,gBAAAC,IACAD,OAAA,kBAAAH,GACA,gBAAAC,SACAA,QAAA,gBAAAD,IAEAD,EAAA,gBAAAC,KACCK,KAAA,WACD,MCAgB,UAAUC,GCN1B,QAAAC,GAAAC,GAGA,GAAAC,EAAAD,GACA,MAAAC,GAAAD,GAAAP,OAGA,IAAAC,GAAAO,EAAAD,IACAE,EAAAF,EACAG,GAAA,EACAV,WAUA,OANAK,GAAAE,GAAAI,KAAAV,EAAAD,QAAAC,IAAAD,QAAAM,GAGAL,EAAAS,GAAA,EAGAT,EAAAD,QAvBA,GAAAQ,KA+DA,OAnCAF,GAAAM,EAAAP,EAGAC,EAAAO,EAAAL,EAGAF,EAAAG,EAAA,SAAAK,GAA2C,MAAAA,IAG3CR,EAAAS,EAAA,SAAAf,EAAAgB,EAAAC,GACAX,EAAAY,EAAAlB,EAAAgB,IACAG,OAAAC,eAAApB,EAAAgB,GACAK,cAAA,EACAC,YAAA,EACAC,IAAAN,KAMAX,EAAAkB,EAAA,SAAAvB,GACA,GAAAgB,GAAAhB,KAAAwB,WACA,WAA2B,MAAAxB,GAAA,SAC3B,WAAiC,MAAAA,GAEjC,OADAK,GAAAS,EAAAE,EAAA,IAAAA,GACAA,GAIAX,EAAAY,EAAA,SAAAQ,EAAAC,GAAsD,MAAAR,QAAAS,UAAAC,eAAAlB,KAAAe,EAAAC,IAGtDrB,EAAAwB,EAAA,GAGAxB,IAAAyB,EAAA,MDgBM,SAAU9B,EAAQD,GEhFxB,GAAAgC,EAGAA,GAAA,WACA,MAAA5B,QAGA,KAEA4B,KAAAC,SAAA,qBAAAC,MAAA,QACC,MAAAC,GAED,gBAAAC,UACAJ,EAAAI,QAOAnC,EAAAD,QAAAgC,GFuFM,SAAU/B,EAAQD,EAASM,IG3GjC,SAAA+B,EAAApC,GAsIA,QAAAqC,GAAAC,EAAAC,GAGA,MADAD,GAAAE,IAAAD,EAAA,GAAAA,EAAA,IACAD,EAWA,QAAAG,GAAAD,EAAA3B,GAGA,MADA2B,GAAAE,IAAA7B,GACA2B,EAaA,QAAAG,GAAAC,EAAAC,EAAAC,GACA,OAAAA,EAAAC,QACA,aAAAH,GAAAlC,KAAAmC,EACA,cAAAD,GAAAlC,KAAAmC,EAAAC,EAAA,GACA,cAAAF,GAAAlC,KAAAmC,EAAAC,EAAA,GAAAA,EAAA,GACA,cAAAF,GAAAlC,KAAAmC,EAAAC,EAAA,GAAAA,EAAA,GAAAA,EAAA,IAEA,MAAAF,GAAAD,MAAAE,EAAAC,GAYA,QAAAE,GAAAC,EAAAC,GAIA,IAHA,GAAAC,IAAA,EACAJ,EAAAE,IAAAF,OAAA,IAEAI,EAAAJ,GACAG,EAAAD,EAAAE,KAAAF,MAAA,IAIA,MAAAA,GAWA,QAAAG,GAAAH,EAAAI,GAKA,IAJA,GAAAF,IAAA,EACAJ,EAAAM,EAAAN,OACAO,EAAAL,EAAAF,SAEAI,EAAAJ,GACAE,EAAAK,EAAAH,GAAAE,EAAAF,EAEA,OAAAF,GAeA,QAAAM,GAAAN,EAAAC,EAAAM,EAAAC,GACA,GAAAN,IAAA,EACAJ,EAAAE,IAAAF,OAAA,CAKA,KAHAU,GAAAV,IACAS,EAAAP,IAAAE,MAEAA,EAAAJ,GACAS,EAAAN,EAAAM,EAAAP,EAAAE,KAAAF,EAEA,OAAAO,GAYA,QAAAE,GAAAnC,EAAA2B,GAIA,IAHA,GAAAC,IAAA,EACAQ,EAAAC,MAAArC,KAEA4B,EAAA5B,GACAoC,EAAAR,GAAAD,EAAAC,EAEA,OAAAQ,GAUA,QAAAE,GAAAjB,GACA,gBAAA/B,GACA,MAAA+B,GAAA/B,IAYA,QAAAiD,GAAArC,EAAAsC,GACA,aAAAtC,EAAAuC,OAAAvC,EAAAsC,GAUA,QAAAE,GAAApD,GAGA,GAAA8C,IAAA,CACA,UAAA9C,GAAA,kBAAAA,GAAAqD,SACA,IACAP,KAAA9C,EAAA,IACK,MAAAqB,IAEL,MAAAyB,GAUA,QAAAQ,GAAA7B,GACA,GAAAa,IAAA,EACAQ,EAAAC,MAAAtB,EAAA8B,KAKA,OAHA9B,GAAA+B,QAAA,SAAAxD,EAAAkD,GACAJ,IAAAR,IAAAY,EAAAlD,KAEA8C,EAWA,QAAAW,GAAA1B,EAAA2B,GACA,gBAAAC,GACA,MAAA5B,GAAA2B,EAAAC,KAWA,QAAAC,GAAAjC,GACA,GAAAW,IAAA,EACAQ,EAAAC,MAAApB,EAAA4B,KAKA,OAHA5B,GAAA6B,QAAA,SAAAxD,GACA8C,IAAAR,GAAAtC,IAEA8C,EAgFA,QAAAe,GAAAC,GACA,GAAAxB,IAAA,EACAJ,EAAA4B,IAAA5B,OAAA,CAGA,KADA5C,KAAAyE,UACAzB,EAAAJ,GAAA,CACA,GAAA8B,GAAAF,EAAAxB,EACAhD,MAAAqC,IAAAqC,EAAA,GAAAA,EAAA,KAWA,QAAAC,KACA3E,KAAA4E,SAAAC,MAAA,SAaA,QAAAC,GAAAlB,GACA,MAAA5D,MAAA+E,IAAAnB,UAAA5D,MAAA4E,SAAAhB,GAYA,QAAAoB,GAAApB,GACA,GAAAqB,GAAAjF,KAAA4E,QACA,IAAAC,GAAA,CACA,GAAArB,GAAAyB,EAAArB,EACA,OAAAJ,KAAA0B,GAAArB,OAAAL,EAEA,MAAA/B,IAAAlB,KAAA0E,EAAArB,GAAAqB,EAAArB,GAAAC,OAYA,QAAAsB,GAAAvB,GACA,GAAAqB,GAAAjF,KAAA4E,QACA,OAAAC,IAAAhB,SAAAoB,EAAArB,GAAAnC,GAAAlB,KAAA0E,EAAArB,GAaA,QAAAwB,GAAAxB,EAAAlD,GACA,GAAAuE,GAAAjF,KAAA4E,QAEA,OADAK,GAAArB,GAAAiB,IAAAhB,SAAAnD,EAAAwE,GAAAxE,EACAV,KAiBA,QAAAqF,GAAAb,GACA,GAAAxB,IAAA,EACAJ,EAAA4B,IAAA5B,OAAA,CAGA,KADA5C,KAAAyE,UACAzB,EAAAJ,GAAA,CACA,GAAA8B,GAAAF,EAAAxB,EACAhD,MAAAqC,IAAAqC,EAAA,GAAAA,EAAA,KAWA,QAAAY,KACAtF,KAAA4E,YAYA,QAAAW,GAAA3B,GACA,GAAAqB,GAAAjF,KAAA4E,SACA5B,EAAAwC,EAAAP,EAAArB,EAEA,IAAAZ,EAAA,EACA,QAEA,IAAAyC,GAAAR,EAAArC,OAAA,CAMA,OALAI,IAAAyC,EACAR,EAAAS,MAEAC,GAAApF,KAAA0E,EAAAjC,EAAA,IAEA,EAYA,QAAA4C,GAAAhC,GACA,GAAAqB,GAAAjF,KAAA4E,SACA5B,EAAAwC,EAAAP,EAAArB,EAEA,OAAAZ,GAAA,EAAAa,OAAAoB,EAAAjC,GAAA,GAYA,QAAA6C,GAAAjC,GACA,MAAA4B,GAAAxF,KAAA4E,SAAAhB,IAAA,EAaA,QAAAkC,GAAAlC,EAAAlD,GACA,GAAAuE,GAAAjF,KAAA4E,SACA5B,EAAAwC,EAAAP,EAAArB,EAOA,OALAZ,GAAA,EACAiC,EAAAc,MAAAnC,EAAAlD,IAEAuE,EAAAjC,GAAA,GAAAtC,EAEAV,KAiBA,QAAAgG,GAAAxB,GACA,GAAAxB,IAAA,EACAJ,EAAA4B,IAAA5B,OAAA,CAGA,KADA5C,KAAAyE,UACAzB,EAAAJ,GAAA,CACA,GAAA8B,GAAAF,EAAAxB,EACAhD,MAAAqC,IAAAqC,EAAA,GAAAA,EAAA,KAWA,QAAAuB,KACAjG,KAAA4E,UACAsB,KAAA,GAAA3B,GACApC,IAAA,IAAAgE,IAAAd,GACAe,OAAA,GAAA7B,IAaA,QAAA8B,GAAAzC,GACA,MAAA0C,IAAAtG,KAAA4D,GAAA,OAAAA,GAYA,QAAA2C,GAAA3C,GACA,MAAA0C,IAAAtG,KAAA4D,GAAAzC,IAAAyC,GAYA,QAAA4C,GAAA5C,GACA,MAAA0C,IAAAtG,KAAA4D,GAAAmB,IAAAnB,GAaA,QAAA6C,GAAA7C,EAAAlD,GAEA,MADA4F,IAAAtG,KAAA4D,GAAAvB,IAAAuB,EAAAlD,GACAV,KAiBA,QAAA0G,GAAAlC,GACAxE,KAAA4E,SAAA,GAAAS,GAAAb,GAUA,QAAAmC,KACA3G,KAAA4E,SAAA,GAAAS,GAYA,QAAAuB,GAAAhD,GACA,MAAA5D,MAAA4E,SAAA,OAAAhB,GAYA,QAAAiD,GAAAjD,GACA,MAAA5D,MAAA4E,SAAAzD,IAAAyC,GAYA,QAAAkD,GAAAlD,GACA,MAAA5D,MAAA4E,SAAAG,IAAAnB,GAaA,QAAAmD,GAAAnD,EAAAlD,GACA,GAAAsG,GAAAhH,KAAA4E,QACA,IAAAoC,YAAA3B,GAAA,CACA,GAAA4B,GAAAD,EAAApC,QACA,KAAAuB,IAAAc,EAAArE,OAAAsE,GAAA,EAEA,MADAD,GAAAlB,MAAAnC,EAAAlD,IACAV,IAEAgH,GAAAhH,KAAA4E,SAAA,GAAAoB,GAAAiB,GAGA,MADAD,GAAA3E,IAAAuB,EAAAlD,GACAV,KAkBA,QAAAmH,GAAAzG,EAAA0G,GAGA,GAAA5D,GAAA6D,GAAA3G,IAAA4G,GAAA5G,GACA6C,EAAA7C,EAAAkC,OAAA2E,WAGA3E,EAAAY,EAAAZ,OACA4E,IAAA5E,CAEA,QAAAgB,KAAAlD,IACA0G,IAAA3F,GAAAlB,KAAAG,EAAAkD,IACA4D,IAAA,UAAA5D,GAAA6D,GAAA7D,EAAAhB,KACAY,EAAAuC,KAAAnC,EAGA,OAAAJ,GAYA,QAAAkE,GAAApG,EAAAsC,EAAAlD,IACAmD,SAAAnD,GAAAiH,GAAArG,EAAAsC,GAAAlD,MACA,gBAAAkD,IAAAC,SAAAnD,GAAAkD,IAAAtC,MACAA,EAAAsC,GAAAlD,GAcA,QAAAkH,GAAAtG,EAAAsC,EAAAlD,GACA,GAAAmH,GAAAvG,EAAAsC,EACAnC,IAAAlB,KAAAe,EAAAsC,IAAA+D,GAAAE,EAAAnH,KACAmD,SAAAnD,GAAAkD,IAAAtC,MACAA,EAAAsC,GAAAlD,GAYA,QAAA8E,GAAA1C,EAAAc,GAEA,IADA,GAAAhB,GAAAE,EAAAF,OACAA,KACA,GAAA+E,GAAA7E,EAAAF,GAAA,GAAAgB,GACA,MAAAhB,EAGA,UAYA,QAAAkF,GAAAxG,EAAAyG,GACA,MAAAzG,IAAA0G,GAAAD,EAAAE,GAAAF,GAAAzG,GAiBA,QAAA4G,GAAAxH,EAAAyH,EAAAC,EAAAC,EAAAzE,EAAAtC,EAAAgH,GACA,GAAA9E,EAIA,IAHA6E,IACA7E,EAAAlC,EAAA+G,EAAA3H,EAAAkD,EAAAtC,EAAAgH,GAAAD,EAAA3H,IAEAmD,SAAAL,EACA,MAAAA,EAEA,KAAA+E,GAAA7H,GACA,MAAAA,EAEA,IAAA8H,GAAAnB,GAAA3G,EACA,IAAA8H,GAEA,GADAhF,EAAAiF,GAAA/H,IACAyH,EACA,MAAAO,IAAAhI,EAAA8C,OAEG,CACH,GAAAmF,GAAAC,GAAAlI,GACAmI,EAAAF,GAAAG,IAAAH,GAAAI,EAEA,IAAAC,GAAAtI,GACA,MAAAuI,IAAAvI,EAAAyH,EAEA,IAAAQ,GAAAO,IAAAP,GAAAQ,IAAAN,IAAAvH,EAAA,CACA,GAAAwC,EAAApD,GACA,MAAAY,GAAAZ,IAGA,IADA8C,EAAA4F,GAAAP,KAA0CnI,IAC1CyH,EACA,MAAAkB,IAAA3I,EAAAoH,EAAAtE,EAAA9C,QAEK,CACL,IAAA4I,GAAAX,GACA,MAAArH,GAAAZ,IAEA8C,GAAA+F,GAAA7I,EAAAiI,EAAAT,EAAAC,IAIAG,MAAA,GAAA5B,GACA,IAAA8C,GAAAlB,EAAAnH,IAAAT,EACA,IAAA8I,EACA,MAAAA,EAIA,IAFAlB,EAAAjG,IAAA3B,EAAA8C,IAEAgF,EACA,GAAAiB,GAAArB,EAAAsB,GAAAhJ,GAAAuH,GAAAvH,EAUA,OARAmC,GAAA4G,GAAA/I,EAAA,SAAAiJ,EAAA/F,GACA6F,IACA7F,EAAA+F,EACAA,EAAAjJ,EAAAkD,IAGAgE,EAAApE,EAAAI,EAAAsE,EAAAyB,EAAAxB,EAAAC,EAAAC,EAAAzE,EAAAlD,EAAA4H,MAEA9E,EAWA,QAAAoG,GAAAC,GACA,MAAAtB,IAAAsB,GAAAC,GAAAD,MAcA,QAAAE,GAAAzI,EAAA0I,EAAAC,GACA,GAAAzG,GAAAwG,EAAA1I,EACA,OAAA+F,IAAA/F,GAAAkC,EAAAP,EAAAO,EAAAyG,EAAA3I,IAUA,QAAA4I,GAAAxJ,GACA,MAAAyJ,IAAA5J,KAAAG,GAWA,QAAA0J,GAAA1J,GACA,IAAA6H,GAAA7H,IAAA2J,GAAA3J,GACA,QAEA,IAAA4J,GAAAC,GAAA7J,IAAAoD,EAAApD,GAAA8J,GAAAC,EACA,OAAAH,GAAAI,KAAAC,GAAAjK,IAUA,QAAAkK,GAAAlK,GACA,MAAAmK,IAAAnK,IACAoK,GAAApK,EAAAkC,WAAAmI,GAAAZ,GAAA5J,KAAAG,IAUA,QAAAsK,GAAA1J,GACA,IAAA2J,GAAA3J,GACA,MAAA4J,IAAA5J,EAEA,IAAAkC,KACA,QAAAI,KAAA7C,QAAAO,GACAG,GAAAlB,KAAAe,EAAAsC,IAAA,eAAAA,GACAJ,EAAAuC,KAAAnC,EAGA,OAAAJ,GAUA,QAAA2H,GAAA7J,GACA,IAAAiH,GAAAjH,GACA,MAAA8J,IAAA9J,EAEA,IAAA+J,GAAAJ,GAAA3J,GACAkC,IAEA,QAAAI,KAAAtC,IACA,eAAAsC,IAAAyH,GAAA5J,GAAAlB,KAAAe,EAAAsC,KACAJ,EAAAuC,KAAAnC,EAGA,OAAAJ,GAcA,QAAA8H,GAAAhK,EAAAyG,EAAAwD,EAAAlD,EAAAC,GACA,GAAAhH,IAAAyG,EAAA,CAGA,IAAAV,GAAAU,KAAAyD,GAAAzD,GACA,GAAA0B,GAAA0B,EAAApD,EAEAlF,GAAA4G,GAAA1B,EAAA,SAAA0D,EAAA7H,GAKA,GAJA6F,IACA7F,EAAA6H,EACAA,EAAA1D,EAAAnE,IAEA2E,GAAAkD,GACAnD,MAAA,GAAA5B,IACAgF,GAAApK,EAAAyG,EAAAnE,EAAA2H,EAAAD,EAAAjD,EAAAC,OAEA,CACA,GAAAqD,GAAAtD,EACAA,EAAA/G,EAAAsC,GAAA6H,EAAA7H,EAAA,GAAAtC,EAAAyG,EAAAO,GACAzE,MAEAA,UAAA8H,IACAA,EAAAF,GAEA/D,EAAApG,EAAAsC,EAAA+H,OAoBA,QAAAD,IAAApK,EAAAyG,EAAAnE,EAAA2H,EAAAK,EAAAvD,EAAAC,GACA,GAAAT,GAAAvG,EAAAsC,GACA6H,EAAA1D,EAAAnE,GACA4F,EAAAlB,EAAAnH,IAAAsK,EAEA,IAAAjC,EAEA,WADA9B,GAAApG,EAAAsC,EAAA4F,EAGA,IAAAmC,GAAAtD,EACAA,EAAAR,EAAA4D,EAAA7H,EAAA,GAAAtC,EAAAyG,EAAAO,GACAzE,OAEAgI,EAAAhI,SAAA8H,CAEAE,KACAF,EAAAF,EACApE,GAAAoE,IAAAD,GAAAC,GACApE,GAAAQ,GACA8D,EAAA9D,EAEAiE,GAAAjE,GACA8D,EAAAjD,GAAAb,IAGAgE,GAAA,EACAF,EAAAzD,EAAAuD,GAAA,IAGAM,GAAAN,IAAAnE,GAAAmE,GACAnE,GAAAO,GACA8D,EAAAK,GAAAnE,IAEAU,GAAAV,IAAA0D,GAAAhB,GAAA1C,IACAgE,GAAA,EACAF,EAAAzD,EAAAuD,GAAA,IAGAE,EAAA9D,EAIAgE,GAAA,GAGAA,IAEAvD,EAAAjG,IAAAoJ,EAAAE,GACAC,EAAAD,EAAAF,EAAAF,EAAAlD,EAAAC,GACAA,EAAA,OAAAmD,IAEA/D,EAAApG,EAAAsC,EAAA+H,GAWA,QAAAM,IAAAxJ,EAAAyJ,GAEA,MADAA,GAAAC,GAAAtI,SAAAqI,EAAAzJ,EAAAG,OAAA,EAAAsJ,EAAA,GACA,WAMA,IALA,GAAAvJ,GAAAyJ,UACApJ,GAAA,EACAJ,EAAAuJ,GAAAxJ,EAAAC,OAAAsJ,EAAA,GACApJ,EAAAW,MAAAb,KAEAI,EAAAJ,GACAE,EAAAE,GAAAL,EAAAuJ,EAAAlJ,EAEAA,IAAA,CAEA,KADA,GAAAqJ,GAAA5I,MAAAyI,EAAA,KACAlJ,EAAAkJ,GACAG,EAAArJ,GAAAL,EAAAK,EAGA,OADAqJ,GAAAH,GAAApJ,EACAN,EAAAC,EAAAzC,KAAAqM,IAYA,QAAApD,IAAAqD,EAAAnE,GACA,GAAAA,EACA,MAAAmE,GAAAC,OAEA,IAAA/I,GAAA,GAAA8I,GAAAE,YAAAF,EAAA1J,OAEA,OADA0J,GAAAG,KAAAjJ,GACAA,EAUA,QAAAkJ,IAAAC,GACA,GAAAnJ,GAAA,GAAAmJ,GAAAH,YAAAG,EAAAC,WAEA,OADA,IAAAC,IAAArJ,GAAAnB,IAAA,GAAAwK,IAAAF,IACAnJ,EAWA,QAAAsJ,IAAAC,EAAA5E,GACA,GAAAmE,GAAAnE,EAAAuE,GAAAK,EAAAT,QAAAS,EAAAT,MACA,WAAAS,GAAAP,YAAAF,EAAAS,EAAAC,WAAAD,EAAAH,YAYA,QAAAK,IAAA9K,EAAAgG,EAAA+E,GACA,GAAApK,GAAAqF,EAAA+E,EAAAlJ,EAAA7B,IAAA,GAAA6B,EAAA7B,EACA,OAAAiB,GAAAN,EAAAZ,EAAA,GAAAC,GAAAqK,aAUA,QAAAW,IAAAC,GACA,GAAA5J,GAAA,GAAA4J,GAAAZ,YAAAY,EAAArF,OAAAsF,GAAAC,KAAAF,GAEA,OADA5J,GAAAiC,UAAA2H,EAAA3H,UACAjC,EAYA,QAAA+J,IAAAlL,EAAA8F,EAAA+E,GACA,GAAApK,GAAAqF,EAAA+E,EAAA5I,EAAAjC,IAAA,GAAAiC,EAAAjC,EACA,OAAAe,GAAAN,EAAAR,EAAA,GAAAD,GAAAmK,aAUA,QAAAgB,IAAAC,GACA,MAAAC,IAAA3M,OAAA2M,GAAAnN,KAAAkN,OAWA,QAAAE,IAAAC,EAAAzF,GACA,GAAAmE,GAAAnE,EAAAuE,GAAAkB,EAAAtB,QAAAsB,EAAAtB,MACA,WAAAsB,GAAApB,YAAAF,EAAAsB,EAAAZ,WAAAY,EAAAhL,QAWA,QAAA8F,IAAAX,EAAAjF,GACA,GAAAE,IAAA,EACAJ,EAAAmF,EAAAnF,MAGA,KADAE,MAAAW,MAAAb,MACAI,EAAAJ,GACAE,EAAAE,GAAA+E,EAAA/E,EAEA,OAAAF,GAaA,QAAAkF,IAAAD,EAAA0B,EAAAnI,EAAA+G,GACA/G,SAKA,KAHA,GAAA0B,IAAA,EACAJ,EAAA6G,EAAA7G,SAEAI,EAAAJ,GAAA,CACA,GAAAgB,GAAA6F,EAAAzG,GAEA2I,EAAAtD,EACAA,EAAA/G,EAAAsC,GAAAmE,EAAAnE,KAAAtC,EAAAyG,GACAlE,MAEA+D,GAAAtG,EAAAsC,EAAAC,SAAA8H,EAAA5D,EAAAnE,GAAA+H,GAEA,MAAArK,GAWA,QAAA+H,IAAAtB,EAAAzG,GACA,MAAA0G,IAAAD,EAAA8F,GAAA9F,GAAAzG,GAUA,QAAAwM,IAAAC,GACA,MAAA9B,IAAA,SAAA3K,EAAA0M,GACA,GAAAhL,IAAA,EACAJ,EAAAoL,EAAApL,OACAyF,EAAAzF,EAAA,EAAAoL,EAAApL,EAAA,GAAAiB,OACAoK,EAAArL,EAAA,EAAAoL,EAAA,GAAAnK,MAWA,KATAwE,EAAA0F,EAAAnL,OAAA,qBAAAyF,IACAzF,IAAAyF,GACAxE,OAEAoK,GAAAC,GAAAF,EAAA,GAAAA,EAAA,GAAAC,KACA5F,EAAAzF,EAAA,EAAAiB,OAAAwE,EACAzF,EAAA,GAEAtB,EAAAP,OAAAO,KACA0B,EAAAJ,GAAA,CACA,GAAAmF,GAAAiG,EAAAhL,EACA+E,IACAgG,EAAAzM,EAAAyG,EAAA/E,EAAAqF,GAGA,MAAA/G,KAWA,QAAAoI,IAAApI,GACA,MAAAyI,GAAAzI,EAAA2G,GAAA4F,IAWA,QAAAvH,IAAAnE,EAAAyB,GACA,GAAAqB,GAAA9C,EAAAyC,QACA,OAAAuJ,IAAAvK,GACAqB,EAAA,gBAAArB,GAAA,iBACAqB,EAAA9C,IAWA,QAAAiM,IAAA9M,EAAAsC,GACA,GAAAlD,GAAAiD,EAAArC,EAAAsC,EACA,OAAAwG,GAAA1J,KAAAmD,OAqDA,QAAA4E,IAAA3F,GACA,GAAAF,GAAAE,EAAAF,OACAY,EAAAV,EAAA0J,YAAA5J,EAOA,OAJAA,IAAA,gBAAAE,GAAA,IAAArB,GAAAlB,KAAAuC,EAAA,WACAU,EAAAR,MAAAF,EAAAE,MACAQ,EAAA6K,MAAAvL,EAAAuL,OAEA7K,EAUA,QAAA4F,IAAA9H,GACA,wBAAAA,GAAAkL,aAAAvB,GAAA3J,MACAsI,EAAA0E,GAAAhN,IAiBA,QAAAiI,IAAAjI,EAAAqH,EAAAuE,EAAA/E,GACA,GAAAoG,GAAAjN,EAAAkL,WACA,QAAA7D,GACA,IAAA6F,IACA,MAAA9B,IAAApL,EAEA,KAAAmN,IACA,IAAAC,IACA,UAAAH,IAAAjN,EAEA,KAAAqN,IACA,MAAA7B,IAAAxL,EAAA6G,EAEA,KAAAyG,IAAA,IAAAC,IACA,IAAAC,IAAA,IAAAC,IAAA,IAAAC,IACA,IAAAC,IAAA,IAAAC,IAAA,IAAAC,IAAA,IAAAC,IACA,MAAAzB,IAAArM,EAAA6G,EAEA,KAAAkH,IACA,MAAApC,IAAA3L,EAAA6G,EAAA+E,EAEA,KAAAoC,IACA,IAAAC,IACA,UAAAhB,GAAAjN,EAEA,KAAAkO,IACA,MAAArC,IAAA7L,EAEA,KAAAmO,IACA,MAAAlC,IAAAjM,EAAA6G,EAAA+E,EAEA,KAAAwC,IACA,MAAAlC,IAAAlM,IAYA,QAAAmG,IAAA/G,EAAAkC,GAEA,MADAA,GAAA,MAAAA,EAAA+M,GAAA/M,IACAA,IACA,gBAAAlC,IAAAkP,GAAAlF,KAAAhK,KACAA,GAAA,GAAAA,EAAA,MAAAA,EAAAkC,EAaA,QAAAsL,IAAAxN,EAAAsC,EAAA1B,GACA,IAAAiH,GAAAjH,GACA,QAEA,IAAAuO,SAAA7M,EACA,oBAAA6M,EACAC,GAAAxO,IAAAmG,GAAAzE,EAAA1B,EAAAsB,QACA,UAAAiN,GAAA7M,IAAA1B,KAEAqG,GAAArG,EAAA0B,GAAAtC,GAYA,QAAAyN,IAAAzN,GACA,GAAAmP,SAAAnP,EACA,iBAAAmP,GAAA,UAAAA,GAAA,UAAAA,GAAA,WAAAA,EACA,cAAAnP,EACA,OAAAA,EAUA,QAAA2J,IAAA5H,GACA,QAAAsN,SAAAtN,GAUA,QAAAwI,IAAAvK,GACA,GAAA6N,GAAA7N,KAAA8L,YACA3C,EAAA,kBAAA0E,MAAA/M,WAAAwO,EAEA,OAAAtP,KAAAmJ,EAYA,QAAAuB,IAAA9J,GACA,GAAAkC,KACA,UAAAlC,EACA,OAAAsC,KAAA7C,QAAAO,GACAkC,EAAAuC,KAAAnC,EAGA,OAAAJ,GAUA,QAAAmH,IAAAlI,GACA,SAAAA,EAAA,CACA,IACA,MAAAwN,IAAA1P,KAAAkC,GACK,MAAAV,IACL,IACA,MAAAU,GAAA,GACK,MAAAV,KAEL,SAmCA,QAAA4F,IAAAjH,EAAAwP,GACA,MAAAxP,KAAAwP,GAAAxP,OAAAwP,MAqBA,QAAA5I,IAAA5G,GAEA,MAAAoL,IAAApL,IAAAe,GAAAlB,KAAAG,EAAA,aACAyP,GAAA5P,KAAAG,EAAA,WAAAyJ,GAAA5J,KAAAG,IAAAyI,IAqDA,QAAA2G,IAAApP,GACA,aAAAA,GAAAoK,GAAApK,EAAAkC,UAAA2H,GAAA7J,GA4BA,QAAAoL,IAAApL,GACA,MAAAmK,IAAAnK,IAAAoP,GAAApP,GAuCA,QAAA6J,IAAA7J,GAGA,GAAAiI,GAAAJ,GAAA7H,GAAAyJ,GAAA5J,KAAAG,GAAA,EACA,OAAAiI,IAAAG,IAAAH,GAAAI,GA6BA,QAAA+B,IAAApK,GACA,sBAAAA,IACAA,GAAA,GAAAA,EAAA,MAAAA,GAAAiP,GA4BA,QAAApH,IAAA7H,GACA,GAAAmP,SAAAnP,EACA,SAAAA,IAAA,UAAAmP,GAAA,YAAAA,GA2BA,QAAAhF,IAAAnK,GACA,QAAAA,GAAA,gBAAAA,GA+BA,QAAAqL,IAAArL,GACA,IAAAmK,GAAAnK,IACAyJ,GAAA5J,KAAAG,IAAAwI,IAAApF,EAAApD,GACA,QAEA,IAAAmJ,GAAAyE,GAAA5N,EACA,WAAAmJ,EACA,QAEA,IAAA0E,GAAA9M,GAAAlB,KAAAsJ,EAAA,gBAAAA,EAAA2C,WACA,yBAAA+B,IACAA,gBAAA0B,GAAA1P,KAAAgO,IAAA6B,GA8CA,QAAApE,IAAAtL,GACA,MAAAsH,IAAAtH,EAAA2P,GAAA3P,IA+BA,QAAAuH,IAAA3G,GACA,MAAAwO,IAAAxO,GAAA6F,EAAA7F,GAAA0J,EAAA1J,GA0BA,QAAA+O,IAAA/O,GACA,MAAAwO,IAAAxO,GAAA6F,EAAA7F,GAAA,GAAA6J,EAAA7J,GAwDA,QAAAgP,MACA,SAgBA,QAAAC,MACA,SAjpEA,GAAArJ,IAAA,IAGAhC,GAAA,4BAGAyK,GAAA,iBAGAxG,GAAA,qBACAqH,GAAA,iBACA/B,GAAA,mBACAC,GAAA,gBACA+B,GAAA,iBACA3H,GAAA,oBACAC,GAAA,6BACAsG,GAAA,eACAC,GAAA,kBACApG,GAAA,kBACAwH,GAAA,mBACAlB,GAAA,kBACAC,GAAA,eACAF,GAAA,kBACAG,GAAA,kBACAiB,GAAA,mBAEAnC,GAAA,uBACAG,GAAA,oBACAC,GAAA,wBACAC,GAAA,wBACAC,GAAA,qBACAC,GAAA,sBACAC,GAAA,sBACAC,GAAA,sBACAC,GAAA,6BACAC,GAAA,uBACAC,GAAA,uBAMAwB,GAAA,sBAGAvD,GAAA,OAGA5C,GAAA,8BAGAmF,GAAA,mBAGA7E,KACAA,IAAA6D,IAAA7D,GAAA8D,IACA9D,GAAA+D,IAAA/D,GAAAgE,IACAhE,GAAAiE,IAAAjE,GAAAkE,IACAlE,GAAAmE,IAAAnE,GAAAoE,IACApE,GAAAqE,KAAA,EACArE,GAAA5B,IAAA4B,GAAAyF,IACAzF,GAAAyD,IAAAzD,GAAA0D,IACA1D,GAAA4D,IAAA5D,GAAA2D,IACA3D,GAAA0F,IAAA1F,GAAAjC,IACAiC,GAAAsE,IAAAtE,GAAAuE,IACAvE,GAAA7B,IAAA6B,GAAAyE,IACAzE,GAAA0E,IAAA1E,GAAAwE,IACAxE,GAAA4F,KAAA,CAGA,IAAArH,MACAA,IAAAH,IAAAG,GAAAkH,IACAlH,GAAAkF,IAAAlF,GAAAqF,IACArF,GAAAmF,IAAAnF,GAAAoF,IACApF,GAAAsF,IAAAtF,GAAAuF,IACAvF,GAAAwF,IAAAxF,GAAAyF,IACAzF,GAAA0F,IAAA1F,GAAA+F,IACA/F,GAAAgG,IAAAhG,GAAAJ,IACAI,GAAAkG,IAAAlG,GAAAmG,IACAnG,GAAAiG,IAAAjG,GAAAoG,IACApG,GAAA2F,IAAA3F,GAAA4F,IACA5F,GAAA6F,IAAA7F,GAAA8F,KAAA,EACA9F,GAAAmH,IAAAnH,GAAAR,IACAQ,GAAAqH,KAAA,CAGA,IAAAE,IAAA,gBAAA5O,SAAAlB,iBAAAkB,EAGA6O,GAAA,gBAAAC,kBAAAhQ,iBAAAgQ,KAGArR,GAAAmR,IAAAC,IAAAjP,SAAA,iBAGAmP,GAAA,gBAAApR,UAAAqR,UAAArR,EAGAsR,GAAAF,IAAA,gBAAAnR,UAAAoR,UAAApR,EAGAsR,GAAAD,OAAAtR,UAAAoR,GAGAI,GAAAD,IAAAN,GAAAQ,QAGAC,GAAA,WACA,IACA,MAAAF,QAAAG,QAAA,QACG,MAAAxP,QAIHyP,GAAAF,OAAA9F,aAmOAiG,GAAAhO,MAAAjC,UACAkQ,GAAA7P,SAAAL,UACAwO,GAAAjP,OAAAS,UAGAmQ,GAAAjS,GAAA,sBAGAqQ,GAAA,WACA,GAAA6B,GAAA,SAAAtE,KAAAqE,OAAA1J,MAAA0J,GAAA1J,KAAA4J,UAAA,GACA,OAAAD,GAAA,iBAAAA,EAAA,MAIA3B,GAAAyB,GAAA3N,SAGAtC,GAAAuO,GAAAvO,eAGA2O,GAAAH,GAAA1P,KAAAQ,QAOAoJ,GAAA6F,GAAAjM,SAGAyG,GAAAsH,OAAA,IACA7B,GAAA1P,KAAAkB,IAAAsQ,QAAAnB,GAAA,QACAmB,QAAA,uEAIAC,GAAAb,GAAAzR,GAAAsS,OAAAnO,OACAoO,GAAAvS,GAAAuS,OACApF,GAAAnN,GAAAmN,WACAyB,GAAAnK,EAAApD,OAAAmR,eAAAnR,QACA+I,GAAA/I,OAAAoR,OACAhC,GAAAH,GAAAG,qBACAxK,GAAA8L,GAAA9L,OAGAyM,GAAArR,OAAAsR,sBACAC,GAAAN,MAAAhJ,SAAAnF,OACAqH,GAAA/G,EAAApD,OAAAkH,KAAAlH,QACAoL,GAAAoG,KAAAC,IAGAC,GAAArE,GAAA1O,GAAA,YACAyG,GAAAiI,GAAA1O,GAAA,OACAgT,GAAAtE,GAAA1O,GAAA,WACAiT,GAAAvE,GAAA1O,GAAA,OACAkT,GAAAxE,GAAA1O,GAAA,WACAmF,GAAAuJ,GAAArN,OAAA,UAGA8R,GAAAlI,GAAA8H,IACAK,GAAAnI,GAAAxE,IACA4M,GAAApI,GAAA+H,IACAM,GAAArI,GAAAgI,IACAM,GAAAtI,GAAAiI,IAGAM,GAAAjB,MAAAzQ,UAAAqC,OACA6J,GAAAwF,MAAAC,QAAAtP,MA8FAU,GAAA/C,UAAAiD,MAAAE,EACAJ,EAAA/C,UAAA,OAAAsD,EACAP,EAAA/C,UAAAL,IAAA6D,EACAT,EAAA/C,UAAAuD,IAAAI,EACAZ,EAAA/C,UAAAa,IAAA+C,EA4GAC,EAAA7D,UAAAiD,MAAAa,EACAD,EAAA7D,UAAA,OAAA+D,EACAF,EAAA7D,UAAAL,IAAAyE,EACAP,EAAA7D,UAAAuD,IAAAc,EACAR,EAAA7D,UAAAa,IAAAyD,EA0FAE,EAAAxE,UAAAiD,MAAAwB,EACAD,EAAAxE,UAAA,OAAA6E,EACAL,EAAAxE,UAAAL,IAAAoF,EACAP,EAAAxE,UAAAuD,IAAAyB,EACAR,EAAAxE,UAAAa,IAAAoE,EAwFAC,EAAAlF,UAAAiD,MAAAkC,EACAD,EAAAlF,UAAA,OAAAoF,EACAF,EAAAlF,UAAAL,IAAA0F,EACAH,EAAAlF,UAAAuD,IAAA+B,EACAJ,EAAAlF,UAAAa,IAAA0E,CAspBA,IAAA8G,IAAAuE,GAAAjO,EAAAiO,GAAArR,QAAAuP,GASA1H,GAAAsB,GAIAuI,IAAA7J,GAAA,GAAA6J,IAAA,GAAAW,aAAA,MAAAzE,IACAxI,IAAAyC,GAAA,GAAAzC,MAAAkJ,IACAqD,IAAA9J,GAAA8J,GAAAW,YAAA3C,IACAiC,IAAA/J,GAAA,GAAA+J,MAAAlD,IACAmD,IAAAhK,GAAA,GAAAgK,MAAAjC,MACA/H,GAAA,SAAAlI,GACA,GAAA8C,GAAA2G,GAAA5J,KAAAG,GACA6N,EAAA/K,GAAA0F,GAAAxI,EAAA8L,YAAA3I,OACAyP,EAAA/E,EAAA5D,GAAA4D,GAAA1K,MAEA,IAAAyP,EACA,OAAAA,GACA,IAAAT,IAAA,MAAAlE,GACA,KAAAmE,IAAA,MAAAzD,GACA,KAAA0D,IAAA,MAAArC,GACA,KAAAsC,IAAA,MAAAvD,GACA,KAAAwD,IAAA,MAAAtC,IAGA,MAAAnN,IA4RA,IAAA6D,IAAA5D,MAAA4D,QA6EA2B,GAAAsJ,IAAA/B,GA8KA/E,GAAAgG,GAAA9N,EAAA8N,IAAA5G,EAwHA2I,GAAAzF,GAAA,SAAAxM,EAAAyG,EAAAwD,GACAD,EAAAhK,EAAAyG,EAAAwD,IA0CA1L,GAAAD,QAAA2T,KH+G6BhT,KAAKX,EAASM,EAAoB,GAAIA,EAAoB,IAAIL,KAIrF,SAAUA,EAAQD,EAASM,GAEjC,cAC4B,SAAS+B,GIruErC,QAAAuR,KACAC,GAAA,CAGA,KAFA,GAAApT,GAAAqT,EACAC,EAAAC,EAAAhR,OACA+Q,GAAA,CAIA,IAHAD,EAAAE,EACAA,KACAvT,GAAA,IACAA,EAAAsT,GACAD,EAAArT,IAEAsT,GAAAC,EAAAhR,OAEA6Q,GAAA,EAIA,QAAAI,GAAAC,GACA,IAAAF,EAAA7N,KAAA+N,IAAAL,GACAM,IAjEA,GAEAA,GAFAC,EAAA/R,EAAAgS,kBAAAhS,EAAAiS,sBAKA,IAAAF,EAAA,CACA,GAAAG,GAAA,EACAC,EAAA,GAAAJ,GAAAR,GACAa,EAAApS,EAAAqS,SAAAC,eAAA,GACAH,GAAAI,QAAAH,GACAI,eAAA,IAEAV,EAAA,WACAM,EAAApP,KAAAkP,MAAA,OAEG,IAAAlS,EAAAyS,cAAA,mBAAAzS,GAAA0S,eAOHZ,EADG,YAAA9R,IAAA,sBAAAA,GAAAqS,SAAAM,cAAA,UACH,WAIA,GAAAC,GAAA5S,EAAAqS,SAAAM,cAAA,SACAC,GAAAC,mBAAA,WACAtB,IAEAqB,EAAAC,mBAAA,KACAD,EAAAE,WAAAC,YAAAH,GACAA,EAAA,MAEA5S,EAAAqS,SAAAW,gBAAAC,YAAAL,IAGA,WACAM,WAAA3B,EAAA,QAvBG,CACH,GAAA4B,GAAA,GAAAnT,GAAA0S,cACAS,GAAAC,MAAAC,UAAA9B,EACAO,EAAA,WACAqB,EAAAG,MAAAC,YAAA,IAwBA,GAAA/B,GACAG,IAkBA/T,GAAAD,QAAAiU,IJ2xE6BtT,KAAKX,EAASM,EAAoB,KAIzD,SAAUL,EAAQ4V,EAAqBvV,GAE7C,YASA,SAASwV,GAAgBC,EAAK/R,EAAKlD,GAAiK,MAApJkD,KAAO+R,GAAO5U,OAAOC,eAAe2U,EAAK/R,GAAOlD,MAAOA,EAAOQ,YAAY,EAAMD,cAAc,EAAM2U,UAAU,IAAkBD,EAAI/R,GAAOlD,EAAgBiV,EARtL,GAAIE,GAAqC3V,EAAoB,IACzD4V,EAA6C5V,EAAoBkB,EAAEyU,GACnEE,EAA6C7V,EAAoB,GACjE8V,EAAqD9V,EAAoBkB,EAAE2U,EACrE7V,GAAoBS,EAAE8U,EAAqB,IAAK,WAAa,MAAOQ,KACpE/V,EAAoBS,EAAE8U,EAAqB,IAAK,WAAa,MAAOS,KACpEhW,EAAoBS,EAAE8U,EAAqB,IAAK,WAAa,MAAOU,KACpEjW,EAAoBS,EAAE8U,EAAqB,IAAK,WAAa,MAAOW,IK/1E5F,IAAMH,GAAO,aAKPC,EAAS,SAACG,GAAuB,GAAnBC,GAAmBlK,UAAAxJ,OAAA,GAAAiB,SAAAuI,UAAA,GAAAA,UAAA,GAAT,IACnC,OAAqB,kBAAPiK,GAAoBA,EAAG9V,KAAK+V,GAAWD,GAQ1CF,EAAa,SAAoBI,GAC5C,MAAOxV,QAAOkH,KAAKsO,GAASC,OAAO,SAACC,EAAI7V,GACtC,MAAOoV,KAAMS,EAANf,KACJ9U,EAAO,WAEN,IAAKZ,KAAK0W,SAAU,KAAM,IAAIC,OAAM,uCAEpC,QAAQ3W,KAAK4W,QAAQC,MAAMX,EAAOlW,KAAK0W,SAAS9V,KAAMZ,YAAc8W,OAClEhB,IAAKI,EAAOK,EAAQ3V,GAAOZ,qBAUxBoW,EAAe,SAACW,EAAKC,GAKhC,IAJA,GAAIC,GAAM,EACNC,EAAOH,EAAInU,OACXuU,SAEGF,EAAMC,GACXC,EAAOF,EAAMC,IAAU,EACvBH,EAAII,GAAKC,IAAMJ,EAAQC,EAAME,EAAM,EAAID,EAAOC,CAEhD,OAAOF,KL82EH,SAAUpX,EAAQD,EAASM,GAEjC,cAC4B,SAAS+B,GMj6ErC,QAAAoV,GAAAC,GAA+B,MAAAA,IAAA,gBAAAA,IAAA,WAAAA,KAAA,QAAAA,EAe/B,QAAAC,GAAAjW,GACA,yBAAA8R,cAAA9R,YAAA8R,cACA,mBAAAoE,OAAAlW,YAAAkW,MAGA,QAAA9K,GAAA+K,GACA,qBAAAA,GAAAlL,MACA,MAAAkL,GAAAlL,MAAA,EAGA,IAAAmL,GAAA,GAAAtE,aAAAqE,EAAA7K,YACA+K,EAAA,GAAA9K,YAAA6K,GACAE,EAAA,GAAA/K,YAAA4K,EAEA,OADAE,GAAAtV,IAAAuV,GACAF,EAGA,QAAAG,GAAAvW,GACA,GAAAA,YAAA8R,aACA,MAAA1G,GAAApL,EAEA,IAAA2C,GAAA3C,EAAA2C,KACA4L,EAAAvO,EAAAuO,IAEA,yBAAAvO,GAAAiL,MACAjL,EAAAiL,MAAA,EAAAtI,EAAA4L,GAGAvO,EAAAwW,YAAA,EAAA7T,EAAA4L,GAUA,QAAA9D,GAAArL,GACA,GAAAmJ,GAAA9I,OAAAmR,eAAAxR,EAEA,WAAAmJ,EACA,QAEA,IAAA0E,GAAA1E,EAAA2C,WACA,yBAAA+B,IACAA,gBAAA0B,GAAA1P,KAAAgO,IAAA6B,GAGA,QAAA2H,GAAAzW,GACA,GAAA0W,GACA3X,EACAsT,CAEA,KAAArS,GAAA,gBAAAA,GACA,MAAAA,EAGA,IAAAmC,MAAA4D,QAAA/F,GAAA,CAEA,IADA0W,KACA3X,EAAA,EAAAsT,EAAArS,EAAAsB,OAAoCvC,EAAAsT,EAAStT,IAC7C2X,EAAA3X,GAAA0X,EAAAzW,EAAAjB,GAEA,OAAA2X,GAKA,GAAA1W,YAAA2W,MACA,MAAA3W,GAAA4W,aAGA,IAAAX,EAAAjW,GACA,MAAAuW,GAAAvW,EAGA,KAAAyK,EAAAzK,GACA,MAAAA,EAGA0W,KACA,KAAA3X,IAAAiB,GAEA,GAAAP,OAAAS,UAAAC,eAAAlB,KAAAe,EAAAjB,GAAA,CACA,GAAAK,GAAAqX,EAAAzW,EAAAjB,GACA,oBAAAK,KACAsX,EAAA3X,GAAAK,GAIA,MAAAsX,GAGA,QAAAG,GAAAC,GACA,GAAAjE,IAAA,CACA,OAAAkE,IAAA,SAAA1V,GAEA,GAAAwR,EAEA,SAAAwC,OAAA,6BAEAxC,IAAA,EACAiE,EAAA5V,MAAAxC,KAAA2C,KAKA,QAAA2V,GAAA7V,GAEA,MAAA4V,IAAA,SAAA1V,GAEAA,EAAAoV,EAAApV,EACA,IAAAoO,GAAA/Q,KAEAuY,EAAA,kBAAA5V,KAAAC,OAAA,IAAAD,EAAA+C,MACA8S,EAAA,GAAAC,IAAA,SAAAC,EAAAC,GACA,GAAAC,EACA,KACA,GAAAC,GAAAV,EAAA,SAAAW,EAAAC,GACAD,EACAH,EAAAG,GAEAJ,EAAAK,IAKApW,GAAAoD,KAAA8S,GACAD,EAAAnW,EAAAD,MAAAuO,EAAApO,GACAiW,GAAA,kBAAAA,GAAAI,MACAN,EAAAE,GAEO,MAAA7W,GACP4W,EAAA5W,KASA,OALAwW,IACAC,EAAAQ,KAAA,SAAAxV,GACA+U,EAAA,KAAA/U,IACO+U,GAEPC,IAMA,QAAAS,GAAArY,EAAAiY,GACA,QAAAK,GAAAnI,EAAAnQ,EAAA+B,GAEA,GAAAwW,GAAAC,QAAA,CAEA,OADAC,IAAAtI,EAAAnQ,QACAP,EAAA,EAAqBA,EAAAsC,EAAAC,OAAA,EAAqBvC,IAC1CgZ,EAAAtT,KAAApD,EAAAtC,GAEA8Y,IAAA3W,MAAA,KAAA6W,EAGA,IAAAC,GAAA3W,IAAAC,OAAA,EACAD,KAAAC,OAAA,YAAAkW,EAAAS,GACA,GAAAC,IAAAzI,EAAAnQ,OACA4Y,KAAAC,OACAX,GAAA,QAAAA,IAAA,UAAAS,IAEAJ,GAAA3W,MAAA,KAAAgX,GACAF,EAAAR,EAAAS,KAKA,MAAAjB,GAAAD,GAAA,SAAA1V,GACA,GAAA3C,KAAA0Z,QACA,MAAAjB,IAAAE,OAAA,GAAAhC,OAAA,sBAEA,IAAA3W,KAAA2Z,WACA,MAAAlB,IAAAE,OAAA,GAAAhC,OAAA,yBAEA,IAAA5F,GAAA/Q,IAEA,OADAkZ,GAAAnI,EAAAnQ,EAAA+B,GACA3C,KAAA4Z,UAAAC,QAWAhB,EAAArW,MAAAxC,KAAA2C,GAVA,GAAA8V,IAAA,SAAAC,EAAAC,GACA5H,EAAA6I,UAAAE,QAAA,SAAAC,GACAA,EACApB,EAAAoB,GAEArB,EAAA3H,EAAAnQ,GAAA4B,MAAAuO,EAAApO,WAUA,QAAAqX,GAAArE,EAAAoB,GAEA,OADAwC,MACAlZ,EAAA,EAAAsT,EAAAoD,EAAAnU,OAAmCvC,EAAAsT,EAAStT,IAAA,CAC5C,GAAA4Z,GAAAlD,EAAA1W,EACA4Z,KAAAtE,KACA4D,EAAAU,GAAAtE,EAAAsE,IAGA,MAAAV,GAGA,QAAAW,GAAAtW,GACA,UAAAA,EAEA,QAAAuW,GAAAvW,GACA,MAAAA,GAAAwW,UAAA,GAEA,QAAAC,KACAra,KAAAsa,UAoCA,QAAAC,GAAAzX,GAIA,GAHA9C,KAAAsa,OAAA,GAAAD,GAGAvX,GAAAW,MAAA4D,QAAAvE,GACA,OAAAzC,GAAA,EAAAsT,EAAA7Q,EAAAF,OAAuCvC,EAAAsT,EAAStT,IAChDL,KAAAuC,IAAAO,EAAAzC,IAyBA,QAAAma,KACA,sBAAAvI,SAAA,mBAAA9L,MAAA,mBAAAwM,KACA,QAEA,IAAAsH,GAAAlZ,OAAA0Z,yBAAAtU,IAAA8L,OAAAyI,QACA,OAAAT,IAAA,OAAAA,IAAA9T,IAAA8L,OAAAyI,WAAAvU,IAwBA,QAAAwU,GAAAC,GACA,MAAAA,GAGA,QAAAC,GAAArX,GACA,QACAsX,GAAAtX,IAKA,QAAAuX,GAAAtE,EAAAuE,EAAAnC,GAiBA,QAAAoC,KACA,GAAAC,KACAC,GAAAjX,QAAA,SAAAqV,GACAA,EAAA6B,KAAAlX,QAAA,SAAAmX,GACAH,EAAAnV,MACAuV,GAAA/B,EAAA+B,GACAF,MAAAC,SAIAxC,EAAA,MAAoBqC,YAGpB,QAAAK,OACAC,IAAAC,GACAR,IAIA,QAAAS,GAAAC,EAAAL,EAAAF,GACAD,EAAAQ,IAA+BL,KAAAF,QAC/BG,IAUA,QAAAK,KAEA,KAAAvb,GAAAwb,EAAAjZ,QAAA,CAIA,GAAAkZ,GAAAvJ,KAAAwJ,IAAA1b,EAAA2b,GAAAH,EAAAjZ,QACAqZ,EAAAJ,EAAAtP,MAAAlM,EAAAyb,EACAI,GAAAD,EAAA5b,GACAA,GAAA4b,EAAArZ,QAGA,QAAAsZ,GAAAD,EAAA9Y,GACA8Y,EAAA/X,QAAA,SAAA8S,EAAAmF,GACA,GAAAC,GAAAjZ,EAAAgZ,EACAE,EAAAC,EAAAnb,IAAA6V,GAQAuF,EAAAvC,EAAAqC,EAAA,gCACAE,GAAAC,UAAAH,EAAAla,IAAA,SAAAsa,GAEA,MAAAA,GAAAC,MAIAH,EAAAC,UAAAD,EAAAC,UAAA1F,OAAA6D,EAEA,IAAAgC,GAAAhC,CAEA,KAAA4B,EAAAC,UAAA5Z,eACA2Z,GAAAC,UAKAG,EAAA9B,IAIA,+CAAA3W,QAAA,SAAA0Y,GACAA,IAAA5B,KACAuB,EAAAK,GAAA5B,EAAA4B,MAGAnG,EAAAtV,IAAA6V,EAAAuF,EAAA,SAAAzD,EAAAS,GACA,GAAA/V,EAGAA,GADAsV,IACqB+D,MAAA/D,IAErB6D,EAAApD,GAEAmC,EAAAU,EAAApF,EAAAxT,GACAoY,QAzGA,GAAAkB,GAAA9B,EAAAI,KAGAkB,EAAA,GAAAS,GACAD,GAAA5Y,QAAA,SAAAuY,GACAH,EAAAvX,IAAA0X,EAAAnB,IACAgB,EAAAnb,IAAAsb,EAAAnB,IAAAvV,KAAA0W,GAEAH,EAAAja,IAAAoa,EAAAnB,IAAAmB,KAIA,IAAAhB,GAAAa,EAAArY,KACAuX,EAAA,EACAL,EAAA,GAAA1X,OAAAgY,GA0BAI,IACAS,GAAApY,QAAA,SAAAxD,EAAAkD,GACAiY,EAAA9V,KAAAnC,IAGA,IAAAvD,GAAA,CAiEAub,KAIA,QAAAoB,KACA,yBAAAC,SACA,mBAAAA,QAAAC,SACA,mBAAAD,QAAAC,QAAAC,MAgBA,QAAAC,KACA,MAAAC,IAMA,QAAAC,GAAAvM,GACAiM,IACAC,OAAAC,QAAAK,UAAAC,YAAA,SAAAzb,GAEA,MAAAA,EAAA0b,SAEA1M,EAAA2M,KAAA3b,EAAA4b,OAAAhS,YAGGyR,MACH,mBAAAQ,kBACAA,iBAAA,mBAAA7b,GACAgP,EAAA2M,KAAA3b,EAAA6B,OAGA5B,OAAA6b,YAAA,mBAAA9b,GACAgP,EAAA2M,KAAA3b,EAAA6B,QAMA,QAAAka,KACAC,GAAAC,aAAAzd,KAAAP,MACAA,KAAAie,cAEAX,EAAAtd,MAwEA,QAAAke,GAAAC,GAEA,iBAAAC,SAAAD,IAAAC,SAAA,CACA,GAAAzb,GAAAc,MAAAjC,UAAA+K,MAAAhM,KAAA6L,UAAA,EACAgS,SAAAD,GAAA3b,MAAA4b,QAAAzb,IAIA,QAAA0b,GAAAtC,EAAAvJ,GACA,GAAA8L,GAAA,GACAvC,GAAAwC,SAAAxC,EAAA,OACAvJ,EAAA+L,SAAA/L,EAAA,IACAA,UAAAuJ,EACAvJ,GAAAuJ,GAAA,MAEAvJ,GAAA,EAGAA,EAAA8L,IACAvC,EAAAuC,GAAA,EACA9L,EAAA8L,EAEA,IAAAE,GAAAjM,KAAAkM,SACAC,EAAAlM,EAAAuJ,CAEA,UAAA2C,EAAAF,EAAAzC,GAGA,QAAA4C,GAAA5C,GACA,GAAAvJ,GAAA,CAIA,OAHAuJ,KACAvJ,EAAA,KAEA6L,EAAAtC,EAAAvJ,GAKA,QAAAoM,GAAAC,EAAAC,GACAZ,EAAA,oBAAAW,EAAA,uBAAAC,GAkCA,QAAAC,GAAAF,EAAAhC,EAAAmC,GACArI,MAAApW,KAAAP,KAAAgf,GACAhf,KAAA6e,SACA7e,KAAAY,KAAAic,EACA7c,KAAAif,QAAAD,EACAhf,KAAA6c,OAAA,EAqCA,QAAAqC,GAAArC,EAAAmC,GACA,QAAAG,GAAAH,GAIA,OAAAtd,KAAAmb,GACA,kBAAAA,GAAAnb,KACA1B,KAAA0B,GAAAmb,EAAAnb,GAIAmC,UAAAmb,IACAhf,KAAAgf,UAIA,MADAG,GAAA3d,UAAAud,EAAAvd,UACA,GAAA2d,GAAAH,GAGA,QAAAI,GAAAtG,GAEA,mBAAAA,GAAA,CACA,GAAA7T,GAAA6T,CACAA,GAAAuG,GACAvG,EAAA7T,OAoBA,MAjBA,SAAA6T,IAAA,aAAAA,EAAA+D,QACA/D,EAAAlY,KAAA,WACAkY,EAAA+F,OAAA,KAGA,QAAA/F,KACAA,EAAAlY,KAAAkY,EAAA+D,OAAA,WAGA,UAAA/D,KACAA,EAAA+F,OAAA,KAGA,WAAA/F,KACAA,EAAAmG,QAAAnG,EAAAmG,SAAAnG,EAAAkG,QAGAlG,EAGA,QAAAwG,GAAAxI,EAAAyI,EAAAC,GACA,IACA,OAAA1I,EAAAyI,EAAAC,GACG,MAAA1G,GACH,GAAA2G,GAAA,0BAAA3G,EAAA/U,UACA,OAAAmb,GAAAQ,GAAAD,IAIA,QAAAE,GAAA3E,GACA,GAAAwE,MACAI,EAAA5E,EAAAlE,QAAA,kBAAAkE,GAAAlE,MAGA,OAFA0I,GAAAK,MAAA7E,EAAA8E,aAEA,SAAAC,GACAA,EAAAR,MAGAQ,EAAAR,OAGA,IAAAS,GAAAJ,GAAAN,EAAAtE,EAAAlE,OAAAiJ,EAAAR,IAAAC,EAEA,oBAAAQ,GACA,MAAAA,EAGA,IAAAA,EACA,QAGA,IAAAhF,EAAAiF,cAEK,IAAAjF,EAAAkF,YACL,OAAAC,KAAAJ,GAAAR,IAAAa,aAEAL,EAAAR,IAAAa,aAAA3e,eAAA0e,KACAJ,EAAAR,IAAAa,aAAAD,GAAAE,MAAA,cALAN,GAAAR,GASA,WAIA,QAAAe,GAAAC,GAEA,OADAhH,MACAlZ,EAAA,EAAAsT,EAAA4M,EAAA3d,OAAoCvC,EAAAsT,EAAStT,IAC7CkZ,IAAAE,OAAA8G,EAAAlgB,GAEA,OAAAkZ,GAOA,QAAAiH,MAsBA,QAAAC,GAAAnF,GACA,GAAAxC,EAQA,IAPAwC,EAEG,gBAAAA,GACHxC,EAAAoG,EAAAwB,IACG,KAAAhW,KAAA4Q,KAAA,mBAAA5Q,KAAA4Q,KACHxC,EAAAoG,EAAAyB,KAJA7H,EAAAoG,EAAA0B,IAMA9H,EACA,KAAAA,GAIA,QAAA+H,GAAAC,EAAAjR,GACA,uBAAAiR,KAAAD,cAAAhR,GACAkO,GAAAC,aAAA6C,cAAAC,EAAAjR,GAeA,QAAAkR,GAAApf,GACA,IAAAA,EACA,WAEA,IAAAqf,GAAArf,EAAAsf,MAAA,IACA,YAAAD,EAAApe,OACAoe,EAEA,IAAAA,EAAApe,QACAjB,KAEA,KAGA,QAAAuf,GAAAvf,GACA,GAAAwf,GAAAJ,EAAApf,EACA,OAAAwf,KAAAC,KAAA,UAeA,QAAAC,GAAAvC,GAKA,IAJA,GAAAte,GAAA8gB,GAAAhU,KAAAwR,GACAyC,KACAlhB,EAAA,GAEAA,KAAA,CACA,GAAAuD,GAAAqE,GAAA5H,GACAK,EAAAF,EAAAH,IAAA,GACAmhB,GAAA,mBAAAC,QAAA7d,MAAA,CACA2d,GAAA3d,GAAA4d,EAAAE,mBAAAhhB,KAUA,MAPA6gB,GAAAI,OACAJ,EAAAtZ,GAAA,KAAA8J,QAAA6P,GAAA,SAAAC,EAAAC,EAAAC,GACAD,IACAP,EAAAI,IAAAG,GAAAC,KAIAR,EAMA,QAAAS,GAAAvL,EAAAO,EAAAiL,GACA,UAAAxJ,IAAA,SAAAC,EAAAC,GACAlC,EAAAtV,IAAA6V,EAAA,SAAA8B,EAAAyG,GACA,GAAAzG,EAAA,CAEA,SAAAA,EAAA+F,OACA,MAAAlG,GAAAG,EAEAyG,MAIA,GAAA2C,GAAA3C,EAAA4C,KACAC,EAAAH,EAAA1C,EAEA,OAAA6C,IAQAA,EAAAhL,IAAAJ,EACAoL,EAAAD,KAAAD,MACAxJ,GAAA2J,EAAA5L,EAAA2L,EAAAH,KAPAvJ,GAAwB4J,SAAA,EAAA5F,IAAAwF,QAYxB,QAAAG,GAAA5L,EAAA8I,EAAA0C,GACA,MAAAxL,GAAA8L,IAAAhD,GAAAvG,KAAA,SAAAO,GACA,OACA+I,SAAA,EACA5F,IAAAnD,EAAAmD,MAEG,SAAA5D,GAEH,SAAAA,EAAA+F,OACA,KAAA/F,EAEA,OAAAkJ,GAAAvL,EAAA8I,EAAAnI,IAAA6K,KA4CA,QAAAte,GAAA6e,GACA,SAAAjQ,KAAAkM,SAAA+D,EAEA,QAAAC,GAAA9O,EAAA6O,GACAA,KAAAE,GAAA9f,MACA,IAAA+f,GAAA,GACAtiB,GAAA,CAEA,IAAAsT,EAAA,CAEA,OAAAtT,EAAAsT,GACAgP,GAAAD,GAAA/e,EAAA6e,GAEA,OAAAG,GAKA,OAAAtiB,EAAA,IACA,OAAAA,GACA,OACA,QACA,QACA,QACAsiB,GAAA,GACA,MACA,SACAA,GAAAD,GAAA,EAAA/e,EAAA,MACA,MACA,SACAgf,GAAAD,GAAA/e,EAAA,KAIA,MAAAgf,GAQA,QAAAC,GAAAC,GAMA,IALA,GAAAC,GACAC,EACAC,EAEAC,EADAC,EAAAL,EAAAM,SAAA5W,QAEA0W,EAAAC,EAAAxd,OAAA,CACA,GAAA0d,GAAAH,EAAAI,IACAC,EAAAF,EAAA,GACAG,EAAAN,EAAAM,GACA,IAAAD,EAAA1gB,OACA,OAAAvC,GAAA,EAAAsT,EAAA2P,EAAA1gB,OAA4CvC,EAAAsT,EAAStT,IACrD6iB,EAAAnd,MAAsBwd,MAAA,EAAAF,IAAAC,EAAAjjB,SAFtB,CAMA,GAAAmjB,KAAAJ,EAAA,GAAAI,QACAlI,EAAA8H,EAAA,EAEAN,MAAAE,IAAAQ,EAAAR,EACAD,IAAAQ,EAAAR,EAAAQ,EAAAT,EAAAxH,KACAwH,EAAAxH,EACAyH,EAAAQ,EACAP,EAAAQ,IAIA,MAAAT,GAAA,IAAAD,EAOA,QAAAW,GAAAC,EAAA7K,GAIA,IAHA,GAEAoK,GAFAC,EAAAQ,EAAAnX,QAGA0W,EAAAC,EAAAxd,OAMA,OALA6d,GAAAN,EAAAM,IACAH,EAAAH,EAAAI,IACAC,EAAAF,EAAA,GACAO,EACA9K,EAAA,IAAAyK,EAAA1gB,OAAA2gB,EAAAH,EAAA,GAAAH,EAAAW,IAAAR,EAAA,IACA/iB,EAAA,EAAAsT,EAAA2P,EAAA1gB,OAA0CvC,EAAAsT,EAAStT,IACnD6iB,EAAAnd,MAAoBwd,MAAA,EAAAF,IAAAC,EAAAjjB,GAAAujB,IAAAD,IAKpB,QAAAE,GAAAC,EAAAC,GACA,MAAAD,GAAAP,IAAAQ,EAAAR,IAGA,QAAAS,GAAAN,GACA,GAAAO,KACAR,GAAAC,EAAA,SAAAQ,EAAAX,EAAAjI,EAAA6I,EAAAnJ,GACAkJ,GACAD,EAAAle,MAAmB2W,IAAA6G,EAAA,IAAAjI,EAAAiI,MAAAvI,WAGnBiJ,EAAAG,KAAAP,GAAAQ,SACA,QAAAhkB,GAAA,EAAAsT,EAAAsQ,EAAArhB,OAAsCvC,EAAAsT,EAAStT,UAC/C4jB,GAAA5jB,GAAAkjB,GAEA,OAAAU,GAMA,QAAAK,GAAAzB,GAIA,OAHA0B,GAAA3B,EAAAC,GACAoB,EAAAD,EAAAnB,EAAAM,UACAqB,KACAnkB,EAAA,EAAAsT,EAAAsQ,EAAArhB,OAAsCvC,EAAAsT,EAAStT,IAAA,CAC/C,GAAAokB,GAAAR,EAAA5jB,EACAokB,GAAA/H,MAAA6H,GAAAE,EAAAzJ,KAAAwI,SACAgB,EAAAze,KAAA0e,EAAA/H,KAGA,MAAA8H,GAKA,QAAAE,GAAA7B,GACA,GAAAa,KAQA,OAPAD,GAAAZ,EAAAM,SAAA,SAAAe,EAAAX,EACAoB,EAAAf,EAAA5I,GACA,cAAAA,EAAA6D,QAAAqF,IACAR,EAAA3d,KAAAwd,EAAA,IAAAoB,GACA3J,EAAA6D,OAAA,aAGA6E,EAIA,QAAAkB,GAAAlB,GAIA,IAHA,GAEAT,GAFA4B,KACA3B,EAAAQ,EAAAnX,QAEA0W,EAAAC,EAAAxd,OAAA,CACA,GAAA6d,GAAAN,EAAAM,IACAH,EAAAH,EAAAI,IACA/H,EAAA8H,EAAA,GACApI,EAAAoI,EAAA,GACAE,EAAAF,EAAA,GACAc,EAAA,IAAAZ,EAAA1gB,OAEAkiB,EAAA7B,EAAA6B,QAAA7B,EAAA6B,QAAAvY,UACAuY,GAAA/e,MAAkBuV,KAAAN,SAClBkJ,GACAW,EAAA9e,MAAkBwd,MAAA,EAAAuB,EAAAliB,OAAAygB,IAAAyB,GAElB,QAAAzkB,GAAA,EAAAsT,EAAA2P,EAAA1gB,OAA0CvC,EAAAsT,EAAStT,IACnD6iB,EAAAnd,MAAoBwd,MAAA,EAAAF,IAAAC,EAAAjjB,GAAAykB,YAGpB,MAAAD,GAAAR,UAcA,QAAAU,GAAAjB,EAAAC,GACA,MAAAD,GAAAP,IAAAQ,EAAAR,IAIA,QAAAnN,GAAAW,EAAAiO,EAAAC,GAIA,IAHA,GAEA9N,GAFAF,EAAA,EACAC,EAAAH,EAAAnU,OAEAqU,EAAAC,GACAC,EAAAF,EAAAC,IAAA,EACA+N,EAAAlO,EAAAI,GAAA6N,GAAA,EACA/N,EAAAE,EAAA,EAEAD,EAAAC,CAGA,OAAAF,GAIA,QAAAiO,IAAAnO,EAAAiO,EAAAC,GACA,GAAAE,GAAA/O,EAAAW,EAAAiO,EAAAC,EACAlO,GAAApR,OAAAwf,EAAA,EAAAH,GAMA,QAAAI,IAAAC,EAAAC,GAGA,OAFA5lB,GACA+kB,EACApkB,EAAAilB,EAAA3R,EAAA0R,EAAAziB,OAA6CvC,EAAAsT,EAAStT,IAAA,CACtD,GAAA4iB,GAAAoC,EAAAhlB,GACAklB,GAAAtC,EAAA3H,GAAA2H,EAAAjI,QACAyJ,IACAA,EAAA,GAAA1e,KAAAwf,GACAd,EAAAc,GAEA7lB,EAAA+kB,EAAAc,EAGA,MAAA7lB,GAIA,QAAA8lB,IAAA1B,EAAAC,GACA,MAAAD,GAAA,GAAAC,EAAA,QAKA,QAAA0B,IAAAC,EAAAC,GAGA,IAFA,GAAA/R,KAAgBgS,MAAAF,EAAAG,MAAAF,IAChBnB,GAAA,EACA5Q,EAAAhR,OAAA,IACA,GAAAoiB,GAAApR,EAAAlO,MACAkgB,EAAAZ,EAAAY,MACAC,EAAAb,EAAAa,OAEAD,EAAA,GAAA/G,QAAAgH,EAAA,GAAAhH,UACA+G,EAAA,GAAA/G,OACA,cAAA+G,EAAA,GAAA/G,QACA,cAAAgH,EAAA,GAAAhH,OAAA,sBAGA,QAAAxe,GAAA,EAAmBA,EAAAwlB,EAAA,GAAAjjB,OAAqBvC,IACxC,GAAAulB,EAAA,OAOA,OADAE,IAAA,EACA3J,EAAA,EAAqBA,EAAAyJ,EAAA,GAAAhjB,OAAqBuZ,IAC1CyJ,EAAA,GAAAzJ,GAAA,KAAA0J,EAAA,GAAAxlB,GAAA,KACAuT,EAAA7N,MAAsB6f,QAAA,GAAAzJ,GAAA0J,QAAA,GAAAxlB,KACtBylB,GAAA,EAGAA,KACAtB,EAAA,aACAU,GAAAU,EAAA,GAAAC,EAAA,GAAAxlB,GAAAmlB,SAdAhB,GAAA,WACAoB,EAAA,MAAAC,EAAA,GAAAxlB,GAiBA,OAAUmkB,YAAApB,KAAAsC,GAGV,QAAAK,IAAA3C,EAAAiC,EAAAW,GACA,GAGAzM,GAHA0M,KACAzB,GAAA,EACAsB,GAAA,CAGA,KAAA1C,EAAAxgB,OACA,OAAYwgB,MAAAiC,GAAAb,UAAA,WAGZ,QAAAnkB,GAAA,EAAAsT,EAAAyP,EAAAxgB,OAAoCvC,EAAAsT,EAAStT,IAAA,CAC7C,GAAA6lB,GAAA9C,EAAA/iB,EACA,IAAA6lB,EAAA3C,MAAA8B,EAAA9B,KAAA2C,EAAA7C,IAAA,KAAAgC,EAAAhC,IAAA,GAGA9J,EAAAkM,GAAAS,EAAA7C,IAAAgC,EAAAhC,KACA4C,EAAAlgB,MAAoBwd,IAAA2C,EAAA3C,IAAAF,IAAA9J,EAAA6J,OACpBoB,KAAAjL,EAAAiL,UACAsB,GAAA,MACK,IAAAE,KAAA,GAML,GAAAG,GAAAD,EAAA3C,IAAA8B,EAAA9B,IAAA2C,EAAAb,EACAe,EAAAF,EAAA3C,IAAA8B,EAAA9B,IAAA8B,EAAAa,EACAG,EAAAD,EAAA7C,IAAA4C,EAAA5C,IAEA+C,KAEAC,IAEA,KADAA,EAAAxgB,MAAkBsd,IAAA8C,EAAA9C,IAAAgD,OAAAG,OAAA,KAAAC,UAAA,OAClBF,EAAA3jB,OAAA,IACA,GAAAoiB,GAAAuB,EAAA7gB,KACA,QAAAsf,EAAAqB,KAOA,OADAK,GAAA1B,EAAA3B,IAAA,GACAlH,EAAA,EAAAwK,EAAAD,EAAA9jB,OAAsDuZ,EAAAwK,EAAiBxK,IACvEoK,EAAAxgB,MACAsd,IAAAqD,EAAAvK,GACAkK,KAAArB,EAAAqB,KAAA,EACAG,OAAAxB,EAAA3B,IACAoD,UAAAtK,QAXA6I,GAAA3B,IAAA,KAAA+C,EAAA/C,IAAA,IACAiD,EAAAvgB,KAAAif,GAeA,GAAA4B,GAAAN,EAAA,EAEAM,IAGArN,EAAAkM,GAAAmB,EAAAvD,IAAA+C,EAAA/C,KACAuD,EAAAJ,OAAA,GAAAI,EAAAH,WAAAlN,EAAA6J,KACA6C,EAAAlgB,MAAsBwd,IAAA4C,EAAA5C,IAAAF,IAAA8C,EAAA9C,MACtBmB,KAAAjL,EAAAiL,UACAsB,GAAA,GANAG,EAAAlgB,KAAAmgB,OASAD,GAAAlgB,KAAAmgB,GAWA,MANAJ,IACAG,EAAAlgB,KAAAsf,GAGAY,EAAA7B,KAAAW,IAGA3B,KAAA6C,EACAzB,aAAA,iBAKA,QAAAqC,IAAAzD,EAAA0D,GAMA,OADAtjB,GAHAqhB,EAAAD,EAAAxB,GACA2D,KAGA1mB,EAAA,EAAAsT,EAAAkR,EAAAjiB,OAAqCvC,EAAAsT,EAAStT,IAAA,CAW9C,OARAglB,GAAAR,EAAAxkB,GACA2mB,EAAA3B,EAAAhC,IACAiC,EAAA/S,KAAAC,IAAA,EAAAwU,EAAApkB,OAAAkkB,GACAG,GACA1D,IAAA8B,EAAA9B,IAAA+B,EACAjC,IAAA+B,GAAA4B,EAAA1B,IAGA3jB,EAAA,EAAmBA,EAAA2jB,EAAgB3jB,IAAA,CACnC,GAAA+a,GAAA2I,EAAA9B,IAAA5hB,EAAA,IAAAqlB,EAAArlB,GAAA2Z,EACAyL,GAAArK,IAAA,EAMAlZ,EADAA,EACAuiB,GAAAviB,EAAAyjB,GAAA,GAAA7D,MAEA6D,GASA,MALAxD,GAAAjgB,EAAA,SAAA0gB,EAAAX,EAAAoB,SAEAoC,GAAAxD,EAAA,IAAAoB,MAIAvB,KAAA5f,EACAkgB,KAAA3iB,OAAAkH,KAAA8e,IAIA,QAAAxT,IAAA6P,EAAAiC,EAAAyB,GACA,GAAAI,GAAAnB,GAAA3C,EAAAiC,GACA2B,EAAAH,GAAAK,EAAA9D,KAAA0D,EACA,QACA1D,KAAA4D,EAAA5D,KACA+D,YAAAH,EAAAtD,KACAc,UAAA0C,EAAA1C,WAKA,QAAA4C,IAAA1D,EAAAhH,GAOA,IANA,GAKAuG,GALAC,EAAAQ,EAAAnX,QACA8a,EAAA3K,EAAAuE,MAAA,KACAqG,EAAA/I,SAAA8I,EAAA,OACAE,EAAAF,EAAA,GAGApE,EAAAC,EAAAxd,OAAA,CACA,GAAAud,EAAAM,MAAA+D,GAAArE,EAAAI,IAAA,KAAAkE,EACA,QAGA,QADAjE,GAAAL,EAAAI,IAAA,GACAhjB,EAAA,EAAAsT,EAAA2P,EAAA1gB,OAA0CvC,EAAAsT,EAAStT,IACnD6iB,EAAAnd,MAAoBwd,IAAAN,EAAAM,IAAA,EAAAF,IAAAC,EAAAjjB,KAGpB,SAGA,QAAAmnB,IAAAvE,GACA,MAAAA,GAAAI,IAMA,QAAAoE,IAAA5E,EAAAnG,GACAA,IACAA,EAAAkG,EAAAC,GAMA,KAJA,GAGAO,GAHA9H,EAAAoB,EAAAtC,UAAAsC,EAAA+E,QAAA,QACAyB,EAAAL,EAAAM,SAAAhhB,IAAAqlB,IAGApE,EAAAF,EAAAxd,OAAA,CACA,GAAA0d,EAAA,KAAA9H,EACA,QAAA8H,EAAA,GAAAI,OAEAN,KAAAzJ,OAAA2J,EAAA,KAIA,QAAAsE,IAAApM,GACA,gBAAA5Q,KAAA4Q,GAIA,QAAAqM,IAAAjL,EAAAmG,GAGA,IAFA,GACAI,GADAC,EAAAL,EAAAM,SAAA5W,QAEA0W,EAAAC,EAAAxd,OAAA,CACA,GAAA6d,GAAAN,EAAAM,IACAH,EAAAH,EAAAI,IACA/H,EAAA8H,EAAA,GACApI,EAAAoI,EAAA,GACAE,EAAAF,EAAA,GACAc,EAAA,IAAAZ,EAAA1gB,OAEAkiB,EAAA7B,EAAA6B,QAAA7B,EAAA6B,QAAAvY,UAGA,IAFAuY,EAAA/e,MAAkBuV,KAAAiI,MAAAvI,SAElBkJ,EACA,OAAA7jB,GAAA,EAAAsT,EAAAmR,EAAAliB,OAA2CvC,EAAAsT,EAAStT,IAAA,CACpD,GAAAunB,GAAA9C,EAAAzkB,GACAwnB,EAAAD,EAAArE,IAAA,IAAAqE,EAAAtM,EAEA,IAAAuM,IAAAnL,EAEA,MAAA6G,GAAA,IAAAjI,EAKA,OAAAa,GAAA,EAAA7b,EAAAgjB,EAAA1gB,OAAwCuZ,EAAA7b,EAAO6b,IAC/C+G,EAAAnd,MAAoBwd,MAAA,EAAAF,IAAAC,EAAAnH,GAAA2I,YAKpB,SAAAnO,OAAA,4CAAAkM,EAAAvH,GAAA,SAAAoB,GAGA,QAAAoL,IAAAzZ,GACA,MAAA0Z,IAAA,yBAAkC1Z,EAAA,QAGlC,QAAA2Z,IAAA3Z,GACA,GAAA4Z,IACA,yBACA,kBACA,yBACA,iCACA,sBACA,OACA,gBAAA5Z,EAAA,IACA,eACA,mBACA,mBACA,MACA,MACA+S,KAAA,KAEA,OAAA2G,IAAAE,MAKA,QAAAC,IAAAnX,EAAAgP,GAEA,IACAhP,EAAA2M,KAAA,SAAAqC,GACG,MAAAhe,GACHmc,EAAA,4CAAAnc,IAIA,QAAAomB,IAAA1R,EAAAuE,EAAAnC,GAsBA,QAAAuP,KACArX,EAAAsX,SAtBAtK,GAAAC,aAAAzd,KAAAP,KACA,IAAA+Q,GAAA/Q,IACAA,MAAAyW,KACAuE,IAAAjD,EAAAiD,KACA,IAAAsN,GAAAtN,EAAAsN,SAAAnQ,EAAA,SAAAW,EAAAF,GACAE,EACA+H,EAAA9P,EAAA,YACAA,EAAA2M,KAAA,QAAA5E,GAGA/H,EAAA2M,KAAA,WAAA9E,GAEA7H,EAAAwX,qBACA9R,EAAA+R,eAAA,YAAAJ,IAEAvP,KACA9H,EAAA0X,GAAA,oBAAA7P,GACAC,EAAA,KAAAD,KAEA7H,EAAA0X,GAAA,QAAA5P,IAKApC,EAAA0B,KAAA,YAAAiQ,GAEApN,EAAA0N,SAAA,SAAA3I,GAEAhP,EAAA4X,aAGAT,GAAAnX,EAAAgP,GAGA,IAAAvH,GAAA,GAAAC,IAAA,SAAAC,EAAAC,GACAqC,EAAAsN,SAAA,SAAAxP,EAAAS,GACAT,EACAH,EAAAG,GAEAJ,EAAAa,KAIAxI,GAAAoH,KAAA,oBACA1B,EAAA+R,eAAA,YAAAJ,GACApN,EAAAsN,SAAA,MAAyBzJ,OAAA,gBAEzB7e,KAAAgZ,KAAAR,EAAAQ,KAAA4P,KAAApQ,GACAxY,KAAA,MAAAwY,EAAA,MAAAoQ,KAAApQ,GACAxY,KAAAgZ,KAAA,SAAAxV,GACA8kB,EAAA,KAAA9kB,IACG8kB,GAIH7R,EAAAmD,UAAAC,QAWA9I,EAAA8X,UAAA7N,GAVAvE,EAAAmD,UAAAE,QAAA,SAAAC,GACAA,EACAiB,EAAAsN,SAAAvO,GACOhJ,EAAA4X,YACP5X,EAAA2M,KAAA,UAEA3M,EAAA8X,UAAA7N,KAaA,QAAA8N,IAAAvJ,EAAAsD,EAAA7H,GACA,GAAA+N,KAAqBrM,IAAA6C,EAAA4C,MACrB,cAAAnH,EAAAgO,QACAD,EAAA/E,EAAAnB,EAAAM,UACAhhB,IAAA,SAAAyY,GAAuB,OAAS8B,IAAA9B,EAAA8B,OAEhC,IAAAqD,IACAzE,GAAAuH,EAAAvH,GACA2N,QAAAF,EACAxJ,MAYA,OATAkI,IAAA5E,EAAAtD,EAAA4C,QACApC,EAAAyD,SAAA,GAEAxI,EAAAwJ,YACAzE,EAAAR,IAAA2J,WAAA5E,EAAAzB,GACA9C,EAAAR,IAAA2J,WAAAtmB,cACAmd,GAAAR,IAAA2J,YAGAnJ,EAgIA,QAAAoJ,IAAAC,EAAAC,GACA,MAAAD,GAAAC,GAAA,EAAAD,EAAAC,EAAA,IAKA,QAAAC,IAAAzQ,GACA,gBAAAC,EAAAoC,GACApC,GAAAoC,EAAA,IAAAA,EAAA,GAAA2B,MACAhE,EAAAC,GAAAoC,EAAA,IAEArC,EAAA,KAAAqC,EAAAtY,OAAAsY,EAAA,GAAAA,IAMA,QAAAqO,IAAAnO,GACA,OAAA/a,GAAA,EAAiBA,EAAA+a,EAAAxY,OAAiBvC,IAAA,CAClC,GAAAkf,GAAAnE,EAAA/a,EACA,IAAAkf,EAAAiK,eACAjK,GAAAa,iBACK,IAAAb,EAAAa,aAGL,OADAqJ,GAAA1oB,OAAAkH,KAAAsX,EAAAa,cACAjE,EAAA,EAAqBA,EAAAsN,EAAA7mB,OAAiBuZ,IAAA,CACtC,GAAAgE,GAAAsJ,EAAAtN,EACAoD,GAAAa,aAAAD,GAAAnG,EAAAuF,EAAAa,aAAAD,IACA,4DAOA,QAAAuJ,IAAA5F,EAAAC,GACA,GAAA4F,GAAAR,GAAArF,EAAA1M,IAAA2M,EAAA3M,IACA,QAAAuS,EACA,MAAAA,EAEA,IAAAC,GAAA9F,EAAA+F,WAAA/F,EAAA+F,WAAA3d,MAAA,EACA4d,EAAA/F,EAAA8F,WAAA9F,EAAA8F,WAAA3d,MAAA,CACA,OAAAid,IAAAS,EAAAE,GAKA,QAAAC,IAAArG,GACA,GAAAsG,MACAC,IAoBA,OAnBAxG,GAAAC,EAAA,SAAAQ,EAAAX,EAAAjI,EAAA4O,GACA,GAAAxN,GAAA6G,EAAA,IAAAjI,CAOA,OANA4I,KACA8F,EAAAtN,GAAA,GAEA7Y,SAAAqmB,GACAD,EAAAlkB,MAAkBokB,KAAAD,EAAAE,GAAA1N,IAElBA,IAGAuN,EAAA5F,UACA4F,EAAA/lB,QAAA,SAAAmmB,GACAxmB,SAAAmmB,EAAAK,EAAAF,MACAH,EAAAK,EAAAF,MAAA,EAAAH,EAAAK,EAAAD,IAEAJ,EAAAK,EAAAF,MAAA5X,KAAAwJ,IAAAiO,EAAAK,EAAAF,MAAA,EAAAH,EAAAK,EAAAD,OAGAJ,EAGA,QAAAM,IAAAC,EAAAvP,EAAAnC,GACA,GAAA5Q,GAAA,SAAA+S,GACAA,EAAA/S,KAAAsE,MAAAyO,EAAAwP,KAAAxP,EAAAyP,MAAAzP,EAAAwP,MACAxP,EAAAwP,KAAA,EAAAxP,EAAA/S,KAAAsE,MAAAyO,EAAAwP,MAAAxP,EAAA/S,IAIA,IAHA+S,EAAA0P,YACAziB,EAAAoc,WAEApc,EAAArF,OACA,MAAA2nB,GAAAI,UAAyBF,MAAA,GAAS5R,EAElC,IAAA+R,IACAznB,OAAA6X,EAAAwP,KAEA,OAAA/R,IAAAoS,IAAA5iB,EAAA9F,IAAA,SAAAyB,GACA,GAAAknB,GAAAC,IAA4BnnB,MAAA4f,QAAA,MAAwBxI,EAIpD,QAHA,uBAAA9W,QAAA,SAAA8mB,SACAF,GAAAE,KAEA,GAAAvS,IAAA,SAAApF,EAAAsF,GACA4R,EAAAI,SAAAG,EAAA,SAAAhS,EAAAS,GAEA,MAAAT,GACAH,EAAAG,IAEA8R,EAAAK,WAAA1R,EAAA0R,eACA5X,GAAAkG,EAAA2R,KAAA,KAAgCtnB,MAAAiZ,MAAA,sBAG7B7D,KAAA,SAAAkC,GAEH,MADA0P,GAAAM,KAAAhQ,EACA0P,IAMA,QAAAO,IAAApa,GACA,GAAA+C,GAAA/C,EAAAqa,iBAAA,GACApQ,EAAAlH,EAAAkH,KACAnC,EAAA/E,EAAA+E,QACA9H,GAAA5P,IAAA,qBAAAkqB,MAAA,WACA,WACGrS,KAAA,SAAAuG,GACHA,KAAA+L,WACAtQ,EAAAsQ,SAAA/L,EAAA+L,UAEAva,EAAAwa,SAAAvQ,EAAA,SAAAlC,EAAAS,GAEAT,EACAD,EAAAC,GAEAD,EAAA,KAAAU,GAEA/F,GAAA,WACAzC,EAAAqa,iBAAAI,QACAza,EAAAqa,iBAAAxoB,QACAuoB,GAAApa,SAOA,QAAA0a,IAAA7qB,GACA,YAAAA,EAAA8qB,OAAA,IACA9qB,EAAA,yEAQA,QAAA+qB,MACA5N,GAAAC,aAAAzd,KAAAP,MA0uBA,QAAA4rB,MACA5rB,KAAA6Z,SAAA,EACA7Z,KAAA+Z,QAAA,EACA/Z,KAAA4T,SAkCA,QAAAiY,IAAAjrB,EAAAoa,GACA,GAAA8Q,GAAAlrB,EAAAkrB,MAAA,sBACA,IAAAA,EAEA,OACAlrB,KAAA,SAAA8J,KAAAohB,EAAA,IAAAA,EAAA,SAAAA,EAAA,GAAAA,EAAA,GACAC,QAAAD,EAAA,GAIA,IAAAE,GAAAC,GAAAD,SACAE,EAAAD,GAAAC,kBACAC,EAAAF,GAAAE,OACAC,EAAApR,EAAA+Q,OAEA,KAAAK,EACA,OAAA/rB,GAAA,EAAmBA,EAAA6rB,EAAAtpB,SAA8BvC,EAAA,CACjD+rB,EAAAF,EAAA7rB,EAGA,eAAA+rB,GAAA,UAAAJ,IACA5O,KAAAiP,aAAA,oBAAAF,EAAAvrB,IAMA,KAJAsd,GAAA,iCAAAtd,EAAA,+EAQA,GAAAmrB,GAAAC,EAAAI,GAGAE,IAAAP,GAAA,cAAAA,KACAA,EAAAQ,UAEA,QACA3rB,KAAA0rB,EAAAH,EAAAvrB,IACAmrB,QAAAK,GAcA,QAAAI,IAAAzb,GAIA,QAAA0b,KACA1b,EAAAyX,eAAA,SAAAkE,GACA3b,EAAAvE,YAAAkR,KAAA,YAAA3M,EAAAnQ,MAGA,QAAA+rB,KACA5b,EAAAyX,eAAA,YAAAiE,GACA1b,EAAAyX,eAAA,SAAAkE,GACA3b,EAAA2M,KAAA,aAGA,QAAAgP,KACA3b,EAAAyX,eAAA,YAAAiE,GACAG,EAAAC,OAAA9b,EAAAnQ,MAfA,GAAAgsB,GAAA7b,EAAAvE,YAAAsgB,qBAkBA/b,GAAAoH,KAAA,YAAAsU,GACA1b,EAAAoH,KAAA,SAAAuU,GAGAE,EAAA7nB,IAAAgM,EAAAnQ,OACAgsB,EAAAvqB,IAAA0O,EAAAnQ,SAEAgsB,EAAAzrB,IAAA4P,EAAAnQ,MAAAmF,KAAA4mB,GAIA,QAAAV,IAAArrB,EAAAoa,GAGA,KAAAhb,eAAAisB,KACA,UAAAA,IAAArrB,EAAAoa,EAGA,IAAAjK,GAAA/Q,IAcA,IAbAgb,QAEApa,GAAA,gBAAAA,KACAoa,EAAApa,EACAA,EAAAoa,EAAApa,WACAoa,GAAApa,MAGAZ,KAAA+sB,OAAA/R,EAAAjD,EAAAiD,GAEAjK,EAAAic,gBAAAhS,EAAAgS,gBACAjc,EAAAob,OAAAF,GAAAE,OAEA,gBAAAvrB,GACA,SAAA+V,OAAA,0BAGA,IAAAsW,IAAAjS,EAAAmR,QAAA,IAAAvrB,EACAssB,EAAArB,GAAAoB,EAAAjS,EASA,IAPAA,EAAApa,KAAAssB,EAAAtsB,KACAoa,EAAA+Q,QAAA/Q,EAAA+Q,SAAAmB,EAAAnB,QAEAhb,EAAAnQ,OACAmQ,EAAAoc,SAAAnS,EAAA+Q,QACAqB,GAAA,sCAAApS,EAAA+Q,UAEAE,GAAAD,SAAAhR,EAAA+Q,WACAE,GAAAD,SAAAhR,EAAA+Q,SAAAsB,QACA,SAAA1W,OAAA,oBAAAqE,EAAA+Q,QAGAJ,IAAAprB,KAAAwQ,GACAA,EAAA6I,UAAA,GAAAgS,IAEA7a,EAAAgb,QAAA/Q,EAAA+Q,QAEAE,GAAAD,SAAAhR,EAAA+Q,SAAAxrB,KAAAwQ,EAAAiK,EAAA,SAAAlC,GACA,MAAAA,GACA/H,EAAA6I,UAAA0T,KAAAxU,IAEA0T,GAAAzb,GAEAA,EAAA2M,KAAA,UAAA3M,GACAkb,GAAAvO,KAAA,UAAA3M,EAAAnQ,UACAmQ,GAAA6I,UAAA2T,MAAAxc,MAcA,QAAAyc,IAAAC,GACA1sB,OAAAkH,KAAA8V,GAAAC,aAAAxc,WAAA0C,QAAA,SAAAN,GACA,kBAAAma,IAAAC,aAAAxc,UAAAoC,KACA6pB,EAAA7pB,GAAA8pB,GAAA9pB,GAAAglB,KAAA8E,MAMA,IAAAC,GAAAF,EAAAX,sBAAA,GAAA/P,GACA0Q,GAAAhF,GAAA,qBAAA7nB,GACA+sB,EAAAxsB,IAAAP,GAAAsD,QAAA,SAAA2U,GACAA,MAEA8U,EAAAd,OAAAjsB,KAoEA,QAAAgtB,IAAA9qB,GACA,MAAAA,GAAA0T,OAAA,SAAAb,EAAAqP,GAEA,MADArP,GAAAqP,IAAA,EACArP,OAoCA,QAAAkY,IAAAnR,GACA,cAAAhS,KAAAgS,GACA,MAAAwC,GAAA4O,GAEA,IAAA3I,GAAAzI,EAAA+E,QAAA,KACA2H,EAAA1M,EAAAtC,UAAA,EAAA+K,GACAkE,EAAA3M,EAAAtC,UAAA+K,EAAA,EACA,QACAgH,OAAA5N,SAAA6K,EAAA,IACA9N,GAAA+N,GAIA,QAAA0E,IAAAC,EAAAhT,GAMA,OALAuI,GAAAyK,EAAA9hB,MAAA8hB,EAAA3K,IAAAzgB,OAAA,EAEAqrB,EAAAD,EAAA3K,IACAA,GAAA4K,EAAA,GAAAjT,MAEA3a,EAAA,EAAAsT,EAAAsa,EAAArrB,OAA2CvC,EAAAsT,EAAStT,IACpDgjB,GAAA4K,EAAA5tB,IAA4Bwe,OAAA,YAAkBwE,GAG9C,SACAE,MACAF,QAMA,QAAA6K,IAAA3O,EAAA4O,GAEA,GAAAC,GACAC,EACAC,EACAtT,GAAc6D,OAAA,YAKd,IAJAU,EAAAiK,WACAxO,EAAAwI,SAAA,GAGA2K,EAKA,GAJA5O,EAAAnI,MACAmI,EAAAnI,IAAAqL,KAEA4L,EAAA5L,EAAA,OAAA8L,cACAhP,EAAA4C,KAAA,CAEA,GADAmM,EAAAT,GAAAtO,EAAA4C,MACAmM,EAAAzR,MACA,MAAAyR,EAEA/O,GAAAiP,YACAjL,IAAA+K,EAAAnC,OACA9I,KAAAiL,EAAAhT,IAA2BuD,OAAA,aAAkBwP,EAAArT,UAE7CoT,EAAAE,EAAAnC,OAAA,MAEA5M,GAAAiP,YACAjL,IAAA,EACAF,KAAAgL,EAAArT,QAEAoT,EAAA,MAQA,IALA7O,EAAAsK,aACAtK,EAAAiP,UAAAT,GAAAxO,EAAAsK,WAAA7O,GACAoT,EAAA7O,EAAAsK,WAAA3d,MACAmiB,EAAA9O,EAAAsK,WAAAxG,IAAA,KAEA9D,EAAAiP,UAAA,CAEA,GADAF,EAAAT,GAAAtO,EAAA4C,MACAmM,EAAAzR,MACA,MAAAyR,EAEAF,GAAAE,EAAAnC,OACAkC,EAAAC,EAAAhT,GACAiE,EAAAiP,YACAjL,IAAA6K,EACA/K,KAAAgL,EAAArT,QAKAyF,EAAAlB,EAAAnI,KAEAmI,EAAA4C,KAAAiM,EAAA,IAAAC,CAEA,IAAA7qB,IAAgBqf,YAAa5d,QAC7B,QAAArB,KAAA2b,GAEA,GAAAxe,OAAAS,UAAAC,eAAAlB,KAAAgf,EAAA3b,GAAA,CACA,GAAA6qB,GAAA,MAAA7qB,EAAA,EACA,IAAA6qB,IAAAC,GAAA9qB,GAAA,CACA,GAAAiZ,GAAAqC,EAAAyP,GAAA/qB,EAEA,MADAiZ,GAAAoC,QAAA0P,GAAA1P,QAAA,KAAArb,EACAiZ,EACO4R,IAAAG,GAAAhrB,GACPJ,EAAAqf,SAAAjf,EAAA2I,MAAA,IAAAgT,EAAA3b,GAEAJ,EAAAyB,KAAArB,GAAA2b,EAAA3b,GAIA,MAAAJ,GAcA,QAAAqrB,IAAA7N,EAAA8N,GAEA9N,QACA8N,OACA,KACA,UAAAtX,MAAAwJ,EAAA8N,GACG,MAAA/sB,GACH,iBAAAA,EAAAnB,KACA,KAAAmB,EAOA,QALAgtB,GAAA,mBAAAC,yBACA,mBAAAC,6BACA,mBAAAC,+BACAC,kBACAC,EAAA,GAAAL,GACA1uB,EAAA,EAAmBA,EAAA2gB,EAAApe,OAAkBvC,GAAA,EACrC+uB,EAAAC,OAAArO,EAAA3gB,GAEA,OAAA+uB,GAAAE,QAAAR,EAAAjf,OAMA,QAAA0f,IAAAC,GAIA,OAHA5sB,GAAA4sB,EAAA5sB,OACA6sB,EAAA,GAAArc,aAAAxQ,GACAmU,EAAA,GAAAlK,YAAA4iB,GACApvB,EAAA,EAAiBA,EAAAuC,EAAYvC,IAC7B0W,EAAA1W,GAAAmvB,EAAAE,WAAArvB,EAEA,OAAAovB,GAGA,QAAAE,IAAAC,EAAA/f,GACA,MAAAgf,KAAAU,GAAAK,KAA6D/f,SAG7D,QAAAggB,IAAAC,EAAAjgB,GACA,MAAA8f,IAAAI,GAAAD,GAAAjgB,GAMA,QAAAmgB,IAAA1jB,GAIA,OAHA2jB,GAAA,GACAC,EAAA,GAAArjB,YAAAP,GACA1J,EAAAstB,EAAAtjB,WACAvM,EAAA,EAAiBA,EAAAuC,EAAYvC,IAC7B4vB,GAAA1oB,OAAA4oB,aAAAD,EAAA7vB,GAEA,OAAA4vB,GAIA,QAAAG,IAAAC,EAAAxX,GACA,sBAAAyX,YAGA,MAAAzX,GAAAmX,IACA,GAAAO,iBAAAC,kBAAAH,IAGA,IAAAI,GAAA,GAAAH,YACAI,EAAA,kBAAAD,GAAAL,kBACAK,GAAAE,UAAA,SAAA5uB,GACA,GAAAyB,GAAAzB,EAAA2V,OAAAlU,QAAA,EACA,OAAAktB,GACA7X,EAAArV,OAEAqV,GAAAmX,GAAAxsB,KAEAktB,EACAD,EAAAL,mBAAAC,GAEAI,EAAAD,kBAAAH,GAIA,QAAAO,IAAAC,EAAAhY,GACAuX,GAAAS,EAAA,SAAArB,GACA3W,EAAA2W,KAIA,QAAAsB,IAAAD,EAAAhY,GACA+X,GAAAC,EAAA,SAAAE,GACAlY,EAAAmY,GAAAD,MAKA,QAAAP,IAAAH,EAAAxX,GACA,sBAAAyX,YAGA,MAAAzX,IAAA,GAAA0X,iBAAAC,kBAAAH,GAGA,IAAAI,GAAA,GAAAH,WACAG,GAAAE,UAAA,SAAA5uB,GACA,GAAAyB,GAAAzB,EAAA2V,OAAAlU,QAAA,GAAA4P,aAAA,EACAyF,GAAArV,IAEAitB,EAAAD,kBAAAH,GAQA,QAAAY,IAAAC,GACA,MAAAF,IAAAE,GAGA,QAAAC,IAAAC,EAAAllB,EAAAmlB,GACA,MAAAD,GAAAtZ,YACAsZ,EAAAtZ,YAAA5L,EAAAmlB,GAEAD,EAAA7kB,MAAAL,EAAAmlB;CAGA,QAAAC,IAAAhlB,EAAA8kB,EAAAllB,EAAAmlB,EAAAxY,IACA3M,EAAA,GAAAmlB,EAAAD,EAAAntB,QAEAmtB,EAAAD,GAAAC,EAAAllB,EAAAmlB,IAEAb,GAAAY,EAAA,SAAAzkB,GACAL,EAAA+iB,OAAA1iB,GACAkM,MAIA,QAAA0Y,IAAAjlB,EAAAlG,EAAA8F,EAAAmlB,EAAAxY,IACA3M,EAAA,GAAAmlB,EAAAjrB,EAAAxD,UAEAwD,IAAAgU,UAAAlO,EAAAmlB,IAEA/kB,EAAAklB,aAAAprB,GACAyS,IAGA,QAAA4Y,IAAAxsB,EAAA4T,GAUA,QAAA6Y,KACAC,GAAAC,GAGA,QAAAC,KACA,GAAAX,GAAA5kB,EAAA+kB,KAAA,GACAN,EAAAE,GAAAC,EACArY,GAAAkY,GACAzkB,EAAAwlB,UAGA,QAAAF,KACA,GAAA1lB,GAAA6lB,EAAAC,EACAX,EAAAnlB,EAAA8lB,CACAD,KACAA,EAAAE,EACA5C,EAAA/iB,EAAArH,EAAAiH,EAAAmlB,EAAAK,GAEArC,EAAA/iB,EAAArH,EAAAiH,EAAAmlB,EAAAQ,GA3BA,GAAAK,GAAA,gBAAAjtB,GACA0O,EAAAue,EAAAjtB,EAAArC,OAAAqC,EAAAhB,KACA+tB,EAAAzf,KAAAwJ,IAAAoW,GAAAxe,GACAse,EAAA1f,KAAA6f,KAAAze,EAAAqe,GACAD,EAAA,EACAzlB,EAAA4lB,EAAA,GAAAG,IAAA,GAAAA,IAAAjf,YAEAic,EAAA6C,EAAAX,GAAAD,EAuBAM,KAGA,QAAAU,IAAAlsB,GACA,MAAAisB,IAAAnsB,KAAAE,GAGA,QAAAmsB,IAAAttB,GACA,IACA,MAAA8qB,IAAA9qB,GACG,MAAAlD,GACH,GAAA+W,GAAAoG,EAAAsT,GACA,0CACA,QAAY3V,MAAA/D,IAIZ,QAAA2Z,IAAAtS,EAAAuS,EAAA7Z,GACA,GAAA8Z,GAAAJ,GAAApS,EAAAlb,KACA,OAAA0tB,GAAA9V,MACAhE,EAAA8Z,EAAA9V,QAGAsD,EAAAvd,OAAA+vB,EAAA/vB,OACA,SAAA8vB,EACAvS,EAAAlb,KAAA0qB,GAAAgD,EAAAxS,EAAAyS,cACG,WAAAF,EACHvS,EAAAlb,KAAA+rB,GAAA2B,GAEAxS,EAAAlb,KAAA0tB,MAEAlB,IAAAkB,EAAA,SAAAnvB,GACA2c,EAAA0S,OAAA,OAAArvB,EACAqV,OAIA,QAAAia,IAAA3S,EAAAuS,EAAA7Z,GACA4Y,GAAAtR,EAAAlb,KAAA,SAAA8tB,GACA5S,EAAA0S,OAAA,OAAAE,EAEA5S,EAAAvd,OAAAud,EAAAlb,KAAAhB,MAAAkc,EAAAlb,KAAArC,QAAA,EACA,WAAA8vB,EACA9B,GAAAzQ,EAAAlb,KAAA,SAAA2qB,GACAzP,EAAAlb,KAAA2qB,EACA/W,MAEK,WAAA6Z,EACL5B,GAAA3Q,EAAAlb,KAAA,SAAA6qB,GACA3P,EAAAlb,KAAA6qB,EACAjX,MAGAA,MAKA,QAAAma,IAAA7S,EAAAuS,EAAA7Z,GACA,MAAAsH,GAAAE,KACAxH,SAEA,gBAAAsH,GAAAlb,KACAwtB,GAAAtS,EAAAuS,EAAA7Z,GAEAia,GAAA3S,EAAAuS,EAAA7Z,IAIA,QAAAoa,IAAAC,EAAAR,EAAA7Z,GAkCA,QAAAgZ,KACAsB,IACAD,EAAAtwB,SAAAuwB,IACAC,EACAva,EAAAua,GAEAva,KAtCA,IAAAqa,EAAAtwB,OACA,MAAAiW,IAGA,IACAua,GADAD,EAAA,CAGAD,GAAAhvB,QAAA,SAAAmvB,GASA,QAAAC,GAAAxa,GACAsa,EAAAta,EACAya,IACAA,IAAArT,EAAAtd,QACAivB,IAZA,GAAA3R,GAAAmT,EAAApuB,MAAAouB,EAAApuB,KAAAmb,aACArf,OAAAkH,KAAAorB,EAAApuB,KAAAmb,iBACAmT,EAAA,CAEA,KAAArT,EAAAtd,OACA,MAAAivB,IAWA,QAAAjuB,KAAAyvB,GAAApuB,KAAAmb,aACAiT,EAAApuB,KAAAmb,aAAA3e,eAAAmC,IACAovB,GAAAK,EAAApuB,KAAAmb,aAAAxc,GACA8uB,EAAAY,KAiBA,QAAAE,IAAAC,EAAAC,EAAAL,EAAAnY,EACA7a,EAAAszB,EAAAC,EAAAzF,GAEA,GAAA/G,GAAAsM,EAAAvQ,SAAAkQ,EAAAxQ,SAAAnG,KAEA,MADAxB,GAAA7a,GAAAgzB,EACAM,GAIA,IAAAE,GAAAH,EAAA9Q,cAAA8Q,GACAI,EAAA,WAAAJ,KAAAlQ,QACAiE,GAAAiM,EAAAG,GACArQ,EAAA,WAAA6P,GAAAxQ,SAAAwQ,EAAAxQ,SAAAW,QACAiE,GAAA4L,EAAAxQ,UACAkR,EAAA,MAAArpB,KAAA2oB,EAAAxQ,SAAAnG,IAEA,IAAAoX,IAAAtQ,GAAA2K,GAAA4F,EAAA,CACA,GAAA3R,GAAAiR,EAAApuB,IACAmd,GAAAD,KAAA0R,EACAzR,EAAAhL,IAAAic,EAAAxQ,SAAAvH,GACA+X,EAAAnF,GAAA9L,EAAA+L,GAGA,GAAArI,GAAAvS,GAAAmgB,EAAAvQ,SAAAkQ,EAAAxQ,SAAAM,SAAA,GAAAsQ,GAEAO,EAAA7F,IAAA2F,GAAAtQ,IACAsQ,GAAA,aAAAhO,EAAAtB,WACAsP,IAAAtQ,GAAA,eAAAsC,EAAAtB,UAEA,IAAAwP,EAAA,CACA,GAAAlb,GAAAoG,EAAA+U,GAEA,OADA/Y,GAAA7a,GAAAyY,EACA6a,IAGA,GAAAO,GAAAb,EAAAxQ,SAAAnG,GACA2W,GAAAxQ,SAAAM,SAAA2C,EAAA1C,KACAiQ,EAAAlM,YAAArB,EAAAqB,gBAEAuM,EAAAS,UACAd,EAAAxQ,SAAAsR,QAAAT,EAAAS,QAIA,IAQAC,GARAC,EAAAzR,EAAAyQ,EAAAxQ,UACAyR,EAAA7M,GAAA4L,EAAAxQ,SAAAwR,GAIAE,EAAAT,IAAAQ,EAAA,EACAR,EAAAQ,GAAA,GAKAF,GAFAF,IAAAG,EAEAC,EAGA7M,GAAA4L,EAAAxQ,SAAAqR,GAGAN,EAAAP,EAAAgB,EAAAC,EAAAF,GACA,EAAAG,EAAAl0B,EAAAszB,GAGA,QAAAa,IAAAnB,GACA,kBAAAA,EAAAxQ,SAAAM,SAAA,GAAAE,IAAA,GAAAxE,OAGA,QAAA4V,IAAAhB,EAAAP,EAAA3I,EAAAmK,EAAAC,EAAAzZ,EACA0Y,EAAA5Y,EAAA4Z,GAKA,QAAAC,GAAAxB,EAAAyB,EAAAjc,GAEA,GAAAwb,GAAAzR,EAAAyQ,EAAAxQ,UACAW,EAAAiE,GAAA4L,EAAAxQ,SAAAwR,EACA,kBAAArZ,IAAAwI,EAEA,MADAtI,GAAA4Z,GAAA5V,EAAA6V,GAAA,WACAlc,GAIA,IAAAmb,GAAA7F,GAAAqG,GAAAnB,EAEA,IAAAW,EAAA,CACA,GAAAlb,GAAAoG,EAAA+U,GAEA,OADA/Y,GAAA4Z,GAAAhc,EACAD,IAGA,GAAA0b,GAAA/Q,EAAA,GAEAoQ,GAAAP,EAAAgB,EAAA7Q,KAAA,EACA+Q,EAAAO,EAAAjc,GASA,QAAAmc,OACAC,IAAAC,GAAAN,GACAA,IAlCAnB,KAAA,GA0BA,IAAAtF,GAAAnT,EAAAma,UACAC,EAAA,GAAArY,IAEAkY,EAAA,EACAC,EAAAhC,EAAAtwB,MAQAswB,GAAAhvB,QAAA,SAAAmxB,EAAAP,GAEA,GAAAO,EAAAje,KAAAsQ,GAAA2N,EAAAje,KAAA,CACA,GAAAgB,GAAAid,EAAA7L,SAAA,0BAKA,YAJAe,GAAAnS,GAAAid,GAA4BzR,IAAA+Q,GAAQ,SAAA7b,EAAAS,GACpC2B,EAAA4Z,GAAAhc,GAAAS,EACAyb,MAKA,GAAA1Z,GAAA+Z,EAAAxS,SAAAvH,EACA8Z,GAAArwB,IAAAuW,IACA4Z,IACAE,EAAAj0B,IAAAma,GAAAvV,MAAAsvB,EAAAP,KAEAM,EAAA/yB,IAAAiZ,IAAA+Z,EAAAP,OAMAM,EAAAlxB,QAAA,SAAAkX,EAAAE,GAGA,QAAAga,OACA9Z,EAAAJ,EAAAxY,OACA2yB,IAEAP,IAGA,QAAAO,KACA,GAAA70B,GAAA0a,EAAAI,GACA6Z,EAAA30B,EAAA,GACAo0B,EAAAp0B,EAAA,EAEA,IAAAg0B,EAAA3vB,IAAAuW,GACAkY,GAAAC,EAAAiB,EAAAvzB,IAAAma,GAAA+Z,EAAAna,EACA4Z,EAAAQ,EAAA1B,EAAAzF,OACO,CAEP,GAAArI,GAAAvS,MAAA8hB,EAAAxS,SAAAM,SAAA,GAAAsQ,EACA4B,GAAAxS,SAAAM,SAAA2C,EAAA1C,KACAiS,EAAAlO,YAAArB,EAAAqB,gBACA0N,EAAAQ,EAAAP,EAAAQ,IAtBA,GAAA9Z,GAAA,CAyBA+Z,OA6BA,QAAAC,IAAA1W,GAIA,IACA,MAAA2W,MAAAC,MAAA5W,GACG,MAAA/c,GAEH,MAAA4zB,IAAAD,MAAA5W,IAIA,QAAA8W,IAAAC,GACA,IACA,MAAAJ,MAAAK,UAAAD,GACG,MAAA9zB,GAEH,MAAA4zB,IAAAG,UAAAD,IAIA,QAAAE,IAAAld,GACA,gBAAAmd,GACA,GAAA/W,GAAA,eACA+W,GAAAte,QAAAse,EAAAte,OAAAmF,QACAoC,EAAA+W,EAAAte,OAAAmF,MAAAjc,MAAAo1B,EAAAte,OAAAmF,MAAAoC,SAEApG,EAAAqG,EAAA+W,GAAAhX,EAAA+W,EAAAnmB,QAWA,QAAAqmB,IAAArT,EAAAD,EAAAY,GACA,OACAve,KAAA2wB,GAAA/S,GACAD,aACAuT,eAAA3S,EAAA,QACA4S,IAAAvT,EAAAuT,IACA9a,GAAAuH,EAAAvH,IAIA,QAAA+a,IAAAC,GACA,IAAAA,EACA,WAEA,IAAAzT,GAAA2S,GAAAc,EAAArxB,KAIA,OAHA4d,GAAAD,WAAA0T,EAAA1T,WACAC,EAAAW,QAAA,MAAA8S,EAAAH,eACAtT,EAAAuT,IAAAE,EAAAF,IACAvT,EAKA,QAAA0T,IAAAhX,GACA,IAAAA,EACA,MAAAA,EAEA,IAAA4F,GAAA5F,EAAAiX,YAAAC,YAAA,IAIA,OAHAlX,GAAAnI,IAAAmI,EAAAiX,YAAApc,UAAA,EAAA+K,EAAA,GACA5F,EAAA4C,KAAA5C,EAAAiX,YAAApc,UAAA+K,EAAA,SACA5F,GAAAiX,YACAjX,EAMA,QAAAmX,IAAAC,EAAA9mB,EAAA+mB,EAAA/d,GACA+d,EAIA/d,EAHA8d,EAEK,gBAAAA,GACLA,EAEA9G,GAAA8G,EAAA9mB,GAJAgf,IAAA,KAAiChf,UAOjC8mB,EAEK,gBAAAA,GACLvG,GAAAuG,EAAA,SAAA1G,GACApX,EAAAmY,GAAAf,MAGApX,EAAA8d,GANA9d,EAAA,IAWA,QAAAge,IAAAtX,EAAAvE,EAAA8b,EAAAnD,GAOA,QAAApY,OACAC,IAAA0E,EAAAtd,QAAA+wB,GACAA,IAIA,QAAAoD,GAAAxX,EAAAY,GACA,GAAA6W,GAAAzX,EAAAa,aAAAD,GACA0S,EAAAmE,EAAAnE,OACArT,EAAAsX,EAAAG,YAAAC,IAAA/1B,IAAA0xB,EACArT,GAAA2X,UAAA,SAAAp1B,GACAi1B,EAAAL,KAAA50B,EAAA2V,OAAAlU,OAAAmzB,KACApb,KAlBA,GAAA2E,GAAAnf,OAAAkH,KAAAsX,EAAAa,iBACA,KAAAF,EAAAtd,OACA,MAAA+wB,OAEA,IAAAnY,GAAA,CAkBA0E,GAAAhc,QAAA,SAAAic,GACAnF,EAAAkF,aAAAlF,EAAAiF,aACA8W,EAAAxX,EAAAY,IAEAZ,EAAAa,aAAAD,GAAAE,MAAA,EACA9E,OASA,QAAA6b,IAAAlc,EAAA0b,GACA,MAAAne,IAAAoS,IAAA3P,EAAA/Y,IAAA,SAAAk1B,GACA,GAAAA,EAAA9X,KAAA8X,EAAA9X,IAAAa,aAAA,CACA,GAAAkX,GAAAv2B,OAAAkH,KAAAovB,EAAA9X,IAAAa,aACA,OAAA3H,IAAAoS,IAAAyM,EAAAn1B,IAAA,SAAAge,GACA,GAAA6W,GAAAK,EAAA9X,IAAAa,aAAAD,EACA,YAAA6W,GAAA,CAGA,GAAAL,GAAAK,EAAAL,KACA9mB,EAAAmnB,EAAApE,YACA,WAAAna,IAAA,SAAApF,GACAqjB,GAAAC,EAAA9mB,EAAA+mB,EAAA,SAAA3xB,GACAoyB,EAAA9X,IAAAa,aAAAD,GAAA4K,GACA/Q,EAAAgd,GAAA,2BACe/xB,SAEfoO,gBAQA,QAAAkkB,IAAA7T,EAAA1M,EAAA8f,GAQA,QAAAvb,KACAic,IACAA,GACAC,IAIA,QAAAA,KACAC,EAAA90B,QAGA80B,EAAAxzB,QAAA,SAAA2uB,GACA,GAAA8E,GAAAC,EAAA50B,MAAA,aAAAw0B,MACAK,YAAAC,MACAjF,EAAA,KAAAA,EAAA,aACA8E,GAAAR,UAAA,SAAAp1B,GACA,GAAAy1B,GAAAz1B,EAAA2V,OAAAlU,MACAg0B,IAEAO,EAAAlL,OAAAgG,MAzBA,GAAA6E,MACAM,EAAAlB,EAAAG,YAAAgB,IACAF,EAAAjB,EAAAG,YAAAC,IACAU,EAAAd,EAAAG,YAAAiB,IACAV,EAAA9T,EAAA9gB,MA2BA8gB,GAAAxf,QAAA,SAAAwY,GACA,GAAA1Z,GAAAg1B,EAAAh1B,MAAA,eACAY,EAAAoT,EAAA,KAAA0F,CACA1Z,GAAAm1B,OAAAv0B,GAAAuzB,UAAA,SAAAp1B,GACA,GAAAq0B,GAAAr0B,EAAA2V,OAAAlU,MACA,oBAAA4yB,GACA,MAAA7a,IAEAyc,GAAAnL,OAAAuJ,EAEA,IAAAgC,GAAAR,EAAA50B,MAAA,OACAq1B,WAAAR,YAAAS,KAAAlC,GAEAgC,GAAAjB,UAAA,SAAAoB,GACA,GAAAH,GAAAG,EAAA7gB,OAAAlU,MACA,IAAA40B,EAAA,CACA,GAAAvF,GAAAuF,EAAA13B,MAAA83B,UAAAvX,MAAA,QACAyW,GAAA3xB,KAAA8sB,GACA+E,EAAA/K,OAAAuL,EAAAK,YACAL,EAAAM,eAEAnd,SAOA,QAAAod,IAAAC,EAAAC,EAAAC,GACA,IACA,OACAhC,IAAA8B,EAAAG,YAAAF,EAAAC,IAEG,MAAAhgB,GACH,OACA+D,MAAA/D,IAOA,QAAAkgB,IAAAC,EAAAzZ,EAAAxE,EAAAuP,EAAAqO,EAAA/f,GAwCA,QAAAqgB,KAEA,GAAAL,IACAM,GAAAlB,GACAf,GACAkC,GAAAlB,GACAmB,IAEAC,EAAAX,GAAAC,EAAAC,EAAA,YACA,OAAAS,GAAAzc,MACAhE,EAAAygB,EAAAzc,QAEAia,EAAAwC,EAAAxC,IACAA,EAAAyC,QAAAxD,GAAAld,GACAie,EAAA0C,UAAAzD,GAAAld,GACAie,EAAA2C,WAAAnR,EACAoR,EAAA5C,EAAAG,YAAAkC,IACAQ,EAAA7C,EAAAG,YAAAgB,IACA2B,EAAA9C,EAAAG,YAAAC,IACA2C,EAAA/C,EAAAG,YAAAiB,IACA4B,EAAAhD,EAAAG,YAAAoC,IAEAS,EAAA34B,IAAAk4B,IAAAlC,UAAA,SAAAp1B,GACAg4B,EAAAh4B,EAAA2V,OAAAlU,OACAw2B,SAGAC,GAAA,SAAAnhB,GACA,MAAAA,IACAohB,GAAA,EACArhB,EAAAC,QAEAqhB,QAIA,QAAAC,KACAC,GAAA,EACAL,IAGA,QAAAM,KACA7F,GAAAwE,EAAAsB,WAAArH,EAAA3I,EAAAmK,EACAoC,EAAA5b,EAAA0Y,EAAA5Y,EAAAof,GAGA,QAAAJ,KACAD,GAAAM,IAKAN,EAAAS,UAAAC,EACAX,EAAAvX,IAAAwX,IAGA,QAAAI,KAQA,QAAA5e,OACAmf,IAAAxH,EAAAtwB,QACA03B,IAIA,QAAAK,GAAApC,GACA,GAAA1V,GAAAwT,GAAAkC,EAAA7gB,OAAAlU,OAEAqf,IACA6R,EAAAryB,IAAAwgB,EAAAvH,GAAAuH,GAEAtH,IAlBA,GAAA2X,EAAAtwB,OAqBA,OAjBA83B,GAAA,EAiBAr6B,EAAA,EAAAsT,EAAAuf,EAAAtwB,OAA0CvC,EAAAsT,EAAStT,IAAA,CACnD,GAAAgzB,GAAAH,EAAA7yB,EACA,IAAAgzB,EAAAjc,KAAAsQ,GAAA2L,EAAAjc,KACAmE,QADA,CAIA,GAAAiE,GAAAka,EAAAv4B,IAAAkyB,EAAAxQ,SAAAvH,GACAkE,GAAA2X,UAAAwD,IAIA,QAAArS,KACA4R,IAIAU,GAAAC,OAAAtQ,EAAAuQ,MAAAl6B,MACAiY,EAAA,KAAAqC,IAGA,QAAA6f,GAAAlI,EAAAha,GAEA,GAAA2G,GAAAoa,EAAAz4B,IAAA0xB,EACArT,GAAA2X,UAAA,SAAAp1B,GACA,GAAAA,EAAA2V,OAAAlU,OAOAqV,QAPA,CACA,GAAAC,GAAAoG,EAAA8b,GACA,uCACAnI,EACA/Z,GAAA+F,OAAA,IACAhG,EAAAC,KAOA,QAAAmhB,GAAAgB,GAoBA,QAAA1f,OACAC,IAAA0f,EAAAt4B,QACAq4B,EAAAniB,GAnBA,GAAAoiB,KAWA,IAVAhI,EAAAhvB,QAAA,SAAAmvB,GACAA,EAAApuB,MAAAouB,EAAApuB,KAAAmb,cACArf,OAAAkH,KAAAorB,EAAApuB,KAAAmb,cAAAlc,QAAA,SAAAi3B,GACA,GAAAhb,GAAAkT,EAAApuB,KAAAmb,aAAA+a,EACAhb,GAAAE,MACA6a,EAAAn1B,KAAAoa,EAAA0S,aAKAqI,EAAAt4B,OACA,MAAAq4B,IAEA,IACAniB,GADA0C,EAAA,CAQA0f,GAAAh3B,QAAA,SAAA2uB,GACAkI,EAAAlI,EAAA,SAAAuI,GACAA,IAAAtiB,IACAA,EAAAsiB,GAEA7f,QAKA,QAAAqY,GAAAP,EAAAgB,EAAAC,EAAAF,EACAiH,EAAA9G,EAAAO,EAAAjc,GAEAwa,EAAAxQ,SAAAD,WAAAyR,EACAhB,EAAAxQ,SAAAW,QAAA8Q,CAEA,IAAA/U,GAAA8T,EAAApuB,IACAsa,GAAAnI,IAAAic,EAAAxQ,SAAAvH,GACAiE,EAAA4C,KAAAkR,EAAAxQ,SAAAnG,IAEA0X,IACA7U,EAAAiK,UAAA,EAGA,IAAA8R,GAAA/b,EAAAa,cACArf,OAAAkH,KAAAsX,EAAAa,cAAAxd,MACA,OAAA04B,GACAC,EAAAlI,EAAAgB,EAAAC,EACA+G,EAAAvG,EAAAjc,IAGA4hB,GAAAlG,EACAyF,QAEAwB,GAAAnI,EAAAgB,EAAAC,EACA+G,EAAAvG,EAAAjc,IAGA,QAAA2iB,GAAAnI,EAAAgB,EAAAC,EACA+G,EAAAvG,EAAAjc,GASA,QAAA4iB,GAAA15B,GACA,GAAA25B,GAAArI,EAAAlM,eAEAkU,IAAA9Q,EAAAyC,kBACA0O,IAAAjiB,OAAAiL,EAAA2O,EAAAxQ,YAGA6Y,KAAA94B,QACA20B,GAAAmE,EAAArI,EAAAxQ,SAAAvH,GAAAwb,GAGAjU,EAAAuT,IAAAr0B,EAAA2V,OAAAlU,MAGA,IAAAm4B,GAAAzF,GAAArT,EAAAwR,EACAC,GACAsH,EAAAlC,EAAAnX,IAAAoZ,EACAC,GAAAzE,UAAA0E,EAGA,QAAAC,GAAA/5B,GAEAA,EAAAg6B,iBACAh6B,EAAAi6B,iBACA,IAAAh5B,GAAA22B,EAAA32B,MAAA,eACAi5B,EAAAj5B,EAAAm1B,OAAA5Y,EAAAiX,YACAyF,GAAA9E,UAAA,SAAAp1B,GACA,GAAAm6B,GAAAvC,EAAApX,IAAAhD,EAAAxd,EAAA2V,OAAAlU,OACA04B,GAAA/E,UAAAsE,GAIA,QAAAI,KACA3gB,EAAA4Z,IACAha,IAAA,EACAQ,GAAAuH,EAAAvH,GACAoB,IAAAmG,EAAAnG,KAEAgY,EAAAryB,IAAAgxB,EAAAxQ,SAAAvH,GAAA+X,EAAAxQ,UACAsZ,EAAA9I,EAAAxQ,EAAAuT,IAAAvd,GA9CA,GAAA0G,GAAA8T,EAAApuB,KACA4d,EAAAwQ,EAAAxQ,QAEAtD,GAAAiX,YAAA3T,EAAAvH,GAAA,KAAAuH,EAAAnG,UACA6C,GAAAnI,UACAmI,GAAA4C,IA4CA,IAAA+Z,GAAAvC,EAAApX,IAAAhD,EAEA2c,GAAA/E,UAAAsE,EACAS,EAAAE,QAAAN,EAGA,QAAAP,GAAAlI,EAAAgB,EAAAC,EACA+G,EAAAvG,EAAAjc,GAQA,QAAAwjB,KACA7gB,IAAA0E,EAAAtd,QACA44B,EAAAnI,EAAAgB,EAAAC,EACA+G,EAAAvG,EAAAjc,GAIA,QAAAyjB,KACA9gB,IACA6gB,IAdA,GAAA9c,GAAA8T,EAAApuB,KAEAuW,EAAA,EACA0E,EAAAnf,OAAAkH,KAAAsX,EAAAa,aAcAF,GAAAhc,QAAA,SAAAN,GACA,GAAAuc,GAAAkT,EAAApuB,KAAAmb,aAAAxc,EACA,IAAAuc,EAAAE,KAOA7E,IACA6gB,QARA,CACA,GAAAp3B,GAAAkb,EAAAlb,WACAkb,GAAAlb,KACAkb,EAAAoc,OAAAhe,SAAA8V,EAAA,GACA,IAAAxB,GAAA1S,EAAA0S,MACA2J,GAAA3J,EAAA5tB,EAAAq3B,MAUA,QAAAH,GAAA9I,EAAA+C,EAAAvd,GASA,QAAA0C,OACAkhB,IAAAC,EAAA95B,QACAiW,IAIA,QAAAtW,GAAA4d,GACA,GAAA0S,GAAAQ,EAAApuB,KAAAmb,aAAAD,GAAA0S,OACArT,EAAAqa,EAAAtX,KACA6T,MACAoC,UAAA3F,EAAA,KAAAuD,GAGA5W,GAAA2X,UAAA5b,EACAiE,EAAA4c,QAAA,SAAAr6B,GAIAA,EAAAg6B,iBACAh6B,EAAAi6B,kBACAzgB,KA3BA,GAAAkhB,GAAA,EACAC,EAAA37B,OAAAkH,KAAAorB,EAAApuB,KAAAmb,iBAEA,KAAAsc,EAAA95B,OACA,MAAAiW,IA0BA,QAAAxY,GAAA,EAAmBA,EAAAq8B,EAAA95B,OAAsBvC,IACzCkC,EAAAm6B,EAAAr8B,IAIA,QAAAm8B,GAAA3J,EAAA5tB,EAAA4T,GAGA,GAAAojB,GAAArC,EAAApC,MAAA3E,EACAoJ,GAAA9E,UAAA,SAAAp1B,GACA,GAAAy1B,GAAAz1B,EAAA2V,OAAAlU,MACA,IAAAg0B,EACA,MAAA3e,IAEA,IAAA8jB,IACA9J,SACA8D,KAAA1xB,GAEAi3B,EAAAtC,EAAArX,IAAAoa,EACAT,GAAA/E,UAAAte,GAlWA,OATAie,GACA4C,EACAC,EACAC,EACAC,EACAC,EACA8C,EACA7C,EARA7G,EAAA1T,EAAApE,KAUA/a,EAAA,EAAAsT,EAAAuf,EAAAtwB,OAAwCvC,EAAAsT,EAAStT,IAAA,CACjD,GAAAkf,GAAA2T,EAAA7yB,EACAkf,GAAAnI,KAAAsQ,GAAAnI,EAAAnI,OAGAmI,EAAA2T,EAAA7yB,GAAA6tB,GAAA3O,EAAAvE,EAAAma,WACA5V,EAAA1C,QAAA+f,IACAA,EAAArd,IAIA,GAAAqd,EACA,MAAA/jB,GAAA+jB,EAGA,IAAAvC,IAAA,EACAI,EAAA,EACAvf,EAAA,GAAAzX,OAAAyvB,EAAAtwB,QACA8xB,EAAA,GAAA3X,IACAmd,GAAA,EACAxH,EAAAnI,EAAAuQ,MAAA+B,YAAA,eAEA5J,IAAAC,EAAAR,EAAA,SAAA5Z,GACA,MAAAA,GACAD,EAAAC,OAEAogB,OAiVA,QAAA4D,IAAA7F,EAAA8F,EAAArS,EAAAsS,EAAAC,GAiBA,QAAAC,GAAAn7B,GACAo7B,EAAAp7B,EAAA2V,OAAAlU,OACA45B,GACAH,EAAAG,EAAAD,EAAAE,GAIA,QAAAC,GAAAv7B,GACAq7B,EAAAr7B,EAAA2V,OAAAlU,OACA25B,GACAF,EAAAG,EAAAD,EAAAE,GAIA,QAAAE,KACA,IAAAH,EAAAx6B,OACA,MAAAq6B,IAGA,IACAO,GADAC,EAAAL,IAAAx6B,OAAA,EAEA,IAAAm6B,KAAAW,MACA,IACAF,EAAA3F,YAAAC,MAAA2F,EAAAV,EAAAW,OACA,EAAAX,EAAAY,WACO,MAAA57B,GACP,iBAAAA,EAAAnB,MAAA,IAAAmB,EAAAkmB,KACA,MAAAgV,SAIAO,GAAA3F,YAAA+F,WAAAH,GAAA,EAEAV,GAAAS,EACAJ,EAAA,KACAD,EAAA,KACAlG,EAAA4G,OAAAd,EAAAC,GAAA7F,UAAA+F,EACAjG,EAAAvtB,WAAAqzB,EAAAC,GAAA7F,UAAAmG,EAGA,QAAAQ,GAAA/7B,GACA,GAAAq2B,GAAAr2B,EAAA2V,OAAAlU,MACA,OAAA40B,OAIA6E,IAAA7E,EAAAx0B,MAAAw0B,EAAA13B,OAAA03B,GAHA6E,IAnDA,GAIAG,GACAD,EACAE,EANAU,EAAA,kBAAA9G,GAAA4G,QACA,kBAAA5G,GAAAvtB,YACAszB,EAAA,IAAAtS,CAuDAqT,IACAV,GAAoB3E,SAAA6E,GACpBtG,EAAA4G,OAAAd,EAAAC,GAAA7F,UAAA+F,EACAjG,EAAAvtB,WAAAqzB,EAAAC,GAAA7F,UAAAmG,GACG5S,EACHuM,EAAAoB,WAAA0E,EAAA,QAAA5F,UAAA2G,EAEA7G,EAAAoB,WAAA0E,GAAA5F,UAAA2G,EAKA,QAAAD,IAAA5G,EAAA8F,EAAAiB,GASA,QAAAF,GAAA/7B,GACA,GAAAq2B,GAAAr2B,EAAA2V,OAAAlU,MACA40B,IACAl1B,EAAA6C,KAAAqyB,EAAA13B,OACA03B,EAAAM,YAEAsF,GACAtmB,QACAlU,OAAAN,KAhBA,qBAAA+zB,GAAA4G,OAGA,YADA5G,EAAA4G,OAAAd,GAAA5F,UAAA6G,EAIA,IAAA96B,KAgBA+zB,GAAAoB,WAAA0E,GAAA5F,UAAA2G,EAGA,QAAAG,IAAA/xB,EAAAmlB,EAAA6M,EAAAt6B,EAAA8mB,GACA,IACA,GAAAxe,GAAAmlB,EACA,MAAA3G,GACAmN,YAAAC,MAAAzG,EAAAnlB,GAAAgyB,GAAA,GAEArG,YAAAC,MAAA5rB,EAAAmlB,GAAA,GAAA6M,EAEK,IAAAhyB,EACL,MAAAwe,GACAmN,YAAAsG,WAAAjyB,GAEA2rB,YAAA+F,WAAA1xB,EAEK,IAAAmlB,EACL,MAAA3G,GACAmN,YAAA+F,WAAAvM,GAAA6M,GAEArG,YAAAsG,WAAA9M,GAAA6M,EAEK,IAAAt6B,EACL,MAAAi0B,aAAAS,KAAA10B,GAEG,MAAA7B,GACH,OAAY8a,MAAA9a,GAEZ,YAGA,QAAAq8B,IAAApjB,EAAA4d,EAAA/f,GA2CA,QAAAwlB,GAAAxb,EAAAwU,EAAAhD,GACA,GAAAzwB,GAAAif,EAAAvH,GAAA,KAAA+Y,CACAiK,GAAAn9B,IAAAyC,GAAAuzB,UAAA,SAAAp1B,GAEA,GADAs1B,EAAA9X,IAAAgX,GAAAx0B,EAAA2V,OAAAlU,QACAwX,EAAAwJ,UAAA,CACA,GAAAA,GAAAF,EAAAzB,EACA2B,GAAA5hB,SACAy0B,EAAA9X,IAAA2J,WAAA1E,GAGAqS,GAAAQ,EAAA9X,IAAAvE,EAAA8b,IAIA,QAAAyH,GAAAlK,EAAAxR,GACA,GAAAwU,IACA/b,GAAAuH,EAAAvH,GACA1X,IAAAif,EAAAvH,GACA5a,OACAgc,IAAA2X,IAGA7Q,EAAAX,EAAAW,OACA,QAAAxI,EAAAwI,SACAtI,EAAAnV,KAAAsxB,GAEA7T,GACA6T,EAAA32B,MAAA8iB,SAAA,EACA6T,EAAA9X,IAAA,MACOvE,EAAAiF,cACPoe,EAAAxb,EAAAwU,EAAAhD,KAEK7Q,GAAAgH,KAAA,IACLtP,EAAAnV,KAAAsxB,GACArc,EAAAiF,cACAoe,EAAAxb,EAAAwU,EAAAhD,IAKA,QAAAnY,GAAAsiB,GACA,OAAAn+B,GAAA,EAAAsT,EAAA6qB,EAAA57B,OAA6CvC,EAAAsT,GAC7CuH,EAAAtY,SAAA6nB,EADsDpqB,IAAA,CAItD,GAAAo+B,GAAAD,EAAAn+B,GACAwiB,EAAAwT,GAAAoI,GACApK,EAAAxR,EAAAD,UACA2b,GAAAlK,EAAAxR,IAIA,QAAAoa,GAAAyB,EAAAF,EAAApG,GACAA,IAGAlc,EAAAsiB,GACAtjB,EAAAtY,OAAA6nB,GACA2N,EAAAM,YAIA,QAAAwE,GAAAn7B,GACA,GAAAmB,GAAAnB,EAAA2V,OAAAlU,MACAwX,GAAA0P,aACAxnB,IAAAmhB,WAEAnI,EAAAhZ,GAGA,QAAAy7B,KACA9lB,EAAA,MACAoS,WAAAuP,EACAr3B,OAAA6X,EAAAwP,KACAU,KAAAhQ,IAIA,QAAA0jB,KACA5jB,EAAAkF,YACAkX,GAAAlc,EAAAF,EAAAiV,QAAAjX,KAAA2lB,GAEAA,IA5HA,GAAAzyB,GAAA,YAAA8O,MAAA6jB,SACAxN,EAAA,UAAArW,MAAA8jB,OACAl7B,EAAA,OAAAoX,MAAApX,IACA4mB,EAAAxP,EAAAwP,MAAA,EACAC,EAAA,gBAAAzP,GAAAyP,MAAAzP,EAAAyP,OAAA,EACAyT,EAAAljB,EAAA+jB,iBAAA,EAEAhC,EAAAkB,GAAA/xB,EAAAmlB,EAAA6M,EAAAt6B,EAAAoX,EAAA0P,YACAsU,EAAAjC,KAAAlgB,KACA,IAAAmiB,IAAA,cAAAA,EAAAp+B,MACA,IAAAo+B,EAAA/W,MAGA,MAAApP,GAAAqG,EAAA+W,GACA+I,EAAAp+B,KAAAo+B,EAAA/f,SAGA,IAAA4Z,IAAAM,GAAAlB,GAAAoB,GAEAre,GAAAkF,aACA2Y,EAAA9yB,KAAAmxB,GAEA,IAAAoC,GAAAX,GAAAC,EAAAC,EAAA,WACA,IAAAS,EAAAzc,MACA,MAAAhE,GAAAygB,EAAAzc,MAEA,IAAAia,GAAAwC,EAAAxC,GACAA,GAAA2C,WAAAmF,EACA9H,EAAAyC,QAAAxD,GAAAld,EACA,IAKA2hB,GALAd,EAAA5C,EAAAG,YAAAkC,IACAnB,EAAAlB,EAAAG,YAAAgB,IACA6B,EAAAhD,EAAAG,YAAAoC,IACAiF,EAAAtG,EAAAh1B,MAAA,eACAkY,IAgGA,OA7FA4e,GAAA34B,IAAAk4B,IAAAlC,UAAA,SAAAp1B,GACAy4B,EAAAz4B,EAAA2V,OAAAlU,OAAAg3B,UA4FAwE,GAAA,IAAAvU,EAAA,OAGAA,KAAA,EACAoT,GAAAnE,EAAAqD,EAAAG,OAIAJ,IAAApD,EAAAqD,EAAA/hB,EAAA0P,WAAAD,EAAAD,EAAAyS,GAeA,QAAAgC,IAAAnI,GACA,UAAAre,IAAA,SAAApF,GACA,GAAA+d,GAAAvC,IAAA,KACArP,EAAAsX,EAAAG,YAAAiI,IAAA3c,IAAA6O,EAAA,MAEA5R,GAAA2X,UAAA,WACA,GAAAgI,GAAAC,UAAAC,UAAAvT,MAAA,iBACAwT,EAAAF,UAAAC,UAAAvT,MAAA,SAGAzY,GAAAisB,IAAAH,GACA5gB,SAAA4gB,EAAA,aAGArI,EAAAyC,QAAA,SAAAx3B,GAGAA,EAAAg6B,iBACAh6B,EAAAi6B,kBACA3oB,GAAA,MAEGgY,MAAA,WACH,WAIA,QAAAkU,IAAAzI,EAAAnD,GACA,GAAA3wB,GAAA8zB,EAAAG,YAAAkC,IAAAn2B,MAAA,iBACAA,GAAAw0B,MAAAK,YAAAS,KAAA,MAAAnB,UAAA,SAAAp1B,GACA4xB,EAAA5xB,EAAA2V,OAAAlU,SAWA,QAAAg8B,IAAApnB,EAAAU,EAAAS,EAAAkmB,GACA,IACArnB,EAAAU,EAAAS,GACG,MAAAT,GAIH2mB,EAAA/hB,KAAA,QAAA5E,IAIA,QAAA4mB,OACAC,IAAA/rB,GAAAhR,SAGA+8B,IAAA,EACA/rB,GAAA4X,WAGA,QAAAoU,IAAAC,EAAAhnB,EAAA4mB,GACA7rB,GAAA7N,KAAA,WACA85B,EAAA,SAAA/mB,EAAAS,GACAimB,GAAA3mB,EAAAC,EAAAS,EAAAkmB,GACAE,IAAA,EACAnsB,GAAA,WACAksB,GAAAD,SAIAC,KAGA,QAAAzW,IAAAjO,EAAAuP,EAAA5M,EAAAib,GA2CA,QAAAqE,GAAAyB,EAAAF,EAAApG,GAQA,QAAA0H,GAAAjd,EAAAkd,GACA,GAAAhgB,GAAA/E,EAAA8N,cAAAiX,EAAAld,EAAA7H,EACAglB,GAAAjgB,EAAAqW,IAAAvT,EAAAuT,GAEA,IAAA6J,GAAAnpB,EAAAiJ,EACA,uBAAAkgB,GACAjlB,EAAAsN,SAAA2X,QAGAA,IACAC,IACAC,GACAjlB,EAAAnV,KAAAga,GAIA/E,EAAAkF,aAAAlF,EAAAiF,aACA4W,GAAAkJ,EAAA/kB,EAAA8b,EAAA,WACAM,IAAArX,GAAA/E,EAAAiV,QAAAjX,KAAA,WACAgC,EAAA0N,SAAA3I,OAIA/E,EAAA0N,SAAA3I,KAKA,QAAAqgB,KACA,OAAA//B,GAAA,EAAAsT,EAAA0sB,EAAAz9B,OAA+CvC,EAAAsT,GAC/CusB,IAAAzV,EADwDpqB,IAAA,CAIxD,GAAA0/B,GAAAM,EAAAhgC,EACA,IAAA0/B,EAAA,CAGA,GAAAld,GAAAyd,EAAAjgC,EACAy/B,GAAAjd,EAAAkd,IAGAG,IAAAzV,GACA2N,EAAAM,WAjDA,GAAAN,GAAAsG,EAAA97B,OAAA,CAIA,GAAAy9B,GAAA,GAAA58B,OAAAi7B,EAAA97B,QACA09B,EAAA,GAAA78B,OAAAi7B,EAAA97B,QAmDA4Y,EAAA,CACAgjB,GAAAt6B,QAAA,SAAAxD,EAAAL,GACA,GAAAkf,GAAAgX,GAAA71B,GACA01B,EAAAsI,EAAAr+B,EACAkgC,GAAAhhB,EAAA6W,EAAA,SAAAvT,EAAAkd,GACAO,EAAAjgC,GAAAwiB,EACAwd,EAAAhgC,GAAA0/B,IACAvkB,IAAAkjB,EAAA97B,QACAw9B,SAMA,QAAAI,GAAAjhB,EAAA6W,EAAAvT,EAAA8Q,GACA,GAAA9Q,EAAAuT,QAEA,MAAAzC,IAGA,IAAA9Q,EAAAD,aAAArD,EAAA4C,KAEA,MAAAwR,GAAA9Q,EAAAtD,EAIA,IAAAkhB,GAAAlhB,EAAAnI,IAAA,KAAAyL,EAAAD,WACApD,EAAA8e,EAAAn9B,IAAAs/B,EACAjhB,GAAA2X,UAAA,SAAAp1B,GACA4xB,EAAA9Q,EAAA0T,GAAAx0B,EAAA2V,OAAAlU,UAIA,QAAA+8B,GAAAhhB,EAAA6W,EAAAzC,GACA,GAAA+M,MAAA37B,IAAAwa,EAAAnI,KACA,MAAAuc,IAGA,IAAA9Q,GAAA8d,EAAAx/B,IAAAoe,EAAAnI,IACA,OAAAyL,GACA2d,EAAAjhB,EAAA6W,EAAAvT,EAAA8Q,QAGA+F,EAAAv4B,IAAAoe,EAAAnI,KAAA+f,UAAA,SAAAp1B,GACA8gB,EAAAwT,GAAAt0B,EAAA2V,OAAAlU,QACAm9B,EAAAt+B,IAAAkd,EAAAnI,IAAAyL,GACA2d,EAAAjhB,EAAA6W,EAAAvT,EAAA8Q,KAIA,QAAAsH,KACAjgB,EAAAsN,SAAA,MACApN,UACAoQ,SAAA0U,IAIA,QAAApB,MACA5jB,EAAA4lB,YAAA5lB,EAAAkF,YAGAkX,GAAAlc,GAAAlC,KAAAiiB,GAEAA,IAhKA,GAFAjgB,EAAAjD,EAAAiD,GAEAA,EAAA4lB,WAAA,CACA,GAAAtlB,GAAAqC,EAAA,IAAA8E,GAGA,OAFAmY,IAAApd,YAAAG,EAAArC,EAAAiP,EAAAvP,GACA4f,GAAAC,OAAAld,IAEA0K,OAAA,WACAuS,GAAApS,eAAA7K,EAAArC,KAKA,GAAAolB,GAAA1lB,EAAA6lB,SAAA,GAAAC,IAAA9lB,EAAA6lB,QAEA7lB,GAAA+lB,MAAA/lB,EAAA+lB,OAAA,CACA,IAAAf,GAAAhlB,EAAA+lB,MAEAtW,EAAA,SAAAzP,KAAAyP,OAAA,CACA,KAAAA,IACAA,EAAA,EAEA,IAAA0V,EAEAA,GADA,eAAAnlB,GACAA,EAAAgmB,cACG,cAAAhmB,KAEHA,EAAAmlB,UAKA,IAKArJ,GACA6C,EACAD,EACA4E,EARApjB,KACAglB,EAAA,EACAppB,EAAA6I,EAAA3E,GACA2lB,EAAA,GAAA5jB,IAmIAkkB,GAAA9H,GAAAlB,GACAjd,GAAAkF,aACA+gB,EAAAl7B,KAAAmxB,GAEA,IAAAoC,GAAAX,GAAAC,EAAAqI,EAAA,WACA,IAAA3H,EAAAzc,MACA,MAAA7B,GAAAsN,SAAAgR,EAAAzc,MAEAia,GAAAwC,EAAAxC,IACAA,EAAAyC,QAAAxD,GAAA/a,EAAAsN,UACAwO,EAAA2C,WAAAmF,EAEAjF,EAAA7C,EAAAG,YAAAgB,IACAyB,EAAA5C,EAAAG,YAAAkC,IACAmF,EAAA3E,EAAA32B,MAAA,cAEA,IAAA+5B,GAAA/hB,EAAA+lB,QAAA/lB,EAAA0P,WACAmN,YAAA+F,WAAA5iB,EAAA+lB,OAAA,OAEAjE,IAAAnD,EAAAoD,EAAA/hB,EAAA0P,WAAAD,EAAAwS,GAOA,QAAAiE,IAAAlmB,EAAAnC,GACA,GAAA0R,GAAAvqB,IAEA4/B,IAAA,SAAAuB,GACAC,GAAA7W,EAAAvP,EAAAmmB,IACGtoB,EAAA0R,EAAA/d,aAGH,QAAA40B,IAAA7W,EAAAvP,EAAAnC,GAQA,QAAAwoB,GAAA5qB,GACA,GAAAijB,GAAAjjB,EAAA6qB,kBAAAnI,IAAoDoI,QAAA,MACpD9qB,GAAA6qB,kBAAArJ,IAAwCuJ,eAAA,IACxCC,YAAA,6BAAkDC,QAAA,IAClDjrB,EAAA6qB,kBAAApK,IAAwCqK,QAAA,WACxC9qB,EAAA6qB,kBAAAjI,IAAsCkI,QAAA,KAAAC,eAAA,IACtC/qB,EAAA6qB,kBAAApC,IAGAxF,EAAA+H,YAAA,mCAA8DC,QAAA,IAG9DjrB,EAAA6qB,kBAAAlI,IAAuCmI,QAAA,OAGvC,IAAA3J,GAAAnhB,EAAA6qB,kBAAApJ,IACOsJ,eAAA,GACP5J,GAAA6J,YAAA,aACA7J,EAAA6J,YAAA,yBAA0DC,QAAA,IAM1D,QAAAC,GAAA7K,EAAAje,GACA,GAAA6gB,GAAA5C,EAAAG,YAAAkC,GACAO,GAAA+H,YAAA,mCAA8DC,QAAA,IAE9DhI,EAAArB,aAAAlB,UAAA,SAAAoB,GACA,GAAAH,GAAAG,EAAA7gB,OAAAlU,MACA,IAAA40B,EAAA,CACA,GAAAvV,GAAAuV,EAAA13B,MACA8iB,EAAAiE,GAAA5E,EACAA,GAAAsT,eAAA3S,EAAA,QACAkW,EAAAnX,IAAAM,GACAuV,EAAAM,eAEA7f,MAMA,QAAA+oB,GAAAnrB,GACAA,EAAA6qB,kBAAAlI,IAAuCmI,QAAA,QACvCE,YAAA,6BAAkDC,QAAA,IAIlD,QAAAG,GAAA/K,EAAAnD,GACA,GAAAmO,GAAAhL,EAAAG,YAAAmC,IACAM,EAAA5C,EAAAG,YAAAkC,IACAnB,EAAAlB,EAAAG,YAAAgB,IAEAG,EAAAsB,EAAArB,YACAD,GAAAjB,UAAA,SAAAoB,GACA,GAAAH,GAAAG,EAAA7gB,OAAAlU,MACA,IAAA40B,EAAA,CACA,GAAAvV,GAAAuV,EAAA13B,MACAsW,EAAA6L,EAAAvH,GACA6B,EAAAuK,GAAA1Q,GACA0F,EAAAkG,EAAAC,EACA,IAAA1F,EAAA,CACA,GAAAsjB,GAAAzpB,EAAA,KAAA0F,EAGAxQ,EAAA8K,EAAA,KACAqa,EAAAra,EAAA,MACAhU,EAAAg1B,EAAAh1B,MAAA,eACA0b,EAAAmZ,YAAAC,MAAA5rB,EAAAmlB,GAAA,MACA0Q,EAAA/+B,EAAAq1B,WAAA3Z,EACAqjB,GAAA5K,UAAA,SAAAp1B,GAEA,GADAggC,EAAAhgC,EAAA2V,OAAAlU,OAKa,CACb,GAAAyB,GAAA88B,EAAArhC,KACAuE,GAAAuxB,cAAAiK,GACAqB,EAAAvf,IAAAtd,GAEA+yB,EAAAnL,OAAAkV,EAAAtJ,YACAsJ,EAAArJ,eARAgB,GAAA7M,OAAAuL,EAAAK,YACAL,EAAAM,gBAWAN,GAAAM,eAEO/E,IACPA,KAMA,QAAAqO,GAAAvrB,GACA,GAAAmhB,GAAAnhB,EAAA6qB,kBAAApJ,IACOsJ,eAAA,GACP5J,GAAA6J,YAAA,aACA7J,EAAA6J,YAAA,yBAA0DC,QAAA,IAI1D,QAAAO,GAAAnL,EAAAje,GACA,GAAAmf,GAAAlB,EAAAG,YAAAgB,IACAF,EAAAjB,EAAAG,YAAAC,IACAU,EAAAd,EAAAG,YAAAiB,IAKA1Y,EAAAuY,EAAAP,OACAhY,GAAA2X,UAAA,SAAAp1B,GACA,GAAAy1B,GAAAz1B,EAAA2V,OAAAlU,MACA,OAAAg0B,QAIAQ,EAAAK,aAAAlB,UAAA,SAAAp1B,GACA,GAAAq2B,GAAAr2B,EAAA2V,OAAAlU,MACA,KAAA40B,EACA,MAAAvf,IAMA,QAJA0G,GAAA6Y,EAAA13B,MACA01B,EAAAgC,EAAAK,WACAhP,EAAA1oB,OAAAkH,KAAAsX,EAAAa,kBACA8hB,KACA/lB,EAAA,EAAuBA,EAAAsN,EAAA7mB,OAAiBuZ,IAAA,CACxC,GAAAgE,GAAAZ,EAAAa,aAAAqJ,EAAAtN,GACA+lB,GAAA/hB,EAAA0S,SAAA,EAEA,GAAAqI,GAAAn6B,OAAAkH,KAAAi6B,EACA,KAAA/lB,EAAA,EAAmBA,EAAA+e,EAAAt4B,OAAoBuZ,IAAA,CACvC,GAAA0W,GAAAqI,EAAA/e,EACAyb,GAAArV,KACA6T,MACAoC,UAAA3F,EAAA,KAAAuD,IAGAgC,EAAAM,aAxBA7f,KAmCA,QAAAspB,GAAArL,GAEA,QAAAsL,GAAA9L,GACA,MAAAA,GAAArxB,KAKAoxB,GAAAC,IAHAA,EAAA9S,QAAA,MAAA8S,EAAAH,eACAG,GAOA,GAAAqD,GAAA7C,EAAAG,YAAAgB,IACAyB,EAAA5C,EAAAG,YAAAkC,IACAf,EAAAsB,EAAArB,YACAD,GAAAjB,UAAA,SAAAp1B,GAUA,QAAAsgC,KAGA,GAAAn2B,GAAA2W,EAAAvH,GAAA,KACA+V,EAAAxO,EAAAvH,GAAA,MACAkE,EAAAma,EAAA32B,MAAA,eAAAq1B,WACAR,YAAAC,MAAA5rB,EAAAmlB,IAEAiR,EAAA,CACA9iB,GAAA2X,UAAA,SAAAp1B,GACA,GAAAq2B,GAAAr2B,EAAA2V,OAAAlU,MACA,KAAA40B,EAEA,MADAvV,GAAAuT,IAAAkM,EACAC,GAEA,IAAAnM,GAAAgC,EAAAK,UACArC,GAAAkM,IACAA,EAAAlM,GAEAgC,EAAAM,YAIA,QAAA6J,KACA,GAAA5G,GAAAzF,GAAArT,EACAA,EAAAD,WAAAC,EAAAW,SAEAhE,EAAAka,EAAAnX,IAAAoZ,EACAnc,GAAA2X,UAAA,WACAiB,EAAAM,YAtCA,GAAAN,GAAAr2B,EAAA2V,OAAAlU,MACA,IAAA40B,EAAA,CAGA,GAAAvV,GAAAuf,EAAAhK,EAAA13B,MAsCA,OApCAmiB,GAAAD,WAAAC,EAAAD,YACAA,EAAAC,GAmCAA,EAAAuT,IACAmM,QAGAF,OA5NA,GAAA1kB,GAAA3C,EAAApa,KAEAg4B,EAAA,IACArO,GAAAuQ,MAAA,KA8NAvQ,EAAA1a,KAAA,WACA,aAGA0a,EAAAnT,IAAAkB,EAAA,SAAAO,GACAA,EAAA,KAAA0R,EAAAuQ,MAAA0H,cAGAjY,EAAAkY,UAAA,SAAAjjB,EAAAkjB,EAAA7pB,GACAmgB,GAAAhe,EAAAwE,EAAAkjB,EAAAnY,EAAAqO,EAAA/f,IAKA0R,EAAAoY,KAAA,SAAArnB,EAAAN,EAAAnC,GAcA,QAAAoiB,KACApiB,EAAAC,GAAqByG,MAAAsD,WAAAe,IAAAkT,IAdrB,GAAAvX,GACAsD,EACA/J,EACAge,EAAA9b,EAAA4I,GACA,KAAAkT,EAAA,CACA,GAAAwC,GAAAX,GAAAC,GACAO,GAAAlB,GAAAf,IAAA,WACA,IAAAoC,EAAAzc,MACA,MAAAhE,GAAAygB,EAAAzc,MAEAia,GAAAwC,EAAAxC,IAOAA,EAAAG,YAAAkC,IAAAh4B,IAAAma,GAAA6b,UAAA,SAAAp1B,GAOA,GANA8gB,EAAAwT,GAAAt0B,EAAA2V,OAAAlU,SAMAqf,EAEA,MADA/J,GAAAoG,EAAA6V,GAAA,WACAkG,GAGA,IAAAve,EACA,IAAA1B,EAAA0B,IAQAA,EAAA1B,EAAA2M,UAAA3M,EAAA0B,IAAAmG,GAAA7H,EAAA0B,QARA,CACAA,EAAAmG,EAAAD,UACA,IAAAY,GAAAiE,GAAA5E,EACA,IAAAW,EAEA,MADA1K,GAAAoG,EAAA6V,GAAA,WACAkG,IAMA,GAAAhE,GAAAH,EAAAG,YAAAgB,IACAr0B,EAAAif,EAAAvH,GAAA,KAAAoB,CAEAua,GAAAj0B,MAAA,eAAA7B,IAAAyC,GAAAuzB,UAAA,SAAAp1B,GAKA,MAJAwd,GAAAxd,EAAA2V,OAAAlU,OACA+b,IACAA,EAAAgX,GAAAhX,IAEAA,MAIA0b,MAHAniB,EAAAoG,EAAA6V,GAAA,WACAkG,QAOA1Q,EAAAqY,eAAA,SAAA5rB,EAAA6rB,EAAAC,EAAA9nB,EAAAnC,GACA,GAAAie,EACA,IAAA9b,EAAA4I,IACAkT,EAAA9b,EAAA4I,QACK,CACL,GAAA0V,GAAAX,GAAAC,GACAO,GAAAlB,GAAAf,IAAA,WACA,IAAAoC,EAAAzc,MACA,MAAAhE,GAAAygB,EAAAzc,MAEAia,GAAAwC,EAAAxC,IAEA,GAAAjE,GAAAiQ,EAAAjQ,OACAhjB,EAAAizB,EAAAlQ,YAEAkE,GAAAG,YAAAC,IAAA/1B,IAAA0xB,GAAAsE,UAAA,SAAAp1B,GACA,GAAA40B,GAAA50B,EAAA2V,OAAAlU,OAAAmzB,IACAD,IAAAC,EAAA9mB,EAAAmL,EAAAiV,OAAA,SAAA8S,GACAlqB,EAAA,KAAAkqB,OAKAxY,EAAAyY,MAAA,SAAAnqB,GACA,GAAAoqB,GACAzI,EAEAlB,EAAAX,GAAAC,GAAAS,GAAApB,IAAA,WACA,IAAAqB,EAAAzc,MACA,MAAAhE,GAAAygB,EAAAzc,MAEA,IAAAia,GAAAwC,EAAAxC,GACAA,GAAAG,YAAAoC,IAAAl4B,IAAAk4B,IAAAlC,UAAA,SAAAp1B,GACAy4B,EAAAz4B,EAAA2V,OAAAlU,OAAAg3B,UAEA1D,EAAAG,YAAAgB,IAAAI,WAAA,aAAAlB,UAAA,SAAAp1B,GACA,GAAAq2B,GAAAr2B,EAAA2V,OAAAlU,MACAy/B,GAAA7K,IAAAx0B,IAAA,GAGAkzB,EAAA2C,WAAA,WACA5gB,EAAA,MACAqqB,UAAA1I,EACA2I,WAAAF,EAEAG,sBAAA7Y,EAAAuQ,MAAA+B,YAAA,sBAKAtS,EAAAI,SAAA,SAAA3P,EAAAnC,GACAulB,GAAApjB,EAAA4d,EAAA/f,IAGA0R,EAAA8Y,SAAA,SAAAroB,GACAiO,GAAAjO,EAAAuP,EAAA5M,EAAAib,IAGArO,EAAA+Y,OAAA,SAAAzqB,GAGA+f,EAAA2K,QACAC,GAAA3W,OAAAlP,GACA9E,KAGA0R,EAAAkZ,iBAAA,SAAAzsB,EAAA6B,GACA,GAAAygB,GAAAX,GAAAC,GAAAO,IAAA,WACA,IAAAG,EAAAzc,MACA,MAAAhE,GAAAygB,EAAAzc,MAEA,IAAAia,GAAAwC,EAAAxC,IACAtX,EAAAsX,EAAAG,YAAAkC,IAAAh4B,IAAA6V,EACAwI,GAAA2X,UAAA,SAAAoB,GACA,GAAAhZ,GAAA8W,GAAAkC,EAAA7gB,OAAAlU,OACA+b,GAGA1G,EAAA,KAAA0G,EAAA4D,UAFAtK,EAAAqG,EAAA6V,OAUAxK,EAAAmZ,cAAA,SAAA1sB,EAAA0M,EAAA7K,GACA,GAAAggB,IACAM,GACAlB,GACAf,GACAgB,IAEAoB,EAAAX,GAAAC,EAAAC,EAAA,YACA,IAAAS,EAAAzc,MACA,MAAAhE,GAAAygB,EAAAzc,MAEA,IAAAia,GAAAwC,EAAAxC,IAEA4C,EAAA5C,EAAAG,YAAAkC,GAEAO,GAAAv4B,IAAA6V,GAAAmgB,UAAA,SAAAoB,GACA,GAAA1V,GAAAwT,GAAAkC,EAAA7gB,OAAAlU,OACAigB,GAAAZ,EAAAM,SAAA,SAAAe,EAAAX,EACAoB,EAAAf,EAAA5I,GACA,GAAA0B,GAAA6G,EAAA,IAAAoB,CACAjB,GAAAjC,QAAA/E,MAAA,IACA1B,EAAA6D,OAAA,aAGA0Y,GAAA7T,EAAA1M,EAAA8f,EACA,IAAAzC,GAAAxR,EAAAD,WACAY,EAAAX,EAAAW,OACAsT,GAAAG,YAAAkC,IAAA5W,IACA2T,GAAArT,EAAAwR,EAAA7Q,KAEAsT,EAAAyC,QAAAxD,GAAAld,GACAie,EAAA2C,WAAA,WACA5gB,MAKA0R,EAAAoZ,UAAA,SAAAroB,EAAAzC,GACA,GAAAygB,GAAAX,GAAAC,GAAAQ,IAAA,WACA,IAAAE,EAAAzc,MACA,MAAAhE,GAAAygB,EAAAzc,MAEA,IAAA8X,GAAA2E,EAAAxC,IACAtX,EAAAmV,EAAAsC,YAAAmC,IAAAj4B,IAAAma,EAEAkE,GAAA4c,QAAArG,GAAAld,GACA2G,EAAA2X,UAAA,SAAAp1B,GACA,GAAAwd,GAAAxd,EAAA2V,OAAAlU,MACA+b,UAGAA,GAAA,YACA1G,EAAA,KAAA0G,IAHA1G,EAAAqG,EAAA6V,OAQAxK,EAAAqZ,UAAA,SAAArkB,EAAAvE,EAAAnC,GACA,kBAAAmC,KACAnC,EAAAmC,EACAA,YAEAuE,GAAAsK,UACA,IAAAga,GAAAtkB,EAAA4C,KACA7G,EAAAiE,EAAAnI,GACAysB,GAGAtkB,EAAA4C,KAAA,MAAA5D,SAAAslB,EAAA5iB,MAAA,eAFA1B,EAAA4C,KAAA,KAKA,IACA2hB,GADAnP,EAAA3Z,EAAA4I,GAEA,KAAA+Q,EAAA,CACA,GAAA2E,GAAAX,GAAAC,GAAAQ,IAAA,YACA,IAAAE,EAAAzc,MACA,MAAAhE,GAAAygB,EAAAzc,MAEA8X,GAAA2E,EAAAxC,IACAnC,EAAAyH,QAAArG,GAAAld,GACA8b,EAAA8E,WAAA,WACAqK,GACAjrB,EAAA,KAAAirB,IAKA,GACAtkB,GADAukB,EAAApP,EAAAsC,YAAAmC,GAEAyK,IACArkB,EAAAukB,EAAA5iC,IAAAma,GACAkE,EAAA2X,UAAA,SAAAp1B,GACA,GAAAiiC,GAAAjiC,EAAA2V,OAAAlU,MACA,IAAAwgC,KAAA7hB,OAAA0hB,EAES,CACT,GAAArkB,GAAAukB,EAAAxhB,IAAAhD,EACAC,GAAA2X,UAAA,WACA2M,GAAmBhpB,IAAA,EAAAQ,GAAAiE,EAAAnI,IAAAsF,IAAA6C,EAAA4C,MACnBnH,EAAA4I,KACA/K,EAAA,KAAAirB,QANAjrB,GAAAqG,EAAA+U,QAYAzU,EAAAukB,EAAAxhC,IAAAgd,GACAC,EAAA4c,QAAA,SAAAr6B,GAEA8W,EAAAqG,EAAA+U,KACAlyB,EAAAg6B,iBACAh6B,EAAAi6B,mBAEAxc,EAAA2X,UAAA,WACA2M,GAAehpB,IAAA,EAAAQ,GAAAiE,EAAAnI,IAAAsF,IAAA6C,EAAA4C,MACfnH,EAAA4I,KACA/K,EAAA,KAAAirB,MAMAvZ,EAAA0Z,aAAA,SAAA1kB,EAAAvE,EAAAnC,GACA,kBAAAmC,KACAnC,EAAAmC,EACAA,KAEA,IAAA2Z,GAAA3Z,EAAA4I,GACA,KAAA+Q,EAAA,CACA,GAAA2E,GAAAX,GAAAC,GAAAQ,IAAA,YACA,IAAAE,EAAAzc,MACA,MAAAhE,GAAAygB,EAAAzc,MAEA8X,GAAA2E,EAAAxC,IACAnC,EAAA8E,WAAA,WACAqK,GACAjrB,EAAA,KAAAirB,IAIA,GAAAA,GACAxoB,EAAAiE,EAAAnI,IACA2sB,EAAApP,EAAAsC,YAAAmC,IACA5Z,EAAAukB,EAAA5iC,IAAAma,EAEAkE,GAAA4c,QAAArG,GAAAld,GACA2G,EAAA2X,UAAA,SAAAp1B,GACA,GAAAiiC,GAAAjiC,EAAA2V,OAAAlU,MACAwgC,MAAA7hB,OAAA5C,EAAA4C,MAGA4hB,EAAAlX,OAAAvR,GACAwoB,GAAehpB,IAAA,EAAAQ,KAAAoB,IAAA,OACf1B,EAAA4I,KACA/K,EAAA,KAAAirB,IALAjrB,EAAAqG,EAAA6V,OAWAxK,EAAA2Z,SAAA,SAAAlpB,EAAAnC,GACA+hB,GAAArS,mBAAA5K,EAGA,IAAAwmB,GAAAC,GAAAjjC,IAAAwc,EACAwmB,MAAA3gC,SACA2gC,EAAA3gC,OAAA+/B,QACAC,GAAA3W,OAAAlP,GAEA,IAAA6B,GAAA6kB,UAAAC,eAAA3mB,EAEA6B,GAAA2X,UAAA,WAEAiN,GAAAvX,OAAAlP,GACAP,KAAAO,IAAA0O,qBACAA,cAAA1O,GAEA9E,EAAA,MAAsBiC,IAAA,KAGtB0E,EAAA4c,QAAArG,GAAAld,GAGA,IAAA0rB,GAAAf,GAAAriC,IAAAwc,EAEA,IAAA4mB,EAGA,MAFA3L,GAAA2L,EAAA3L,IACArO,EAAAuQ,MAAAyJ,EAAAtiC,OACAuR,GAAA,WACAqF,EAAA,KAAA0R,IAIA,IAAA/K,EAEAA,GADAxE,EAAAkC,QACAsnB,GAAA7mB,EAAA3C,EAAAkC,SAEAmnB,UAAAI,KAAA9mB,EAAA+mB,IAGAN,GAAA/hC,IAAAsb,EAAA6B,GAEAA,EAAAmlB,gBAAA,SAAA5iC,GA2BA,QAAA2vB,KACA,GAAAkT,GAAAC,EAAAxkC,EAAA,EACAA,KACAukC,GACAA,EAAA9N,EAAApF,GA9BA,GAAAjb,GAAA1U,EAAA2V,OAAAlU,MACA,IAAAzB,EAAA+iC,WAAA,EACA,MAAAzD,GAAA5qB,EAIA,IAAAqgB,GAAA/0B,EAAAgjC,cAAAhM,WAIAh3B,GAAA+iC,WAAA,GACAlD,EAAAnrB,GAEA1U,EAAA+iC,WAAA,GACA9C,EAAAvrB,EAGA,IAAAouB,IACAlD,EACAE,EACAI,EACAE,GAGA9hC,EAAA0B,EAAA+iC,UAUApT,MAGAlS,EAAA2X,UAAA,SAAAp1B,GAkCA,QAAAijC,KACA,mBAAAnI,IAAAoI,IAGA1a,EAAAuQ,OACAl6B,KAAA+c,EACA6kB,aACA3F,eAGA2G,GAAAnhC,IAAAsb,GACAib,MACA32B,OAAAsoB,EAAAuQ,QAEAjiB,EAAA,KAAA0R,IAGA,QAAA2a,KACA,sBAAA1K,IAAA,mBAAAT,GAAA,CAGA,GAAAoL,GAAAxnB,EAAA,KACAwnB,KAAApL,GACAyI,EAAAzI,EAAAoL,GAEApL,EAAAoL,GAAA3C,EAAA/f,IAEAsX,EAAAS,WACA1D,EAAAG,YAAAoC,IAAA9W,IAAAwX,IA5DAnB,EAAA72B,EAAA2V,OAAAlU,OAEAo1B,EAAAwM,gBAAA,WACAxM,EAAA2K,QACAC,GAAA3W,OAAAlP,IAGAib,EAAAW,QAAA,SAAAx3B,GACAmc,EAAA,wCAAAnc,EAAA2V,OAAAmF,OACA+b,EAAA2K,QACAC,GAAA3W,OAAAlP,GAUA,IAOAoc,GACAS,EACAqC,EACA2F,EAVA1L,EAAA8B,EAAAG,aACAM,GACA6F,GACA/F,IACA,aAEA8L,GAAA,CAwCAnO,GAAAG,YAAAoC,IAAAl4B,IAAAk4B,IAAAlC,UAAA,SAAAp1B,GACAg4B,EAAAh4B,EAAA2V,OAAAlU,SAAoC8X,GAAA+d,IACpC6L,KAMA3F,GAAAzI,EAAA,SAAAU,GACAgD,EAAAhD,EACA0N,MAMAG,KAEAA,GAAApG,GAAAnI,IAGAuO,GAAArsB,KAAA,SAAAssB,GACAzI,EAAAyI,EACAN,MAKAlO,EAAA2C,WAAA,WACAwL,GAAA,EACAD,MAIAxlB,EAAA4c,QAAA,WACA,GAAA3c,GAAA,6DACAvB,GAAA,QAAAuB,GACA5G,EAAAqG,EAAA+W,GAAAxW,KAmBA,QAAA+kB,IAAA7mB,EAAAT,GACA,IACA,MAAAmnB,WAAAI,KAAA9mB,GACA4nB,QAAAb,GACAxnB,YAEG,MAAApE,GACH,MAAAurB,WAAAI,KAAA9mB,EAAA+mB,KAmBA,QAAAc,IAAA1mB,GACA,MAAA4C,oBAAA+jB,OAAA3mB,IAGA,QAAA4mB,IAAAC,GAIA,MAAAA,GAAA,GAAAA,EAAA,GAAAA,EAAA,GAQA,QAAAC,IAAA9mB,EAAA5S,EAAAmlB,GAEA,IADA,GAAA7tB,GAAA,GACA0I,EAAAmlB,GACA7tB,GAAA+D,OAAA4oB,aACAuV,GAAA5mB,EAAA4Q,WAAAxjB,OAAA,EACAw5B,GAAA5mB,EAAA4Q,WAAAxjB,MAEA,OAAA1I,GAQA,QAAAqiC,IAAA/mB,EAAA5S,EAAAmlB,GAEA,IADA,GAAA7tB,GAAA,GACA0I,EAAAmlB,GAEA7tB,GAAA+D,OAAA4oB,aACAuV,GAAA5mB,EAAA4Q,WAAAxjB,EAAA,QACAw5B,GAAA5mB,EAAA4Q,WAAAxjB,EAAA,OACAw5B,GAAA5mB,EAAA4Q,WAAAxjB,KAAA,EACAw5B,GAAA5mB,EAAA4Q,WAAAxjB,EAAA,KACAA,GAAA,CAEA,OAAA1I,GAGA,QAAAsiC,IAAAhnB,EAAAinB,GACA,gBAAAA,EACAP,GAAAI,GAAA9mB,EAAA,EAAAA,EAAAlc,SAEAijC,GAAA/mB,EAAA,EAAAA,EAAAlc,QAIA,QAAAojC,IAAAlnB,GACA,UAAAA,EAAA,IAwBA,QAAAmnB,IAAAnnB,GACA,MAAAA,GACA/M,QAAA,gBACAA,QAAA,gBACAA,QAAA,gBAGA,QAAAm0B,IAAApnB,GACA,MAAAA,GACA/M,QAAA,sBACAA,QAAA,qBACAA,QAAA,qBAGA,QAAAo0B,IAAA5mB,GAKA,aAFAA,GAAAnI,UACAmI,GAAA4C,KACAsT,KAAAK,UAAAvW,GAGA,QAAA6mB,IAAA7mB,EAAAjE,EAAAoB,GAIA,MAHA6C,GAAAkW,KAAAC,MAAAnW,GACAA,EAAAnI,IAAAkE,EACAiE,EAAA4C,KAAAzF,EACA6C,EAIA,QAAA8mB,IAAAC,GAEA,IADA,GAAA3kC,GAAA,IACA2kC,KACA3kC,GAAA,IACA2kC,IACA3kC,GAAA,IAGA,OAAAA,GAAA,IAGA,QAAA4kC,IAAAC,EAAAC,EAAAC,EAAAC,EAAAC,GACA,gBAAAJ,EAAA,UACA,gBAAAC,OAAArlB,KAAA,YACAslB,EAAA,OAAAA,EAAA,KACAC,EAAA,WACA,gBAAAA,OAAAvlB,KAAA,eACAwlB,EAAA,aAAAA,EAAA,IAGA,QAAAC,IAAAnjB,EAAA1M,EAAA2d,GASA,QAAApZ,OACAC,IAAAkI,EAAA9gB,QACAkkC,IAIA,QAAAA,KAGA,GAAAC,EAAAnkC,OAAA,CAIA,GAAAokC,GAAA,yCACAC,GAAA,iBAAAZ,GAAAU,EAAAnkC,OAEA+xB,GAAAuS,WAAAF,EAAAD,EAAA,SAAApS,EAAApb,GAGA,OADA4tB,MACA9mC,EAAA,EAAqBA,EAAAkZ,EAAA2R,KAAAtoB,OAAqBvC,IAC1C8mC,EAAAphC,KAAAwT,EAAA2R,KAAAlG,KAAA3kB,GAAAwyB,OAEA,IAAAsU,EAAAvkC,OAAA,CAIA,GAAAokC,GAAA,eAAAC,GACA,kBACAF,EAAA5kC,IAAA,WAA8B,YAAcif,KAAA,KAC5C,GACAuT,GAAAuS,WAAAF,EAAAD,EAAA,SAAApS,GAEA,GAAAqS,GAAA,sBAAAC,GACA,qBACAE,EAAAhlC,IAAA,WAA0C,YAAcif,KAAA,KACxD,GACAuT,GAAAuS,WAAAF,EAAAG,EAAA,SAAAxS,EAAApb,GAEA,OADA6tB,GAAA,GAAAtG,IACAzgC,EAAA,EAAyBA,EAAAkZ,EAAA2R,KAAAtoB,OAAqBvC,IAC9C+mC,EAAA7kC,IAAAgX,EAAA2R,KAAAlG,KAAA3kB,GAAAwyB,OAEAsU,GAAAjjC,QAAA,SAAA2uB,GACAuU,EAAAriC,IAAA8tB,KAGA8B,EAAAuS,WACA,eAAAD,GAAA,mBACApU,IACA8B,EAAAuS,WACA,eAAAG,GAAA,mBAAAxU,eAxDA,GAAAnP,EAAA9gB,OAAA,CAIA,GAAA4Y,GAAA,EACAurB,IA2DArjB,GAAAxf,QAAA,SAAAwY,GACA,GAAAsqB,GAAA,mBAAAM,GACA,2BAEA3S,GAAAuS,WAAAF,GAAAhwB,EAAA0F,GAAA,SAAAiY,EAAApb,GACA,IAAAA,EAAA2R,KAAAtoB,OACA,MAAA2Y,IAEA,IAAA6a,GAAA7c,EAAA2R,KAAAlG,KAAA,GAAAoR,GACA2Q,GAAAhhC,KAAAqwB,GAEAzB,EAAAuS,WACA,eAAAI,GAAA,gBAAAlR,GAAA7a,QAKA,QAAAgsB,IAAA1uB,GACA,gBAAA0f,GACAra,EAAA,gCAAAqa,EAEA,IAAAiP,GAAAjP,KAAA/rB,YAAAzI,WACA+nB,MAAA,qBACA2b,EAAAD,KAAA,IAAAjP,EAAA1oB,KACA63B,EAAAnP,EAAA7gB,QAAA6gB,EAAAtZ,OACApG,GAAAqG,EAAAyoB,GAAAD,EAAAD,KAIA,QAAAG,IAAA5sB,GACA,WAAAA,GAGA,WAAAA,EAAA/W,IAQA,IAAA4jC,GAAA,mBAAAzI,YACA,UAAA10B,KAAA00B,UAAAC,UACA,OAAAwI,GAAA,MAGA,QAAAC,IAAA7O,EAAAzZ,EAAAxE,EAAAuP,EAAA9T,EAAAsxB,EAAAlvB,GAyBA,QAAAyP,KACA,MAAA4R,GACArhB,EAAAqhB,IAEA6N,EAAAlN,OAAAtQ,EAAAyd,WACAnvB,GAAA,KAAAqC,IAGA,QAAA6f,GAAAlI,EAAAha,GACA,GAAAmuB,GAAA,+BAAAK,GACA,iBACA1S,GAAAuS,WAAAF,GAAAnU,GAAA,SAAA8B,EAAAnxB,GACA,OAAAA,EAAA0nB,KAAAlG,KAAA,GAAAijB,IAAA,CACA,GAAAnvB,GAAAoG,EAAA8b,GACA,uCACAnI,EACAha,GAAAC,OAEAD,OAKA,QAAAohB,GAAAgB,GAkBA,QAAA1f,OACAC,IAAA0f,EAAAt4B,QACAq4B,EAAAniB,GAnBA,GAAAoiB,KAWA,IAVAhI,EAAAhvB,QAAA,SAAAmvB,GACAA,EAAApuB,MAAAouB,EAAApuB,KAAAmb,cACArf,OAAAkH,KAAAorB,EAAApuB,KAAAmb,cAAAlc,QAAA,SAAAi3B,GACA,GAAAhb,GAAAkT,EAAApuB,KAAAmb,aAAA+a,EACAhb,GAAAE,MACA6a,EAAAn1B,KAAAoa,EAAA0S,aAKAqI,EAAAt4B,OACA,MAAAq4B,IAEA,IACAniB,GADA0C,EAAA,CAQA0f,GAAAh3B,QAAA,SAAA2uB,GACAkI,EAAAlI,EAAA,SAAAuI,GACAA,IAAAtiB,IACAA,EAAAsiB,GAEA7f,QAKA,QAAAqY,GAAAP,EAAAgB,EAAAC,EAAAF,EACAiH,EAAA9G,EAAAO,EAAAjc,GAEA,QAAAoiB,KAaA,QAAAkB,GAAA/F,EAAAvd,GAOA,QAAA0C,KAIA,QAHAkhB,IAAAC,EAAA95B,QACAiW,KAEA,EAEA,QAAAtW,GAAA4d,GACA,GAAA6mB,GAAA,eAAAC,GACA,8BACAiB,GAAAjjC,EAAAmb,aAAAD,GAAA0S,OAAAuD,EACAzB,GAAAuS,WAAAF,EAAAkB,EAAA3sB,KAhBA,GAAAkhB,GAAA,EACAC,EAAA37B,OAAAkH,KAAAhD,EAAAmb,iBAEA,KAAAsc,EAAA95B,OACA,MAAAiW,IAiBA,QAAAxY,GAAA,EAAuBA,EAAAq8B,EAAA95B,OAAsBvC,IAC7CkC,EAAAm6B,EAAAr8B,IAnCA,GAAA4E,GAAAouB,EAAApuB,KACAkjC,EAAA/T,EAAA,IAEA9Y,EAAArW,EAAAmS,IACAsF,EAAAzX,EAAAkd,KACA0T,EAAAsQ,GAAAlhC,GACA+hC,EAAA,eAAAM,GACA,qDACAY,GAAA5sB,EAAAoB,EAAAmZ,EAAAsS,EA+BAxT,GAAAuS,WAAAF,EAAAkB,EAAA,SAAAvT,EAAAnxB,GACA,GAAA4yB,GAAA5yB,EAAA4kC,QACAjM,GAAA/F,EAAA,WACAiS,EAAA1T,EAAAyB,MAEO,WAEP,GAAAkS,GAAA/B,GAAA,MAAAe,GAAA,KACA,qBAYA,OAXA3S,GAAAuS,WAAAoB,GAAAhtB,EAAAoB,GAAA,SAAAiY,EAAApb,GACA,GAAA6c,GAAA7c,EAAA2R,KAAAlG,KAAA,GAAAoR,IACA4Q,EAAA,UAAAM,GACA,mDACAY,GAAArS,EAAAsS,EAAA7sB,EAAAoB,EACAiY,GAAAuS,WAAAF,EAAAkB,EAAA,SAAAvT,GACAwH,EAAA/F,EAAA,WACAiS,EAAA1T,EAAAyB,UAIA,IAIA,QAAAiG,GAAAkM,GACAzvB,IACAyvB,GACAzvB,EAAAyvB,EACA1vB,EAAAC,IACSya,IAAArT,EAAAtd,QACTq4B,KAiBA,QAAAqB,GAAAxjB,GACAya,IACA8I,EAAAvjB,GAqBA,QAAAuvB,GAAA1T,EAAAyB,GACA,GAAA9a,GAAA+X,EAAAxQ,SAAAvH,GAEAktB,EAAAnV,EAAAlM,eACAkU,IAAA9Q,EAAAyC,kBACAwb,EAAA9jB,EAAA2O,EAAAxQ,UAAApJ,OAAA+uB,IAEAA,EAAA5lC,QACAikC,GAAA2B,EAAAltB,EAAAqZ,GAGAtB,EAAAxQ,SAAAuT,KACA,IAAA1Z,GAAA2W,EAAAxQ,SAAAnG,UACA2W,GAAAxQ,SAAAnG,GAEA,IAAAsqB,GAAA3L,EACA,UAAAoN,GACA,uDACAnB,GACA,iBAAAmB,GAAA,4BACA,eAAAA,GACA,qDACAC,EAAA9S,GAAAvC,EAAAxQ,UACA8lB,EAAAtN,GACAqN,EAAAtS,EAAA/B,EAAA/Y,IACAA,EAAA8a,IAAAsS,EACA/T,GAAAuS,WAAAF,EAAA2B,EAAA,WACAztB,EAAA4Z,IACAha,IAAA,EACAQ,GAAA+X,EAAAxQ,SAAAvH,GACAoB,OAEAgY,EAAAryB,IAAAiZ,EAAA+X,EAAAxQ,UACAhK,MApEA,GAAAC,GAAA,KACAya,EAAA,CAEAF,GAAApuB,KAAAmS,IAAAic,EAAAxQ,SAAAvH,GACA+X,EAAApuB,KAAAkd,KAAAkR,EAAAxQ,SAAAnG,GACA,IAAAwD,GAAAnf,OAAAkH,KAAAorB,EAAApuB,KAAAmb,iBAGAgU,KACAf,EAAApuB,KAAAukB,UAAA,GAQAtJ,EAAAhc,QAAA,SAAAN,GACA,GAAAuc,GAAAkT,EAAApuB,KAAAmb,aAAAxc,EACA,IAAAuc,EAAAE,KAOAkT,IACA8I,QARA,CACA,GAAAp3B,GAAAkb,EAAAlb,WACAkb,GAAAlb,KACAkb,EAAAoc,OAAAhe,SAAA8V,EAAA,GACA,IAAAxB,GAAA1S,EAAA0S,MACA2J,GAAA3J,EAAA5tB,EAAAq3B,MAOApc,EAAAtd,QACAq4B,IAyCA,QAAA2N,KACAnU,GAAAwE,EAAAsB,WAAArH,EAAA3I,EAAAmK,EAAAC,EACAzZ,EAAA0Y,EAAA5Y,GAGA,QAAAmf,GAAAthB,GAOA,QAAA0C,OACAmf,IAAAxH,EAAAtwB,QACAiW,IARA,IAAAqa,EAAAtwB,OACA,MAAAiW,IAGA,IAAA6hB,GAAA,CAQAxH,GAAAhvB,QAAA,SAAAmvB,GACA,GAAAA,EAAAjc,KAAAsQ,GAAA2L,EAAAjc,KACA,MAAAmE,IAEA,IAAAD,GAAA+X,EAAAxQ,SAAAvH,EACAqZ,GAAAuS,WAAA,oBAAAuB,GACA,iBAAAntB,GAAA,SAAAqZ,EAAAnxB,GACA,GAAAA,EAAA0nB,KAAAtoB,OAAA,CACA,GAAAigB,GAAA2S,GAAAhyB,EAAA0nB,KAAAlG,KAAA,GAAA6Q,KACAnB,GAAAryB,IAAAiZ,EAAAuH,GAEAtH,QAKA,QAAAihB,GAAA3J,EAAA5tB,EAAA4T,GACA,GAAAmuB,GAAA,sBAAAK,GAAA,iBACA1S,GAAAuS,WAAAF,GAAAnU,GAAA,SAAA8B,EAAAnxB,GACA,MAAAA,GAAA0nB,KAAAtoB,OACAiW,KAKAmuB,EAAA,eAAAK,GACA,8CACA1S,GAAAuS,WAAAF,GAAAnU,EAAAoT,GAAAhhC,IAAA,WACA4T,KACO,WAGP,MADAA,MACA,OAzRA,GAAAsV,GAAAnT,EAAAma,UACA0T,EAAArpB,EAAApE,KAGA8X,EAAA2V,EAAA1mC,IAAA,SAAAod,GACA,GAAAA,EAAAnI,KAAAsQ,GAAAnI,EAAAnI,KACA,MAAAmI,EAEA,IAAA6C,GAAA8L,GAAA3O,EAAA4O,EACA,OAAA/L,KAGA0mB,EAAA5V,EAAApc,OAAA,SAAAuc,GACA,MAAAA,GAAAxW,OAEA,IAAAisB,EAAAlmC,OACA,MAAAiW,GAAAiwB,EAAA,GAGA,IAAAnU,GAIAuF,EAHAhf,EAAA,GAAAzX,OAAAyvB,EAAAtwB,QACA8xB,EAAA,GAAA3X,GAyQAkW,IAAAC,EAAA,kBAAApa,GACA,MAAAA,GACAD,EAAAC,OAEArC,GAAAsiB,YAAA,SAAAjC,GACAnC,EAAAmC,EACAmD,EAAA,SAAAnhB,GACAA,EACAohB,EAAAphB,EAEAqhB,EAAAyO,MAGKrB,GAAA1uB,GAAAyP,KAOL,QAAAygB,IAAA/tB,GACA,MAAAA,GAAAguB,OAAAhuB,EAAApa,KAAAoa,EAAAuqB,QAAAvqB,EAAAiuB,YAAAjuB,EAAA/W,MAGA,QAAAilC,IAAAluB,GACA,IACA,OACAvE,GAAAsyB,GAAA/tB,IAEG,MAAAlC,GACH,OACA+D,MAAA/D,IAKA,QAAAqwB,IAAAnuB,GACA,GAAAouB,GAAAC,GAAAloC,IAAA6Z,EAAApa,KAKA,OAJAwoC,KACAA,EAAAF,GAAAluB,GACAquB,GAAAhnC,IAAA2Y,EAAApa,KAAAwoC,IAEAA,EAKA,QAAAE,IAAA/pB,EAAAvE,EAAAuP,EAAAuM,EAAAnD,GAOA,QAAApY,OACAC,IAAA0E,EAAAtd,QAAA+wB,GACAA,IAIA,QAAAoD,GAAAxX,EAAAY,GACA,GAAA6W,GAAAzX,EAAAa,aAAAD,GACAopB,GAAmBtZ,OAAAjV,EAAAiV,OAAArM,IAAAkT,EACnBvM,GAAAqY,eAAArjB,EAAAnI,IAAA+I,EAAA6W,EAAAuS,EAAA,SAAAC,EAAAvkC,GACAsa,EAAAa,aAAAD,GAAA4K,GACA/Q,EAAAgd,GAAA,2BACS/xB,SAETsW,MApBA,GAAA2E,GAAAnf,OAAAkH,KAAAsX,EAAAa,iBACA,KAAAF,EAAAtd,OACA,MAAA+wB,OAEA,IAAAnY,GAAA,CAoBA0E,GAAAhc,QAAA,SAAAic,GACAnF,EAAAkF,aAAAlF,EAAAiF,aACA8W,EAAAxX,EAAAY,IAEAZ,EAAAa,aAAAD,GAAAE,MAAA,EACA9E,OAiCA,QAAAkuB,IAAAzuB,EAAAnC,GA0BA,QAAA6wB,KAEAtsB,MACApb,OAAAqqB,aAAA,oBAAA9B,EAAAyd,QAAA,GAEAnvB,EAAA,KAAA0R,GAQA,QAAAof,GAAAhV,EAAA9b,GAEA8b,EAAAuS,WAAA0C,IAEAjV,EAAAuS,WAAA,eAAAI,GACA,yDACA3S,EAAAuS,WAAA2C,IACAlV,EAAAuS,WAAA,eAAAuB,GACA,uDACA9T,EAAAuS,WAAA,uDACAuB,GAAA,eAEA,IAAAzB,GAAA,UAAAyB,GAAA,uBAAAA,GACA,0BAAAnB,GAAA,SAAAmB,GACA,OAAAnB,GAAA,UAAAmB,GAAA,aAEA9T,GAAAuS,WAAAF,KAAA,SAAArS,EAAAnxB,GAKA,OAHAggB,MACArG,KAEA9c,EAAA,EAAyBA,EAAAmD,EAAA0nB,KAAAtoB,OAAwBvC,IAAA,CACjD,GAAA2kB,GAAAxhB,EAAA0nB,KAAAlG,KAAA3kB,GACA+1B,EAAApR,EAAAoR,IACAvT,EAAA4S,KAAAC,MAAA1Q,EAAAnC,SACA4E,IAAA5E,IACAW,EAAAzd,KAAAqwB,GAEA1O,GAAA7E,EAAAvH,KACA6B,EAAApX,KAAA8c,EAAAvH,IAGAqZ,EAAAuS,WAAA,UAAAuB,GAAA,6BACApC,GAAAlpB,EAAAva,QAAAua,EAAA,WACAwX,EAAAuS,WAAA,UAAAI,GACA,iCACAjB,GAAA7iB,EAAA5gB,QAAA4gB,EAAA3K,WAQA,QAAAixB,GAAAnV,EAAA9b,GACA,GAAAsE,GAAA,8BAAA4sB,GACA,yBACApV,GAAAuS,WAAA/pB,KAAA,WACA,GAAA6pB,GAAA,UAAAyB,GAAA,cACAnB,GAAA,sBACAA,GAAA,SACAmB,GAAA,OAAAnB,GAAA,UACAmB,GAAA,6BACA9T,GAAAuS,WAAAF,KAAA,SAAArS,EAAApb,GAKA,QAAAywB,KACA,IAAA9e,EAAAtoB,OACA,MAAAiW,GAAA8b,EAEA,IAAA0C,GAAAnM,EAAAM,QACA9O,EAAA+Y,KAAAC,MAAA2B,EAAApyB,MAAAkd,IACAwS,GAAAuS,WAAA,eAAA6C,GACA,mCACA1S,EAAA/b,GAAAoB,EAAA2a,EAAApyB,MAAA,SAAA0vB,GACAA,EAAAuS,WAAA,eAAAuB,GAAA,eACApR,EAAA/b,IAAA,SAAAqZ,GACAA,EAAAuS,WAAA,eAAAI,GAAA,gBACAjQ,EAAAjB,KAAA,WACA4T,UAhBA,OADA9e,MACA7qB,EAAA,EAAuBA,EAAAkZ,EAAA2R,KAAAtoB,OAAqBvC,IAC5C6qB,EAAAnlB,KAAAwT,EAAA2R,KAAAlG,KAAA3kB,GAoBA2pC,SAMA,QAAAC,GAAAtV,EAAA9b,GAEA,QAAAqxB,GAAAhf,GACA,QAAA8e,KACA,IAAA9e,EAAAtoB,OACA,MAAAiW,GAAA8b,EAEA,IAAA0C,GAAAnM,EAAAM,QACA2e,EAAArE,GAAAzO,EAAA+S,IAAArE,GACA5gB,EAAAglB,EAAA1T,YAAA,MACA4T,EAAAF,EAAA/vB,UAAA,EAAA+K,GACAzI,EAAAytB,EAAA/vB,UAAA+K,EAAA,GACA6hB,EAAA,UAAAM,GACA,yCACA3S,GAAAuS,WAAAF,GAAAqD,EAAA3tB,EAAAytB,GAAA,WACAH,MAGAA,IAGA,GAAAhD,GAAA,eAAAM,GAAA,oBACA3S,GAAAuS,WAAAF,KAAA,SAAArS,GACA,GAAAqS,GAAA,eAAAM,GAAA,iBACA3S,GAAAuS,WAAAF,KAAA,SAAArS,GACAA,EAAAuS,WAAAoD,MAAA,SAAA3V,GACA,GAAAqS,GAAA,sCAAAM,EACA3S,GAAAuS,WAAAF,KAAA,SAAArS,EAAApb,GAEA,OADA2R,MACA7qB,EAAA,EAA2BA,EAAAkZ,EAAA2R,KAAAtoB,OAAqBvC,IAChD6qB,EAAAnlB,KAAAwT,EAAA2R,KAAAlG,KAAA3kB,GAEA6pC,GAAAhf,WASA,QAAAqf,GAAA5V,EAAA9b,GAEA,QAAAopB,GAAAtN,GAIA,GAAAqS,GAAA,+BAAAK,EACA1S,GAAAuS,WAAAF,KAAA,SAAArS,EAAApb,GAQA,QAAAixB,KACA,GAAAxD,GAAAT,GACAkE,GAAA,KAAAhC,GAAA,aACAA,GAAAnB,IACAoD,GACA,KACAjC,GAAA,OAEAzB,IAAA,UAAA2D,EAAA,WAAAxnC,EACAA,GAAAwnC,EACAhW,EAAAuS,WAAAF,KAAA,SAAArS,EAAApb,GAKA,QAAAqxB,GAAA/X,EAAAuD,GAEA,GAAA2Q,GAAA8D,EAAAhY,GAAAgY,EAAAhY,MACAkU,GAAAtlB,QAAA2U,MAAA,GACA2Q,EAAAhhC,KAAAqwB,GARA,IAAA7c,EAAA2R,KAAAtoB,OACA,MAAAiW,GAAA8b,EAUA,QARAkW,MAQAxqC,EAAA,EAA2BA,EAAAkZ,EAAA2R,KAAAtoB,OAAqBvC,IAIhD,OAHAg3B,GAAA9d,EAAA2R,KAAAlG,KAAA3kB,GACAkf,EAAA6mB,GAAA/O,EAAApyB,KAAAoyB,EAAA/b,GAAA+b,EAAA3a,KACA+M,EAAA1oB,OAAAkH,KAAAsX,EAAAa,kBACAjE,EAAA,EAA6BA,EAAAsN,EAAA7mB,OAAiBuZ,IAAA,CAC9C,GAAAgE,GAAAZ,EAAAa,aAAAqJ,EAAAtN,GACAyuB,GAAAzqB,EAAA0S,OAAAwE,EAAAjB,KAGA,GAAA0U,KAOA,IANA/pC,OAAAkH,KAAA4iC,GAAA3mC,QAAA,SAAA2uB,GACA,GAAAkU,GAAA8D,EAAAhY,EACAkU,GAAA7iC,QAAA,SAAAkyB,GACA0U,EAAA/kC,MAAA8sB,EAAAuD,SAGA0U,EAAAloC,OACA,MAAA4nC,IAEA,IAAAhvB,GAAA,CACAsvB,GAAA5mC,QAAA,SAAA9B,GACA,GAAA4kC,GAAA,eAAAC,GACA,6BACAtS,GAAAuS,WAAAF,EAAA5kC,EAAA,aACAoZ,IAAAsvB,EAAAloC,QACA4nC,UAtDA,GAAAhT,GAAAje,EAAA2R,KAAAlG,KAAA,GAAAijB,GACA,KAAAzQ,EACA,MAAA3e,GAAA8b,EAGA,IAAAxxB,GAAA,EACAwnC,EAAA,EAsDAH,OAIA,GAAAO,GAAA,8BACA9D,GAAA,wBACAtS,GAAAuS,WAAA6D,KAAA,SAAApW,GACAA,EAAAuS,WACA8D,MAAA,SAAArW,GACAA,EAAAuS,WACA+D,MACAhJ,OAOA,QAAAiJ,GAAAvW,EAAA9b,GACA,GAAAmuB,GAAA,eAAAK,GACA,0CACA1S,GAAAuS,WAAAF,KAAAnuB,GAKA,QAAAsyB,GAAAxW,EAAA9b,GACA,GAAAmuB,GAAA,eAAAyB,GACA,6BACA9T,GAAAuS,WAAAF,KAAA,SAAArS,GACA,GAAAqS,GAAA,UAAAyB,GAAA,sCACAnB,GAAA,mBACA3S,GAAAuS,WAAAF,KAAA,SAAArS,GAGA,GAAAqS,GACA,0DACAyB,GAAA,YACA9T,GAAAuS,WAAAF,KAAAnuB,OAKA,QAAAuyB,GAAAzW,EAAAhB,GAEAgB,EAAAuS,WAAA,qCAAAvS,EAAApb,GACA,GAAA6wB,GAAA7wB,EAAA2R,KAAAlG,KAAA,GAAAolB,GACArE,GAAA,IAAAqE,EAAAxnC,OAAA,iBACA+wB,MAKA,QAAA0X,KACA,KAAAC,EAAA1oC,OAAA,IACA,GAAA2oC,GAAAD,EAAA5lC,KACA6lC,GAAA,KAAA/I,IAIA,QAAAgJ,GAAA7W,EAAA8W,GACA,OAAAA,EAAA,CAGA,GAAAC,GAAA,8BAAAC,GACA,8BACAC,EAAA,8BAAAvE,GACA,kDACA0D,EAAA,8BACA9D,GAAA,yBAEA1nB,EAAA,8BAAAkpB,GACA,yDACArS,EAAA,8BAAAkR,GACA,2FAEAnqB,EAAA,8BAAA4sB,GACA,yBAGApV,GAAAuS,WAAA0E,GACAjX,EAAAuS,WAAA/pB,GACAwX,EAAAuS,WAAA6D,KAAA,WACApW,EAAAuS,WAAA+D,IACAtW,EAAAuS,WAAA8D,MAEArW,EAAAuS,WAAA3nB,KAAA,WACAoV,EAAAuS,WAAA0C,IACAjV,EAAAuS,WAAA9Q,KAAA,WACAzB,EAAAuS,WAAA2C,IACAlV,EAAAuS,WAAAoD,IACA3V,EAAAuS,WAAAwE,KAAA,WAEA,GAAAG,GAAA,eAAAF,GACA,kCACAnJ,GAAA/f,GACA,IAAAqpB,IAAAC,GAAAvJ,EACA7N,GAAAuS,WAAA2E,EAAAC,EAAA,WACAT,gBAKK,CAEL,GAAAW,GAAA,WACA,GAAAC,GAAAR,EAAAM,EACAE,IAEAtX,EAAAuS,WAAA,UAAAyE,GAAA,qBACAI,GAGA,IAAA/E,GAAA,oBAAA2E,EACAhX,GAAAuS,WAAAF,KAAA,SAAArS,EAAAnxB,GACAg/B,EAAAh/B,EAAA0nB,KAAAlG,KAAA,GAAAknB,KACAb,OAMAc,GACAxC,EACAG,EACAG,EACAM,EACAW,EACAC,EACAa,GAIA3rC,EAAAorC,EACAW,EAAA,SAAAzX,GACAwX,EAAA9rC,EAAA,GAAAs0B,EAAAyX,GACA/rC,IAEA+rC,GAAAzX,IAIA,QAAA0X,KACA51B,EAAAsiB,YAAA,SAAApE;AAEAyW,EAAAzW,EAAA,WAEA2X,EAAA3X,MAEK4S,GAAA1uB,GAAA6wB,GAGL,QAAA4C,GAAA3X,GACA,GAAAqS,GAAA,kDAAA2E,EACAhX,GAAAuS,WAAAF,KAAA,SAAArS,EAAAnxB,GACAA,EAAA0nB,KAAAtoB,OAGO,aAAA8H,KAAAlH,EAAA0nB,KAAAlG,KAAA,GAAAgiB,KASPrS,EAAAuS,WAAA,0BAAAyE,MACA,SAAAhX,EAAAnxB,GACA,GAAAioC,GAAAjoC,EAAA0nB,KAAAlG,KAAA,GAAAunB,UACAf,GAAA7W,EAAA8W,KATA9W,EAAAuS,WAAA,eAAAyE,GACA,+CAEAH,EAAA7W,EAAA,KAPA6W,EAAA7W,EAAA,KAqBA,QAAA6X,GAAA7X,EAAA9b,GACA,GAAAmuB,GAAA,+BAAAM,EACA3S,GAAAuS,WAAAF,KAAA,SAAArS,EAAApb,GACA,GAAA0pB,GAAA1pB,EAAA2R,KAAAlG,KAAA,GAAAoR,KAAA,CACAvd,GAAAoqB,KAIA,QAAA1D,GAAA5K,EAAA9b,GAEA,GAAAmuB,GAAAT,GACA,SAAAkC,GAAA,iBACAA,GAAAnB,IACAoD,GACApD,GAAA,aAEA3S,GAAAuS,WAAAF,KAAA,SAAArS,EAAAnxB,GACAqV,EAAArV,EAAA0nB,KAAAlG,KAAA,GAAAshB,OAmCA,QAAAmG,GAAA9X,EAAArZ,EAAAoB,EAAA7D,EAAAoiB,GACA,GAAA+L,GAAAT,GACAkE,IACAhC,GAAAnB,IACAoD,GACAjC,GAAA,SACAP,GAAA5sB,EAEAqZ,GAAAuS,WAAAF,EAAAkB,EAAA,SAAApkB,EAAA5I,GACA,IAAAA,EAAAgQ,KAAAtoB,OAAA,CACA,GAAAkW,GAAAoG,EAAA6V,GAAA,UACA,OAAAkG,GAAAniB,GAEA,GAAAkM,GAAA9J,EAAAgQ,KAAAlG,KAAA,GACAnC,EAAA2S,GAAAxQ,EAAAnC,SACAhK,GAAA8O,GAAAjL,EAAAmG,MA1dA,GAIAkjB,GAJAxb,EAAAvqB,KACAwiC,EAAA,KACAv+B,EAAA2jC,GAAA5sB,GACAswB,IAGA/gB,GAAAyd,MAAAhtB,EAAApa,IAIA,IAAA8rC,GAAA3hB,MAA8B/P,GAC9BuqB,QAAAoH,GACA1D,YAAAjuB,EAAApa,KACAqD,SAEA2oC,EAAAzD,GAAAuD,EACA,IAAAE,EAAA/vB,MACA,MAAA0qB,IAAA1uB,GAAA+zB,EAAA/vB,MAEA,IAAApG,GAAAm2B,EAAAn2B,EACA,mBAAAA,GAAAo2B,kBAEAp2B,EAAAo2B,gBAAAp2B,EAAAsiB,aA+XAsT,IAuBA9hB,EAAA1a,KAAA,WACA,gBAGA0a,EAAAnT,IAAAkB,EAAA,SAAAO,GACAA,EAAA,KAAA2pB,KAGAjY,EAAAyY,MAAA,SAAAnqB,GACA,GAAAud,GACAoE,CACA/jB,GAAAo2B,gBAAA,SAAAlY,GACA6X,EAAA7X,EAAA,SAAAmY,GACA1W,EAAA0W,IAEAvN,EAAA5K,EAAA,SAAAoY,GACAvS,EAAAuS,KAEKxF,GAAA1uB,GAAA,WACLA,EAAA,MACAqqB,UAAA1I,EACA2I,WAAA/M,EACA4W,gBAAAjH,OAKAxb,EAAAkY,UAAA,SAAAjjB,EAAAkjB,EAAA7pB,GACAivB,GAAA9sB,EAAAwE,EAAAkjB,EAAAnY,EAAA9T,EAAAsxB,GAAAlvB,IAsBA0R,EAAAoY,KAAA,SAAArnB,EAAAN,EAAAnC,GAUA,QAAAoiB,GAAAniB,GACAD,EAAAC,GAAqByG,MAAAsD,WAAAe,IAAA+Q,IAVrB,GAAApV,GACAsD,EACA8R,EAAA3Z,EAAA4I,GACA,KAAA+Q,EACA,MAAAle,GAAAo2B,gBAAA,SAAA/V,GACAvM,EAAAoY,KAAArnB,EAAAyP,IAA+BnH,IAAAkT,GAAS9b,GAAAnC,IAQxC,IAAAmuB,GACAkB,CAEA,IAAAltB,EAAA0B,IAOK,IAAA1B,EAAA2M,OAML,WALA8kB,GAAA9X,EAAArZ,EAAAN,EAAA0B,IAAA,SAAAuwB,GACAjyB,EAAA2M,QAAA,EACA3M,EAAA0B,IAAAuwB,EACA1iB,EAAAoY,KAAArnB,EAAAN,EAAAnC,IACOoiB,EAGP+L,GAAAT,GACAkE,IACAhC,GAAAnB,IACAmB,GAAA,OAAAnB,GAAA,WACAA,GAAA,YAAAA,GAAA,WACAY,GAAA5sB,EAAAN,EAAA0B,SAnBAsqB,GAAAT,GACAkE,IACAhC,GAAAnB,IACAoD,GACAjC,GAAA,SACAP,GAAA5sB,EAiBAqZ,GAAAuS,WAAAF,EAAAkB,EAAA,SAAApkB,EAAA5I,GACA,IAAAA,EAAAgQ,KAAAtoB,OAAA,CACA,GAAAsqC,GAAAhuB,EAAA6V,GAAA,UACA,OAAAkG,GAAAiS,GAEA,GAAAloB,GAAA9J,EAAAgQ,KAAAlG,KAAA,EAEA,IADAnC,EAAA2S,GAAAxQ,EAAAnC,UACAmC,EAAAxB,UAAAxI,EAAA0B,IAAA,CACA,GAAAywB,GAAAjuB,EAAA6V,GAAA,UACA,OAAAkG,GAAAkS,GAEA5tB,EAAA6mB,GAAAphB,EAAA/f,KAAA4d,EAAAvH,GAAA0J,EAAAtI,KACAue,OAIA1Q,EAAAI,SAAA,SAAA3P,EAAAnC,GACA,GACAu0B,GADAlyB,KAGAhP,EAAA,YAAA8O,MAAA6jB,SACAxN,EAAA,UAAArW,MAAA8jB,OACAl7B,EAAA,OAAAoX,MAAApX,IACA8mB,EAAA,cAAA1P,MAAA0P,WACAD,EAAA,SAAAzP,KAAAyP,OAAA,EACAtnB,EAAA,QAAA6X,KAAAwP,KAAA,EACA0T,EAAAljB,EAAA+jB,iBAAA,EAEAmJ,KACAmF,IAEA,IAAAzpC,KAAA,EACAypC,EAAAtnC,KAAA0iC,GAAA,WACAP,EAAAniC,KAAAnC,OACK,IAAAsI,KAAA,GAAAmlB,KAAA,GAKL,GAJAnlB,KAAA,IACAmhC,EAAAtnC,KAAA0iC,GAAA,QAAA/d,EAAA,iBACAwd,EAAAniC,KAAAmG,IAEAmlB,KAAA,GACA,GAAApM,GAAAyF,EAAA,OACAwT,KACAjZ,GAAA,KAEAooB,EAAAtnC,KAAA0iC,GAAA,OAAAxjB,EAAA,MACAijB,EAAAniC,KAAAsrB,GAEAztB,KAAA,IACAypC,EAAAtnC,KAAA0iC,GAAA,WACAP,EAAAniC,KAAAnC,IAIA,OAAAoX,EAAAwI,SAEA6pB,EAAAtnC,KAAAuhC,GAAA,gBAGA7wB,EAAAo2B,gBAAA,SAAAlY,GAMA,GAJA4K,EAAA5K,EAAA,SAAA6F,GACA4S,EAAA5S,IAGA,IAAA/P,EAAA,CAKA,GAAAuc,GAAAT,GACAkE,IACAhC,GAAAnB,IACAoD,GACA2C,EACA5E,GAAA,QAAA/d,EAAA,cAEAsc,IAAA,UAAAvc,EAAA,WAAAtnB,EAEAwxB,EAAAuS,WAAAF,EAAAkB,EAAA,SAAAvT,EAAAnxB,GACA,OAAAnD,GAAA,EAAAC,EAAAkD,EAAA0nB,KAAAtoB,OAA+CvC,EAAAC,EAAOD,IAAA,CACtD,GAAA2kB,GAAAxhB,EAAA0nB,KAAAlG,KAAA3kB,GACAwiB,EAAA2S,GAAAxQ,EAAAnC,UACAvH,EAAAuH,EAAAvH,GACArW,EAAAmhC,GAAAphB,EAAA/f,KAAAqW,EAAA0J,EAAAtI,KACA2X,EAAApvB,EAAAkd,KACA5C,GACAjE,KACA1X,IAAA0X,EACA5a,OAAoBgc,IAAA2X,GAEpB,IAAArZ,EAAAiF,aAAA,CAGA,GAFAV,MAAAta,EACAsa,MAAA4C,KAAAkS,EACArZ,EAAAwJ,UAAA,CACA,GAAAA,GAAAF,EAAAzB,EACA2B,GAAA5hB,SACA2c,MAAA2J,WAAA1E,GAGA8kB,GAAA/pB,MAAAvE,EAAAuP,EAAAoK,GAEA,GAAA3P,EAAAxB,QAAA,CACA,UAAAxI,EAAAwI,QAIA,QAHAjE,GAAA7e,MAAA8iB,SAAA,EACAjE,MAAA,KAKArE,EAAAnV,KAAAwZ,QAGKgoB,GAAA1uB,GAAA,WACLA,EAAA,MACAoS,WAAAmiB,EACAjqC,OAAA6X,EAAAwP,KACAU,KAAAhQ,OAKAqP,EAAA8Y,SAAA,SAAAroB,GAoCA,QAAAsyB,KAEA,GAAAC,GACA9E,GAAA,sBACAA,GAAA,uBACAnB,GAAA,wBACAA,GAAA,sBAEAnd,EAAAse,GAAA,SAAAnB,GAEAZ,EAAA+B,GAAA,OAAAnB,GAAA,eACAmB,GAAA,eAAAnB,GAAA,OAEA+F,GAAA,cACAnF,GAAAltB,EAAA+lB,MAEA/lB,GAAA6lB,UACAwM,EAAAtnC,KAAA0iC,GAAA,UAAApC,GAAArrB,EAAA6lB,QAAAj+B,SACAslC,IAAAzuB,OAAAuB,EAAA6lB,SAGA,IAAA+F,GAAA,WAAAlc,EAAA,cAEAsc,EAAAT,GAAAgH,EAAApjB,EAAAuc,EAAA2G,EAAAzG,GAEA9vB,EAAA6I,EAAA3E,EACAA,GAAAwyB,MAAAxyB,EAAAlE,SAEAkwB,GAAA,UAAAvc,EAGA,IAAAuV,GAAAhlB,EAAA+lB,OAAA,CACAtqB,GAAAo2B,gBAAA,SAAAlY,GACAA,EAAAuS,WAAAF,EAAAkB,EAAA,SAAAvT,EAAAnxB,GACA,QAAAiqC,GAAA1tB,GACA,kBACA/E,EAAA0N,SAAA3I,IAGA,OAAA1f,GAAA,EAAAC,EAAAkD,EAAA0nB,KAAAtoB,OAAiDvC,EAAAC,EAAOD,IAAA,CACxD,GAAA2kB,GAAAxhB,EAAA0nB,KAAAlG,KAAA3kB,GACAwiB,EAAA2S,GAAAxQ,EAAAnC,SACAmd,GAAAhb,EAAA0oB,MAEA,IAAAnuB,GAAA6mB,GAAAphB,EAAA+a,WAAAld,EAAAvH,GACA0J,EAAApC,YACA7C,EAAA/E,EAAA8N,cAAAvJ,EAAAsD,EAAA7H,EACA+E,GAAAqW,IAAApR,EAAA0oB,MAEA,IAAAzN,GAAAnpB,EAAAiJ,EACA,oBAAAkgB,GACA,MAAAjlB,GAAAsN,SAAA2X,EAiBA,IAdAA,IACAC,IACAC,GACAjlB,EAAAnV,KAAAga,GAIA/E,EAAAkF,aAAAlF,EAAAiF,aACAqpB,GAAA/pB,EAAAvE,EAAAuP,EAAAoK,EACA8Y,EAAA1tB,IAEA0tB,EAAA1tB,MAGAmgB,IAAAzV,EACA,UAIO8c,GAAAvsB,EAAAsN,UAAA,WACPtN,EAAA4lB,YACA5lB,EAAAsN,SAAA,MACApN,UACAoQ,SAAA0U,MA9GA,GAFAhlB,EAAAjD,EAAAiD,GAEAA,EAAA4lB,WAAA,CACA,GAAAtlB,GAAAiP,EAAAyd,MAAA,IAAAvlB,GAGA,OAFAslB,IAAAvqB,YAAA+M,EAAAyd,MAAA1sB,EAAAiP,EAAAvP,GACA+sB,GAAAlN,OAAAtQ,EAAAyd,QAEA3f,OAAA,WACA0f,GAAAvf,eAAA+B,EAAAyd,MAAA1sB,KAKA,GAAAoP,GAAA1P,EAAA0P,UAGA1P,GAAA+lB,MAAA/lB,EAAA+lB,QAAArW,EAAA1P,EAAA+lB,MAAA,CAEA,IAAAtW,GAAA,SAAAzP,KAAAyP,OAAA,CACA,KAAAA,IACAA,EAAA,EAGA,IAAA0V,EAEAA,GADA,eAAAnlB,GACAA,EAAAgmB,cACK,cAAAhmB,KAELA,EAAAmlB,UAIA,IAAAjlB,MACAglB,EAAA,CAqFAoN,MAGA/iB,EAAA+Y,OAAA,SAAAzqB,GAEAA,KAGA0R,EAAAqY,eAAA,SAAA5rB,EAAA6rB,EAAAC,EAAA9nB,EAAAnC,GACA,GAAAU,GACAob,EAAA3Z,EAAA4I,IACAiP,EAAAiQ,EAAAjQ,OACAhjB,EAAAizB,EAAAlQ,aACAoU,EAAA,mFAEAK,GAAA,iBACA1S,GAAAuS,WAAAF,GAAAnU,GAAA,SAAA8B,EAAAnxB,GAKA,GAAAwhB,GAAAxhB,EAAA0nB,KAAAlG,KAAA,GACA/f,EAAA+f,EAAA2oB,QAAAzH,GAAAlhB,EAAA2R,MACAmP,GAAA9gB,EAAA2R,KAAAoP,EAEAxsB,GADAyB,EAAAiV,OACAN,GAAA1qB,EAAA4K,GAEAmhB,GAAA/rB,GAEA4T,EAAA,KAAAU,MAIAgR,EAAAkZ,iBAAA,SAAAzsB,EAAA6B,GACApC,EAAAo2B,gBAAA,SAAAlY,GACA,GAAAqS,GAAA,gCAAAyB,GAAA,eACA9T,GAAAuS,WAAAF,GAAAhwB,GAAA,SAAA2d,EAAAnxB,GACA,GAAAA,EAAA0nB,KAAAtoB,OAES,CACT,GAAAqC,GAAAuwB,GAAAhyB,EAAA0nB,KAAAlG,KAAA,GAAAnC,SACAhK,GAAA,KAAA5T,EAAAke,cAHAtK,GAAAqG,EAAA6V,UASAxK,EAAAmZ,cAAA,SAAA1sB,EAAA0M,EAAA7K,GACA,MAAA6K,GAAA9gB,WAGA6T,GAAAsiB,YAAA,SAAApE,GAGA,GAAAqS,GAAA,gCAAAyB,GAAA,eACA9T,GAAAuS,WAAAF,GAAAhwB,GAAA,SAAA2d,EAAAnxB,GACA,GAAAqf,GAAA2S,GAAAhyB,EAAA0nB,KAAAlG,KAAA,GAAAnC,SACAY,GAAAZ,EAAAM,SAAA,SAAAe,EAAAX,EACAoB,EAAAf,EAAA5I,GACA,GAAA0B,GAAA6G,EAAA,IAAAoB,CACAjB,GAAAjC,QAAA/E,MAAA,IACA1B,EAAA6D,OAAA,YAIA,IAAAmoB,GAAA,UAAAyB,GAAA,4BACA9T,GAAAuS,WAAAF,GAAApR,GAAA/S,GAAA7L,MAGA6vB,GAAAnjB,EAAA1M,EAAA2d,IACK4S,GAAA1uB,GAAA,WACLA,MAtBAA,KA0BA0R,EAAAoZ,UAAA,SAAAroB,EAAAzC,GACApC,EAAAo2B,gBAAA,SAAAlY,GACA,GAAAqS,GAAA,yBAAA+C,GAAA,aACApV,GAAAuS,WAAAF,GAAA1rB,GAAA,SAAAqZ,EAAApb,GACA,GAAAA,EAAA2R,KAAAtoB,OAAA,CACA,GAAAoiB,GAAAzL,EAAA2R,KAAAlG,KAAA,GACAzF,EAAA6mB,GAAAphB,EAAA6Q,KAAAva,EAAA0J,EAAAtI,IACA7D,GAAA,KAAA0G,OAEA1G,GAAAqG,EAAA6V,UAMAxK,EAAAqZ,UAAA,SAAArkB,EAAAvE,EAAAnC,GAiBA,QAAA+0B,GAAAjZ,GACA,GAAAqS,GACA9jC,CACA2gC,IACAmD,EAAA,UAAA+C,GAAA,0CAEA7mC,GAAAgxB,EAAA2B,EAAAva,EAAAuoB,KAEAmD,EAAA,eAAA+C,GAAA,kCACA7mC,GAAAoY,EAAA4Y,EAAA2B,IAEAlB,EAAAuS,WAAAF,EAAA9jC,EAAA,SAAAyxB,EAAApb,GACAA,EAAAs0B,cACA/J,GAAiBhpB,IAAA,EAAAQ,KAAAoB,IAAAwX,GACjBlZ,EAAA4I,KACA/K,EAAA,KAAAirB,IAGAjrB,EAAAqG,EAAA+U,MAEO,WAEP,MADApb,GAAAqG,EAAA+U,MACA,IAtCA,kBAAAjZ,KACAnC,EAAAmC,EACAA,YAEAuE,GAAAsK,UACA,IAEAqK,GAFA2P,EAAAtkB,EAAA4C,KACA7G,EAAAiE,EAAAnI,GAKA8c,GAHA2P,EAGAtkB,EAAA4C,KAAA,MAAA5D,SAAAslB,EAAA5iB,MAAA,eAFA1B,EAAA4C,KAAA,KAIA,IAEA2hB,GAFAjO,EAAAsQ,GAAA5mB,EA6BAvE,GAAA4I,IACAgqB,EAAA5yB,EAAA4I,KAEAnN,EAAAsiB,YAAA6U,EAAArG,GAAA1uB,GAAA,WACAirB,GACAjrB,EAAA,KAAAirB,MAMAvZ,EAAA0Z,aAAA,SAAA1kB,EAAAvE,EAAAnC,GAOA,QAAAi1B,GAAAnZ,GACA,GAAAqS,GAAA,eAAA+C,GAAA,wBACApB,GAAAppB,EAAAnI,IAAAmI,EAAA4C,KACAwS,GAAAuS,WAAAF,EAAA2B,EAAA,SAAAhU,EAAApb,GACA,MAAAA,GAAAs0B,cAGA/J,GAAehpB,IAAA,EAAAQ,GAAAiE,EAAAnI,IAAAsF,IAAA,YACf1B,EAAA4I,KACA/K,EAAA,KAAAirB,KAJAjrB,EAAAqG,EAAA6V,OAXA,kBAAA/Z,KACAnC,EAAAmC,EACAA,KAEA,IAAA8oB,EAgBA9oB,GAAA4I,IACAkqB,EAAA9yB,EAAA4I,KAEAnN,EAAAsiB,YAAA+U,EAAAvG,GAAA1uB,GAAA,WACAirB,GACAjrB,EAAA,KAAAirB,MAMAvZ,EAAA2Z,SAAA,SAAAlpB,EAAAnC,GACAkvB,GAAAxf,mBAAAgC,EAAAyd,OACAvxB,EAAAsiB,YAAA,SAAApE,GACA,GAAAkE,IAAA4P,GAAAnB,GAAAD,GAAAsE,GACA5B,GAAA9C,GACApO,GAAA30B,QAAA,SAAA6pC,GACApZ,EAAAuS,WAAA,wBAAA6G,SAEKxG,GAAA1uB,GAAA,WACLuE,YACApb,QAAAqqB,aAAA,oBAAA9B,EAAAyd,aACAhmC,QAAAqqB,aAAA9B,EAAAyd,QAEAnvB,EAAA,MAAsBiC,IAAA,OAKtB,QAAAkzB,MACA,IAEA,MADAC,cAAA,kCACA,EACG,MAAAn1B,GACH,UAQA,QAAAo1B,MAcA,sBAAA7J,YAAA,OAAAA,YACA,iBAAA35B,KAAA00B,UAAAC,WAEA,QAKA,IAAA8O,GAAA/wB,IAGAgxB,EAAA,0BAAAhP,UAAAC,SACA,IAAA8O,GAAA9hB,aAAA+hB,GACA,YAAA/hB,aAAA+hB,EAEA,IAAAC,GAAAL,IAIA,OAHAG,KACA9hB,aAAA+hB,GAAAC,EAAA,SAEAA,EAGA,QAAAhhB,MACA,wBAAA4gB,eAGAC,KAGA,QAAAI,IAAA1tC,EAAA2kC,EAAA0D,EAAAhlC,GAEA,MAAAgqC,cAAArtC,EAAA2kC,EAAA0D,EAAAhlC,GAGA,QAAAsqC,IAAAvzB,EAAAnC,GACA,GAAA21B,GAAAzjB,IACAie,OAAAsF,IACGtzB,EAEHyuB,IAAAlpC,KAAAP,KAAAwuC,EAAA31B,GAaA,QAAA41B,MAUA,OATAC,MAEAl2B,EAAA,GAAAC,IAAA,SAAApF,EAAAsF,GACA+1B,EAAAr7B,UACAq7B,EAAA/1B,WAGAhW,EAAA,GAAAc,OAAA2I,UAAAxJ,QAEAvC,EAAA,EAAiBA,EAAAsC,EAAAC,OAAiBvC,IAClCsC,EAAAtC,GAAA+L,UAAA/L,EAaA,OAVAquC,GAAAl2B,UAEAC,GAAApF,UAAA2F,KAAA,WACA,MAAA21B,OAAAnsC,MAAA,KAAAG,KACGqW,KAAA,SAAA41B,GACHF,EAAAr7B,QAAAu7B,KACGvjB,MAAA,SAAAxO,GACH6xB,EAAA/1B,OAAAkE,KAGA6xB,EAGA,QAAAG,IAAAC,EAAAj2B,GACA,GAAA61B,GAAAK,EAAAH,EAEAI,EAAA,GAAAC,SAEAC,GACA/wB,OAAA2wB,EAAA3wB,OACAgxB,YAAA,UACAH,UA+DA,OA5DAF,GAAAjZ,OACAmZ,EAAA3sC,IAAA,6BACA2sC,EAAA3sC,IAAA,eAAAysC,EAAAE,QAAA,iBACA,qBAGAF,EAAAnY,MACAmY,EAAAM,aACA,gBAAAN,GAAAnY,KACAuY,EAAAvY,KAAAlB,KAAAK,UAAAgZ,EAAAnY,MACG,QAAAmY,GACHI,EAAAvY,KAAAmY,EAAAnY,KAEAuY,EAAAvY,KAAA,KAGA51B,OAAAkH,KAAA6mC,EAAAE,SAAA9qC,QAAA,SAAAN,GACAkrC,EAAAE,QAAAvtC,eAAAmC,IACAorC,EAAA3sC,IAAAuB,EAAAkrC,EAAAE,QAAAprC,MAIA8qC,EAAAD,GAAAK,EAAAO,IAAAH,GAEAJ,EAAAQ,QAAA,IACAP,EAAA55B,WAAA,WACAu5B,EAAA/1B,OAAA,GAAAhC,OAAA,8BACAm4B,EAAAO,OACKP,EAAAQ,UAGLZ,EAAAl2B,QAAAQ,KAAA,SAAAu2B,GASA,MARAX,IACAY,WAAAD,EAAA1wB,QAGAiwB,EAAAQ,QAAA,GACAG,aAAAV,GAGAH,EAAAY,YAAA,KAAAZ,EAAAY,WAAA,IACAV,EAAA7e,OAAAsf,EAAAlf,OAAAkf,EAAAG,OAGAH,EAAA1Z,SACG7c,KAAA,SAAAxV,GACHorC,EAAAY,YAAA,KAAAZ,EAAAY,WAAA,IACA32B,EAAA,KAAA+1B,EAAAprC,IAEAA,EAAAqb,OAAA+vB,EAAAY,WACA32B,EAAArV,MAEG6nB,MAAA,SAAAxO,GACHA,IAEAA,EAAA,GAAAlG,OAAA,aAEAkC,EAAAgE,MAGU8yB,MAAAjB,EAAA/1B,QAGV,QAAAi3B,IAAAd,EAAAj2B,GAEA,GAAAg3B,GAAAd,EACAe,GAAA,EAEAC,EAAA,WACAF,EAAAF,QACAK,KAGAC,EAAA,WACAH,GAAA,EACAD,EAAAF,QACAK,KAGAlM,GAAa6L,MAAAI,GAEbC,EAAA,WACAP,aAAAV,GACAjL,EAAA6L,MAAA,aACAE,IACAA,EAAAK,WAAArsC,OACAgsC,EAAAM,SACAN,EAAAM,OAAAD,WAAArsC,QAEAgsC,EAAA/6B,mBAAAjR,OACAgsC,EAAAhsC,QAKAgsC,GADAf,EAAAe,IACA,GAAAf,GAAAe,IAEA,GAAAO,eAGA,KACAP,EAAApL,KAAAqK,EAAA3wB,OAAA2wB,EAAAO,KACG,MAAAgB,GACH,MAAAx3B,GAAA,GAAAlC,OAAA05B,EAAAzvC,MAAA,mBAGAivC,EAAAS,kBAAA,mBAAAxB,KACAA,EAAAwB,gBAEA,QAAAxB,EAAA3wB,aACA2wB,GAAAE,QAAA,gBACGF,EAAAjZ,OACHiZ,EAAAE,QAAAuB,OAAA,mBACAzB,EAAAE,QAAA,gBAAAF,EAAAE,QAAA,iBACA,mBACAF,EAAAnY,MACAmY,EAAAM,aACA,gBAAAN,GAAAnY,OACAmY,EAAAnY,KAAAlB,KAAAK,UAAAgZ,EAAAnY,QAIAmY,EAAA7e,SACA4f,EAAAW,aAAA,eAGA,QAAA1B,KACAA,EAAAnY,KAAA,KAGA,QAAA/yB,KAAAkrC,GAAAE,QACAF,EAAAE,QAAAvtC,eAAAmC,IACAisC,EAAAY,iBAAA7sC,EAAAkrC,EAAAE,QAAAprC,GA4DA,OAxDAkrC,GAAAQ,QAAA,IACAP,EAAA55B,WAAA86B,EAAAnB,EAAAQ,SACAO,EAAAK,WAAA,WACAT,aAAAV,GACA,IAAAc,EAAAa,aACA3B,EAAA55B,WAAA86B,EAAAnB,EAAAQ,WAGA,mBAAAO,GAAAM,SACAN,EAAAM,OAAAD,WAAAL,EAAAK,aAIAL,EAAA/6B,mBAAA,WACA,OAAA+6B,EAAAa,WAAA,CAIA,GAAA9B,IACAY,WAAAK,EAAAhxB,OAGA,IAAAgxB,EAAAhxB,QAAA,KAAAgxB,EAAAhxB,OAAA,KACA,GAAA5Z,EAEAA,GADA6pC,EAAA7e,OACApB,IAAAghB,EAAAjB,UAAA,KACA/+B,KAAAggC,EAAAc,kBAAA,kBAGAd,EAAAe,aAEA/3B,EAAA,KAAA+1B,EAAA3pC,OACK,CACL,GAAA6T,KACA,IAAAg3B,EACAh3B,EAAA,GAAAnC,OAAA,aACAmC,EAAAmP,KAAA,gBACO,oBAAA4nB,GAAAjB,SACP,IACA91B,EAAA2c,KAAAC,MAAAma,EAAAjB,UACS,MAAA7sC,IAET+W,EAAA+F,OAAAgxB,EAAAhxB,OACAhG,EAAAC,GAEAk3B,MAGAlB,EAAAnY,MAAAmY,EAAAnY,eAAAnf,MACAgZ,GAAAse,EAAAnY,KAAA,SAAAhqB,GACAkjC,EAAAgB,KAAAlkC,KAGAkjC,EAAAgB,KAAA/B,EAAAnY,MAGAmN,EAGA,QAAAgN,MACA,IAEA,MADA,IAAAV,iBACA,EACG,MAAAt3B,GACH,UAMA,QAAAi4B,IAAAjC,EAAAj2B,GACA,MAAAm4B,KAAAlC,EAAAe,IACAD,GAAAd,EAAAj2B,GAEAg2B,GAAAC,EAAAj2B,GAOA,QAAAo4B,MACA,SAGA,QAAAC,IAAApC,EAAAj2B,GAeA,QAAAmlB,GAAAroB,EAAAiD,EAAA+a,GACA,IAAAmb,EAAA7e,QAAA6e,EAAAjZ,MAAA,gBAAAlgB,GAEA,IACAA,EAAA8f,KAAAC,MAAA/f,GACO,MAAA5T,GAEP,MAAA4xB,GAAA5xB,GAGA0B,MAAA4D,QAAAsO,KACAA,IAAAxT,IAAA,SAAAgvC,GACA,MAAAA,GAAAt0B,OAAAs0B,EAAAC,QACAhyB,EAAA+xB,GAEAA,KAIArC,EAAA7e,QACAohB,GAAA17B,EAAAiD,GAEA+a,EAAA,KAAAhe,EAAAiD,GAnCAk2B,EAAA/2B,EAAA+2B,EAEA,IAAAwC,IACAnzB,OAAA,MACA6wB,WACAnZ,MAAA,EACAuZ,aAAA,EACAE,QAAA,IACAtoC,OAAA,EA+CA,OA5CA8nC,GAAA/jB,GAAAumB,EAAAxC,GA2BAA,EAAAjZ,OACAiZ,EAAA7e,SACA6e,EAAAE,QAAAuB,OAAA,oBAEAzB,EAAAE,QAAA,gBAAAF,EAAAE,QAAA,iBACA,oBAGAF,EAAA7e,SACA6e,EAAA/I,SAAA,KACA+I,EAAAjZ,MAAA,GAGAiZ,EAAAM,cACAN,EAAAjZ,MAAA,GAGAkb,GAAAjC,EAAA,SAAAh2B,EAAA81B,EAAAjY,GAEA,GAAA7d,EACA,MAAAD,GAAAuG,EAAAtG,GAGA,IAAA+D,GACA+V,EAAAgc,EAAAI,SAAAJ,EAAAI,QAAA,gBACA/pC,EAAA0xB,GAAAsa,IAIA,KAAAnC,EAAA7e,SAAA6e,EAAAjZ,OAAAiZ,EAAAM,cACA,gBAAAnqC,KACA,OAAAyF,KAAAkoB,IACA,WAAmBloB,KAAAzF,IAAA,WAAmByF,KAAAzF,IACtC,IACAA,EAAAwwB,KAAAC,MAAAzwB,EAAAlB,YACO,MAAAhC,IAGP6sC,EAAAY,YAAA,KAAAZ,EAAAY,WAAA,IACAxR,EAAA/4B,EAAA2pC,EAAA/1B,IAEAgE,EAAAuC,EAAAna,GACA4X,EAAAgC,OAAA+vB,EAAAY,WACA32B,EAAAgE,MAKA,QAAA00B,IAAAv2B,EAAAnC,GAKA,GAAA24B,GAAApS,qBAAAC,UACAD,UAAAC,UAAA9Q,cAAA,GAEAkjB,EAAAD,EAAA/vB,QAAA,gBAAA+vB,EAAA/vB,QAAA,eACAiwB,EAAAF,EAAA/vB,QAAA,aACAkwB,EAAAH,EAAA/vB,QAAA,aAIAmwB,EAAAH,IACAC,GAAAC,IAAA,QAAA32B,EAAAmD,OAEAnX,IAAA,SAAAgU,OAAAhU,MAEA6qC,EAAA,SAAAnnC,KAAAsQ,EAAAq0B,IAEA,KAAAwC,IAAAD,IAAA5qC,GAAA,CACA,GAAA8qC,GAAA92B,EAAAq0B,IAAA5tB,QAAA,SACAzG,GAAAq0B,MAAAyC,EAAA,mBAAA75B,KAAA85B,MAGA,MAAAb,IAAAl2B,EAAAnC,GAMA,QAAAm5B,IAAAC,EAAAxnB,GACA,UAAAhS,IAAA,SAAApF,EAAAsF,GAOA,QAAAu5B,KACAvS,IACAsS,EAAAE,OAAAn5B,KAAAglB,EAAAoU,GAGA,QAAApI,OACAnY,IAAAle,EAEAmF,EACAH,EAAAG,GAEAzF,IAGAg/B,IAIA,QAAArU,KACA2B,IACAqK,IAIA,QAAAoI,GAAAE,GACA3S,IACA7mB,KAAAw5B,EACAtI,IAGA,QAAAqI,KACA,KAAA1S,EAAAlV,GAAA0nB,EAAAx+B,GACAu+B,IAtCA,GAIAp5B,GAJA6mB,EAAA,EACAwS,EAAA,EACAtgB,EAAA,EACAle,EAAAs+B,EAAArvC,MAuCAyvC,OAWA,QAAAE,IAAAlb,GACA,GAAA5N,GAAA4N,EAAA9X,KAAA8X,EAAA9X,IAAAa,YACAqJ,IAGA1oB,OAAAkH,KAAAwhB,GAAAvlB,QAAA,SAAAi3B,GACA,GAAAhb,GAAAsJ,EAAA0R,EACAhb,GAAAlb,KAAA4qB,GAAA1P,EAAAlb,KAAAkb,EAAAyS,gBAIA,QAAA4f,IAAAl3B,GACA,iBAAA5Q,KAAA4Q,GACA,WAAAm3B,mBAAAn3B,EAAA/O,MAAA,IAEA,UAAA7B,KAAA4Q,GACA,UAAAm3B,mBAAAn3B,EAAA/O,MAAA,IAEAkmC,mBAAAn3B,GAGA,QAAAo3B,IAAAnzB,GACA,MAAAA,GAAAa,cAAArf,OAAAkH,KAAAsX,EAAAa,cAIA3H,GAAAoS,IAAA9pB,OAAAkH,KAAAsX,EAAAa,cAAAje,IAAA,SAAAyB,GACA,GAAAk/B,GAAAvjB,EAAAa,aAAAxc,EACA,IAAAk/B,EAAA79B,MAAA,gBAAA69B,GAAA79B,KACA,UAAAwT,IAAA,SAAApF,GACAyd,GAAAgS,EAAA79B,KAAAoO,KACO2F,KAAA,SAAA8W,GACPgT,EAAA79B,KAAA6qB,OATArX,GAAApF,UAeA,QAAAs/B,IAAA33B,GACA,IAAAA,EAAAmR,OACA,QAGA,IAAAymB,GAAAvxB,EAAArG,EAAAmR,QAAAymB,QAEA,gBAAAA,GAAA,UAAAA,EAKA,QAAAC,IAAAjyC,EAAAoa,GAGA,GAAA23B,GAAA33B,GAAA,CACA,GAAA2C,GAAA3C,EAAApa,KAAAkyC,OAAA93B,EAAAmR,OAAAvpB,OACAhC,GAAAoa,EAAAmR,OAAAsmB,mBAAA90B,GAIA,GAAA4D,GAAAF,EAAAzgB,IAGA2gB,EAAAwxB,MAAAxxB,EAAAyxB,YACAzxB,EAAA0xB,MAAgBC,SAAA3xB,EAAAwxB,KAAAC,SAAAzxB,EAAAyxB,UAKhB,IAAAhyB,GAAAO,EAAA8D,KAAAtT,QAAA,iBAAAkP,MAAA,IAcA,OAVAM,GAAA9K,GAAAuK,EAAAtb,MAEA6b,EAAA9K,GAAAgL,QAAA,YACAF,EAAA9K,GAAAg8B,mBAAAlxB,EAAA9K,KAKA8K,EAAA8D,KAAArE,EAAAI,KAAA,KAEAG,EAIA,QAAA4xB,IAAAn4B,EAAAqK,GACA,MAAA+tB,IAAAp4B,IAAAvE,GAAA,IAAA4O,GAIA,QAAA+tB,IAAAp4B,EAAAqK,GAGA,GAAAguB,GAAAr4B,EAAAqK,KAAA,MAIA,OAAArK,GAAA43B,SAAA,MAAA53B,EAAAs4B,MACAt4B,EAAAu4B,KAAA,IAAAv4B,EAAAu4B,KAAA,IACA,IAAAv4B,EAAAqK,KAAAguB,EAAAhuB,EAGA,QAAAmuB,IAAA7K,GACA,UAAA5nC,OAAAkH,KAAA0gC,GAAAxmC,IAAA,SAAAsxC,GACA,MAAAA,GAAA,IAAAhB,mBAAA9J,EAAA8K,MACGryB,KAAA,KAIH,QAAAsyB,IAAA14B,EAAAnC,GAuBA,QAAA86B,GAAAC,EAAA9E,EAAAj2B,GACA,GAAAg7B,GAAAD,EAAArC,SACA7O,EAAA3X,GAAAhT,EAAA+7B,GAAAD,EAAA/E,EAEA,OADAiF,IAAArR,EAAAvkB,OAAA,IAAAukB,EAAA2M,KACA9kB,EAAAypB,MAAAtR,EAAA7pB,GAGA,QAAAo7B,GAAAL,EAAA54B,GACA,UAAAvC,IAAA,SAAApF,EAAAsF,GACAg7B,EAAAC,EAAA54B,EAAA,SAAAlC,EAAAS,GAEA,MAAAT,GACAH,EAAAG,OAEAzF,GAAAkG,OAKA,QAAA26B,GAAAtzC,EAAAwX,GACA,MAAAa,GAAArY,EAAAyX,GAAA,SAAA1V,GACA0pC,IAAArzB,KAAA,WACA,MAAAZ,GAAA5V,MAAAxC,KAAA2C,KACO0oB,MAAA,SAAAtpB,GACP,GAAA8W,GAAAlW,EAAA+C,KACAmT,GAAA9W,QAOA,QAAAsqC,KAEA,GAAArxB,EAAAm5B,WAAAn5B,EAAAo5B,WACA,MAAA37B,IAAApF,SAMA,IAAAghC,EACA,MAAAA,EAGA,IAAAC,IAAuBn2B,OAAA,MAAAkxB,IAAAkF,EAuBvB,OAtBAF,GAAAJ,KAAiCK,GAAAjpB,MAAA,SAAAvS,GACjC,MAAAA,MAAA+F,QAAA,MAAA/F,EAAA+F,QAEAD,EAAA,uDACAq1B,MAAgC91B,OAAA,MAAAkxB,IAAAkF,KAEhC97B,GAAAE,OAAAG,KAEKuS,MAAA,SAAAvS,GAIL,SAAAA,MAAA+F,QAAA,MAAA/F,EAAA+F,SAGApG,GAAAE,OAAAG,KAGAu7B,EAAAhpB,MAAA,WACAgpB,EAAA,OAGAA,EAuSA,QAAAG,GAAAC,GACA,MAAAA,GAAAxzB,MAAA,KAAA9e,IAAAswC,oBAAArxB,KAAA,KAhYA,GAAAmJ,GAAAvqB,KAEAszC,EAAAT,GAAA73B,EAAApa,KAAAoa,GACAu5B,EAAApB,GAAAG,EAAA,GAEAt4B,GAAAjD,EAAAiD,EACA,IAAA84B,GAAA94B,EAAAu2B,QAEA,IAAAv2B,EAAAi4B,MAAAK,EAAAL,KAAA,CACA,GAAAyB,GAAA15B,EAAAi4B,MAAAK,EAAAL,KACAn0B,EAAA41B,EAAAxB,SAAA,IAAAwB,EAAA1B,SACA2B,EAAA3jB,GAAA4jB,SAAAnC,mBAAA3zB,IACAg1B,GAAA9E,QAAA8E,EAAA9E,YACA8E,EAAA9E,QAAA6F,cAAA,SAAAF,EAKApqB,EAAAypB,MAAAzC,EAgCA,IAAA8C,EAyCA7gC,IAAA,WACAqF,EAAA,KAAA0R,KAGAA,EAAA1a,KAAA,WACA,cAGA0a,EAAAjP,GAAA44B,EAAA,cAAAr7B,GACA86B,MAAiBx1B,OAAA,MAAAkxB,IAAA+D,GAAAE,EAAA,KAAqC,SAAAx6B,EAAAtV,GACtD,GAAAsxC,GAAAtxC,KAAAif,KACAjf,EAAAif,KAAA6wB,EAAA78B,GAAA08B,GAAAG,EAAA,GACAz6B,GAAA,KAAAi8B,OAIAvqB,EAAA9N,QAAAy3B,EAAA,mBAAApF,EAAAj2B,GACAi2B,EAAAO,IAAA8D,GAAAG,EAAAxE,EAAAO,KACAsE,KAAc7E,EAAAj2B,KAKd0R,EAAAwqB,QAAAb,EAAA,mBAAAl5B,EAAAnC,GACA,kBAAAmC,KACAnC,EAAAmC,EACAA,MAEAA,EAAAjD,EAAAiD,GACA24B,EAAA34B,GACAq0B,IAAA8D,GAAAG,EAAA,YACAn1B,OAAA,QACK,WACL,QAAA62B,KACAzqB,EAAAlP,KAAA,SAAAvC,EAAAS,GACAA,MAAA07B,gBACAp8B,EAAA,MAA4BiC,IAAA,IAE5B3F,WAAA6/B,EAAAh6B,EAAAk6B,UAAA,OAKAF,QAIAzqB,EAAAxP,QAAA9B,EAAA,mBAAA+B,EAAAnC,GAGA,QAAAs8B,GAAAxhB,GACA,GAAAgV,KACA3tB,GAAA0I,OACAilB,EAAAjlB,MAAA,GAEA1I,EAAAkF,cAEAyoB,EAAAzoB,aAAA,GAEAlF,EAAA2M,SACAghB,EAAAhhB,QAAA,GAEAgsB,EAAA34B,GACAq0B,IAAA8D,GAAAG,EAAA,YAAAE,GAAA7K,IACAxqB,OAAA,OACAwY,MAAevb,KAAAJ,EAAAI,OACRuY,GAGP,QAAAyhB,KAOA,QAAAC,GAAAC,GACA,gBAAAx8B,EAAAS,GAEA2B,EAAAo6B,GAAA/7B,EAAA2B,UACAM,IAAA+5B,GACA18B,EAAA,MAA4BqC,QAAAoF,EAAApF,MAK5B,OAfA8hB,GAAAwY,GACAD,EAAAhjC,KAAA6f,KAAApX,EAAAI,KAAAxY,OAAAo6B,GACAxhB,EAAA,EACAN,EAAA,GAAAzX,OAAA8xC,GAYAl1C,EAAA,EAAqBA,EAAAk1C,EAAgBl1C,IAAA,CACrC,GAAAyqB,GAAA9Q,EAAAgB,GAAA,+BACA8P,GAAAymB,KAAAuC,EACAhpB,EAAA1P,KAAAJ,EAAAI,KAAA7O,MAAAlM,EAAA28B,EACAzqB,KAAAwJ,IAAAf,EAAAI,KAAAxY,QAAAvC,EAAA,GAAA28B,IACAjiB,EAAAhK,EAAA+Z,EAAAuqB,EAAAh1C,KA3CA,GAAA0Q,GAAA/Q,KAgDAu0C,EAAAnB,GAAAE,EAAA,IACAmC,EAAAC,GAAAnB,EAEA,kBAAAkB,GAEAN,EAAA,SAAAr8B,EAAAS,GAEAT,GACA48B,GAAAnB,IAAA,EACA31B,EACA9F,EAAA+F,OACA,uEAGAu2B,MAEAM,GAAAnB,IAAA,EACA17B,EAAA,KAAAU,MAGKk8B,EAELN,EAAAt8B,GAEAu8B,MAOA7qB,EAAAyY,MAAA,SAAAnqB,GACAwzB,IAAArzB,KAAA,WACA26B,MACAx1B,OAAA,MACAkxB,IAAA8D,GAAAG,EAAA,KACO,SAAAx6B,EAAAS,GAEP,MAAAT,GACAD,EAAAC,IAEAS,EAAA+5B,KAAAH,GAAAG,EAAA,QACAz6B,GAAA,KAAAU,QAEK8R,MAAAxS,IAML0R,EAAAppB,IAAA+yC,EAAA,eAAA54B,EAAAN,EAAAnC,GA8CA,QAAA88B,GAAAp2B,GAUA,QAAAovB,GAAAxT,GACA,GAAAhb,GAAAsJ,EAAA0R,GACA9V,EAAAmtB,GAAAjzB,EAAAnI,KAAA,IAAAo9B,EAAArZ,GACA,QAAA5b,EAAA4C,IACA,OAAA8xB,GAAAj5B,GACAmD,OAAA,MACAkxB,IAAA8D,GAAAG,EAAAjuB,GACA4K,QAAA,IACSjX,KAAA,SAAAoY,GACT,MAAApW,GAAAiV,OACAmB,EAEA,GAAA3Y,IAAA,SAAApF,GACAyd,GAAAM,EAAA/d,OAES2F,KAAA,SAAA/T,SACTkb,GAAAE,WACAF,GAAAvd,OACAud,EAAAlb,SA3BA,GAAAwkB,GAAAlK,EAAAa,aACAw1B,EAAAnsB,GAAA1oB,OAAAkH,KAAAwhB,EACA,IAAAA,GAAAmsB,EAAAhzC,OAAA,CA6BA,GAAAqvC,GAAA2D,EAAAzzC,IAAA,SAAAg5B,GACA,kBACA,MAAAwT,GAAAxT,KAMA,OAAA6W,IAAAC,EAAA,IAGA,QAAA4D,GAAAC,GACA,MAAAryC,OAAA4D,QAAAyuC,GACAr9B,GAAAoS,IAAAirB,EAAA3zC,IAAA,SAAAod,GACA,GAAAA,EAAAzE,GACA,MAAA66B,GAAAp2B,EAAAzE,OAIA66B,EAAAG,GA/FA,kBAAA96B,KACAnC,EAAAmC,EACAA,MAEAA,EAAAjD,EAAAiD,EAGA,IAAA2tB,KAEA3tB,GAAA0I,OACAilB,EAAAjlB,MAAA,GAGA1I,EAAA+6B,YACApN,EAAAoN,WAAA,GAGA/6B,EAAA2M,SACAghB,EAAAhhB,QAAA,GAGA3M,EAAAwB,YACA,QAAAxB,EAAAwB,YACAxB,EAAAwB,UAAAiZ,KAAAK,UAAA9a,EAAAwB,YAEAmsB,EAAAnsB,UAAAxB,EAAAwB,WAGAxB,EAAA0B,MACAisB,EAAAjsB,IAAA1B,EAAA0B,KAGA1B,EAAAwJ,YACAmkB,EAAAnkB,UAAAxJ,EAAAwJ,WAGAlJ,EAAAk3B,GAAAl3B,EAGA,IAAAwzB,IACA3wB,OAAA,MACAkxB,IAAA8D,GAAAG,EAAAh4B,EAAAk4B,GAAA7K,IAyDAsL,GAAAj5B,EAAA8zB,GAAA91B,KAAA,SAAAO,GACA,MAAAd,IAAApF,UAAA2F,KAAA,WACA,GAAAgC,EAAAkF,YACA,MAAA21B,GAAAt8B,KAEOP,KAAA,WACPH,EAAA,KAAAU,OAEK8R,MAAAxS,KAIL0R,EAAAyrB,OAAA9B,EAAA,SACA,SAAA+B,EAAAC,EAAAl7B,EAAAnC,GACA,GAAA0G,EACA,iBAAA22B,IAEA32B,GACAnI,IAAA6+B,EACA9zB,KAAA+zB,GAEA,kBAAAl7B,KACAnC,EAAAmC,EACAA,QAIAuE,EAAA02B,EACA,kBAAAC,IACAr9B,EAAAq9B,EACAl7B,OAEAnC,EAAAmC,EACAA,EAAAk7B,GAIA,IAAAx5B,GAAA6C,EAAA4C,MAAAnH,EAAA0B,GAGAi3B,GAAA34B,GACAmD,OAAA,SACAkxB,IAAA8D,GAAAG,EAAAd,GAAAjzB,EAAAnI,MAAA,QAAAsF,GACK7D,KAQL0R,EAAA4rB,cACAjC,EAAA,yBAAAl9B,EAAAy9B,EAAAz5B,EACAnC,GACA,kBAAAmC,KACAnC,EAAAmC,EACAA,KAEA,IAAA2tB,GAAA3tB,EAAA0B,IAAA,QAAA1B,EAAA0B,IAAA,GACA2yB,EAAA8D,GAAAG,EAAAd,GAAAx7B,IAAA,IACAw9B,EAAAC,GAAA9L,CACAgL,GAAA34B,GACAmD,OAAA,MACAkxB,MACApf,QAAA,GACKpX,KAIL0R,EAAA6rB,iBACAlC,EAAA,4BAAAl9B,EAAAy9B,EAAA/3B,EACA7D,GAEA,GAAAw2B,GAAA8D,GAAAG,EAAAd,GAAAx7B,GAAA,IACAw9B,EAAAC,IAAA,QAAA/3B,CAEAi3B,OACAx1B,OAAA,SACAkxB,OACKx2B,KAML0R,EAAA8rB,cACAnC,EAAA,yBAAAl9B,EAAAy9B,EAAA/3B,EAAA0U,EACAvhB,EAAAgJ,GACA,kBAAAhJ,KACAgJ,EAAAhJ,EACAA,EAAAuhB,EACAA,EAAA1U,EACAA,EAAA,KAEA,IAAApB,GAAAk3B,GAAAx7B,GAAA,IAAAw9B,EAAAC,GACApF,EAAA8D,GAAAG,EAAAh4B,EAKA,IAJAoB,IACA2yB,GAAA,QAAA3yB,GAGA,gBAAA0U,GAAA,CAEA,GAAAnB,EACA,KACAA,EAAAF,GAAAqB,GACO,MAAAtY,GACP,MAAAD,GAAAqG,EAAAsT,GACA,4CAEApB,EAAAnB,EAAAN,GAAAM,EAAApgB,GAAA,GAGA,GAAAmL,IACAg0B,SAAgBsH,eAAAzmC,GAChBsO,OAAA,MACAkxB,MACAD,aAAA,EACAzY,KAAAvF,EACAke,QAAAwE,EAAAxE,SAAA,IAGAqE,MAAc34B,EAAAnC,KAKd0R,EAAAkY,UAAA,SAAAjjB,EAAAxE,EAAAnC,GAIA2G,EAAA2V,UAAAna,EAAAma,UAEAkX,IAAArzB,KAAA,WACA,MAAAP,IAAAoS,IAAArL,EAAApE,KAAAjZ,IAAAuwC,OACK15B,KAAA,WAEL26B,EAAA34B,GACAmD,OAAA,OACAkxB,IAAA8D,GAAAG,EAAA,cACAhE,QAAAt0B,EAAAs0B,QACA3Y,KAAAnX,GACO,SAAA1G,EAAAoC,GACP,MAAApC,GACAD,EAAAC,IAEAoC,EAAAhX,QAAA,SAAAV,GACAA,EAAAsX,IAAA,QAEAjC,GAAA,KAAAqC,QAEKmQ,MAAAxS,IAKL0R,EAAAgsB,KAAA,SAAAh3B,EAAAvE,EAAAnC,GACAwzB,IAAArzB,KAAA,WACA,MAAA05B,IAAAnzB,KACKvG,KAAA,WAEL26B,EAAA34B,GACAmD,OAAA,MACAkxB,IAAA8D,GAAAG,EAAAd,GAAAjzB,EAAAnI,MACAuf,KAAApX,GACO,SAAAzG,EAAAtV,GACP,MAAAsV,GACAD,EAAAC,OAEAD,GAAA,KAAArV,OAEK6nB,MAAAxS,IAML0R,EAAAisB,QAAAtC,EAAA,mBAAAl5B,EAAAnC,GACA,kBAAAmC,KACAnC,EAAAmC,EACAA,MAEAA,EAAAjD,EAAAiD,EAGA,IACA2b,GADAgS,KAEAxqB,EAAA,KAEAnD,GAAAwJ,YACAmkB,EAAAnkB,WAAA,GAGAxJ,EAAA0P,aACAie,EAAAje,YAAA,GAGA1P,EAAAiF,eACA0oB,EAAA1oB,cAAA,GAIAjF,EAAAkF,cACAyoB,EAAAzoB,aAAA,GAGAlF,EAAApX,MACA+kC,EAAA/kC,IAAA6xB,KAAAK,UAAA9a,EAAApX,MAGAoX,EAAAy7B,YACAz7B,EAAA6jB,SAAA7jB,EAAAy7B,WAGAz7B,EAAA6jB,WACA8J,EAAA9J,SAAApJ,KAAAK,UAAA9a,EAAA6jB,WAGA7jB,EAAA07B,UACA17B,EAAA8jB,OAAA9jB,EAAA07B,SAGA17B,EAAA8jB,SACA6J,EAAA7J,OAAArJ,KAAAK,UAAA9a,EAAA8jB,SAGA,mBAAA9jB,GAAA+jB,gBACA4J,EAAA5J,gBAAA/jB,EAAA+jB,eAGA,mBAAA/jB,GAAAyP,QACAke,EAAAle,MAAAzP,EAAAyP,OAGA,mBAAAzP,GAAAwP,OACAme,EAAAne,KAAAxP,EAAAwP,KAGA,IAAAmsB,GAAAnD,GAAA7K,EAEA,oBAAA3tB,GAAA/S,OACAkW,EAAA,OACAwY,GAAc1uB,KAAA+S,EAAA/S,OAIdgsC,EAAAj5B,GACAmD,SACAkxB,IAAA8D,GAAAG,EAAA,YAAAqD,GACAhgB,SACK3d,KAAA,SAAAO,GACLyB,EAAAiF,cAAAjF,EAAAkF,aAAAlF,EAAAiV,QACA1W,EAAA2R,KAAAhnB,QAAAquC,IAEA15B,EAAA,KAAAU,KACK8R,MAAAxS,KAML0R,EAAA8Y,SAAA,SAAAroB,GAMA,GAAAgiB,GAAA,cAAAhiB,KAAA47B,WAAAC,EAEA77B,GAAAjD,EAAAiD,GACAA,EAAAs0B,QAAA,WAAAt0B,KAAAs0B,QACA,WAAAwE,KAAAxE,QACA,GAIA,IAEAnP,GAFAwI,EAAA3tB,EAAAs0B,SAAiCA,QAAAt0B,EAAAs0B,QAAA,QACjC7kB,EAAA,mBAAAzP,GAAAyP,OAAAzP,EAAAyP,KAGA0V,GADA,eAAAnlB,GACAA,EAAAgmB,cACK,cAAAhmB,KAELA,EAAAmlB,UAKA,IAAA2W,GAAArsB,CA+CA,IA7CAzP,EAAAgO,QACA2f,EAAA3f,MAAAhO,EAAAgO,QAGAhO,EAAAiF,cAAAjF,EAAAlE,QAAA,kBAAAkE,GAAAlE,UACA6xB,EAAA1oB,cAAA,GAGAjF,EAAAkF,cACAyoB,EAAAzoB,aAAA,GAGAlF,EAAA4lB,aACA+H,EAAAoO,KAAA,YAGA/7B,EAAAwJ,YACAmkB,EAAAnkB,WAAA,GAGAxJ,EAAA0P,aACAie,EAAAje,YAAA,GAGA,aAAA1P,GAEAA,EAAAg8B,YACArO,EAAAqO,UAAAh8B,EAAAg8B,WAEKh8B,EAAA4lB,aAEL+H,EAAAqO,UAAA,KAGAh8B,EAAAlE,QAAA,gBAAAkE,GAAAlE,SACA6xB,EAAA7xB,OAAAkE,EAAAlE,QAGAkE,EAAAwyB,MAAA,gBAAAxyB,GAAAwyB,OACA7E,EAAA7xB,OAAA,QACA6xB,EAAA6E,KAAAxyB,EAAAwyB,MAKAxyB,EAAA8E,cAAA,gBAAA9E,GAAA8E,aACA,OAAAm3B,KAAAj8B,GAAA8E,aAEA9E,EAAA8E,aAAAre,eAAAw1C,KACAtO,EAAAsO,GAAAj8B,EAAA8E,aAAAm3B,GAKA,IACAtgB,GADAxY,EAAA,KAGAnD,GAAA6lB,UAGA8H,EAAA7xB,OAAA,WACAqH,EAAA,OACAwY,GAAckK,QAAA7lB,EAAA6lB,SAGd,IAAAgP,GACAqH,EAIAvI,EAAA,SAAA5N,EAAAloB,GACA,IAAAmC,EAAAm8B,QAAA,CAGAxO,EAAA5H,QAGA,gBAAA4H,GAAA5H,QACA4H,EAAA5H,MAAAtL,KAAAK,UAAA6S,EAAA5H,QAGA/lB,EAAA0P,WACAD,IACAke,EAAAle,MAAAqsB,GAGAnO,EAAAle,UAAAqsB,EAAA9Z,EACAA,EAAA8Z,CAIA,IAAAM,IACAj5B,SACAkxB,IAAA8D,GAAAG,EAAA,WAAAE,GAAA7K,IACA2G,QAAAt0B,EAAAs0B,QACA3Y,OAEAugB,GAAAnW,EAGA/lB,EAAAm8B,SAKA9K,IAAArzB,KAAA,WACA62B,EAAA8D,EAAA34B,EAAAo8B,EAAAv+B,KACOwS,MAAAxS,KAMPqC,GAAmBA,YAEnBm8B,EAAA,SAAAv+B,EAAAS,GACA,IAAAyB,EAAAm8B,QAAA,CAGA,GAAAG,GAAA,CAEA,IAAA/9B,KAAA2B,QAAA,CACAo8B,EAAA/9B,EAAA2B,QAAAtY,OACAsY,EAAAoQ,SAAA/R,EAAA+R,QAEA,IAAA9L,KACAA,GAAAK,MAAA7E,EAAA8E,aACAvG,EAAA2B,QAAA3B,EAAA2B,QAAApE,OAAA,SAAArW,GACAq2C,GACA,IAAAhT,GAAAnkB,EAAA3E,GAAAva,EAUA,OATAqjC,KACA9oB,EAAAiF,cAAAjF,EAAAkF,aAAAlF,EAAAiV,QACAsiB,GAAA9xC,GAEA0/B,GACAjlB,UAAAnV,KAAAtF,GAEAua,EAAA0N,SAAAjoB,IAEAqjC,QAEO,IAAAhrB,EAKP,MAFAkC,GAAAm8B,SAAA,MACAn8B,GAAAsN,SAAAxP,EAMAS,MAAA+R,WACA4rB,EAAA39B,EAAA+R,SAGA,IAAAisB,GAAA9sB,GAAAqsB,GAAA,GACAv9B,GAAA+9B,EAAAta,GACAhiB,EAAA,aAEAA,EAAA4lB,YAAAnW,GAAAqsB,GAAA,IAAAS,EAKAv8B,EAAAsN,SAAA,KAAApN,GAHA1H,GAAA,WAA8Bm7B,EAAAuI,EAAAG,MAU9B,OAHA1I,GAAA3zB,EAAA+lB,OAAA,EAAAsW,IAIAhvB,OAAA,WACArN,EAAAm8B,SAAA,EACAtH,GACAA,EAAAF,WASAplB,EAAAitB,SAAAtD,EAAA,oBAAA10B,EAAAxE,EAAAnC,GAEA,kBAAAmC,KACAnC,EAAAmC,EACAA,MAIA24B,EAAA34B,GACAmD,OAAA,OACAkxB,IAAA8D,GAAAG,EAAA,cACA3c,KAAAnX,GACK3G,KAGL0R,EAAA+Y,OAAA,SAAAzqB,GACAA,KAGA0R,EAAA2Z,SAAA,SAAA4K,EAAAj2B,GACA86B,EAAA7E,GACAO,IAAA8D,GAAAG,EAAA,IACAn1B,OAAA,UACK,SAAArF,EAAAF,GACL,MAAAE,MAAA+F,QAAA,MAAA/F,EAAA+F,OACAhG,EAAAC,OAEAD,GAAA,KAAAD,MAeA,QAAA6+B,IAAA34B,EAAA44B,EAAAC,GAIA,IAHA,GAAAC,GAAA,GACAC,EAAAF,EAAA74B,EAAAlc,OAEAg1C,EAAAh1C,OAAAi1C,GACAD,GAAAF,CAEA,OAAAE,GAGA,QAAAE,IAAAh5B,EAAA44B,EAAAC,GACA,GAAAC,GAAAH,GAAA34B,EAAA44B,EAAAC,EACA,OAAAC,GAAA94B,EAOA,QAAAi5B,IAAAj0B,EAAAC,GAEA,GAAAD,IAAAC,EACA,QAGAD,GAAAk0B,GAAAl0B,GACAC,EAAAi0B,GAAAj0B,EAEA,IAAAk0B,GAAAC,GAAAp0B,GACAq0B,EAAAD,GAAAn0B,EACA,IAAAk0B,EAAAE,IAAA,EACA,MAAAF,GAAAE,CAEA,cAAAr0B,IACA,aACA,MAAAA,GAAAC,CACA,eACA,MAAAD,GAAAC,GAAA,GACA,cACA,MAAAq0B,IAAAt0B,EAAAC,GAEA,MAAAtgB,OAAA4D,QAAAyc,GAAAu0B,GAAAv0B,EAAAC,GAAAu0B,GAAAx0B,EAAAC,GAKA,QAAAi0B,IAAAp0C,GACA,aAAAA,IACA,gBACA,WACA,cACA,MAAAA,KAAA20C,KAAA30C,MAAA20C,MAAAC,MAAA50C,GACA,KAEAA,CACA,cACA,GAAA60C,GAAA70C,CACA,IAAAH,MAAA4D,QAAAzD,GAAA,CACA,GAAA+P,GAAA/P,EAAAhB,MACAgB,GAAA,GAAAH,OAAAkQ,EACA,QAAAtT,GAAA,EAAuBA,EAAAsT,EAAStT,IAChCuD,EAAAvD,GAAA23C,GAAAS,EAAAp4C,QAGO,IAAAuD,YAAAqU,MACP,MAAArU,GAAA80C,QACO,WAAA90C,EAAA,CACPA,IACA,QAAA6vC,KAAAgF,GACA,GAAAA,EAAAh3C,eAAAgyC,GAAA,CACA,GAAAnO,GAAAmT,EAAAhF,EACA,oBAAAnO,KACA1hC,EAAA6vC,GAAAuE,GAAA1S,OAMA,MAAA1hC,GAGA,QAAA+0C,IAAA/0C,GACA,UAAAA,EACA,aAAAA,IACA,cACA,MAAAA,GAAA,GACA,cACA,MAAAg1C,IAAAh1C,EACA,cAMA,MAAAA,GACAmO,QAAA,gBACAA,QAAA,gBACAA,QAAA,eACA,cACA,GAAA1K,GAAA5D,MAAA4D,QAAAzD,GACAmT,EAAA1P,EAAAzD,EAAA7C,OAAAkH,KAAArE,GACAvD,GAAA,EACAsT,EAAAoD,EAAAnU,OACAY,EAAA,EACA,IAAA6D,EACA,OAAAhH,EAAAsT,GACAnQ,GAAAq1C,GAAA9hC,EAAA1W,QAGA,QAAAA,EAAAsT,GAAA,CACA,GAAAmlC,GAAA/hC,EAAA1W,EACAmD,IAAAq1C,GAAAC,GACAD,GAAAj1C,EAAAk1C,IAGA,MAAAt1C,GAGA,SAMA,QAAAq1C,IAAAj1C,GACA,GAAAm1C,GAAA,IAEA,OADAn1C,GAAAo0C,GAAAp0C,GACAs0C,GAAAt0C,GAAAo1C,GAAAL,GAAA/0C,GAAAm1C,EAGA,QAAAE,IAAAn6B,EAAAze,GACA,GACAimC,GADA4S,EAAA74C,EAEA04C,EAAA,MAAAj6B,EAAAze,EACA,IAAA04C,EACAzS,EAAA,EACAjmC,QACG,CACH,GAAA84C,GAAA,MAAAr6B,EAAAze,EACAA,IACA,IAAA+4C,GAAA,GACAC,EAAAv6B,EAAA1E,UAAA/Z,IAAAi5C,IACAC,EAAAh7B,SAAA86B,EAAA,IAAAG,EAMA,KAJAL,IACAI,MAEAl5C,GAAAi5C,KACA,CACA,GAAAG,GAAA36B,EAAAze,EACA,WAAAo5C,EACA,KAEAL,IAAAK,EAEAp5C,IAEA+4C,IAAAn4B,MAAA,KAEAqlB,EADA,IAAA8S,EAAAx2C,OACA2b,SAAA66B,EAAA,IAGAM,WAAAN,EAAA,OAAAA,EAAA,IAGAD,IACA7S,GAAA,IAGA,IAAAiT,IAIAjT,EAAAoT,WAAApT,EAAA,IAAAiT,IAGA,OAAUjT,MAAA1jC,OAAAvC,EAAA64C,GAKV,QAAAxzC,IAAA4C,EAAAqxC,GACA,GAAAhkC,GAAArN,EAAA5C,KAEA,IAAAi0C,EAAA/2C,OAAA,CACA,GAAAg3C,GAAAD,IAAA/2C,OAAA,EACA+S,KAAAikC,EAAAvlC,UAEAslC,EAAAj0C,MACAk0C,EAAAD,IAAA/2C,OAAA,GAEA,IAAAyR,GAAAulC,EAAAvlC,QACAwlC,EAAAD,EAAA52C,KACA,IAAAS,MAAA4D,QAAAgN,GACAA,EAAAtO,KAAA4P,OACK,IAAAkkC,IAAAvxC,EAAA1F,OAAA,GACL,GAAAgB,GAAA0E,EAAA5C,KACA2O,GAAAzQ,GAAA+R,MAEArN,GAAAvC,KAAA4P,IAKA,QAAAmkC,IAAAh7B,GAMA,IALA,GAAAxW,MACAqxC,KACAt5C,EAAA,IAGA,CACA,GAAA63C,GAAAp5B,EAAAze,IACA,WAAA63C,EAQA,OAAAA,GACA,QACA5vC,EAAAvC,KAAA,KACA,MACA,SACAuC,EAAAvC,KAAA,MAAA+Y,EAAAze,IACAA,GACA,MACA,SACA,GAAA05C,GAAAd,GAAAn6B,EAAAze,EACAiI,GAAAvC,KAAAg0C,EAAAzT,KACAjmC,GAAA05C,EAAAn3C,MACA,MACA,SAGA,IAFA,GAAAo3C,GAAA,KAEA,CACA,GAAAP,GAAA36B,EAAAze,EACA,WAAAo5C,EACA,KAEAO,IAAAP,EACAp5C,IAIA25C,IAAAjoC,QAAA,sBACAA,QAAA,qBACAA,QAAA,qBACAzJ,EAAAvC,KAAAi0C,EACA,MACA,SACA,GAAAC,IAA4B5lC,WAAArR,MAAAsF,EAAA1F,OAC5B0F,GAAAvC,KAAAk0C,EAAA5lC,SACAslC,EAAA5zC,KAAAk0C,EACA,MACA,SACA,GAAAC,IAA0B7lC,WAAYrR,MAAAsF,EAAA1F,OACtC0F,GAAAvC,KAAAm0C,EAAA7lC,SACAslC,EAAA5zC,KAAAm0C,EACA,MAEA,SACA,SAAAvjC,OACA,4DACAuhC,OArDA,CACA,OAAA5vC,EAAA1F,OACA,MAAA0F,GAAA5C,KAEAA,IAAA4C,EAAAqxC,KAsDA,QAAAtB,IAAAv0B,EAAAC,GAEA,OADApQ,GAAApB,KAAAwJ,IAAA+H,EAAAlhB,OAAAmhB,EAAAnhB,QACAvC,EAAA,EAAiBA,EAAAsT,EAAStT,IAAA,CAC1B,GAAA+jB,GAAA2zB,GAAAj0B,EAAAzjB,GAAA0jB,EAAA1jB,GACA,QAAA+jB,EACA,MAAAA,GAGA,MAAAN,GAAAlhB,SAAAmhB,EAAAnhB,OAAA,EACAkhB,EAAAlhB,OAAAmhB,EAAAnhB,OAAA,KAEA,QAAAw1C,IAAAt0B,EAAAC,GAIA,MAAAD,KAAAC,EAAA,EAAAD,EAAAC,EAAA,KAEA,QAAAu0B,IAAAx0B,EAAAC,GAGA,OAFAo2B,GAAAp5C,OAAAkH,KAAA6b,GAAAs2B,EAAAr5C,OAAAkH,KAAA8b,GACApQ,EAAApB,KAAAwJ,IAAAo+B,EAAAv3C,OAAAw3C,EAAAx3C,QACAvC,EAAA,EAAiBA,EAAAsT,EAAStT,IAAA,CAE1B,GAAA+jB,GAAA2zB,GAAAoC,EAAA95C,GAAA+5C,EAAA/5C,GACA,QAAA+jB,EACA,MAAAA,EAIA,IADAA,EAAA2zB,GAAAj0B,EAAAq2B,EAAA95C,IAAA0jB,EAAAq2B,EAAA/5C,KACA,IAAA+jB,EACA,MAAAA,GAIA,MAAA+1B,GAAAv3C,SAAAw3C,EAAAx3C,OAAA,EACAu3C,EAAAv3C,OAAAw3C,EAAAx3C,OAAA,KAMA,QAAAs1C,IAAAt9B,GACA,GAAAU,IAAA,sCACA6J,EAAA7J,EAAAmG,cAAA7G,GAEA,QAAAuK,EACA,OAAAvK,EACA,EAEAnX,MAAA4D,QAAAuT,GACA,EAEAuK,EAAA,EAAAA,EAAA,EAAAA,EAAA,EAGA1hB,MAAA4D,QAAAuT,GACA,EADA,OAUA,QAAAg+B,IAAAtS,GAEA,OAAAA,EACA,SAKA,IAAA+T,GAAA/T,EAAAgU,gBAAAr5B,MAAA,QACAs4B,EAAAh7B,SAAA87B,EAAA,OAEAlB,EAAA7S,EAAA,EAEA9iC,EAAA21C,EAAA,QAIAoB,GAAApB,GAAAI,KAAAC,GACAgB,EAAA1C,GAAA,EAAA/zC,WAAA,IAAAu1C,GAEA91C,IAAAw1C,GAAAwB,CAGA,IAAAC,GAAAloC,KAAAmoC,IAAAhB,WAAAW,EAAA,IAEAlB,KACAsB,EAAA,GAAAA,EAGA,IAAAE,GAAAF,EAAAG,QAAA,GAOA,OAJAD,KAAA5oC,QAAA,aAEAvO,GAAAw1C,GAAA2B,EAUA,QAAAE,MACA76C,KAAAwY,QAAA,GAAAC,IAAA,SAAAC,GAAwDA,MAcxD,QAAAoiC,IAAA9/B,GACA,GAUA+/B,GAVAC,EAAAhgC,EAAAvE,GACAwkC,EAAAjgC,EAAAigC,SACAC,EAAAlgC,EAAA7Y,IACAg5C,EAAAngC,EAAAxE,OACA4kC,EAAApgC,EAAAogC,UAGAC,EAAAH,EAAAn3C,YAAAo3C,KAAAp3C,YACA,WAGA,KAAAq3C,IAEAL,EAAAC,EAAAM,aAAAN,EAAAM,iBACAP,EAAAM,IACA,MAAAN,GAAAM,EAIA,IAAAE,GAAAP,EAAA3/B,OAAArC,KAAA,SAAAqC,GAOA,QAAAmgC,GAAAj8B,GACAA,EAAAk8B,MAAAl8B,EAAAk8B,SACA,IAAAC,GAAAT,CACAS,GAAAj6B,QAAA,YACAi6B,EAAAT,EAAA,IAAAA,EAEA,IAAAU,GAAAp8B,EAAAk8B,MAAAC,GAAAn8B,EAAAk8B,MAAAC,MAEA,KAAAC,EAAAC,GAIA,MADAD,GAAAC,IAAA,EACAr8B,EAjBA,GAAAq8B,GAAAvgC,EAAAoC,QAAA,YACA29B,EAAA,OAAA9oB,GAAA+oB,GAkBA,OAAAr5B,GAAAg5B,EAAA,iBAAAQ,GAAAxiC,KAAA,WACA,MAAAgiC,GAAAa,0BAAAD,GAAA5iC,KAAA,SAAAO,GACA,GAAA9C,GAAA8C,EAAA9C,EACAA,GAAAuW,iBAAA,CACA,IAAAwgB,IACA5sC,KAAAg7C,EACAnlC,KACAukC,WACAjvB,QAAAivB,EAAAjvB,QACAmvB,SACAC,YAEA,OAAA3N,GAAA/2B,GAAAtV,IAAA,kBAAAkqB,MAAA,SAAAvS,GAEA,SAAAA,EAAA+F,OACA,KAAA/F,KAESE,KAAA,SAAA8iC,GAOT,MANAtO,GAAApX,IAAA0lB,IAAA1lB,IAAA,EACA2kB,GACAvN,EAAA/2B,GAAA0B,KAAA,6BACA4iC,GAAAM,KAGA7N,SASA,OAHAuN,KACAA,EAAAM,GAAAE,GAEAA,EAGA,QAAAQ,IAAA98B,GACAjf,KAAA6e,OAAA,IACA7e,KAAAY,KAAA,oBACAZ,KAAAif,UACAjf,KAAA6c,OAAA,CACA,KACAlG,MAAAqlC,kBAAAh8C,KAAA+7C,IACG,MAAAh6C,KAKH,QAAAk6C,IAAAh9B,GACAjf,KAAA6e,OAAA,IACA7e,KAAAY,KAAA,YACAZ,KAAAif,UACAjf,KAAA6c,OAAA,CACA,KACAlG,MAAAqlC,kBAAAh8C,KAAAi8C,IACG,MAAAl6C,KAKH,QAAAm6C,IAAAj9B,GACAjf,KAAA6e,OAAA,IACA7e,KAAAY,KAAA,gBACAZ,KAAAif,UACAjf,KAAA6c,OAAA,CACA,KACAlG,MAAAqlC,kBAAAh8C,KAAAk8C,IACG,MAAAn6C,KAKH,QAAAo6C,IAAAv7C,GACA,GAAAqe,GAAA,WAAAre,EACA,8DAEA,WAAAs7C,IAAAj9B,GAGA,QAAAm9B,IAAAl5C,GAEA,OADAM,GAAA,EACAnD,EAAA,EAAAsT,EAAAzQ,EAAAN,OAAsCvC,EAAAsT,EAAStT,IAAA,CAC/C,GAAAimC,GAAApjC,EAAA7C,EACA,oBAAAimC,GAAA,CACA,IAAA7iC,MAAA4D,QAAAi/B,GAcA,KAAA6V,IAAA,OAZA34C,GAAA,gBAAAA,QACA,QAAA2Y,GAAA,EAAAkgC,EAAA/V,EAAA1jC,OAA0CuZ,EAAAkgC,EAAUlgC,IAAA,CACpD,GAAAmgC,GAAAhW,EAAAnqB,EACA,oBAAAmgC,GACA,KAAAH,IAAA,OACW,oBAAA34C,GAAA2Y,GACX3Y,EAAAuC,KAAAu2C,GAEA94C,EAAA2Y,IAAAmgC,OAMK,gBAAA94C,GACLA,GAAA8iC,EAEA9iC,EAAA,IAAA8iC,EAGA,MAAA9iC,GAOA,QAAA+4C,IAAA95C,EAAAib,GACA,MAAAqK,IACA,WAAAtlB,EAAAsP,QAAA,QAAgC,UAEhC2L,OACA0+B,OACAjjC,IAAAqjC,GACAn1C,WACAqxC,YAKA,QAAA+D,IAAAjkC,EAAAK,GAYA,MAXAA,IACAL,EAAAQ,KAAA,SAAAO,GACA/F,GAAA,WACAqF,EAAA,KAAAU,MAEK,SAAAyF,GACLxL,GAAA,WACAqF,EAAAmG,OAIAxG,EAGA,QAAAkkC,IAAAtkC,GACA,MAAAC,IAAA,SAAA1V,GACA,GAAAgxB,GAAAhxB,EAAA+C,MACA8S,EAAAJ,EAAA5V,MAAAxC,KAAA2C,EAIA,OAHA,kBAAAgxB,IACA8oB,GAAAjkC,EAAAmb,GAEAnb,IAKA,QAAAmkC,IAAAnkC,EAAAokC,GACA,MAAApkC,GAAAQ,KAAA,SAAAO,GACA,MAAAqjC,KAAA5jC,KAAA,WACA,MAAAO,MAEG,SAAAyF,GACH,MAAA49B,KAAA5jC,KAAA,WACA,KAAAgG,OAKA,QAAA69B,IAAAjpC,EAAAkpC,GACA,kBACA,GAAAn6C,GAAAyJ,UACA2wC,EAAA/8C,IACA,OAAA4T,GAAArR,IAAA,WACA,MAAAu6C,GAAAt6C,MAAAu6C,EAAAp6C,MAOA,QAAAq6C,IAAAjmC,GACA,GAAAkmC,GAAA,GAAAnc,IAAA/pB,GACAvT,EAAA,GAAAC,OAAAw5C,EAAAh5C,MACAjB,GAAA,CAIA,OAHAi6C,GAAA/4C,QAAA,SAAAxD,GACA8C,IAAAR,GAAAtC,IAEA8C,EAGA,QAAA05C,IAAA/6C,GACA,GAAAqB,GAAA,GAAAC,OAAAtB,EAAA8B,MACAjB,GAAA,CAIA,OAHAb,GAAA+B,QAAA,SAAAxD,EAAAkD,GACAJ,IAAAR,GAAAY,IAEAJ,EAOA,QAAA25C,IAAAv8C,GAGA,MAAAA,GAAA6gB,QAAA,WAAA7gB,OAAAqgB,MAAA,KAGA,QAAAm8B,IAAAn0B,GAGA,WAAAA,EAAArmB,QAAA,MAAA8H,KAAAue,EAAA,GAAAvM,KAGA,QAAA2gC,IAAA5mC,EAAA1U,GACA,IACA0U,EAAAiH,KAAA,QAAA3b,GACG,MAAA+W,GACHoF,EAAA,QACA,qMAIAA,EAAA,QAAAnc,IAGA,QAAAu7C,IAAA7mC,EAAA2B,EAAAmH,GAGA,IACAnH,EAAAmH,GACG,MAAAxd,GACHs7C,GAAA5mC,EAAA1U,IAIA,QAAAw7C,IAAA9mC,EAAA2B,EAAAnQ,EAAA/E,EAAAs6C,GAKA,IACA,OAAYC,OAAArlC,EAAAnQ,EAAA/E,EAAAs6C,IACT,MAAAz7C,GAEH,MADAs7C,IAAA5mC,EAAA1U,IACY8a,MAAA9a,IAIZ,QAAA27C,IAAA9iC,EAAA+iC,GACA,GAAAC,GAAA7F,GAAAn9B,EAAAhX,IAAA+5C,EAAA/5C,IACA,YAAAg6C,IAAA7F,GAAAn9B,EAAAla,MAAAi9C,EAAAj9C,OAGA,QAAAm9C,IAAA3iC,EAAAuP,EAAAD,GAEA,MADAA,MAAA,EACA,gBAAAC,GACAvP,EAAA3O,MAAAie,EAAAC,EAAAD,GACGA,EAAA,EACHtP,EAAA3O,MAAAie,GAEAtP,EAGA,QAAA4iC,IAAAzmB,GACA,GAAAiO,GAAAjO,EAAA32B,MAGAsW,EAAAsuB,GAAA,gBAAAA,MAAAluB,KAAAigB,EAAA/b,EACA,OAAAtE,GAGA,QAAA+mC,IAAAxkC,GACAA,EAAA2R,KAAAhnB,QAAA,SAAAmzB,GACA,GAAA5N,GAAA4N,EAAA9X,KAAA8X,EAAA9X,IAAAa,YACAqJ,IAGA1oB,OAAAkH,KAAAwhB,GAAAvlB,QAAA,SAAAi3B,GACA,GAAAhb,GAAAsJ,EAAA0R,EACA1R,GAAA0R,GAAAl2B,KAAA4qB,GAAA1P,EAAAlb,KAAAkb,EAAAyS,kBAKA,QAAAorB,IAAAhjC,GACA,gBAAAzB,GAIA,MAHAyB,GAAAiF,cAAAjF,EAAAkF,aAAAlF,EAAAiV,QACA8tB,GAAAxkC,GAEAA,GAkCA,QAAA0kC,IAAAC,EAAAljC,EAAA2tB,EAAAwV,GAEA,GAAA7Y,GAAAtqB,EAAAkjC,EACA,oBAAA5Y,KACA6Y,IACA7Y,EAAAmN,mBAAAhd,KAAAK,UAAAwP,KAEAqD,EAAA5iC,KAAAm4C,EAAA,IAAA5Y,IAIA,QAAA8Y,IAAAC,GACA,sBAAAA,GAAA,CACA,GAAAC,GAAAC,OAAAF,EAEA,OAAA7F,OAAA8F,QAAA//B,SAAA8/B,EAAA,IAGAA,EAFAC,GAOA,QAAAE,IAAAxjC,GAIA,MAHAA,GAAAyjC,YAAAL,GAAApjC,EAAAyjC,aACAzjC,EAAAyP,MAAA2zB,GAAApjC,EAAAyP,OACAzP,EAAAwP,KAAA4zB,GAAApjC,EAAAwP,MACAxP,EAGA,QAAA0jC,IAAAC,GACA,GAAAA,EAAA,CACA,mBAAAA,GACA,UAAA5C,IAAA,+BACA4C,EAAA,IAEA,IAAAA,EAAA,EACA,UAAA5C,IAAA,wCACA4C,EAAA,MAKA,QAAAC,IAAA9P,EAAA12B,GACA,GAAAymC,GAAA/P,EAAApkB,WAAA,oBACAo0B,EAAAhQ,EAAApkB,WAAA,mBAEA,uBAAAokB,GAAA+P,IACA,mBAAA/P,GAAAgQ,IACA/G,GAAAjJ,EAAA+P,GAAA/P,EAAAgQ,IAAA,EACA,SAAA/C,IAAA,kGAEG,IAAA3jC,EAAA5B,QAAAs4B,EAAAt4B,UAAA,GACH,GAAAs4B,EAAA7uB,aACA,SAAA87B,IAAA,4CACK,IAAAjN,EAAA7mC,MAAA6mC,EAAA7mC,KAAArF,OAAA,IACLksC,EAAAiQ,QAAAjQ,EAAA2P,YACA,SAAA1C,IAAA,8DAIA,8BAAA73C,QAAA,SAAA86C,GACA,GAAAniC,GAAA6hC,GAAA5P,EAAAkQ,GACA,IAAAniC,EACA,KAAAA,KAKA,QAAAoiC,IAAAxoC,EAAA2B,EAAA4C,GAEA,GACA2b,GADAgS,KAEAxqB,EAAA,KA6BA,IAvBA8/B,GAAA,SAAAjjC,EAAA2tB,GACAsV,GAAA,eAAAjjC,EAAA2tB,GACAsV,GAAA,cAAAjjC,EAAA2tB,GACAsV,GAAA,QAAAjjC,EAAA2tB,GACAsV,GAAA,aAAAjjC,EAAA2tB,GACAsV,GAAA,QAAAjjC,EAAA2tB,GACAsV,GAAA,cAAAjjC,EAAA2tB,GACAsV,GAAA,OAAAjjC,EAAA2tB,GACAsV,GAAA,QAAAjjC,EAAA2tB,GACAsV,GAAA,YAAAjjC,EAAA2tB,GACAsV,GAAA,WAAAjjC,EAAA2tB,GAAA,GACAsV,GAAA,YAAAjjC,EAAA2tB,GAAA,GACAsV,GAAA,SAAAjjC,EAAA2tB,GAAA,GACAsV,GAAA,UAAAjjC,EAAA2tB,GAAA,GACAsV,GAAA,gBAAAjjC,EAAA2tB,GACAsV,GAAA,MAAAjjC,EAAA2tB,GAAA,GAGAA,IAAAvnB,KAAA,KACAunB,EAAA,KAAAA,EAAA,OAAAA,EAIA,mBAAA3tB,GAAA/S,KAAA,CACA,GAAAi3C,GAAA,IAIAC,EACA,QAAA1M,mBAAAhd,KAAAK,UAAA9a,EAAA/S,MACAk3C,GAAAv8C,OAAA+lC,EAAA/lC,OAAA,GAAAs8C,EAGAvW,IAAA,MAAAA,EAAA,YAAAwW,GAEAhhC,EAAA,OACA,gBAAA/F,GACAue,GAAgB1uB,KAAA+S,EAAA/S,MAEhBmQ,EAAAnQ,KAAA+S,EAAA/S,MAMA,mBAAAmQ,GAAA,CACA,GAAA4I,GAAAm8B,GAAA/kC,EACA,OAAA3B,GAAAgG,SACA0B,SACAkxB,IAAA,WAAAruB,EAAA,aAAAA,EAAA,GAAA2nB,EACAhS,SACK3d,KAAAglC,GAAAhjC,IAYL,MARA2b,SACA51B,OAAAkH,KAAAmQ,GAAAlU,QAAA,SAAAN,GACAH,MAAA4D,QAAA+Q,EAAAxU,IACA+yB,EAAA/yB,GAAAwU,EAAAxU,GAEA+yB,EAAA/yB,GAAAwU,EAAAxU,GAAAG,aAGA0S,EAAAgG,SACA0B,OAAA,OACAkxB,IAAA,aAAA1G,EACAhS,SACG3d,KAAAglC,GAAAhjC,IAMH,QAAAokC,IAAA3oC,EAAA2B,EAAA4C,GACA,UAAAvC,IAAA,SAAApF,EAAAsF,GACAlC,EAAA4oC,OAAAjnC,EAAA4C,EAAA,SAAAlC,EAAAS,GACA,MAAAT,GACAH,EAAAG,OAEAzF,GAAAkG,OAQA,QAAA+lC,IAAA7oC,GACA,UAAAgC,IAAA,SAAApF,EAAAsF,GACAlC,EAAA8oC,aAAA,SAAAzmC,EAAAS,GACA,MAAAT,GACAH,EAAAG,OAEAzF,GAAAkG,OAKA,QAAAimC,IAAA9+C,GACA,gBAAAse,GAEA,SAAAA,EAAAH,OACA,MAAAne,EAEA,MAAAse,IAQA,QAAAygC,IAAAzoC,EAAAw2B,EAAAkS,GAOA,QAAAC,KACA,MAAAvC,IAAAn0B,GAGAxQ,GAAApF,QAAAusC,GAEApS,EAAA/2B,GAAAtV,IAAA0+C,GAAAx0B,MAAAm0B,GAAAI,IAGA,QAAAE,GAAA/lB,GACA,MAAAA,GAAA9xB,KAAArF,OAIA4qC,EAAA/2B,GAAA+/B,SACAvuC,KAAA8xB,EAAA9xB,KACAgY,cAAA,IAJAxH,GAAApF,SAAqC6X,UAQrC,QAAA60B,GAAAhmB,EAAAimB,GAIA,OAHAC,MACAC,EAAA,GAAApf,IAEAzgC,EAAA,EAAAsT,EAAAqsC,EAAA90B,KAAAtoB,OAAgDvC,EAAAsT,EAAStT,IAAA,CACzD,GAAAg3B,GAAA2oB,EAAA90B,KAAA7qB,GACAkf,EAAA8X,EAAA9X,GACA,IAAAA,IAGA0gC,EAAAl6C,KAAAwZ,GACA2gC,EAAA39C,IAAAgd,EAAAnI,KACAmI,EAAAiK,UAAA22B,EAAAp7C,IAAAwa,EAAAnI,MACAmI,EAAAiK,UAAA,CACA,GAAA42B,GAAAD,EAAAh/C,IAAAoe,EAAAnI,IACA,UAAAgpC,KACA7gC,EAAA7e,MAAA0/C,EAAA1/C,QAIA,GAAA2/C,GAAAnD,GAAAiD,EAiBA,OAhBAE,GAAAn8C,QAAA,SAAAN,GACA,IAAAs8C,EAAAn7C,IAAAnB,GAAA,CAEA,GAAA08C,IACAlpC,IAAAxT,GAEAw8C,EAAAD,EAAAh/C,IAAAyC,EACA,UAAAw8C,KACAE,EAAA5/C,MAAA0/C,EAAA1/C,OAEAu/C,EAAAl6C,KAAAu6C,MAGAvmB,EAAA9xB,KAAA+0C,GAAAqD,EAAA5mC,OAAAsgB,EAAA9xB,OACAg4C,EAAAl6C,KAAAg0B,GAEAkmB,EA/DA,GAAAJ,GAAA,cAAA7oC,EACA4oC,GAAwBxoC,IAAAyoC,EAAA53C,SACxBs4C,EAAAb,EAAAv+C,IAAA6V,GACAmpC,EAAAI,EAAA,GACAt3B,EAAAs3B,EAAA,EA8DA,OAAAZ,KAAA3mC,KAAA,SAAA+gB,GACA,MAAA+lB,GAAA/lB,GAAA/gB,KAAA,SAAAgnC,GACA,MAAAD,GAAAhmB,EAAAimB,OAOA,QAAAQ,IAAAhT,EAAAkS,EAAAtpB,GACA,GAAAqqB,GAAA,gBACA,OAAAjT,GAAA/2B,GAAAtV,IAAAs/C,GACAp1B,MAAAm0B,IAAqBpoC,IAAAqpC,EAAArqB,IAAA,KACrBpd,KAAA,SAAA8iC,GACA,GAAApb,GAAAwc,GAAAwC,EACA,OAAAjnC,IAAAoS,IAAA6V,EAAAv+B,IAAA,SAAA6U,GACA,MAAAyoC,IAAAzoC,EAAAw2B,EAAAkS,MACK1mC,KAAA,SAAA0nC,GACL,GAAAC,GAAArgC,EAAAogC,EAIA,OAHA5E,GAAA1lB,MACAuqB,EAAA56C,KAAA+1C,GAEAtO,EAAA/2B,GAAAmqC,UAA+BxlC,KAAAulC,QAK/B,QAAAE,IAAArT,GACA,GAAAyN,GAAA,gBAAAzN,OAAA5sC,KACAgT,EAAAktC,GAAA7F,EAIA,OAHArnC,KACAA,EAAAktC,GAAA7F,GAAA,GAAAJ,KAEAjnC,EAGA,QAAAmtC,IAAAvT,GACA,MAAAqP,IAAAgE,GAAArT,GAAA,WACA,MAAAwT,IAAAxT,OAIA,QAAAwT,IAAAxT,GAKA,QAAA9vB,GAAA9Z,EAAAlD,GACA,GAAA+8C,IAAkBniC,GAAAiE,EAAAnI,IAAAxT,IAAAo0C,GAAAp0C,GAGlB,oBAAAlD,IAAA,OAAAA,IACA+8C,EAAA/8C,MAAAs3C,GAAAt3C,IAEAugD,EAAAl7C,KAAA03C,GAgBA,QAAA30B,GAAA42B,EAAAtpB,GACA,kBACA,MAAAoqB,IAAAhT,EAAAkS,EAAAtpB,IAMA,QAAA8qB,KACA,MAAA1T,GAAAwN,SAAA/xB,SACAzE,WAAA,EACAvE,cAAA,EACA+I,MAAA,WACA+X,MAAAogB,EACA12B,MAAA22B,KACKpoC,KAAAkD,GAGL,QAAAA,GAAA0yB,GACA,GAAA1zB,GAAA0zB,EAAA1zB,OACA,IAAAA,EAAAtY,OAAA,CAGA,GAAA88C,GAAA2B,EAAAnmC,EAEA,IADAtH,EAAArR,IAAAumB,EAAA42B,EAAAyB,MACAjmC,EAAAtY,OAAAw+C,IAGA,MAAAF,MAGA,QAAAG,GAAAnmC,GAEA,OADAwkC,GAAA,GAAA3iC,IACA1c,EAAA,EAAAsT,EAAAuH,EAAAtY,OAAyCvC,EAAAsT,EAAStT,IAAA,CAClD,GAAA0f,GAAA7E,EAAA7a,EACA,UAAA0f,EAAAR,IAAAnI,IAAA,IACA6pC,KACA1hC,EAAAQ,EAAAR,IAEAA,EAAAiK,UACA8zB,GAAA9P,EAAAwN,SAAAE,EAAA37B,GAEA0hC,EAAA78B,KAAAs5B,GAEA,IAAAyC,GAAAmB,EAAAL,EACAvB,GAAAr9C,IAAA0d,EAAAR,IAAAnI,KACA+oC,EACApgC,EAAAkJ,UAGAk4B,EAAAphC,EAAAqW,IAEA,MAAAspB,GAGA,QAAA4B,GAAAL,GAGA,OADAxjB,GADA0iB,EAAA,GAAApjC,IAEA1c,EAAA,EAAAsT,EAAAstC,EAAAr+C,OAA4CvC,EAAAsT,EAAStT,IAAA,CACrD,GAAAkhD,GAAAN,EAAA5gD,GACAmhD,GAAAD,EAAA39C,IAAA29C,EAAAjmC,GACAjb,GAAA,OAAA03C,GAAAwJ,EAAA39C,IAAA65B,IACA+jB,EAAAz7C,KAAA1F,GAEA8/C,EAAA99C,IAAAw2C,GAAA2I,GAAAD,GACA9jB,EAAA8jB,EAAA39C,IAEA,MAAAu8C,GA7FA,GAAAc,GACA1hC,EAYA27B,CAEA,sBAAA1N,GAAA0N,QAAA,IAAA1N,EAAA0N,OAAAt4C,OAAA,CACA,GAAA6+C,GAAAjU,EAAA0N,MACAA,GAAA,SAAA37B,GACA,MAAAkiC,GAAAliC,EAAA7B,QAGAw9B,GAAAqB,GAAA/O,EAAA0N,OAAAn3C,WAAA2Z,EAGA,IAAAyjC,GAAA3T,EAAApX,KAAA,EAQAxiB,EAAA,GAAAinC,GAgEA,OAAAqG,KAAAloC,KAAA,WACA,MAAApF,GAAAqnB,WACGjiB,KAAA,WACHw0B,EAAApX,IAAA+qB,IAIA,QAAAO,IAAAlU,EAAAtyB,EAAA4zB,GACA,IAAAA,EAAA2P,mBACA3P,GAAA2P,WAGA,IAEAtD,GAFAwG,EAAA7S,EAAAiQ,OAAAjQ,EAAA2P,WAIAtD,GADAyG,GAAApU,EAAA2N,WACAyG,GAAApU,EAAA2N,WAEAoB,GAAA/O,EAAA2N,UAAAp3C,WAGA,IAAA89C,MACAC,EAAAtJ,MAAA1J,EAAA2P,aAAAF,OAAAwD,kBACAjT,EAAA2P,WACAvjC,GAAAhX,QAAA,SAAAnC,GACA,GAAAigD,GAAAH,IAAAj/C,OAAA,GACAq/C,EAAAN,EAAA5/C,EAAA6B,IAAA,IAOA,OAJA+9C,IAAAl+C,MAAA4D,QAAA46C,KACAA,IAAA11C,MAAA,EAAAu1C,IAGAE,GAAA,IAAAjK,GAAAiK,EAAAC,aACAD,EAAA/5C,KAAAlC,MAAAhE,EAAA6B,IAAA7B,EAAAuZ,SACA0mC,GAAA9+C,OAAA6C,KAAAhE,EAAArB,YAGAmhD,GAAA97C,MACAkC,OAAAlG,EAAA6B,IAAA7B,EAAAuZ,KACApY,QAAAnB,EAAArB,OACAuhD,eAGA/mC,IACA,QAAA7a,GAAA,EAAAsT,EAAAkuC,EAAAj/C,OAAsCvC,EAAAsT,EAAStT,IAAA,CAC/C,GAAA0B,GAAA8/C,EAAAxhD,GACA6hD,EAAA3E,GAAA/P,EAAAwN,SAAAG,EAAAp5C,EAAAkG,KAAAlG,EAAAmB,QAAA,EACA,IAAAg/C,EAAArlC,OAAAqlC,EAAArlC,gBAAAq/B,IAEA,KAAAgG,GAAArlC,KAEA3B,GAAAnV,MAEArF,MAAAwhD,EAAArlC,MAAA,KAAAqlC,EAAAzE,OACA75C,IAAA7B,EAAAkgD,WAIA,OAAU/2B,KAAA2yB,GAAA3iC,EAAA4zB,EAAArkB,MAAAqkB,EAAAtkB,OAGV,QAAA23B,IAAA3U,EAAAxyB,GACA,MAAA6hC,IAAAgE,GAAArT,GAAA,WACA,MAAA4U,IAAA5U,EAAAxyB,OAIA,QAAAonC,IAAA5U,EAAAxyB;AAUA,QAAAqnC,GAAAC,GAEA,MADAA,GAAAriC,cAAA,EACAutB,EAAA/2B,GAAA+/B,QAAA8L,GAAAtpC,KAAA,SAAAO,GAEA,MADA6zB,GAAA7zB,EAAA0R,WACA1R,EAAA2R,KAAA/oB,IAAA,SAAAqB,GAMA,YAAAA,GAAA+b,KAAA,gBAAA/b,GAAA+b,IAAA7e,OACA,OAAA8C,EAAA+b,IAAA7e,MAAA,CACA,GAAAuH,GAAAlH,OAAAkH,KAAAzE,EAAA+b,IAAA7e,OAAA0jB,OAGAm+B,GAAA,mBACA,MAAAt6C,EAAAs6C,GAAAt6C,EAAAs6C,GACA,MAAA/+C,GAAA+b,IAAA7e,MAIA,GAAA8hD,GAAA1I,GAAAt2C,EAAA+b,IAAAnI,IACA,QACAxT,IAAA4+C,EAAA,GACAlnC,GAAAknC,EAAA,GACA9hD,MAAA,SAAA8C,GAAA+b,IAAA/b,EAAA+b,IAAA7e,MAAA,UAMA,QAAA+hD,GAAAv3B,GACA,GAAAN,EAUA,IARAA,EADA83B,EACAhB,GAAAlU,EAAAtiB,EAAAlQ,IAGAiQ,WAAAmiB,EACAjqC,OAAAqnB,EACAU,QAGAlQ,EAAAiF,aAAA,CACA,GAAAygB,GAAAsc,GAAA9xB,EAAA/oB,IAAA27C,IAEA,OAAAtQ,GAAAwN,SAAAxE,SACAvuC,KAAAy4B,EACAzgB,cAAA,EACAuE,UAAAxJ,EAAAwJ,UACAtE,YAAAlF,EAAAkF,YACA+P,OAAAjV,EAAAiV,SACOjX,KAAA,SAAA2pC,GACP,GAAAC,GAAA,GAAA7lC,GAWA,OAVA4lC,GAAAz3B,KAAAhnB,QAAA,SAAAmzB,GACAurB,EAAAvgD,IAAAg1B,EAAA/b,GAAA+b,EAAA9X,OAEA2L,EAAAhnB,QAAA,SAAAmzB,GACA,GAAArgB,GAAA8mC,GAAAzmB,GACA9X,EAAAqjC,EAAAzhD,IAAA6V,EACAuI,KACA8X,EAAA9X,SAGAqL,IAGA,MAAAA,GA3EA,GAAAwiB,GACAsV,EAAAlV,EAAA2N,WAAAngC,EAAAxE,UAAA,EACAgU,EAAAxP,EAAAwP,MAAA,CA6EA,IA5EA,mBAAAxP,GAAA/S,MAAA+S,EAAA/S,KAAArF,SAEAoY,EAAAyP,MAAA,QACAzP,GAAA/S,MAyEA,mBAAA+S,GAAA/S,KAAA,CACA,GAAAA,GAAA+S,EAAA/S,KACA46C,EAAA56C,EAAA9F,IAAA,SAAAyB,GACA,GAAA0+C,IACAzjB,SAAAga,IAAAj1C,IACAk7B,OAAA+Z,IAAAj1C,OAEA,OAAAy+C,GAAAC,IAEA,OAAA7pC,IAAAoS,IAAAg4B,GAAA7pC,KAAAsH,GAAAtH,KAAAypC,GAEA,GAAAH,IACA53B,WAAA1P,EAAA0P,WAaA,IAXA1P,EAAAy7B,YACAz7B,EAAA6jB,SAAA7jB,EAAAy7B,WAEAz7B,EAAA07B,UACA17B,EAAA8jB,OAAA9jB,EAAA07B,SAEA,mBAAA17B,GAAA6jB,WACAyjB,EAAAzjB,SACAga,GADA79B,EAAA0P,YACA1P,EAAA6jB,cACA7jB,EAAA6jB,YAEA,mBAAA7jB,GAAA8jB,OAAA,CACA,GAAAZ,GAAAljB,EAAA+jB,iBAAA,CACA/jB,GAAA0P,aACAwT,MAGAokB,EAAAxjB,OAAA+Z,GACA3a,GAAAljB,EAAA8jB,YAAuC9jB,EAAA8jB,SAEvC,sBAAA9jB,GAAApX,IAAA,CACA,GAAAk/C,GAAAjK,IAAA79B,EAAApX,MACAm/C,EAAAlK,IAAA79B,EAAApX,QACA0+C,GAAA53B,YACA43B,EAAAxjB,OAAAgkB,EACAR,EAAAzjB,SAAAkkB,IAEAT,EAAAzjB,SAAAikB,EACAR,EAAAxjB,OAAAikB,GASA,MANAL,KACA,gBAAA1nC,GAAAyP,QACA63B,EAAA73B,MAAAzP,EAAAyP,OAEA63B,EAAA93B,QAEA63B,EAAAC,GAAAtpC,KAAAypC,GAIA,QAAAO,IAAAvsC,GACA,MAAAA,GAAAgG,SACA0B,OAAA,OACAkxB,IAAA,kBAIA,QAAA4T,IAAAxsC,GACA,MAAAA,GAAAtV,IAAA,kBAAA6X,KAAA,SAAA+gB,GACA,GAAAmpB,GAAA,GAAAnmC,GACAhc,QAAAkH,KAAA8xB,EAAA0hB,OAAAv3C,QAAA,SAAAw3C,GACA,GAAA16B,GAAAm8B,GAAAzB,GACAyH,EAAA,WAAAniC,EAAA,GACAi6B,EAAAj6B,EAAA,GACAy6B,EAAAyH,EAAA/hD,IAAAgiD,EACA1H,KACAA,EAAA,GAAA3a,IACAoiB,EAAA7gD,IAAA8gD,EAAA1H,IAEAA,EAAAl5C,IAAA04C,IAEA,IAAAjgC,IACA/S,KAAAi1C,GAAAgG,GACAjjC,cAAA,EAEA,OAAAxJ,GAAA+/B,QAAAx7B,GAAAhC,KAAA,SAAAO,GACA,GAAA6pC,KACA7pC,GAAA2R,KAAAhnB,QAAA,SAAAmzB,GACA,GAAAgsB,GAAAhsB,EAAAzzB,IAAAwW,UAAA,EACA8oC,GAAA/hD,IAAAk2B,EAAAzzB,KAAAM,QAAA,SAAA+2C,GACA,GAAAS,GAAA2H,EAAA,IAAApI,CAEAlhB,GAAA0hB,MAAAC,KAGAA,EAAAT,EAEA,IAAAqI,GAAAviD,OAAAkH,KAAA8xB,EAAA0hB,MAAAC,IAEA6H,EAAAlsB,EAAA9X,KAAA8X,EAAA9X,IAAAk8B,OACApkB,EAAA9X,IAAAk8B,MAAAR,EACAqI,GAAAp/C,QAAA,SAAAs/C,GACAJ,EAAAI,GACAJ,EAAAI,IAAAD,OAIA,IAAAE,GAAA1iD,OAAAkH,KAAAm7C,GAAAtsC,OACA,SAAA0sC,GAA+B,OAAAJ,EAAAI,KAC/BE,EAAAD,EAAAthD,IAAA,SAAAqhD,GACA,MAAA3G,IAAAgE,GAAA2C,GAAA,WACA,UAAA/sC,GAAAjK,YAAAg3C,EAAA/sC,EAAAsW,QAAA+E,eAGA,OAAArZ,IAAAoS,IAAA64B,GAAA1qC,KAAA,WACA,OAAgB8B,IAAA,QAGb0kC,IAAc1kC,IAAA,KAejB,QAAA6oC,IAAAltC,EAAA2B,EAAA4C,GACA,YAAAvE,EAAA5G,OACA,MAAAovC,IAAAxoC,EAAA2B,EAAA4C,EAIA,sBAAAvE,GAAA4oC,OACA,MAAAD,IAAA3oC,EAAA2B,EAAA4C,EAGA,oBAAA5C,GAAA,CAEAwmC,GAAA5jC,EAAA5C,EAEA,IAAAwrC,IACAntC,KACAwkC,SAAA,sBACA94C,IAAAiW,EAAAjW,IACAqU,OAAA4B,EAAA5B,OACA4kC,WAAA,EAYA,OAVAyI,IAAAthD,IAAA,WACA,MAAAu4C,IAAA8I,GAAA5qC,KAAA,SAAAw0B,GACA,QAAAsW,KACA,MAAAtW,GAAA/2B,GAAAqb,UAEA,MAAA6qB,IAAAoE,GAAAvT,GAAAx0B,KAAA,WACA,MAAAmpC,IAAA3U,EAAAxyB,KACS8oC,OAGTD,GAAA5oB,SAGA,GAAAygB,GAAAtjC,EACA4I,EAAAm8B,GAAAzB,GACAyH,EAAAniC,EAAA,GACAi6B,EAAAj6B,EAAA,EACA,OAAAvK,GAAAtV,IAAA,WAAAgiD,GAAAnqC,KAAA,SAAAuG,GACA,GAAAnH,GAAAmH,EAAAk8B,OAAAl8B,EAAAk8B,MAAAR,EAEA,KAAA7iC,GAAA,gBAAAA,GAAAjW,IACA,SAAA85C,IAAA,QAAAkH,EACA,sBAAAlI,EAEA2D,IAAA5jC,EAAA5C,EAEA,IAAAwrC,IACAntC,KACAwkC,SAAAS,EACAv5C,IAAAiW,EAAAjW,IACAqU,OAAA4B,EAAA5B,OAEA,OAAAskC,IAAA8I,GAAA5qC,KAAA,SAAAw0B,GACA,aAAAxyB,EAAA+oC,OAAA,iBAAA/oC,EAAA+oC,OACA,iBAAA/oC,EAAA+oC,OACAvwC,GAAA,WACAutC,GAAAvT,KAGA2U,GAAA3U,EAAAxyB,IAEA+lC,GAAAvT,GAAAx0B,KAAA,WACA,MAAAmpC,IAAA3U,EAAAxyB,SAiCA,QAAAgpC,IAAAtnC,GACA,YAAAhS,KAAAgS,GAGA,QAAAunC,IAAAC,EAAAC,EAAAhpB,GACA,OAAA+oB,EAAA9jC,eACA8jC,EAAA9jC,aAAA+a,IACA+oB,EAAA9jC,aAAA+a,GAAAtI,SAAAsxB,EAAA/jC,aAAA+a,GAAAtI,OAGA,QAAAuxB,IAAA3tC,EAAA8I,GACA,GAAAq2B,GAAA70C,OAAAkH,KAAAsX,EAAAa,aACA,OAAA3H,IAAAoS,IAAA+qB,EAAAzzC,IAAA,SAAAg5B,GACA,MAAA1kB,GAAA0/B,cAAA52B,EAAAnI,IAAA+jB,GAAgDze,IAAA6C,EAAA4C,UAIhD,QAAAkiC,IAAA3sC,EAAA4sC,EAAA/kC,GACA,GAAAglC,GAAA,SAAAD,EAAAz0C,QAAA,SAAA6H,EAAA7H,OACA+lC,EAAA70C,OAAAkH,KAAAsX,EAAAa,aAEA,OAAAmkC,GAIA7sC,EAAAvW,IAAAoe,EAAAnI,KAAA4B,KAAA,SAAAkrC,GACA,MAAAzrC,IAAAoS,IAAA+qB,EAAAzzC,IAAA,SAAAg5B,GACA,MAAA8oB,IAAAC,EAAA3kC,EAAA4b,GACAmpB,EAAAnO,cAAA52B,EAAAnI,IAAA+jB,GAGAzjB,EAAAy+B,cAAA+N,EAAA9sC,IAAA+jB,QAEG9P,MAAA,SAAAxO,GAEH,SAAAA,EAAAgC,OACA,KAAAhC,EAGA,OAAAunC,IAAAE,EAAA/kC,KAjBA6kC,GAAAE,EAAA/kC,GAqBA,QAAAilC,IAAAC,GACA,GAAA3nC,KAWA,OAVA/b,QAAAkH,KAAAw8C,GAAAvgD,QAAA,SAAAoX,GACA,GAAAopC,GAAAD,EAAAnpC,GAAA81B,OACAsT,GAAAxgD,QAAA,SAAAygD,GACA7nC,EAAA/W,MACAuV,KACAoB,IAAAioC,SAMAvpC,KAAA0B,EACA4G,MAAA,EACAiE,QAAA,GAUA,QAAAi9B,IAAAN,EAAA5sC,EAAA+sC,EAAA5tC,GAMA,QAAAguC,KAEA,GAAAC,GAAAN,GAAAC,EAEA,IAAAK,EAAA1pC,KAAAxY,OAIA,MAAA0hD,GAAAvpC,QAAA+pC,GAAA9rC,KAAA,SAAA+rC,GAEA,GAAAluC,EAAAmuC,UACA,SAAAruC,OAAA,YAEA,OAAA8B,IAAAoS,IAAAk6B,EAAA7pC,QAAA/Y,IAAA,SAAA8iD,GACA,MAAAxsC,IAAAoS,IAAAo6B,EAAA7pC,KAAAjZ,IAAA,SAAAod,GACA,GAAA4kC,GAAA5kC,EAAAzE,EAQA,OANAyE,GAAA1C,QAGA/B,GAAA,GAGAqpC,KAAA/jC,aAIAikC,GAAA3sC,EAAA4sC,EAAAH,GAAAnrC,KAAA,SAAAkH,GACA,GAAA01B,GAAA70C,OAAAkH,KAAAk8C,EAAA/jC,aAQA,OAPAF,GAAAhc,QAAA,SAAA4+B,EAAAziC,GACA,GAAA8f,GAAAgkC,EAAA/jC,aAAAw1B,EAAAv1C,UACA8f,GAAAE,WACAF,GAAAvd,OACAud,EAAAlb,KAAA69B,IAGAqhB,IAZAA,QAiBAnrC,KAAA,SAAAkC,GACAgqC,IAAAzrC,OAAA6G,EAAApF,GAAApE,OAAAquC,cAKA,QAAA7pB,GAAA/b,GACA,MAAAA,GAAAa,cAAArf,OAAAkH,KAAAsX,EAAAa,cAAAxd,OAAA,EAGA,QAAAwiD,GAAA7lC,GACA,MAAAA,GAAA2J,YAAA3J,EAAA2J,WAAAtmB,OAAA,EAGA,QAAAyiD,GAAAhiC,GAGA,MAAAihC,GAAA9N,SACAvuC,KAAAob,EACApD,cAAA,EACAuE,WAAA,IACKxL,KAAA,SAAAO,GACL,GAAA1C,EAAAmuC,UACA,SAAAruC,OAAA,YAEA4C,GAAA2R,KAAAhnB,QAAA,SAAAmzB,GACAA,EAAA7T,UAAA6T,EAAA9X,MAAAykC,GAAA3sB,EAAA32B,MAAAgc,MACA4e,EAAAjE,EAAA9X,MAAA6lC,EAAA/tB,EAAA9X,OAOA8X,EAAA9X,IAAA2J,kBACAmO,GAAA9X,IAAA2J,WAIAg8B,EAAAn/C,KAAAsxB,EAAA9X,WACAklC,GAAAptB,EAAA/b,SAKA,QAAAgqC,KAGA,GAAAjiC,GAAAtiB,OAAAkH,KAAAw8C,GAAA3tC,OAAA,SAAAwE,GACA,GAAA81B,GAAAqT,EAAAnpC,GAAA81B,OACA,YAAAA,EAAAxuC,QAAAohD,GAAA5S,EAAA,KAEA,IAAA/tB,EAAAzgB,OAAA,EACA,MAAAyiD,GAAAhiC,GAIA,QAAAkiC,KACA,OAAYzqC,KAAAM,KAAA8pC,GAxGZT,EAAA1sC,EAAA0sC,EAEA,IAAAS,MACApqC,GAAA,CAwGA,OAAArC,IAAApF,UACA2F,KAAAssC,GACAtsC,KAAA6rC,GACA7rC,KAAAusC,GAeA,QAAAC,IAAA/uC,EAAA6E,EAAAmqC,EAAAC,EAAAC,GACA,MAAAlvC,GAAAtV,IAAAma,GAAA+P,MAAA,SAAAvS,GACA,SAAAA,EAAA+F,OAMA,MALA,SAAApI,EAAA5G,QACA+O,EACA,gEAIAgnC,WAAAF,EACAtuC,IAAAkE,EACAwJ,WACA+gC,WAAAC,GACAvgB,QAAAwgB,GAGA,MAAAjtC,KACGE,KAAA,SAAAuG,GACH,IAAAomC,EAAAX,WAKAzlC,EAAA+L,WAAAm6B,EA0BA,MArBAlmC,GAAAuF,SAAAvF,EAAAuF,aAAAhO,OAAA,SAAAkO,GACA,MAAAA,GAAA4gC,aAAAF,IAIAnmC,EAAAuF,QAAAkhC,SACA16B,SAAAm6B,EACAG,WAAAF,IAMAnmC,EAAAuF,QAAAvF,EAAAuF,QAAAvY,MAAA,EAAA05C,IAEA1mC,EAAAgmB,QAAAwgB,GACAxmC,EAAAsmC,WAAAC,GAEAvmC,EAAAqmC,WAAAF,EACAnmC,EAAA+L,SAAAm6B,EAEAhvC,EAAA8L,IAAAhD,GAAA8L,MAAA,SAAAvS,GACA,SAAAA,EAAA+F,OAEA,MAAA2mC,IAAA/uC,EAAA6E,EAAAmqC,EAAAC,EAAAC,EAEA,MAAA7sC,OAKA,QAAAotC,IAAA5B,EAAA5sC,EAAA4D,EAAAqqC,GACA3lD,KAAAskD,MACAtkD,KAAA0X,SACA1X,KAAAsb,KACAtb,KAAA2lD,cAsGA,QAAAQ,IAAAC,EAAAC,GACA,MAAAD,GAAAR,aAAAS,EAAAT,YAEAt6B,SAAA86B,EAAA96B,SACAxG,QAAAshC,EAAAthC,SAIAwhC,GAAAF,EAAAthC,QAAAuhC,EAAAvhC,SAGA,QAAAwhC,IAAAC,EAAAC,GAGA,GAAAC,GAAAF,EAAA,GACAG,EAAAH,EAAAh6C,MAAA,GACAo6C,EAAAH,EAAA,GACAI,EAAAJ,EAAAj6C,MAAA,EAEA,KAAAk6C,GAAA,IAAAD,EAAA5jD,OACA,OACA0oB,SAAAu7B,GACA/hC,WAIA,IAAAgiC,GAAAL,EAAAb,UAEA,IAAAmB,GAAAD,EAAAN,GACA,OACAl7B,SAAAm7B,EAAAn7B,SACAxG,QAAAyhC,EAIA,IAAAh/B,GAAAo/B,EAAAf,UACA,OAAAmB,IAAAx/B,EAAAm/B,IAEAp7B,SAAAq7B,EAAAr7B,SACAxG,QAAA8hC,GAIAN,GAAAI,EAAAE,GAGA,QAAAG,IAAAC,EAAAliC,GACA,GAAArb,GAAAqb,EAAA,GACAmiC,EAAAniC,EAAAvY,MAAA,EAEA,UAAAy6C,GAAA,IAAAliC,EAAAliB,UAIAokD,IAAAv9C,EAAAm8C,YAIAmB,GAAAC,EAAAC,IAGA,QAAAC,IAAApuC,GACA,sBAAAA,GAAA+F,QAAA,IAAAtM,KAAA40C,MAAAruC,EAAA+F,OAAA,KAKA,QAAAuoC,IAAApsC,EAAA2qC,EAAA9oC,EAAAhE,GACA,GAAAmC,EAAAqsC,SAAA,EAGA,MAFA1B,GAAAjoC,KAAA,QAAAb,OACA8oC,GAAAp9B,oBAOA,IAJA,kBAAAvN,GAAAssC,oBACAtsC,EAAAssC,kBAAA3oC,GAEAgnC,EAAAjoC,KAAA,eAAAb,GACA,WAAA8oC,EAAA9uC,OAAA,YAAA8uC,EAAA9uC,MAAA,CACA8uC,EAAAjoC,KAAA,SAAAb,GACA8oC,EAAA9uC,MAAA,SACA,IAAA0wC,GAAA,WACAvsC,EAAAwsC,iBAAAC,IAEAC,EAAA,WACA/B,EAAAn9B,eAAA,SAAA++B,GAEA5B,GAAAxtC,KAAA,SAAAuvC,GACA/B,EAAAxtC,KAAA,SAAAovC,GAGAvsC,EAAAwsC,iBAAAxsC,EAAAwsC,kBAAAC,GACAzsC,EAAAwsC,iBAAAxsC,EAAAssC,kBAAAtsC,EAAAwsC,kBACAryC,WAAA0D,EAAAmC,EAAAwsC,kBAGA,QAAAG,IAAAC,GACA,MAAA7mD,QAAAkH,KAAA2/C,GAAAxjC,KAAA2zB,IAAAvhC,OAAA,SAAAhT,EAAAI,GAEA,MADAJ,GAAAI,GAAAgkD,EAAAhkD,GACAJ,OAMA,QAAAqkD,IAAAvD,EAAA5sC,EAAAsD,GACA,GAAA0lB,GAAA1lB,EAAA6lB,QAAA7lB,EAAA6lB,QAAAzc,KAAA2zB,IAAA,GACA+P,EAAA9sC,EAAAlE,OAAAkE,EAAAlE,OAAA/S,WAAA,GACA6jD,EAAA,GACAG,EAAA,EAUA,OARA/sC,GAAAlE,QAAAkE,EAAA8E,eACA8nC,EAAAnyB,KAAAK,UAAA6xB,GAAA3sC,EAAA8E,gBAGA9E,EAAAlE,QAAA,UAAAkE,EAAAlE,SACAixC,EAAA/sC,EAAAwyB,KAAAzpC,YAGA0U,GAAAoS,KAAAy5B,EAAAhpC,KAAA5D,EAAA4D,OAAAtC,KAAA,SAAAO,GACA,GAAAyuC,GAAAzuC,EAAA,GAAAA,EAAA,GAAAuuC,EAAAC,EACAH,EAAAlnB,CACA,WAAAjoB,IAAA,SAAApF,GACAoe,GAAAu2B,EAAA30C,OAEG2F,KAAA,SAAAivC,GAKH,MADAA,KAAAl2C,QAAA,WAAAA,QAAA,WACA,UAAAk2C,IAIA,QAAAC,IAAA5D,EAAA5sC,EAAAsD,EAAA2qC,EAAAniD,GAmCA,QAAA2kD,KACA,MAAAC,GACA3vC,GAAApF,UAEAw0C,GAAAvD,EAAA5sC,EAAAsD,GAAAhC,KAAA,SAAAO,GACA8uC,EAAA9uC,EACA6uC,EAAA,GAAAlC,IAAA5B,EAAA5sC,EAAA2wC,EAAA1C,KAIA,QAAA2C,KAGA,GAFAC,KAEA,IAAAC,EAAAptC,KAAAxY,OAAA,CAGA,GAAAwY,GAAAotC,EAAAptC,KACAqtC,GAAoBnZ,QAAAt0B,EAAAs0B,QACpB,OAAA53B,GAAAkpC,UAA4BxlC,OAAA+Z,WAAA,GAA6BszB,GAAAzvC,KAAA,SAAAO,GAEzD,GAAAosC,EAAAX,UAEA,KADA0D,KACA,GAAA/xC,OAAA,YAKA,IAAAgyC,GAAA5nD,OAAAoR,OAAA,KACAoH,GAAArV,QAAA,SAAAqV,GACAA,EAAAsD,QACA8rC,EAAApvC,EAAA+B,IAAA/B,IAIA,IAAAqvC,GAAA7nD,OAAAkH,KAAA0gD,GAAA/lD,MACAY,GAAAqlD,oBAAAD,EACAplD,EAAAslD,cAAA1tC,EAAAxY,OAAAgmD,EAEAxtC,EAAAlX,QAAA,SAAAqb,GACA,GAAA1C,GAAA8rC,EAAAppC,EAAAnI,IACA,IAAAyF,EAAA,CAEA,GADArZ,EAAAulD,OAAAhjD,KAAA8W,GACA,iBAAAA,EAAAjc,MAAA,cAAAic,EAAAjc,KAGA,KAAAic,EAFA8oC,GAAAjoC,KAAA,SAAA3F,EAAA8E,QAKA0rC,GAAAxiD,KAAAwZ,MAIK,SAAAzG,GAEL,KADAtV,GAAAqlD,oBAAAztC,EAAAxY,OACAkW,KAIA,QAAAkwC,KACA,GAAAR,EAAA3rC,MACA,SAAAlG,OAAA,oCAEAnT,GAAA8nB,WAAAk9B,EAAApyB,GACA,IAAA6yB,GAAAlxC,EAAAvU,EAMA,OALA+kD,GAAA3lD,SACAqmD,EAAA7tC,KAAAmtC,EACA5C,EAAAjoC,KAAA,SAAAurC,IAEAC,GAAA,EACAd,EAAAe,gBAAAX,EAAApyB,IACAsvB,GAAA1sC,KAAA,WAGA,GAFAkwC,GAAA,EAEAvD,EAAAX,UAEA,KADA0D,KACA,GAAA/xC,OAAA,YAEA6xC,GAAA3kD,OACAulD,MACK/9B,MAAA,SAAAvS,GAEL,KADAuwC,GAAAvwC,GACAA,IAIA,QAAAwwC,KACA,GAAAjjC,KAWA,OAVAmiC,GAAAv/B,QAAA/kB,QAAA,SAAA6b,GAGA,WAAAA,EAAAzE,KAGA+K,EAAAtG,EAAAzE,IAAAyE,EAAAkJ,QAAA9mB,IAAA,SAAAyY,GACA,MAAAA,GAAA8B,SAGAhF,EAAA8/B,SAAAnxB,GAAArN,KAAA,SAAAyrC,GAEA,GAAAkB,EAAAX,UAEA,KADA0D,KACA,GAAA/xC,OAAA,YAGA6xC,GAAA/D,UAIA,QAAA8E,KACA,MAAA3E,IAAAN,EAAA5sC,EAAA8wC,EAAA/D,MAAAkB,GAAA3sC,KAAA,SAAAwwC,GACAhB,EAAA3rC,OAAA2sC,EAAA1uC,GACA0uC,EAAApuC,KAAAlX,QAAA,SAAAqb,SACAipC,GAAA/D,MAAAllC,EAAAnI,KACA5T,EAAAimD,YACAjB,EAAAptC,KAAArV,KAAAwZ,OAKA,QAAAmqC,KACA,IAAA/D,EAAAX,YAAAwD,EAAA,CAGA,OAAAmB,EAAA/mD,OAEA,WADAgnD,IAAA,EAGApB,GAAAmB,EAAAn+B,QACA89B,IACAtwC,KAAAuwC,GACAvwC,KAAAsvC,GACAtvC,KAAAgwC,GACAhwC,KAAA0wC,GACAr+B,MAAA,SAAAvS,GACA+wC,EAAA,yCAAA/wC,MAKA,QAAA8wC,GAAA/1C,GACA,WAAAi2C,EAAA7gC,QAAArmB,YACA,IAAA+mD,EAAA/mD,QAAA4lD,KACA5nB,GAAAmpB,EAAAC,MAAAC,KACAtE,EAAA9uC,MAAA,UACA8uC,EAAAjoC,KAAA,WAEAusC,GACAvB,YAMA70C,GACAo2C,GACAH,EAAA7gC,QAAArmB,QAAAg0C,KAEA+S,EAAA5jD,KAAA+jD,GACAA,GACA1zB,IAAA,EACAnN,WACA7N,SAEA,YAAAuqC,EAAA9uC,OAAA,YAAA8uC,EAAA9uC,QACA8uC,EAAA9uC,MAAA,SACA8uC,EAAAjoC,KAAA,WAEAgsC,MAKA,QAAAG,GAAA7qC,EAAAlG,GACAoxC,IAGApxC,EAAAmG,UACAnG,EAAAmG,QAAAD,GAEAxb,EAAAsX,IAAA,EACAtX,EAAAqb,OAAA,WACA8qC,KACAG,GACA1zB,IAAA,EACAnN,WACA7N,SAEAstC,EAAA5vC,IAIA,QAAA4vC,GAAAyB,GACAD,GAIAvE,EAAAX,YACAxhD,EAAAqb,OAAA,YACAqqC,KAIA1lD,EAAAqb,OAAArb,EAAAqb,QAAA,WACArb,EAAA4mD,SAAA,GAAAnyC,MACAzU,EAAA8nB,WACA4+B,GAAA,EAEAC,GACAA,EAAA3mD,SAEA,iBAAA2mD,EAAAvpD,MAAA,cAAAupD,EAAAvpD,MACA+kD,EAAAjoC,KAAA,QAAAysC,GACAxE,EAAAp9B,sBAEA6+B,GAAApsC,EAAA2qC,EAAAwE,EAAA,WACAjC,GAAA5D,EAAA5sC,EAAAsD,EAAA2qC,OAIAA,EAAAjoC,KAAA,WAAAla,GACAmiD,EAAAp9B,uBAKA,QAAAG,GAAA3I,GAEA,GAAA4lC,EAAAX,UACA,MAAA0D,IAEA,IAAA5xC,GAAA6I,EAAA3E,GAAA+E,EACAjJ,KAGAgzC,EAAA1zB,IAAArW,EAAAqW,IACA0zB,EAAA7gC,QAAAljB,KAAAga,GACA6pC,EAAA,IAAAD,EAAA/mD,QAAAmnD,EAAAC,OAIA,QAAAK,GAAAphC,GAGA,GAFAqhC,GAAA,EAEA3E,EAAAX,UACA,MAAA0D,IAKA,IAAAz/B,EAAA/N,QAAAtY,OAAA,EACAmnD,EAAAhpB,MAAA9X,EAAAqC,SACA89B,IACAQ,GAAA,OACK,CAEL,GAAAthC,GAAA,WACAsY,GACAmpB,EAAAC,MAAA,EACAZ,KAEAa,GAAA,EAEAL,GAAA,GAIApB,IAAA,IAAAv/B,EAAA/N,QAAAtY,OAUA0lB,KATA4gC,GAAA,EACAd,EAAAe,gBAAAlgC,EAAAqC,SACAo6B,GAAA1sC,KAAA,WACAkwC,GAAA,EACA1lD,EAAA8nB,WAAArC,EAAAqC,SACAhD,MAEA+C,MAAAg+B,KAQA,QAAAkB,GAAAzxC,GAGA,MAFAwxC,IAAA,EAEA3E,EAAAX,UACA0D,QAEAmB,GAAA,mBAAA/wC,GAIA,QAAAswC,KASA,QAAAoB,KACAvhC,EAAAZ,SAEA,QAAAG,KACAm9B,EAAAn9B,eAAA,SAAAgiC,GAZA,IACAF,IACAL,GACAN,EAAA/mD,OAAA6nD,EAHA,CAOAH,GAAA,EAQA3E,EAAAtiB,WACAsiB,EAAAn9B,eAAA,SAAAm9B,EAAA+E,eACA/E,EAAAtiB,SAAAhb,UAEAs9B,EAAAxtC,KAAA,SAAAqyC,EAEA,IAAAvhC,GAAAq7B,EAAAr7B,QAAA8gC,GACAthC,GAAA,SAAAC,EACAO,GAAAjQ,KAAAwP,KACAS,EAAAjQ,KAAAqxC,GACAh/B,MAAAk/B,GAEAvvC,EAAAqsC,QAEA1B,EAAAtiB,SAAApa,EACA08B,EAAA+E,cAAAF,IAKA,QAAAG,KACAxC,IAAAnvC,KAAA,WAEA,MAAA2sC,GAAAX,cACA0D,KAGAN,EAAAwC,gBAAA5xC,KAAA,SAAAysC,GACAn6B,EAAAm6B,EACAsE,GACAhpB,MAAAzV,EACAb,MAAAmsB,EACAA,aACA5tB,MAAA,WACA6X,UACAG,aAAA,GAEAhmB,EAAAlE,SACA,gBAAAkE,GAAAlE,OAEAizC,EAAA9pC,cAAA,EAEA8pC,EAAAjzC,OAAAkE,EAAAlE,QAGA,aAAAkE,KACA+uC,EAAA/S,UAAAh8B,EAAAg8B,WAEA,WAAAh8B,KACA+uC,EAAAza,QAAAt0B,EAAAs0B,SAEAt0B,EAAA8E,eACAiqC,EAAAjqC,aAAA9E,EAAA8E,cAEA9E,EAAAwyB,OACAuc,EAAAvc,KAAAxyB,EAAAwyB,MAEA4b,QAEK/9B,MAAA,SAAAvS,GACL+wC,EAAA,+BAAA/wC,KAKA,QAAAuwC,GAAAvwC,GACAowC,GAAA,EACAW,EAAA,uCAAA/wC,GAzZA,GACA0vC,GAeAH,EACAD,EAjBAuB,KAEAG,GACA1zB,IAAA,EACAnN,WACA7N,SAEA8tC,GAAA,EACAe,GAAA,EACAC,GAAA,EACA5+B,EAAA,EACAsV,EAAA5lB,EAAA4lB,YAAA5lB,EAAAgvC,OAAA,EACApT,EAAA57B,EAAA47B,YAAA,IACA6T,EAAAzvC,EAAAyvC,eAAA,GACAH,GAAA,EACAzpB,EAAA7lB,EAAA6lB,QAGA0nB,KAEA7C,EAAAjjC,GAEAjf,OACAsX,IAAA,EACA+vC,WAAA,GAAA5yC,MACAwxC,UAAA,EACAX,aAAA,EACAD,mBAAA,EACAE,UAGA,IAAAgB,KA8XA,OA7XApE,GAAAp4B,MAAA+2B,EAAA5sC,GA6XAiuC,EAAAX,cACA0D,MAIA/C,EAAAmF,kBACAnF,EAAAxtC,KAAA,SAAAuwC,GAEA,kBAAA1tC,GAAAsN,WACAq9B,EAAAxtC,KAAA,QAAA6C,EAAAsN,UACAq9B,EAAAxtC,KAAA,oBAAA3U,GACAwX,EAAAsN,SAAA,KAAA9kB,MAGAmiD,EAAAmF,iBAAA,QAGA,mBAAA9vC,GAAA+lB,MACA4pB,IAEAxC,IAAAnvC,KAAA,WAEA,MADAkwC,IAAA,EACAd,EAAAe,gBAAAnuC,EAAA+lB,MAAA2kB,KACK1sC,KAAA,WAGL,MAFAkwC,IAAA,EAEAvD,EAAAX,cACA0D,MAGAp9B,EAAAtQ,EAAA+lB,UACA4pB,QACKt/B,MAAAg+B,KAOL,QAAA0B,MACAhtC,GAAAC,aAAAzd,KAAAP,MACAA,KAAAglD,WAAA,EACAhlD,KAAA6W,MAAA,SACA,IAAA9F,GAAA/Q,KACAwY,EAAA,GAAAC,IAAA,SAAAC,EAAAC,GACA5H,EAAAoH,KAAA,WAAAO,GACA3H,EAAAoH,KAAA,QAAAQ,IAEA5H,GAAAiI,KAAA,SAAA3F,EAAAsF,GACA,MAAAH,GAAAQ,KAAA3F,EAAAsF,IAEA5H,EAAAsa,MAAA,SAAA1S,GACA,MAAAH,GAAA6S,MAAA1S,IAIA5H,EAAAsa,MAAA,cA4BA,QAAA2/B,IAAAv0C,EAAAuE,GACA,GAAAiwC,GAAAjwC,EAAAiwC,gBACA,uBAAAx0C,GACA,GAAAw0C,GAAAx0C,EAAAuE,GAEAvE,EAIA,QAAAy0C,IAAA5G,EAAA5sC,EAAAsD,EAAAnC,GAUA,GARA,kBAAAmC,KACAnC,EAAAmC,EACAA,MAEA,mBAAAA,KACAA,MAGAA,EAAA6lB,UAAAp9B,MAAA4D,QAAA2T,EAAA6lB,SACA,KAAA3hB,GAAAQ,GACA,4CAGA1E,GAAAsN,SAAAzP,EACAmC,EAAAjD,EAAAiD,GACAA,EAAA4lB,WAAA5lB,EAAA4lB,YAAA5lB,EAAAgvC,KACAhvC,EAAAqsC,MAAA,SAAArsC,MAAAqsC,MAEArsC,EAAAiwC,iBAAAjwC,EAAAiwC,kBAAAjrD,IACA,IAAAmrD,GAAA,GAAAJ,IAAA/vC,GACAowC,EAAAJ,GAAA1G,EAAAtpC,GACAqwC,EAAAL,GAAAtzC,EAAAsD,EAEA,OADAktC,IAAAkD,EAAAC,EAAArwC,EAAAmwC,GACAA,EAIA,QAAAG,IAAAhH,EAAA5sC,EAAAsD,EAAAnC,GAaA,MAZA,kBAAAmC,KACAnC,EAAAmC,EACAA,MAEA,mBAAAA,KACAA,MAEAA,EAAAjD,EAAAiD,GAEAA,EAAAiwC,iBAAAjwC,EAAAiwC,kBAAAjrD,KACAskD,EAAA0G,GAAA1G,EAAAtpC,GACAtD,EAAAszC,GAAAtzC,EAAAsD,GACA,GAAAuwC,IAAAjH,EAAA5sC,EAAAsD,EAAAnC,GAGA,QAAA0yC,IAAAjH,EAAA5sC,EAAAsD,EAAAnC,GAaA,QAAA2yC,GAAAzrC,GACAhP,EAAA2M,KAAA,UACA+tC,UAAA,OACA1rC,WAGA,QAAA2rC,GAAA3rC,GACAhP,EAAA2M,KAAA,UACA+tC,UAAA,OACA1rC,WAGA,QAAA4rC,GAAApsC,GACAxO,EAAA2M,KAAA,UACA+tC,UAAA,OACAlsC,QAGA,QAAAqsC,GAAArsC,GACAxO,EAAA2M,KAAA,UACA+tC,UAAA,OACAlsC,QAGA,QAAAssC,KACA96C,EAAA86C,YAAA,EAEA96C,EAAA+6C,YACA/6C,EAAA2M,KAAA,UAGA,QAAAouC,KACA/6C,EAAA+6C,YAAA,EAEA/6C,EAAA86C,YACA96C,EAAA2M,KAAA,UAGA,QAAAquC,KACAh7C,EAAA86C,YAAA,EAEA96C,EAAA+6C,YACA/6C,EAAA2M,KAAA,UACA+tC,UAAA,SAIA,QAAAO,KACAj7C,EAAA+6C,YAAA,EAEA/6C,EAAA86C,YACA96C,EAAA2M,KAAA,UACA+tC,UAAA,SAOA,QAAAQ,GAAAp8C,GACA,gBAAA0oB,EAAA91B,GACA,GAAAypD,GAAA,WAAA3zB,IACA91B,IAAA+oD,GAAA/oD,IAAAipD,GACAS,EAAA,WAAA5zB,IACA91B,IAAAmpD,GAAAnpD,IAAAkpD,GACAS,EAAA,WAAA7zB,IACA91B,IAAAqpD,GAAArpD,IAAAopD,GACAQ,EAAA,WAAA9zB,IACA91B,IAAAupD,GAAAvpD,IAAAspD,IAEAG,GAAAC,GAAAC,GAAAC,KACA9zB,IAAA+zB,KACAA,EAAA/zB,OAEA+zB,EAAA/zB,GAAA1oB,IAAA,EACA,IAAA9O,OAAAkH,KAAAqkD,EAAA/zB,IAAA31B,QAEAmO,EAAAwX,mBAAAgQ,KAWA,QAAAg0B,GAAAzrC,EAAAyX,EAAAi0B,GACA1rC,EAAA2rC,UAAAl0B,GAAA9W,QAAA+qC,KAAA,GACA1rC,EAAA2H,GAAA8P,EAAAi0B,GAtGA,GAAAz7C,GAAA/Q,IACAA,MAAA0sD,UAAA,CAEA,IAAAC,GAAA3xC,EAAAjV,KAAAglB,MAAwC/P,IAAAjV,MAAAiV,EACxC4xC,EAAA5xC,EAAA6xC,KAAA9hC,MAAwC/P,IAAA6xC,MAAA7xC,CAExChb,MAAA+F,KAAAmlD,GAAA5G,EAAA5sC,EAAAi1C,GACA3sD,KAAA6sD,KAAA3B,GAAAxzC,EAAA4sC,EAAAsI,GAEA5sD,KAAA6rD,YAAA,EACA7rD,KAAA8rD,YAAA,CA2DA,IAAAQ,KA0BAtxC,GAAAgvC,OACAhqD,KAAA+F,KAAA0iB,GAAA,WAAA1X,EAAA87C,KAAAxkC,OAAAO,KAAA7X,EAAA87C,OACA7sD,KAAA6sD,KAAApkC,GAAA,WAAA1X,EAAAhL,KAAAsiB,OAAAO,KAAA7X,EAAAhL,QASA/F,KAAAyoB,GAAA,uBAAA8P,GACA,WAAAA,GACAg0B,EAAAx7C,EAAA87C,KAAA,SAAArB,GACAe,EAAAx7C,EAAAhL,KAAA,SAAA2lD,IACK,WAAAnzB,GACLg0B,EAAAx7C,EAAA87C,KAAA,SAAAjB,GACAW,EAAAx7C,EAAAhL,KAAA,SAAA4lD,IACK,WAAApzB,GACLg0B,EAAAx7C,EAAA87C,KAAA,SAAAb,GACAO,EAAAx7C,EAAAhL,KAAA,SAAAgmD,IACK,WAAAxzB,IACLg0B,EAAAx7C,EAAA87C,KAAA,SAAAf,GACAS,EAAAx7C,EAAAhL,KAAA,SAAA8lD,MAIA7rD,KAAAyoB,GAAA,0BAAA8P,GACA,WAAAA,GACAxnB,EAAA87C,KAAArkC,eAAA,SAAAgjC,GACAz6C,EAAAhL,KAAAyiB,eAAA,SAAAkjC,IACK,WAAAnzB,GACLxnB,EAAA87C,KAAArkC,eAAA,SAAAojC,GACA76C,EAAAhL,KAAAyiB,eAAA,SAAAmjC,IACK,WAAApzB,GACLxnB,EAAA87C,KAAArkC,eAAA,SAAAwjC,GACAj7C,EAAAhL,KAAAyiB,eAAA,SAAAujC,IACK,WAAAxzB,IACLxnB,EAAA87C,KAAArkC,eAAA,SAAAsjC,GACA/6C,EAAAhL,KAAAyiB,eAAA,SAAAqjC,MAIA7rD,KAAA6sD,KAAApkC,GAAA,iBAAAwjC,EAAA,SACAjsD,KAAA+F,KAAA0iB,GAAA,iBAAAwjC,EAAA,QAEA,IAAAzzC,GAAAC,GAAAoS,KACA7qB,KAAA+F,KACA/F,KAAA6sD,OACA7zC,KAAA,SAAAJ,GACA,GAAA+J,IACA5c,KAAA6S,EAAA,GACAi0C,KAAAj0C,EAAA,GAOA,OALA7H,GAAA2M,KAAA,WAAAiF,GACA9J,GACAA,EAAA,KAAA8J,GAEA5R,EAAAwX,qBACA5F,GACG,SAAA7J,GAaH,GAZA/H,EAAAsX,SACAxP,EAGAA,EAAAC,GAKA/H,EAAA2M,KAAA,QAAA5E,GAEA/H,EAAAwX,qBACA1P,EAEA,KAAAC,IAIA9Y,MAAAgZ,KAAA,SAAA8zC,EAAAh0C,GACA,MAAAN,GAAAQ,KAAA8zC,EAAAh0C,IAGA9Y,KAAAqrB,MAAA,SAAAvS,GACA,MAAAN,GAAA6S,MAAAvS,IAYA,QAAAi0C,IAAAttB,GACAA,EAAAyoB,UAAAgD,GACAzrB,EAAAutB,KAAA1B,GAEAvqD,OAAAC,eAAAy+B,EAAAj+B,UAAA,aACAL,IAAA,WACA,GAAA4P,GAAA/Q,IACA,QACAmqB,KAAA,SAAAja,EAAA8K,EAAAnC,GACA,MAAA9H,GAAAvE,YAAA07C,UAAAh4C,EAAAa,EAAAiK,EAAAnC,IAEAuR,GAAA,SAAAla,EAAA8K,EAAAnC,GACA,MAAA9H,GAAAvE,YAAA07C,UAAAn3C,EAAAb,EAAA8K,EAAAnC,QAMA4mB,EAAAj+B,UAAAwrD,KAAA,SAAArvC,EAAA3C,EAAAnC,GACA,MAAA7Y,MAAAwM,YAAAwgD,KAAAhtD,KAAA2d,EAAA3C,EAAAnC,IAnjWA,GAAAo0C,IAAA51C,EAAAnX,EAAA,KACAmY,GAAAhB,EAAAnX,EAAA,IACAktB,GAAA/V,EAAAnX,EAAA,IACA6d,GAAA7d,EAAA,GACAgtD,GAAA71C,EAAAnX,EAAA,IACAsT,GAAA6D,EAAAnX,EAAA,IACA6nB,GAAA1Q,EAAAnX,EAAA,KACAmyB,GAAAhb,EAAAnX,EAAA,KACAy1B,GAAAte,EAAAnX,EAAA,KAGAuY,GAAA,kBAAA/F,iBAAAu6C,GAqCAh9C,GAAApO,SAAAL,UAAAuC,SACAqM,GAAAH,GAAA1P,KAAAQ,QA8GAoY,GAAAiU,GAAA,cAsEA/S,GAAA7Y,UAAAL,IAAA,SAAAyC,GACA,GAAAupD,GAAAjzC,EAAAtW,EACA,OAAA5D,MAAAsa,OAAA6yC,IAEA9yC,EAAA7Y,UAAAa,IAAA,SAAAuB,EAAAlD,GACA,GAAAysD,GAAAjzC,EAAAtW,EAEA,OADA5D,MAAAsa,OAAA6yC,GAAAzsD,GACA,GAEA2Z,EAAA7Y,UAAAuD,IAAA,SAAAnB,GACA,GAAAupD,GAAAjzC,EAAAtW,EACA,OAAAupD,KAAAntD,MAAAsa,QAEAD,EAAA7Y,UAAAqrB,OAAA,SAAAjpB,GACA,GAAAupD,GAAAjzC,EAAAtW,GACA2V,EAAA4zC,IAAAntD,MAAAsa,MAEA,cADAta,MAAAsa,OAAA6yC,GACA5zC,GAEAc,EAAA7Y,UAAA0C,QAAA,SAAAyvB,GAEA,OADA1rB,GAAAlH,OAAAkH,KAAAjI,KAAAsa,QACAja,EAAA,EAAAsT,EAAA1L,EAAArF,OAAoCvC,EAAAsT,EAAStT,IAAA,CAC7C,GAAAuD,GAAAqE,EAAA5H,GACAK,EAAAV,KAAAsa,OAAA1W,EACAA,GAAAuW,EAAAvW,GACA+vB,EAAAjzB,EAAAkD,KAGA7C,OAAAC,eAAAqZ,EAAA7Y,UAAA,QACAL,IAAA,WACA,MAAAJ,QAAAkH,KAAAjI,KAAAsa,QAAA1X,UAcA2X,EAAA/Y,UAAAe,IAAA,SAAAqB,GACA,MAAA5D,MAAAsa,OAAAjY,IAAAuB,GAAA,IAEA2W,EAAA/Y,UAAAuD,IAAA,SAAAnB,GACA,MAAA5D,MAAAsa,OAAAvV,IAAAnB,IAEA2W,EAAA/Y,UAAA0C,QAAA,SAAAyvB,GACA3zB,KAAAsa,OAAApW,QAAA,SAAAxD,EAAAkD,GACA+vB,EAAA/vB,MAGA7C,OAAAC,eAAAuZ,EAAA/Y,UAAA,QACAL,IAAA,WACA,MAAAnB,MAAAsa,OAAArW,OAmBA,IAAA68B,IACA/jB,EAGAvC,MACAsmB,GAAAnuB,IACAoK,GAAA5W,MAEA26B,GAAAvmB,EACAwC,GAAA1C,EAOA,IAsIAgD,IAtIArB,GAAA,CAwIA,IAAAgB,IACAK,IAAA,MAEA,KACAgP,aAAA+gC,QAAA,+BACA/vC,KAAAgP,aAAAghC,QAAA,6BACG,MAAAtrD,GACHsb,IAAA,EAQA6vC,GAAApvC,EAAAC,GAAAC,cA+BAF,EAAAtc,UAAAgc,YAAA,SAAAG,EAAArC,EAAA7E,EAAAuE,GAOA,QAAAsyC,KAgBA,QAAAlb,KACAmb,GAAA,EAfA,GAAAx8C,EAAAkN,WAAA3C,GAAA,CAGA,GAAAiyC,EAEA,YADAA,EAAA,UAGAA,IAAA,CACA,IAAAxD,GAAA/vC,EAAAgB,GACA,0DACA,kDAQAvE,GAAAwS,QAAA8gC,GAAAthC,GAAA,kBAAAhoB,GACAA,EAAA21B,IAAApb,EAAA+lB,QAAA/lB,EAAAgqC,YACAhqC,EAAA+lB,MAAAtgC,EAAA21B,IACApb,EAAA0N,SAAAjoB,MAEKgoB,GAAA,sBACL,YAAA8kC,GACA/5C,GAAA85C,GAEAC,GAAA,IACK9kC,GAAA,QAAA2pB,IAnCL,IAAApyC,KAAAie,WAAA3C,GAAA,CAGA,GAAAvK,GAAA/Q,KACAutD,GAAA,CAiCAvtD,MAAAie,WAAA3C,GAAAgyC,EACAttD,KAAAyoB,GAAA9K,EAAA2vC,KAGAxvC,EAAAtc,UAAAgnB,eAAA,SAAA7K,EAAArC,GAEAA,IAAAtb,MAAAie,aAGAF,GAAAC,aAAAxc,UAAAgnB,eAAAjoB,KAAAP,KAAA2d,EACA3d,KAAAie,WAAA3C,UACAtb,MAAAie,WAAA3C,KAKAwC,EAAAtc,UAAAgsD,mBAAA,SAAA7vC,GAGAX,IACAC,OAAAC,QAAAC,MAAA9a,KAA8Bsb,WAC3BP,MACHiP,aAAA1O,GAAA,MAAA0O,aAAA1O,GAAA,UAIAG,EAAAtc,UAAAq5B,OAAA,SAAAld,GACA3d,KAAA0d,KAAAC,GACA3d,KAAAwtD,mBAAA7vC,GA6CA,IAAA8vC,GAGAA,IADA,kBAAA1sD,QAAA0sD,OACA1sD,OAAA0sD,OAIA,SAAA/1C,GAGA,OAFA0S,GAAArpB,OAAA2W,GAEA1U,EAAA,EAAyBA,EAAAoJ,UAAAxJ,OAA0BI,IAAA,CACnD,GAAA0qD,GAAAthD,UAAApJ,EAEA,UAAA0qD,EACA,OAAAC,KAAAD,GAEA3sD,OAAAS,UAAAC,eAAAlB,KAAAmtD,EAAAC,KACAvjC,EAAAujC,GAAAD,EAAAC,IAKA,MAAAvjC,GAKA,IAAAW,IAAA0iC,EAEAP,IAAAnuC,EAAApI,OAUAoI,EAAAvd,UAAAuC,SAAA,WACA,MAAA0xB,MAAAK,WACAjX,OAAA7e,KAAA6e,OACAje,KAAAZ,KAAAY,KACAqe,QAAAjf,KAAAif,QACAD,OAAAhf,KAAAgf,SAIA,IAoIAzF,IAnIAq0C,IADA,GAAA7uC,GAAA,qDACA,GAAAA,GAAA,kDACAgW,GAAA,GAAAhW,GAAA,2BACAkV,GAAA,GAAAlV,GAAA,2CACA2B,GAAA,GAAA3B,GAAA,qDACA6B,GAAA,GAAA7B,GAAA,6CACA4B,GAAA,GAAA5B,GAAA,2EAEAM,IADA,GAAAN,GAAA,+CACA,GAAAA,GAAA,8DACAyT,GAAA,GAAAzT,GAAA,+CAEA8uC,IADA,GAAA9uC,GAAA,6CACA,GAAAA,GAAA,4DACA4P,GAAA,GAAA5P,GAAA,oDACAW,GAAA,GAAAX,GAAA,sDACA+uC,GAAA,GAAA/uC,GAAA,oDAEAkX,IADA,GAAAlX,GAAA,sCACA,GAAAA,GAAA,sCACA4oB,GAAA,GAAA5oB,GAAA,kCAGA+O,IAFA,GAAA/O,GAAA,uCACA,GAAAA,GAAA,wEACA,GAAAA,GAAA,yCAEAic,IADA,GAAAjc,GAAA,iFACA,GAAAA,GAAA,mEA6GAgvC,IA5GA,GAAAhvC,GAAA,6CA4GAyB,EAAA5f,KAMA2Y,IADAw0C,GACA,SAAA31C,GACA,MAAAA,GAAAxX,MAGA,SAAAwX,GACA,MAAAA,GAAArU,WAAA+nB,MAAA,gCA8DA,IAAA7jB,KAAA,6DACA,qEACA0Z,GAAA,WACAC,GAAA,4BAIAN,GAAA,mMA4GAoB,GAAA,iEAGAzB,MAAA,GA0fAisC,IAAA/kC,GAAApK,GAAAC,cAiFAmK,GAAA3mB,UAAA6mB,OAAA,WACAroB,KAAA2oB,aAAA,EACA3oB,KAAAyW,GAAAmD,UAAAC,SACA7Z,KAAA0d,KAAA,WA2BAyK,GAAA3mB,UAAAqnB,UAAA,SAAA7N,GACA,GAAAjK,GAAA/Q,KACA6Y,EAAAmC,EAAAsN,QAcA,IAZAtN,EAAAjD,EAAAiD,GACA,QAAAA,MAAA,cAAAA,MACAA,EAAA4lB,WAAA5lB,EAAAgvC,MAEAhvC,EAAA8N,iBAEA,WAAA9N,EAAA+lB,QACA/lB,EAAA+lB,MAAA,OAEA/lB,EAAA+lB,QACA/lB,EAAA+lB,MAAA,GAEA,QAAA/lB,EAAA+lB,MAUA,WATA/gC,MAAAyW,GAAA4E,OAAArC,KAAA,SAAAqC,GAEA,MAAAtK,GAAA4X,gBACA9P,GAAA,MAAwBgG,OAAA,eAGxB7D,EAAA+lB,MAAA1lB,EAAA8nB,eACApyB,GAAA8X,UAAA7N,KACKnC,EASL,IAJAmC,EAAAwyB,OAAAxyB,EAAAlE,SACAkE,EAAAlE,OAAA,SAGAkE,EAAAlE,QAAA,gBAAAkE,GAAAlE,SACA,UAAAkE,EAAAlE,OACAkE,EAAAwyB,KAAAtsB,EAAAlG,EAAAwyB,MAEAxyB,EAAAlE,OAAAoK,EAAAlG,EAAAlE,QAGA,SAAA9W,KAAAyW,GAAA5G,SAAAmL,EAAA6lB,SACA,MAAA7gC,MAAAguD,cAAAhzC,EAIA,eAAAA,KACAA,EAAA0P,YAAA,GAIA1P,EAAAyP,MAAA,IAAAzP,EAAAyP,MAAA,EAAAzP,EAAAyP,MACAzP,EAAAsN,SAAAzP,CACA,IAAAo1C,GAAAjuD,KAAAyW,GAAA4sB,SAAAroB,EAEA,IAAAizC,GAAA,kBAAAA,GAAA5lC,OAAA,CACA,GAAAA,GAAAtX,EAAAsX,MACAtX,GAAAsX,OAAAhQ,GAAA,SAAA1V,GACAsrD,EAAA5lC,SACAA,EAAA7lB,MAAAxC,KAAA2C,OAKAwlB,GAAA3mB,UAAAwsD,cAAA,SAAAhzC,GACA,GAAAjK,GAAA/Q,KACA6Y,EAAAmC,EAAAsN,QACA,cAAAtN,EAAAlE,OAAA,CACA,IAAAkE,EAAAwyB,MAAA,gBAAAxyB,GAAAwyB,KAAA,CACA,GAAA10B,GAAAoG,EAAAQ,GACA,gDACA,OAAA7G,GAAAC,GAGA,GAAAmiC,GAAAl6B,EAAA/F,EAAAwyB,KACAxtC,MAAAyW,GAAAtV,IAAA,WAAA85C,EAAA,YAAAniC,EAAAo1C,GAEA,GAAAn9C,EAAA4X,YACA,MAAA9P,GAAA,MAA+BgG,OAAA,aAG/B,IAAA/F,EACA,MAAAD,GAAAuG,EAAAtG,GAEA,IAAAoiC,GAAAgT,KAAAzS,OAAAyS,EAAAzS,MAAAR,EAAA,KACAiT,EAAAzS,MAAAR,EAAA,IAAA94C,GACA,OAAA+4C,IAKAlgC,EAAAlE,OAAAkR,GAAAkzB,OACAnqC,GAAA8X,UAAA7N,IALAnC,EAAAqG,EAAA6V,GACAm5B,EAAAzS,MAAA,qBAAAR,EAAA,GACA,kCAKG,CAEH,GAAAkT,GAAAptC,EAAA/F,EAAAlE,OACA,KAAAq3C,EACA,MAAAp9C,GAAA8X,UAAA7N,EAEAhb,MAAAyW,GAAAtV,IAAA,WAAAgtD,EAAA,YAAAr1C,EAAAo1C,GAEA,GAAAn9C,EAAA4X,YACA,MAAA9P,GAAA,MAA+BgG,OAAA,aAG/B,IAAA/F,EACA,MAAAD,GAAAuG,EAAAtG,GAEA,IAAAgvC,GAAAoG,KAAAE,SAAAF,EAAAE,QAAAD,EAAA,GACA,OAAArG,IAKA9sC,EAAAlE,OAAAgR,GAAAggC,OACA/2C,GAAA8X,UAAA7N,IALAnC,EAAAqG,EAAA6V,GACAm5B,KAAAE,QAAA,qBAAAD,EAAA,GACA,kCA2JAjB,GAAAvhC,GAAA5N,GAAAC,cAMA2N,GAAAnqB,UAAA6sD,KACAp1C,EAAA,gBAAAsG,EAAAvE,EAAAnC,GAKA,MAJA,kBAAAmC,KACAnC,EAAAmC,EACAA,MAEA,gBAAAuE,IAAA9b,MAAA4D,QAAAkY,GACA1G,EAAAqG,EAAA4uC,SAEA9tD,MAAA4gD,UAAiBxlC,MAAAmE,IAAYvE,EAAAsO,GAAAzQ,MAG7B8S,GAAAnqB,UAAA+gB,IAAAtJ,EAAA,eAAAsG,EAAAvE,EAAA2Y,GAKA,MAJA,kBAAA3Y,KACA2Y,EAAA3Y,EACAA,MAEA,gBAAAuE,IAAA9b,MAAA4D,QAAAkY,GACAoU,EAAAzU,EAAA4uC,MAEArtC,EAAAlB,EAAAnI,KACAsQ,GAAAnI,EAAAnI,MAAA,kBAAApX,MAAA4jC,UACArkB,EAAAiK,SACAxpB,KAAAikC,aAAA1kB,EAAAoU,GAEA3zB,KAAA4jC,UAAArkB,EAAAoU,QAGA,kBAAA3zB,MAAAu2C,MAAAv7B,EAAAma,aAAA,EACAn1B,KAAAu2C,KAAAh3B,EAAAvE,EAAA2Y,GAEA3zB,KAAA4gD,UAAmBxlC,MAAAmE,IAAYvE,EAAAsO,GAAAqK,QAI/BhI,GAAAnqB,UAAA60C,cACAp9B,EAAA,yBAAAjC,EAAAy9B,EAAA/3B,EACA2T,EAAAxgB,GAkBA,QAAAy+C,GAAA/uC,GACA,GAAAgvC,GAAA,QAAAhvC,GAAAhB,SAAAgB,EAAA4C,KAAA,KAOA,OANA5C,GAAAa,aAAAb,EAAAa,iBACAb,EAAAa,aAAAq0B,IACA7hB,aAAA/iB,EACA5K,KAAAorB,EACAkM,SAAAgyB,GAEAhkC,EAAAhI,IAAAhD,GAzBA,GAAAgL,GAAAvqB,IA4BA,OA3BA,kBAAA6P,KACAA,EAAAwgB,EACAA,EAAA3T,EACAA,EAAA,MAIA,mBAAA7M,KACAA,EAAAwgB,EACAA,EAAA3T,EACAA,EAAA,MAEA7M,GACAqO,EAAA,oBAAAu2B,EAAA,cAAAz9B,EAAA,2BAcAuT,EAAAppB,IAAA6V,GAAAgC,KAAA,SAAAuG,GACA,GAAAA,EAAA4C,OAAAzF,EACA,KAAAwC,GAAA+U,GAGA,OAAAq6B,GAAA/uC,IACG,SAAAzG,GAGH,GAAAA,EAAAkG,SAAA+V,GAAA9V,QACA,MAAAqvC,IAA+Bl3C,IAAAJ,GAE/B,MAAA8B,OAKA6S,GAAAnqB,UAAA40C,iBACAn9B,EAAA,4BAAAjC,EAAAy9B,EAAA/3B,EACA7D,GACA,GAAA9H,GAAA/Q,IACA+Q,GAAA5P,IAAA6V,EAAA,SAAA8B,EAAAnD,GAEA,MAAAmD,OACAD,GAAAC,GAGAnD,EAAAwM,OAAAzF,MACA7D,GAAAqG,EAAA+U,KAIAte,EAAAyK,oBAGAzK,GAAAyK,aAAAq0B,GACA,IAAA1zC,OAAAkH,KAAA0N,EAAAyK,cAAAxd,cACA+S,GAAAyK,iBAEArP,GAAAwR,IAAA5M,EAAAkD,IANAA,QAUA8S,GAAAnqB,UAAAw0C,OACA/8B,EAAA,kBAAAg9B,EAAAC,EAAAl7B,EAAAnC,GACA,GAAA0G,EACA,iBAAA22B,IAEA32B,GACAnI,IAAA6+B,EACA9zB,KAAA+zB,GAEA,kBAAAl7B,KACAnC,EAAAmC,EACAA,QAIAuE,EAAA02B,EACA,kBAAAC,IACAr9B,EAAAq9B,EACAl7B,OAEAnC,EAAAmC,EACAA,EAAAk7B,IAGAl7B,QACAA,EAAAwzC,YAAA,CACA,IAAApsC,IAAgBhL,IAAAmI,EAAAnI,IAAA+K,KAAA5C,EAAA4C,MAAAnH,EAAA0B,IAEhB,OADA0F,GAAAoH,UAAA,EACA9B,GAAAtF,EAAAhL,MAAA,kBAAApX,MAAAikC,aACAjkC,KAAAikC,aAAA1kB,EAAA1G,OAEA7Y,MAAA4gD,UAAiBxlC,MAAAgH,IAAepH,EAAAsO,GAAAzQ,MAGhC8S,GAAAnqB,UAAAg2C,SACAv+B,EAAA,oBAAAuG,EAAAxE,EAAAnC,GAcA,QAAA41C,GAAAnzC,EAAAozC,GACAtd,EAAArsC,IAAAuW,IACA81B,EAAA/uC,IAAAiZ,GAAuB81B,aAEvBA,EAAAjwC,IAAAma,GAAA81B,QAAArrC,KAAA2oD,GAGA,QAAAC,GAAArzC,EAAA6H,GAEA,GAAAyrC,GAAApvC,EAAAlE,GAAA/O,MAAA,EACAkX,GAAAN,EAAA,SAAAe,EAAAX,EAAAoB,EAAAf,EACA5I,GACA,GAAA0B,GAAA6G,EAAA,IAAAoB,EACAQ,EAAAypC,EAAAntC,QAAA/E,EACAyI,MAAA,IAIAypC,EAAAjpD,OAAAwf,EAAA,GAEA,cAAAnK,EAAA6D,QACA4vC,EAAAnzC,EAAAoB,MAMAkyC,EAAA1qD,QAAA,SAAAwY,GACA+xC,EAAAnzC,EAAAoB,KAzCA,kBAAA1B,KACAnC,EAAAmC,EACAA,KAEA,IAAAqI,GAAAtiB,OAAAkH,KAAAuX,EAEA,KAAA6D,EAAAzgB,OACA,MAAAiW,GAAA,QAGA,IAAA2e,GAAA,EACA4Z,EAAA,GAAAr0B,GAkCAsG,GAAAlhB,IAAA,SAAAmZ,GACAtb,KAAAyjC,iBAAAnoB,EAAA,SAAAxC,EAAAqK,GACA,GAAArK,GAAA,MAAAA,EAAA+F,QAAA,YAAA/F,EAAAmG,QACAmyB,EAAA/uC,IAAAiZ,GAAyB81B,QAAA5xB,EAAAlE,SAClB,IAAAxC,EAEP,MAAAD,GAAAC,EAEA61C,GAAArzC,EAAA6H,GAGA,KAAAqU,IAAAnU,EAAAzgB,OAAA,CAEA,GAAAisD,KAIA,OAHAzd,GAAAltC,QAAA,SAAAxD,EAAAkD,GACAirD,EAAAjrD,GAAAlD,IAEAmY,EAAA,KAAAg2C,OAGG7uD,QAUH2rB,GAAAnqB,UAAAuZ,QACA9B,EAAA,mBAAA+B,EAAAnC,GACAkC,EAAA/a,KAAAgb,EAAAnC,KAMA8S,GAAAnqB,UAAAstD,gBACA71C,EAAA,2BAAAjC,EAAA+3C,EAAAl2C,GACA,GAAA9H,GAAA/Q,IACAA,MAAAyjC,iBAAAzsB,EAAA,SAAA8B,EAAAk2C,GAEA,GAAAl2C,EACA,MAAAD,GAAAC,EAEA,IAAAkR,GAAAD,GAAAilC,GACAC,KACAvrC,IACA3iB,QAAAkH,KAAA+hB,GAAA9lB,QAAA,SAAAwY,GACAsN,EAAAtN,GAAAqyC,GACAE,EAAAlpD,KAAA2W,KAIA+G,EAAAurC,EAAA,SAAA9qC,EAAAX,EAAAoB,EAAAf,EAAA5I,GACA,GAAA0B,GAAA6G,EAAA,IAAAoB,CACA,eAAA3J,EAAA6D,QAAAowC,EAAAxtC,QAAA/E,MAAA,GACAgH,EAAA3d,KAAA2W,KAGA3L,EAAA2yB,cAAA1sB,EAAA0M,EAAA7K,OAMA8S,GAAAnqB,UAAAuzC,QACA97B,EAAA,mBAAA+B,EAAAnC,GACA,kBAAAmC,KACAnC,EAAAmC,EACAA,KAGA,IAAAjK,GAAA/Q,IACAgb,SAEAjK,EAAAqa,iBAAAra,EAAAqa,qBACAra,EAAAqa,iBAAArlB,MAA8BiV,OAAAnC,aAC9B,IAAA9H,EAAAqa,iBAAAxoB,QACAuoB,GAAApa,KAGA4a,GAAAnqB,UAAA+pB,SAAA,SAAAvQ,EAAAnC,GAQA,QAAA6P,GAAA2O,GACA63B,EAAAnpD,KAAAgL,EAAA+9C,gBAAAz3B,EAAA/b,GAAA,IAEA,QAAA6zC,GAAAv2C,GACA,GAAAonB,GAAApnB,EAAA0S,QACA7S,IAAAoS,IAAAqkC,GAAAl2C,KAAA,WACA,MAAAgJ,GAAAjR,EAAA,6BAAAwO,GACA,QAAAA,EAAA+L,UAAA/L,EAAA+L,SAAA0U,KACAzgB,EAAA+L,SAAA0U,EACAzgB,OAIKvG,KAAA,WACLH,EAAA,MAAsBiC,IAAA,MACjBuQ,MAAAxS,GAtBL,GAAA9H,GAAA/Q,KACA+pD,GACA/oB,aAAA,EACA1V,SAAAtQ,EAAAsQ,UAAA,GAEA4jC,IAmBAn+C,GAAAkY,QAAA8gC,GACAthC,GAAA,SAAAC,GACAD,GAAA,WAAA0mC,GACA1mC,GAAA,QAAA5P,IAKA8S,GAAAnqB,UAAAL,IAAA8X,EAAA,eAAAqC,EAAAN,EAAA2Y,GAaA,QAAAy7B,KACA,GAAA5rD,MACAg0B,EAAAvT,EAAArhB,MAEA,OAAA40B,OAKAvT,GAAA/f,QAAA,SAAAugB,GACA1T,EAAA5P,IAAAma,GACAoB,IAAA+H,EACAf,KAAA1I,EAAA0I,KACAiE,OAAA3M,EAAA2M,OACAzH,YAAAlF,EAAAkF,aACO,SAAApH,EAAAyG,GACP,GAAAzG,EAaAtV,EAAAuC,MAAuBqrC,QAAA3sB,QAbvB,CAGA,OADA4qC,GACAhvD,EAAA,EAAAC,EAAAkD,EAAAZ,OAA4CvC,EAAAC,EAAOD,IACnD,GAAAmD,EAAAnD,GAAAya,IAAAtX,EAAAnD,GAAAya,GAAAqH,OAAA5C,EAAA4C,KAAA,CACAktC,GAAA,CACA,OAGAA,GACA7rD,EAAAuC,MAAyB+U,GAAAyE,IAKzBiY,IACAA,GACA7D,EAAA,KAAAnwB,OA5BAmwB,EAAA,KAAAnwB,GAbA,GAJA,kBAAAwX,KACA2Y,EAAA3Y,EACAA,MAEA,gBAAAM,GACA,MAAAqY,GAAAzU,EAAAwB,IAEA,IAAAgH,GAAApM,IAAA,kBAAAtb,MAAA2jC,UACA,MAAA3jC,MAAA2jC,UAAAroB,EAAAqY,EAEA,IAAA1P,MAAAlT,EAAA/Q,IAyCA,KAAAgb,EAAAwB,UA6BA,MAAAxc,MAAA2iC,KAAArnB,EAAAN,EAAA,SAAAlC,EAAAtV,GACA,GAAAsV,EACA,MAAA6a,GAAA7a,EAGA,IAAAyG,GAAA/b,EAAA+b,IACAsD,EAAArf,EAAAqf,SACAe,EAAApgB,EAAAogB,GAEA,IAAA5I,EAAAwJ,UAAA,CACA,GAAAA,GAAAF,EAAAzB,EACA2B,GAAA5hB,SACA2c,EAAA2J,WAAA1E,GAQA,GAJAiD,GAAA5E,EAAAtD,EAAA4C,QACA5C,EAAAiK,UAAA,GAGAxO,EAAA0I,MAAA1I,EAAA+6B,UAAA,CAQA,OAPAuZ,GAAA/vC,EAAA4C,KAAAlB,MAAA,KACAsuC,EAAAhxC,SAAA+wC,EAAA,OACA3qC,EAAA2qC,EAAA,GAEAzqC,EAAAD,EAAA/B,EAAAM,UACAkC,EAAA,KAEAhlB,EAAA,EAAqBA,EAAAwkB,EAAAjiB,OAAkBvC,IAAA,CACvC,GAAAmvD,GAAA3qC,EAAAxkB,GACAovD,EAAAD,EAAAnsC,IAAAlhB,IAAA,SAAAyY,GAA0D,MAAAA,GAAAU,KAC1DmG,QAAAkD,GACA+qC,EAAAD,IAAAF,EAAA,GAEAG,IAAArqC,GAAAoqC,KAAA,KACApqC,EAAAmqC,GAIA,GAAAG,GAAAtqC,EAAAhC,IAAAlhB,IAAA,SAAAyY,GAAkD,MAAAA,GAAAU,KAClDmG,QAAAlC,EAAA4C,KAAAlB,MAAA,WACA2uC,EAAAvqC,EAAAhC,IAAAzgB,OAAA+sD,CAYA,IAXAtqC,EAAAhC,IAAA1d,OAAAgqD,EAAAC,GACAvqC,EAAAhC,IAAAgB,UAEArJ,EAAA0I,OACAnE,EAAAsK,YACA3d,MAAAmZ,EAAA9B,IAAA8B,EAAAhC,IAAAzgB,OAAA,EACAygB,IAAAgC,EAAAhC,IAAAlhB,IAAA,SAAAua,GACA,MAAAA,GAAApB,OAIAN,EAAA+6B,UAAA,CACA,GAAAxyB,GAAA8B,EAAA9B,IAAA8B,EAAAhC,IAAAzgB,MACA2c,GAAAswC,WAAAxqC,EAAAhC,IAAAlhB,IAAA,SAAAua,GAEA,MADA6G,MAEA7G,IAAA6G,EAAA,IAAA7G,EAAApB,GACAuD,OAAAnC,EAAA1B,KAAA6D,WAMA,GAAA7D,EAAAkF,aAAAX,EAAAa,aAAA,CACA,GAAAF,GAAAX,EAAAa,aACAoX,EAAAz2B,OAAAkH,KAAAiY,GAAAtd,MACA,QAAA40B,EACA,MAAA7D,GAAA,KAAApU,EAEAxe,QAAAkH,KAAAiY,GAAAhc,QAAA,SAAAN,GACA5D,KAAA4iC,eAAArjB,EAAAnI,IAAAxT,EAAAsc,EAAAtc,IAIA8Y,IAAA6C,EAAA4C,KACA8N,OAAAjV,EAAAiV,OACArM,OACS,SAAA9K,EAAA7T,GACT,GAAAkb,GAAAZ,EAAAa,aAAAxc,EACAuc,GAAAlb,aACAkb,GAAAE,WACAF,GAAAvd,SACA40B,GACA7D,EAAA,KAAApU,MAGOxO,OACF,CACL,GAAAwO,EAAAa,aACA,OAAAxc,KAAA2b,GAAAa,aAEAb,EAAAa,aAAA3e,eAAAmC,KACA2b,EAAAa,aAAAxc,GAAAyc,MAAA,EAIAsT,GAAA,KAAApU,KA9HA,YAAAvE,EAAAwB,UACAxc,KAAAyjC,iBAAAnoB,EAAA,SAAAxC,EAAAqK,GACA,MAAArK,GACA6a,EAAA7a,IAEAmL,EAAAD,EAAAb,GAAAhhB,IAAA,SAAAsiB,GACA,MAAAA,GAAA/H,UAEA0yC,YAEK,CACL,IAAA3rD,MAAA4D,QAAA2T,EAAAwB,WAWA,MAAAmX,GAAAzU,EAAAG,GAAA,mBAVA4E,GAAAjJ,EAAAwB,SACA,QAAAnc,GAAA,EAAuBA,EAAA4jB,EAAArhB,OAAmBvC,IAAA,CAC1C,GAAAC,GAAA2jB,EAAA5jB,EAEA,iCAAAqK,KAAApK,GACA,MAAAqzB,GAAAzU,EAAA4O,KAGAshC,OAkHAzjC,GAAAnqB,UAAA20C,cACAl9B,EAAA,yBAAAjC,EAAAy9B,EAAAz5B,EAAAnC,GACA,GAAA9H,GAAA/Q,IACAgb,aAAAnZ,YACAgX,EAAAmC,EACAA,MAEAhb,KAAA2iC,KAAA3rB,EAAAgE,EAAA,SAAAlC,EAAAS,GACA,MAAAT,GACAD,EAAAC,GAEAS,EAAAgG,IAAAa,cAAA7G,EAAAgG,IAAAa,aAAAq0B,IACAz5B,EAAA4I,IAAArK,EAAAqK,IACA5I,EAAAiV,QAAA,EACAlf,EAAA6xB,eAAA5rB,EAAAy9B,EACAl7B,EAAAgG,IAAAa,aAAAq0B,GAAAz5B,EAAAnC,GAHAmC,QAKAnC,EAAAqG,EAAA6V,SAKApJ,GAAAnqB,UAAAg1C,QACAv9B,EAAA,mBAAA+B,EAAAnC,GAYA,GAXA,kBAAAmC,KACAnC,EAAAmC,EACAA,MAEAA,EAAAwP,KAAA,mBAAAxP,GAAAwP,KAAAxP,EAAAwP,KAAA,EACAxP,EAAAy7B,YACAz7B,EAAA6jB,SAAA7jB,EAAAy7B,WAEAz7B,EAAA07B,UACA17B,EAAA8jB,OAAA9jB,EAAA07B,SAEA,QAAA17B,GAAA,CACA,IAAAvX,MAAA4D,QAAA2T,EAAA/S,MACA,MAAA4Q,GAAA,GAAAi3C,WAAA,iCAEA,IAAAC,IACA,2BAAAj5C,OAAA,SAAAi5C,GACA,MAAAA,KAAA/0C,KACK,EACL,IAAA+0C,EAKA,WAJAl3C,GAAAqG,EAAA2uC,GACA,oBAAAkC,EACA,sCAIA,aAAA/vD,KAAA6P,OACA,MAAAya,IAAAtqB,KAAAgb,EAAAnC,GAIA,MAAA7Y,MAAA2qB,SAAA3P,EAAAnC,KAGA8S,GAAAnqB,UAAAynB,QAAA,SAAAjO,EAAAnC,GAKA,MAJA,kBAAAmC,KACAnC,EAAAmC,EACAA,MAEA,GAAAmN,IAAAnoB,KAAAgb,EAAAnC,IAGA8S,GAAAnqB,UAAA+hC,MAAAtqB,EAAA,iBAAAJ,GAGA,MAFA7Y,MAAA0Z,SAAA,EACA1Z,KAAA0d,KAAA,UACA1d,KAAAsjC,OAAAzqB,KAGA8S,GAAAnqB,UAAA6Z,KAAApC,EAAA,gBAAAJ,GACA,GAAA9H,GAAA/Q,IACAA,MAAAgjC,MAAA,SAAAlqB,EAAAuC,GACA,MAAAvC,GACAD,EAAAC,IAGAuC,EAAAoC,QAAApC,EAAAoC,SAAA1M,EAAAnQ,KACAya,EAAA2R,mBAAAjc,EAAAic,iBAAA,SAAAjc,EAAAlB,QACAwL,EAAA0Q,QAAAhb,EAAAlB,WACAgJ,GAAA,KAAAwC,QAIAsQ,GAAAnqB,UAAA8Z,GAAArC,EAAA,cAAAJ,GACA,MAAA7Y,MAAAoX,IAAAyB,KAIA8S,GAAAnqB,UAAAqO,KAAA,WACA,wBAAA7P,MAAAgwD,MAAAhwD,KAAAgwD,QAAAhwD,KAAA+rB,SAGAJ,GAAAnqB,UAAAo/C,SACA3nC,EAAA,oBAAAuG,EAAAxE,EAAAnC,GAcA,GAbA,kBAAAmC,KACAnC,EAAAmC,EACAA,MAGAA,QAEAvX,MAAA4D,QAAAmY,KACAA,GACApE,KAAAoE,KAIAA,MAAApE,OAAA3X,MAAA4D,QAAAmY,EAAApE,MACA,MAAAvC,GAAAqG,EAAA0uC,IAGA,QAAAvtD,GAAA,EAAiBA,EAAAmf,EAAApE,KAAAxY,SAAqBvC,EACtC,mBAAAmf,GAAApE,KAAA/a,IAAAoD,MAAA4D,QAAAmY,EAAApE,KAAA/a,IACA,MAAAwY,GAAAqG,EAAA4uC,IAIA,IAAAmC,EAYA,IAXAzwC,EAAApE,KAAAlX,QAAA,SAAAqb,GACAA,EAAAa,cACArf,OAAAkH,KAAAsX,EAAAa,cAAAlc,QAAA,SAAAtD,GACAqvD,KAAAxkC,GAAA7qB,GACA2e,EAAAa,aAAAxf,GAAAgyB,cACA1U,EAAA,oBAAAtd,EAAA,cAAA2e,EAAAnI,IAAA,+BAMA64C,EACA,MAAAp3C,GAAAqG,EAAAQ,GAAAuwC,GAGA,cAAAj1C,KACA,aAAAwE,GACAxE,EAAAma,UAAA3V,EAAA2V,UAEAna,EAAAma,WAAA,EAIA,IAAApJ,GAAA/rB,IACAgb,GAAAma,WAAA,SAAApJ,EAAAlc,QAGA2P,EAAApE,KAAAgJ,KAAAsF,IAGAH,GAAA/J,EAAApE,KAKA,IAAAiI,GAAA7D,EAAApE,KAAAjZ,IAAA,SAAAod,GACA,MAAAA,GAAAnI,KAGA,OAAApX,MAAAyiC,UAAAjjB,EAAAxE,EAAA,SAAAlC,EAAAS,GACA,GAAAT,EACA,MAAAD,GAAAC,EASA,IAPAkC,EAAAma,YAEA5b,IAAAzC,OAAA,SAAA8D,GACA,MAAAA,GAAAiC,SAIA,SAAAkP,EAAAlc,OACA,OAAAxP,GAAA,EAAAC,EAAAiZ,EAAA3W,OAAqCvC,EAAAC,EAAOD,IAC5CkZ,EAAAlZ,GAAAib,GAAA/B,EAAAlZ,GAAAib,IAAA+H,EAAAhjB,EAIAwY,GAAA,KAAAU,OAIAoS,GAAAnqB,UAAAq6C,0BACA5iC,EAAA,qCAAAi3C,EACAr3C,GAGA,QAAAoJ,GAAA1C,GAEA,MADAA,GAAA4wC,aAAA5wC,EAAA4wC,kBACA5wC,EAAA4wC,aAAAD,KAGA3wC,EAAA4wC,aAAAD,IAAA,EACA3wC,GARA,GAAA6wC,GAAA,GAAApwD,MAAAwM,YAAA0jD,EAAAlwD,KAAA+sB,OAUA/K,GAAAhiB,KAAA,6BAAAiiB,GACAjJ,KAAA,WACAH,EAAA,MAAsBpC,GAAA25C,MACjB/kC,MAAAxS,KAGL8S,GAAAnqB,UAAAswB,QACA7Y,EAAA,mBAAA+B,EAAAnC,GAUA,QAAAw3C,KAEAt/C,EAAAmzB,SAAAlpB,EAAA,SAAAlC,EAAAF,GACA,MAAAE,GACAD,EAAAC,IAEA/H,EAAA4I,YAAA,EACA5I,EAAA2M,KAAA,iBACA7E,GAAA,KAAAD,IAA8BkC,IAAA,OAhB9B,kBAAAE,KACAnC,EAAAmC,EACAA,KAGA,IAAAjK,GAAA/Q,KACAssB,IAAA,cAAAvb,OAAAwb,UAcA,gBAAAxb,EAAAlB,OAEAwgD,QAGAt/C,GAAA5P,IAAA,sCAAA2X,EAAAorC,GACA,GAAAprC,EAEA,aAAAA,EAAA+F,OACAhG,EAAAC,GAEAu3C,GAGA,IAAAF,GAAAjM,EAAAiM,aACA1wB,EAAA1uB,EAAAvE,YACA8jD,EAAAvvD,OAAAkH,KAAAkoD,GAAAhuD,IAAA,SAAAvB,GAGA,GAAA2vD,GAAAjkC,EACA1rB,EAAAmR,QAAA,GAAAD,QAAA,IAAA2tB,EAAAtT,QAAA,IAAAvrB,CACA,WAAA6+B,GAAA8wB,EAAAx/C,EAAAgc,QAAA+E,WAEArZ,IAAAoS,IAAAylC,GAAAt3C,KAAAq3C,EAAAx3C,OAUA+S,GAAApqB,UAAAgvD,QAAA,WACA,GAAAp4C,EACA,IAAApY,KAAA+Z,OACA,KAAA3B,EAAApY,KAAA4T,MAAA4X,SACApT,EAAApY,KAAA+Z,YAGA,MAAA3B,EAAApY,KAAA4T,MAAA4X,SACApT,KAKAwT,GAAApqB,UAAA8rB,KAAA,SAAAxU,GACA9Y,KAAA+Z,OAAAjB,EACA9Y,KAAAwwD,WAGA5kC,GAAApqB,UAAA+rB,MAAA,SAAA9W,GACAzW,KAAA6Z,SAAA,EACA7Z,KAAAyW,KACAzW,KAAAwwD,WAGA5kC,GAAApqB,UAAAsY,QAAA,SAAA1B,GACApY,KAAA4T,MAAA7N,KAAAqS,GACApY,KAAA+Z,QACA/Z,KAAAwwD,WAuFAtD,GAAAjhC,GAAAN,IA2DAM,GAAAmB,SAEAnB,GAAAD,YACAC,GAAAC,qBAEAD,GAAAE,OAAA,SAEA,IAAAuB,IAAA,GAAA3P,IAAAC,YAoBAwP,IAAAvB,IAEAA,GAAAF,QAAA,SAAAzQ,EAAA3F,EAAA86C,GAEA96C,EAAA0X,UACApB,GAAAD,SAAA1Q,GAAA3F,EACA86C,GACAxkC,GAAAC,kBAAAnmB,KAAAuV,KAKA2Q,GAAAykC,OAAA,SAAA/6C,GACA,qBAAAA,GACAA,EAAAsW,QACG,oBAAAtW,IAAA,IAAA5U,OAAAkH,KAAA0N,GAAA/S,OACH,SAAA+T,OAAA,wBAAAhB,EAAA,sCAEA5U,QAAAkH,KAAA0N,GAAAzR,QAAA,SAAAoX,GACA2Q,GAAAzqB,UAAA8Z,GAAA3F,EAAA2F,KAGA,MAAA2Q,KAGAA,GAAA0kC,SAAA,SAAAC,GACA,QAAAC,GAAAjwD,EAAAoa,GACA,MAAAhb,gBAAA6wD,IAIA71C,QAEApa,GAAA,gBAAAA,KACAoa,EAAApa,EACAA,EAAAoa,EAAApa,WACAoa,GAAApa,MAGAoa,EAAA+P,MAAsB8lC,EAAAC,WAAA91C,OACtBiR,IAAA1rB,KAAAP,KAAAY,EAAAoa,IAZA,GAAA61C,GAAAjwD,EAAAoa,GA4BA,MAbAkyC,IAAA2D,EAAA5kC,IAEA4kC,EAAA3kC,kBAAAD,GAAAC,kBAAA3f,QACAxL,OAAAkH,KAAAgkB,IAAA/nB,QAAA,SAAAN,GACAA,IAAAitD,KACAA,EAAAjtD,GAAAqoB,GAAAroB,MAMAitD,EAAAC,WAAA/lC,MAAmC/qB,KAAA8wD,WAAAF,GAEnCC,EAIA,IAAAtrB,IAAA,OAEAtZ,IAAAsZ,UASA,IAuvDAF,IAvvDA3W,GAAAd,IACA,MACA,OACA,eACA,WACA,aACA,aACA,aACA,qBACA,aACA,YAEA,kBACA,qBACA,0BACA,4BACA,qBAEA,aAIAgB,GAAAhB,IACA,eAEA,kBACA,qBACA,0BACA,4BACA,uBA6GAmC,GAAA,SAAAjR,GACA,MAAAiyC,MAAAjyC,IAGAkS,GAAA,SAAAlS,GACA,MAAAkyC,MAAAlyC,IAoHA6S,GAAA1vB,EAAAyS,cAAAzS,EAAAkT,WACAgd,GAAA,MAwVAuS,GAAA,EAKAvL,GAAA,iBAGAlB,GAAA,cAEAf,GAAA,eAGAgB,GAAA,mBAIAmB,GAAA,aAEAD,GAAA,cAEA8F,GAAA,sBA0OAtE,GAAA,GAAA9c,GA2rBA6hB,IAAA,EACA/rB,MA+NA4vB,GAAA,GAAAzmB,IAEAqnB,GAAA,GAAArnB,GAyuBAmkB,IAAA7T,MAAA,WAIA,GAAAokB,GAAA,mBAAAxD,eACA,4BAAAvjC,KAAA00B,UAAAC,aACA,SAAA30B,KAAA00B,UAAAC,aACA,aAAA30B,KAAA00B,UAAA6xB,SAIA,QAAAxf,GAAA,mBAAApN,YACA,mBAAAxM,aAcA,IAAAq5B,IAAA,SAAAzxB,GACAA,EAAA1T,QAAA,MAAAmV,IAAA,IAuEA6K,GAAA,EAIAtD,GAAAzC,GAAA,kBAGAsB,GAAAtB,GAAA,eAEAqB,GAAArB,GAAA,gBACA+D,GAAA/D,GAAA,eACA2F,GAAA3F,GAAA,kBAGAiB,GAAAjB,GAAA,oBAydAqD,GAAA,GAAAtsB,IA4BAgrB,GAAA,GAAAjqB,GAqCA6uB,GAAA,EAGA9C,GACA,sDACAvC,GAAA,kBACAgD,GACA,4DACAhD,GAAA,iBACAsC,GACA,sDACAnB,GAAA,gBACAwC,GACA,sDACAhE,GAAA,SACA+D,GACA,gEACA/D,GAAA,iBAEAyD,GAAApD,GACA,UAAAmB,GAAA,cAEAgC,GAAAnD,GAAA,gBACAA,GAAA,wBACAA,GAAA,kBACAA,GAAA,gBACAmB,GAAA;AAggCA8F,GAAAlhB,SAEAkhB,GAAAhiB,YAAA,CAEA,IAAA4kC,IAAA,SAAA1xB,GACAA,EAAA1T,QAAA,SAAAwiB,IAAA,IAuPAyC,GAAAF,KAWAO,GAAA,aA8KAwF,GAAA,GACArB,GAAA,GAEAE,MAEA3B,GAAA3mB,GAAA,eA87BAsmB,IAAArmB,MAAA,WACA,SAGA,IAAA+jC,IAAA,SAAA3xB,GACAA,EAAA1T,QAAA,OAAA2nB,IAAA,GACAjU,EAAA1T,QAAA,QAAA2nB,IAAA,IAkBA8F,IAAA,IACAF,GAAA,EACAN,GAAA,EA4WA6B,IAAAr5C,UAAAe,IAAA,SAAAu6C,GAMA,MALA98C,MAAAwY,QAAAxY,KAAAwY,QAAA6S,MAAA,cAEGrS,KAAA,WACH,MAAA8jC,OAEA98C,KAAAwY,SAEAqiC,GAAAr5C,UAAAy5B,OAAA,WACA,MAAAj7B,MAAAwY,SA0FA00C,GAAAnR,GAAAplC,OAYAu2C,GAAAjR,GAAAtlC,OAYAu2C,GAAAhR,GAAAvlC,MAuCA,IAAA6lC,IAAAt+B,EAAA0K,KAAA,YACAvhB,GAAA5D,MAAA4D,QACAqxC,GAAAjjB,KAAAC,MAqFAorB,MACA+C,GAAA,GAAAhJ,IACAuG,GAAA,GA8FAQ,IACAyP,KAAA,SAAAppD,EAAA/E,GACA,MAAAk5C,IAAAl5C,IAGAouD,OAAA,SAAArpD,EAAA/E,GACA,MAAAA,GAAAN,QAGA2uD,OAAA,SAAAtpD,EAAA/E,GAGA,QAAAsuD,GAAAtuD,GAEA,OADAuuD,GAAA,EACApxD,EAAA,EAAAsT,EAAAzQ,EAAAN,OAA0CvC,EAAAsT,EAAStT,IAAA,CACnD,GAAAimC,GAAApjC,EAAA7C,EACAoxD,IAAAnrB,IAEA,MAAAmrB,GAEA,OACArV,OAAAl5C,GACA6Y,IAAAxJ,KAAAwJ,IAAAvZ,MAAA,KAAAU,GACAsP,IAAAD,KAAAC,IAAAhQ,MAAA,KAAAU,GACAs0B,MAAAt0B,EAAAN,OACA4uD,SAAAtuD,MA2pBAwuD,GAAAhV,GAAA,WACA,GAAAjmC,GAAAzW,IACA,gBAAAyW,EAAA5G,OACAmzC,GAAAvsC,GAGA,kBAAAA,GAAA8oC,aACAD,GAAA7oC,GAEAwsC,GAAAxsC,KA0EAoJ,GAAA,SAAAzH,EAAA4C,EAAAnC,GACA,kBAAAmC,KACAnC,EAAAmC,EACAA,MAEAA,IAAAwjC,GAAAxjC,MAEA,kBAAA5C,KACAA,GAAWjW,IAAAiW,GAGX,IAAA3B,GAAAzW,KACAwY,EAAAC,GAAApF,UAAA2F,KAAA,WACA,MAAA2qC,IAAAltC,EAAA2B,EAAA4C,IAGA,OADAyhC,IAAAjkC,EAAAK,GACAL,GAIAm5C,IACA9xC,SACA6xC,gBAyLA3L,GAAA,EACAD,GAAA,UAQAG,GAAA,EACAY,GAAA,CAoEAX,IAAA1kD,UAAA2nD,gBAAA,SAAA1D,EAAAC,GACA,GAAA30C,GAAA/Q,IACA,OAAAA,MAAA4xD,aAAAnM,EAAAC,GAAA1sC,KAAA,WACA,MAAAjI,GAAA8gD,aAAApM,EAAAC,MAIAQ,GAAA1kD,UAAAowD,aAAA,SAAAnM,EAAAC,GACA,MAAAF,IAAAxlD,KAAA0X,OAAA1X,KAAAsb,GAAAmqC,EACAC,EAAA1lD,KAAA2lD,cAGAO,GAAA1kD,UAAAqwD,aAAA,SAAApM,EAAAC,GACA,GAAA30C,GAAA/Q,IACA,OAAAA,MAAA8xD,eACAr5C,GAAApF,SAAA,GAEAmyC,GAAAxlD,KAAAskD,IAAAtkD,KAAAsb,GAAAmqC,EACAC,EAAA1lD,KAAA2lD,aACAt6B,MAAA,SAAAvS,GACA,GAAAouC,GAAApuC,GAEA,MADA/H,GAAA+gD,gBAAA,GACA,CAEA,MAAAh5C,KAIA,IAAAi5C,KACAluD,UAAA,SAAAmuD,EAAAC,GAEA,WAAAla,GAAAia,EAAA1mC,SAAA2mC,EAAA3mC,UACA2mC,EAAA3mC,SAGA,GAEA4mC,EAAA,SAAAF,EAAAC,GAEA,MAAA9L,IAAA8L,EAAAD,GAAA1mC,UAIA46B,IAAA1kD,UAAAopD,cAAA,WACA,GAAA75C,GAAA/Q,IACA,OAAA+Q,GAAA2G,OAAAvW,IAAA4P,EAAAuK,IAAAtC,KAAA,SAAAg5C,GACA,MAAAjhD,GAAA+gD,eACAr5C,GAAApF,QAAA2+C,EAAA1mC,UAGAva,EAAAuzC,IAAAnjD,IAAA4P,EAAAuK,IAAAtC,KAAA,SAAAi5C,GAIA,GAAAD,EAAAzsB,UAAA0sB,EAAA1sB,QACA,MAAAshB,GAGA,IAAAthB,EAOA,OALAA,GADAysB,EAAAzsB,QACAysB,EAAAzsB,QAAAxhC,WAEA,YAGAwhC,IAAAwsB,IACAA,GAAAxsB,GAAAysB,EAAAC,GAGApL,IACK,SAAA/tC,GACL,SAAAA,EAAA+F,QAAAmzC,EAAA1mC,SACA,MAAAva,GAAAuzC,IAAA/hC,KACAnL,IAAArG,EAAAuK,GACAgQ,SAAAu7B,KACS7tC,KAAA,WACT,MAAA6tC,KACS,SAAA/tC,GACT,MAAAouC,IAAApuC,IACA/H,EAAA+gD,gBAAA,EACAE,EAAA1mC,UAGAu7B,IAGA,MAAA/tC,OAEGuS,MAAA,SAAAvS,GACH,SAAAA,EAAA+F,OACA,KAAA/F,EAEA,OAAA+tC,MAwEA,IAAAY,IAAA,CAwgBAyF,IAAAnC,GAAAhtC,GAAAC,cAqBA+sC,GAAAvpD,UAAA6mB,OAAA,WACAroB,KAAAglD,WAAA,EACAhlD,KAAA6W,MAAA,YACA7W,KAAA0d,KAAA,WAGAqtC,GAAAvpD,UAAA+rB,MAAA,SAAA+2B,EAAA5sC,GAOA,QAAA0Q,KACArX,EAAAsX,SAIA,QAAAy7B,KACAQ,EAAA97B,eAAA,YAAAJ,GACA1Q,EAAA8Q,eAAA,YAAAJ,GAbA,GAAArX,GAAA/Q,IACA+Q,GAAAohD,eAGAphD,EAAAohD,cAAA,EAKA7N,EAAAnsC,KAAA,YAAAiQ,GACA1Q,EAAAS,KAAA,YAAAiQ,GAKArX,EAAAoH,KAAA,WAAA2rC,KAwCAoJ,GAAA3B,GAAAxtC,GAAAC,cAyMAutC,GAAA/pD,UAAA6mB,OAAA,WACAroB,KAAA0sD,WACA1sD,KAAA0sD,UAAA,EACA1sD,KAAA+F,KAAAsiB,SACAroB,KAAA6sD,KAAAxkC,WA2BA4D,GAAAykC,OAAAQ,IACAR,OAAAS,IACAT,OAAAU,IACAV,OAAAiB,IACAjB,OAAA3D,IAEAltD,EAAAD,QAAAqsB,KNq6E6B1rB,KAAKX,EAASM,EAAoB,KAIzD,SAAUL,EAAQD,EAASM,GAEjC,YOx+aA,SAAAkyD,GAAAh6C,GACA,kBACA,GAAAzE,GAAAvH,UAAAxJ,MACA,IAAA+Q,EAAA,CAGA,IAFA,GAAAhR,MACAtC,GAAA,IACAA,EAAAsT,GACAhR,EAAAtC,GAAA+L,UAAA/L,EAEA,OAAA+X,GAAA7X,KAAAP,KAAA2C,GAEA,MAAAyV,GAAA7X,KAAAP,UAbAH,EAAAD,QAAAwyD,GPigbM,SAAUvyD,EAAQD,EAASM,IQngbjC,SAAAmR,GAsCA,QAAAghD,KAIA,2BAAArwD,kBAAA,mBAAAA,QAAAqP,SAAA,aAAArP,OAAAqP,QAAAxB,QAMA,mBAAAyE,qBAAA,oBAAAA,UAAAW,gBAAA+T,OAEA,mBAAAhnB,wBAAAoc,kBAAAk0C,SAAAl0C,QAAAiyB,WAAAjyB,QAAAqoB,QAGA,mBAAArH,iCAAAC,WAAAD,UAAAC,UAAA9Q,cAAAzC,MAAA,mBAAAvN,SAAAzM,OAAAgQ,GAAA,SAEA,mBAAAsd,iCAAAC,WAAAD,UAAAC,UAAA9Q,cAAAzC,MAAA,uBAsBA,QAAAymC,GAAA5vD,GACA,GAAA0vD,GAAAryD,KAAAqyD,SASA,IAPA1vD,EAAA,IAAA0vD,EAAA,SACAryD,KAAAwyD,WACAH,EAAA,WACA1vD,EAAA,IACA0vD,EAAA,WACA,IAAAzyD,EAAA6yD,SAAAzyD,KAAAqmB,MAEAgsC,EAAA,CAEA,GAAA5xD,GAAA,UAAAT,KAAA0yD,KACA/vD,GAAAgD,OAAA,IAAAlF,EAAA,iBAKA,IAAAuC,GAAA,EACA2vD,EAAA,CACAhwD,GAAA,GAAAoP,QAAA,uBAAA+Z,GACA,OAAAA,IACA9oB,IACA,OAAA8oB,IAGA6mC,EAAA3vD,MAIAL,EAAAgD,OAAAgtD,EAAA,EAAAlyD,IAUA,QAAA0Y,KAGA,sBAAAiF,UACAA,QAAAjF,KACAtX,SAAAL,UAAAgB,MAAAjC,KAAA6d,QAAAjF,IAAAiF,QAAAhS,WAUA,QAAAwmD,GAAAC,GACA,IACA,MAAAA,EACAjzD,EAAAsd,QAAA41C,WAAA,SAEAlzD,EAAAsd,QAAAkQ,MAAAylC,EAEG,MAAA9wD,KAUH,QAAAgxD,KACA,IACA,MAAAnzD,GAAAsd,QAAAkQ,MACG,MAAArrB,IAGH,sBAAAsP,IAAA,OAAAA,GACA,OAAA2hD,SAAA,cAAAC,MAqBA,QAAAC,KACA,IACA,MAAAlxD,QAAAqqB,aACG,MAAAtqB,KA9KHnC,EAAAC,EAAAD,QAAAM,EAAA,GACAN,EAAAuZ,MACAvZ,EAAA2yD,aACA3yD,EAAAgzD,OACAhzD,EAAAmzD,OACAnzD,EAAAyyD,YACAzyD,EAAAsd,QAAA,mBAAAD,SACA,mBAAAA,QAAAC,QACAD,OAAAC,QAAAC,MACA+1C,IAMAtzD,EAAAuzD,QACA,gBACA,cACA,YACA,aACA,aACA,WAmCAvzD,EAAAwzD,WAAAj3C,EAAA,SAAAg1B,GACA,IACA,MAAA1b,MAAAK,UAAAqb,GACG,MAAAr4B,GACH,qCAAAA,EAAAmG,UAkGArf,EAAAyzD,OAAAN,ORwhb6BxyD,KAAKX,EAASM,EAAoB,MAIzD,SAAUL,EAAQD,EAASM,GSrpbjC,QAAAozD,GAAAd,GACA,GAAAnyD,GAAA6F,EAAA,CAEA,KAAA7F,IAAAmyD,GACAtsD,MAAA,GAAAA,EAAAssD,EAAA9iC,WAAArvB,GACA6F,GAAA,CAGA,OAAAtG,GAAAuzD,OAAA5gD,KAAAmoC,IAAAx0C,GAAAtG,EAAAuzD,OAAAvwD,QAWA,QAAA2wD,GAAAf,GAEA,QAAAplC,KAEA,GAAAA,EAAAhU,QAAA,CAEA,GAAArI,GAAAqc,EAGAomC,GAAA,GAAAv7C,MACAw7C,EAAAD,GAAAE,GAAAF,EACAziD,GAAAsV,KAAAotC,EACA1iD,EAAA2iB,KAAAggC,EACA3iD,EAAAyiD,OACAE,EAAAF,CAIA,QADA7wD,GAAA,GAAAc,OAAA2I,UAAAxJ,QACAvC,EAAA,EAAmBA,EAAAsC,EAAAC,OAAiBvC,IACpCsC,EAAAtC,GAAA+L,UAAA/L,EAGAsC,GAAA,GAAA/C,EAAA+zD,OAAAhxD,EAAA,IAEA,gBAAAA,GAAA,IAEAA,EAAAqjD,QAAA,KAIA,IAAAhjD,GAAA,CACAL,GAAA,GAAAA,EAAA,GAAAoP,QAAA,yBAAA+Z,EAAA8nC,GAEA,UAAA9nC,EAAA,MAAAA,EACA9oB,IACA,IAAA6wD,GAAAj0D,EAAAwzD,WAAAQ,EACA,sBAAAC,GAAA,CACA,GAAAvuB,GAAA3iC,EAAAK,EACA8oB,GAAA+nC,EAAAtzD,KAAAwQ,EAAAu0B,GAGA3iC,EAAAgD,OAAA3C,EAAA,GACAA,IAEA,MAAA8oB,KAIAlsB,EAAA2yD,WAAAhyD,KAAAwQ,EAAApO,EAEA,IAAAmxD,GAAA1mC,EAAAjU,KAAAvZ,EAAAuZ,KAAAiF,QAAAjF,IAAAyP,KAAAxK,QACA01C,GAAAtxD,MAAAuO,EAAApO,IAaA,MAVAyqB,GAAAolC,YACAplC,EAAAhU,QAAAxZ,EAAAwZ,QAAAo5C,GACAplC,EAAAilC,UAAAzyD,EAAAyyD,YACAjlC,EAAAslC,MAAAY,EAAAd,GAGA,kBAAA5yD,GAAAwhC,MACAxhC,EAAAwhC,KAAAhU,GAGAA,EAWA,QAAAimC,GAAAR,GACAjzD,EAAAgzD,KAAAC,EAKA,QAHA5xC,IAAA4xC,GAAA,IAAA5xC,MAAA,UACAtN,EAAAsN,EAAAre,OAEAvC,EAAA,EAAiBA,EAAAsT,EAAStT,IAC1B4gB,EAAA5gB,KACAwyD,EAAA5xC,EAAA5gB,GAAA0R,QAAA,aACA,MAAA8gD,EAAA,GACAjzD,EAAAm0D,MAAAhuD,KAAA,GAAA+L,QAAA,IAAA+gD,EAAA/f,OAAA,SAEAlzC,EAAAo0D,MAAAjuD,KAAA,GAAA+L,QAAA,IAAA+gD,EAAA,OAWA,QAAAoB,KACAr0D,EAAAyzD,OAAA,IAWA,QAAAj6C,GAAAxY,GACA,GAAAP,GAAAsT,CACA,KAAAtT,EAAA,EAAAsT,EAAA/T,EAAAm0D,MAAAnxD,OAAyCvC,EAAAsT,EAAStT,IAClD,GAAAT,EAAAm0D,MAAA1zD,GAAAqK,KAAA9J,GACA,QAGA,KAAAP,EAAA,EAAAsT,EAAA/T,EAAAo0D,MAAApxD,OAAyCvC,EAAAsT,EAAStT,IAClD,GAAAT,EAAAo0D,MAAA3zD,GAAAqK,KAAA9J,GACA,QAGA,UAWA,QAAA+yD,GAAAruB,GACA,MAAAA,aAAA3uB,OAAA2uB,EAAAh9B,OAAAg9B,EAAArmB,QACAqmB,EA7LA1lC,EAAAC,EAAAD,QAAA2zD,EAAAnmC,MAAAmmC,EAAAW,QAAAX,EACA3zD,EAAA+zD,SACA/zD,EAAAq0D,UACAr0D,EAAAyzD,SACAzzD,EAAAwZ,UACAxZ,EAAA6yD,SAAAvyD,EAAA,IAMAN,EAAAo0D,SACAp0D,EAAAm0D,SAQAn0D,EAAAwzD,aAMA,IAAAM,IT22bM,SAAU7zD,EAAQD,GUx3bxB,QAAAoe,KACAhe,KAAAm0D,QAAAn0D,KAAAm0D,YACAn0D,KAAAo0D,cAAAp0D,KAAAo0D,eAAAvwD,OAwQA,QAAA0G,GAAAlG,GACA,wBAAAA,GAGA,QAAAgwD,GAAAhwD,GACA,sBAAAA,GAGA,QAAAkE,GAAAlE,GACA,sBAAAA,IAAA,OAAAA,EAGA,QAAAiwD,GAAAjwD,GACA,gBAAAA,EAnRAxE,EAAAD,QAAAoe,EAGAA,iBAEAA,EAAAxc,UAAA2yD,QAAAtwD,OACAma,EAAAxc,UAAA4yD,cAAAvwD,OAIAma,EAAAu2C,oBAAA,GAIAv2C,EAAAxc,UAAAgzD,gBAAA,SAAApzD,GACA,IAAAizD,EAAAjzD,MAAA,GAAAo3C,MAAAp3C,GACA,KAAA0uD,WAAA,8BAEA,OADA9vD,MAAAo0D,cAAAhzD,EACApB,MAGAge,EAAAxc,UAAAkc,KAAA,SAAA7N,GACA,GAAA4kD,GAAAC,EAAA/gD,EAAAhR,EAAAtC,EAAAosD,CAMA,IAJAzsD,KAAAm0D,UACAn0D,KAAAm0D,YAGA,UAAAtkD,KACA7P,KAAAm0D,QAAAt3C,OACAtU,EAAAvI,KAAAm0D,QAAAt3C,SAAA7c,KAAAm0D,QAAAt3C,MAAAja,QAAA,CAEA,GADA6xD,EAAAroD,UAAA,GACAqoD,YAAA99C,OACA,KAAA89C,EAGA,IAAA37C,GAAA,GAAAnC,OAAA,yCAAA89C,EAAA,IAEA,MADA37C,GAAAxC,QAAAm+C,EACA37C,EAOA,GAFA47C,EAAA10D,KAAAm0D,QAAAtkD,GAEAykD,EAAAI,GACA,QAEA,IAAAnqD,EAAAmqD,GACA,OAAAtoD,UAAAxJ,QAEA,OACA8xD,EAAAn0D,KAAAP,KACA,MACA,QACA00D,EAAAn0D,KAAAP,KAAAoM,UAAA,GACA,MACA,QACAsoD,EAAAn0D,KAAAP,KAAAoM,UAAA,GAAAA,UAAA,GACA,MAEA,SACAzJ,EAAAc,MAAAjC,UAAA+K,MAAAhM,KAAA6L,UAAA,GACAsoD,EAAAlyD,MAAAxC,KAAA2C,OAEG,IAAA4F,EAAAmsD,GAIH,IAHA/xD,EAAAc,MAAAjC,UAAA+K,MAAAhM,KAAA6L,UAAA,GACAqgD,EAAAiI,EAAAnoD,QACAoH,EAAA84C,EAAA7pD,OACAvC,EAAA,EAAeA,EAAAsT,EAAStT,IACxBosD,EAAApsD,GAAAmC,MAAAxC,KAAA2C,EAGA,WAGAqb,EAAAxc,UAAAgc,YAAA,SAAA3N,EAAA28C,GACA,GAAAhsD,EAEA,KAAA+J,EAAAiiD,GACA,KAAAsD,WAAA,8BA2CA,OAzCA9vD,MAAAm0D,UACAn0D,KAAAm0D,YAIAn0D,KAAAm0D,QAAAQ,aACA30D,KAAA0d,KAAA,cAAA7N,EACAtF,EAAAiiD,YACAA,cAEAxsD,KAAAm0D,QAAAtkD,GAGAtH,EAAAvI,KAAAm0D,QAAAtkD,IAEA7P,KAAAm0D,QAAAtkD,GAAA9J,KAAAymD,GAGAxsD,KAAAm0D,QAAAtkD,IAAA7P,KAAAm0D,QAAAtkD,GAAA28C,GANAxsD,KAAAm0D,QAAAtkD,GAAA28C,EASAjkD,EAAAvI,KAAAm0D,QAAAtkD,MAAA7P,KAAAm0D,QAAAtkD,GAAA+kD,SAIAp0D,EAHA8zD,EAAAt0D,KAAAo0D,eAGAp2C,EAAAu2C,oBAFAv0D,KAAAo0D,cAKA5zD,KAAA,GAAAR,KAAAm0D,QAAAtkD,GAAAjN,OAAApC,IACAR,KAAAm0D,QAAAtkD,GAAA+kD,QAAA,EACAx2C,QAAAvB,MAAA,mIAGA7c,KAAAm0D,QAAAtkD,GAAAjN,QACA,kBAAAwb,SAAAy2C,OAEAz2C,QAAAy2C,UAKA70D,MAGAge,EAAAxc,UAAAinB,GAAAzK,EAAAxc,UAAAgc,YAEAQ,EAAAxc,UAAA2W,KAAA,SAAAtI,EAAA28C,GAMA,QAAA5qD,KACA5B,KAAAwoB,eAAA3Y,EAAAjO,GAEAkzD,IACAA,GAAA,EACAtI,EAAAhqD,MAAAxC,KAAAoM,YAVA,IAAA7B,EAAAiiD,GACA,KAAAsD,WAAA,8BAEA,IAAAgF,IAAA,CAcA,OAHAlzD,GAAA4qD,WACAxsD,KAAAyoB,GAAA5Y,EAAAjO,GAEA5B,MAIAge,EAAAxc,UAAAgnB,eAAA,SAAA3Y,EAAA28C,GACA,GAAAuI,GAAAC,EAAApyD,EAAAvC,CAEA,KAAAkK,EAAAiiD,GACA,KAAAsD,WAAA,8BAEA,KAAA9vD,KAAAm0D,UAAAn0D,KAAAm0D,QAAAtkD,GACA,MAAA7P,KAMA,IAJA+0D,EAAA/0D,KAAAm0D,QAAAtkD,GACAjN,EAAAmyD,EAAAnyD,OACAoyD,GAAA,EAEAD,IAAAvI,GACAjiD,EAAAwqD,EAAAvI,WAAAuI,EAAAvI,mBACAxsD,MAAAm0D,QAAAtkD,GACA7P,KAAAm0D,QAAA3rC,gBACAxoB,KAAA0d,KAAA,iBAAA7N,EAAA28C,OAEG,IAAAjkD,EAAAwsD,GAAA,CACH,IAAA10D,EAAAuC,EAAoBvC,KAAA,GACpB,GAAA00D,EAAA10D,KAAAmsD,GACAuI,EAAA10D,GAAAmsD,UAAAuI,EAAA10D,GAAAmsD,aAAA,CACAwI,EAAA30D,CACA,OAIA,GAAA20D,EAAA,EACA,MAAAh1D,KAEA,KAAA+0D,EAAAnyD,QACAmyD,EAAAnyD,OAAA,QACA5C,MAAAm0D,QAAAtkD,IAEAklD,EAAApvD,OAAAqvD,EAAA,GAGAh1D,KAAAm0D,QAAA3rC,gBACAxoB,KAAA0d,KAAA,iBAAA7N,EAAA28C,GAGA,MAAAxsD,OAGAge,EAAAxc,UAAA+mB,mBAAA,SAAA1Y,GACA,GAAAjM,GAAA6oD,CAEA,KAAAzsD,KAAAm0D,QACA,MAAAn0D,KAGA,KAAAA,KAAAm0D,QAAA3rC,eAKA,MAJA,KAAApc,UAAAxJ,OACA5C,KAAAm0D,WACAn0D,KAAAm0D,QAAAtkD,UACA7P,MAAAm0D,QAAAtkD,GACA7P,IAIA,QAAAoM,UAAAxJ,OAAA,CACA,IAAAgB,IAAA5D,MAAAm0D,QACA,mBAAAvwD,GACA5D,KAAAuoB,mBAAA3kB,EAIA,OAFA5D,MAAAuoB,mBAAA,kBACAvoB,KAAAm0D,WACAn0D,KAKA,GAFAysD,EAAAzsD,KAAAm0D,QAAAtkD,GAEAtF,EAAAkiD,GACAzsD,KAAAwoB,eAAA3Y,EAAA48C,OACG,IAAAA,EAEH,KAAAA,EAAA7pD,QACA5C,KAAAwoB,eAAA3Y,EAAA48C,IAAA7pD,OAAA,GAIA,cAFA5C,MAAAm0D,QAAAtkD,GAEA7P,MAGAge,EAAAxc,UAAAirD,UAAA,SAAA58C,GACA,GAAAi0B,EAOA,OAHAA,GAHA9jC,KAAAm0D,SAAAn0D,KAAAm0D,QAAAtkD,GAEAtF,EAAAvK,KAAAm0D,QAAAtkD,KACA7P,KAAAm0D,QAAAtkD,IAEA7P,KAAAm0D,QAAAtkD,GAAAtD,YAIAyR,EAAAxc,UAAAqf,cAAA,SAAAhR,GACA,GAAA7P,KAAAm0D,QAAA,CACA,GAAAc,GAAAj1D,KAAAm0D,QAAAtkD,EAEA,IAAAtF,EAAA0qD,GACA,QACA,IAAAA,EACA,MAAAA,GAAAryD,OAEA,UAGAob,EAAA6C,cAAA,SAAAq0C,EAAArlD,GACA,MAAAqlD,GAAAr0C,cAAAhR,KVq6bM,SAAUhQ,EAAQD,GWjscxB,kBAAAmB,QAAAoR,OAEAtS,EAAAD,QAAA,SAAAu1D,EAAAC,GACAD,EAAAE,OAAAD,EACAD,EAAA3zD,UAAAT,OAAAoR,OAAAijD,EAAA5zD,WACAgL,aACA9L,MAAAy0D,EACAj0D,YAAA,EACA0U,UAAA,EACA3U,cAAA,MAMApB,EAAAD,QAAA,SAAAu1D,EAAAC,GACAD,EAAAE,OAAAD,CACA,IAAAE,GAAA,YACAA,GAAA9zD,UAAA4zD,EAAA5zD,UACA2zD,EAAA3zD,UAAA,GAAA8zD,GACAH,EAAA3zD,UAAAgL,YAAA2oD,IX0scM,SAAUt1D,EAAQD,EAASM,GAEjC,YY5tcA,SAAAq1D,MAUA,QAAA7iD,GAAA8iD,GACA,qBAAAA,GACA,SAAA1F,WAAA,8BAEA9vD,MAAA6W,MAAA4+C,EACAz1D,KAAA4T,SACA5T,KAAA01D,QAAA,OACAF,IAAAD,GACAI,EAAA31D,KAAAw1D,GAsBA,QAAAI,GAAAp9C,EAAAq9C,EAAAC,GACA91D,KAAAwY,UACA,kBAAAq9C,KACA71D,KAAA61D,cACA71D,KAAA+1D,cAAA/1D,KAAAg2D,oBAEA,kBAAAF,KACA91D,KAAA81D,aACA91D,KAAAi2D,aAAAj2D,KAAAk2D,mBAgBA,QAAAC,GAAA39C,EAAA/V,EAAA/B,GACAmT,EAAA,WACA,GAAA8xC,EACA,KACAA,EAAAljD,EAAA/B,GACK,MAAAqB,GACL,MAAAq0D,GAAAz9C,OAAAH,EAAAzW,GAEA4jD,IAAAntC,EACA49C,EAAAz9C,OAAAH,EAAA,GAAAs3C,WAAA,uCAEAsG,EAAA/iD,QAAAmF,EAAAmtC,KAoCA,QAAA0Q,GAAA1gD,GAEA,GAAAqD,GAAArD,KAAAqD,IACA,IAAArD,GAAA,gBAAAA,IAAA,kBAAAqD,GACA,kBACAA,EAAAxW,MAAAmT,EAAAvJ,YAKA,QAAAupD,GAAA5kD,EAAAulD,GAGA,QAAAlkB,GAAA1xC,GACAyT,IAGAA,GAAA,EACAiiD,EAAAz9C,OAAA5H,EAAArQ,IAGA,QAAAs9B,GAAAt9B,GACAyT,IAGAA,GAAA,EACAiiD,EAAA/iD,QAAAtC,EAAArQ,IAGA,QAAA61D,KACAD,EAAAt4B,EAAAoU,GAlBA,GAAAj+B,IAAA,EAqBA3Q,EAAAgzD,EAAAD,EACA,WAAA/yD,EAAAqb,QACAuzB,EAAA5uC,EAAA9C,OAIA,QAAA81D,GAAA/zD,EAAA/B,GACA,GAAAiiB,KACA,KACAA,EAAAjiB,MAAA+B,EAAA/B,GACAiiB,EAAA9D,OAAA,UACG,MAAA9c,GACH4gB,EAAA9D,OAAA,QACA8D,EAAAjiB,MAAAqB,EAEA,MAAA4gB,GAIA,QAAAtP,GAAA3S,GACA,MAAAA,aAAAV,MACAU,EAEA01D,EAAA/iD,QAAA,GAAArT,MAAAu1D,GAAA70D,GAIA,QAAAiY,GAAAqG,GACA,GAAAxG,GAAA,GAAAxY,MAAAu1D,EACA,OAAAa,GAAAz9C,OAAAH,EAAAwG,GAIA,QAAA6L,GAAA4rC,GAqBA,QAAAC,GAAAh2D,EAAAL,GAOA,QAAAs2D,GAAAC,GACA1zD,EAAA7C,GAAAu2D,IACAC,IAAAljD,GAAAQ,IACAA,GAAA,EACAiiD,EAAA/iD,QAAAmF,EAAAtV,IAVA6N,EAAAsC,QAAA3S,GAAAsY,KAAA29C,EAAA,SAAA95C,GACA1I,IACAA,GAAA,EACAiiD,EAAAz9C,OAAAH,EAAAqE,MAxBA,GAAA9L,GAAA/Q,IACA,uBAAAe,OAAAS,UAAAuC,SAAAxD,KAAAk2D,GACA,MAAAz2D,MAAA2Y,OAAA,GAAAm3C,WAAA,oBAGA,IAAAn8C,GAAA8iD,EAAA7zD,OACAuR,GAAA,CACA,KAAAR,EACA,MAAA3T,MAAAqT,WAQA,KALA,GAAAnQ,GAAA,GAAAO,OAAAkQ,GACAkjD,EAAA,EACAx2D,GAAA,EACAmY,EAAA,GAAAxY,MAAAu1D,KAEAl1D,EAAAsT,GACA+iD,EAAAD,EAAAp2D,KAEA,OAAAmY,GAmBA,QAAAs+C,GAAAL,GAmBA,QAAAjB,GAAA90D,GACAqQ,EAAAsC,QAAA3S,GAAAsY,KAAA,SAAA41B,GACAz6B,IACAA,GAAA,EACAiiD,EAAA/iD,QAAAmF,EAAAo2B,KAEK,SAAA/xB,GACL1I,IACAA,GAAA,EACAiiD,EAAAz9C,OAAAH,EAAAqE,MA3BA,GAAA9L,GAAA/Q,IACA,uBAAAe,OAAAS,UAAAuC,SAAAxD,KAAAk2D,GACA,MAAAz2D,MAAA2Y,OAAA,GAAAm3C,WAAA,oBAGA,IAAAn8C,GAAA8iD,EAAA7zD,OACAuR,GAAA,CACA,KAAAR,EACA,MAAA3T,MAAAqT,WAMA,KAHA,GAAAhT,IAAA,EACAmY,EAAA,GAAAxY,MAAAu1D,KAEAl1D,EAAAsT,GACA6hD,EAAAiB,EAAAp2D,GAEA,OAAAmY,GA7OA,GAAA3E,GAAA3T,EAAA,GAKAk2D,KAEAW,GAAA,YACAC,GAAA,aACAvB,GAAA,UAEA51D,GAAAD,QAAA8S,EAcAA,EAAAlR,UAAA,eAAAs0D,GACA,MAAA91D,MAAAgZ,KAAA,KAAA88C,IAEApjD,EAAAlR,UAAAwX,KAAA,SAAA68C,EAAAC,GACA,qBAAAD,IAAA71D,KAAA6W,QAAAmgD,GACA,kBAAAlB,IAAA91D,KAAA6W,QAAAkgD,EACA,MAAA/2D,KAEA,IAAAwY,GAAA,GAAAxY,MAAAwM,YAAA+oD,EACA,IAAAv1D,KAAA6W,QAAA4+C,EAAA,CACA,GAAAD,GAAAx1D,KAAA6W,QAAAmgD,EAAAnB,EAAAC,CACAK,GAAA39C,EAAAg9C,EAAAx1D,KAAA01D,aAEA11D,MAAA4T,MAAA7N,KAAA,GAAA6vD,GAAAp9C,EAAAq9C,EAAAC,GAGA,OAAAt9C,IAaAo9C,EAAAp0D,UAAAu0D,cAAA,SAAAr1D,GACA01D,EAAA/iD,QAAArT,KAAAwY,QAAA9X,IAEAk1D,EAAAp0D,UAAAw0D,mBAAA,SAAAt1D,GACAy1D,EAAAn2D,KAAAwY,QAAAxY,KAAA61D,YAAAn1D,IAEAk1D,EAAAp0D,UAAAy0D,aAAA,SAAAv1D,GACA01D,EAAAz9C,OAAA3Y,KAAAwY,QAAA9X,IAEAk1D,EAAAp0D,UAAA00D,kBAAA,SAAAx1D,GACAy1D,EAAAn2D,KAAAwY,QAAAxY,KAAA81D,WAAAp1D,IAmBA01D,EAAA/iD,QAAA,SAAAtC,EAAArQ,GACA,GAAA8C,GAAAgzD,EAAAH,EAAA31D,EACA,cAAA8C,EAAAqb,OACA,MAAAu3C,GAAAz9C,OAAA5H,EAAAvN,EAAA9C,MAEA,IAAA41D,GAAA9yD,EAAA9C,KAEA,IAAA41D,EACAX,EAAA5kD,EAAAulD,OACG,CACHvlD,EAAA8F,MAAAmgD,EACAjmD,EAAA2kD,QAAAh1D,CAGA,KAFA,GAAAL,IAAA,EACAsT,EAAA5C,EAAA6C,MAAAhR,SACAvC,EAAAsT,GACA5C,EAAA6C,MAAAvT,GAAA01D,cAAAr1D,GAGA,MAAAqQ,IAEAqlD,EAAAz9C,OAAA,SAAA5H,EAAA8L,GACA9L,EAAA8F,MAAAkgD,EACAhmD,EAAA2kD,QAAA74C,CAGA,KAFA,GAAAxc,IAAA,EACAsT,EAAA5C,EAAA6C,MAAAhR,SACAvC,EAAAsT,GACA5C,EAAA6C,MAAAvT,GAAA41D,aAAAp5C,EAEA,OAAA9L,IAsDA2B,EAAAW,UAQAX,EAAAiG,SAMAjG,EAAAmY,MAuCAnY,EAAAokD,QZuwcM,SAAUj3D,EAAQD,Gar7cxB,QAAA81B,GAAA5W,GAEA,GADAA,EAAAvX,OAAAuX,KACAA,EAAAlc,OAAA,MAGA,GAAAkpB,GAAA,wHAAAxe,KAAAwR,EACA,IAAAgN,EAAA,CAGA,GAAA1qB,GAAAs4C,WAAA5tB,EAAA,IACAjc,GAAAic,EAAA,UAAAyC,aACA,QAAA1e,GACA,YACA,WACA,UACA,SACA,QACA,MAAAzO,GAAAu8C,CACA,YACA,UACA,QACA,MAAAv8C,GAAAT,CACA,aACA,WACA,UACA,SACA,QACA,MAAAS,GAAA61D,CACA,eACA,aACA,WACA,UACA,QACA,MAAA71D,GAAAZ,CACA,eACA,aACA,WACA,UACA,QACA,MAAAY,GAAAO,CACA,oBACA,kBACA,YACA,WACA,SACA,MAAAP,EACA,SACA,UAYA,QAAA81D,GAAAzD,GACA,MAAAA,IAAA9yD,EACA4R,KAAA4kD,MAAA1D,EAAA9yD,GAAA,IAEA8yD,GAAAwD,EACA1kD,KAAA4kD,MAAA1D,EAAAwD,GAAA,IAEAxD,GAAAjzD,EACA+R,KAAA4kD,MAAA1D,EAAAjzD,GAAA,IAEAizD,GAAA9xD,EACA4Q,KAAA4kD,MAAA1D,EAAA9xD,GAAA,IAEA8xD,EAAA,KAWA,QAAA2D,GAAA3D,GACA,MAAA4D,GAAA5D,EAAA9yD,EAAA,QACA02D,EAAA5D,EAAAwD,EAAA,SACAI,EAAA5D,EAAAjzD,EAAA,WACA62D,EAAA5D,EAAA9xD,EAAA,WACA8xD,EAAA,MAOA,QAAA4D,GAAA5D,EAAAryD,EAAAR,GACA,KAAA6yD,EAAAryD,GAGA,MAAAqyD,GAAA,IAAAryD,EACAmR,KAAA40C,MAAAsM,EAAAryD,GAAA,IAAAR,EAEA2R,KAAA6f,KAAAqhC,EAAAryD,GAAA,IAAAR,EAAA,IA/IA,GAAAe,GAAA,IACAnB,EAAA,GAAAmB,EACAs1D,EAAA,GAAAz2D,EACAG,EAAA,GAAAs2D,EACAtZ,EAAA,OAAAh9C,CAgBAd,GAAAD,QAAA,SAAA0lC,EAAAwJ,GACAA,OACA,IAAAj/B,SAAAy1B,EACA,eAAAz1B,GAAAy1B,EAAA1iC,OAAA,EACA,MAAA8yB,GAAA4P,EACG,eAAAz1B,GAAA2oC,MAAAlT,MAAA,EACH,MAAAwJ,GAAAwoB,KACAF,EAAA9xB,GACA4xB,EAAA5xB,EAEA,UAAA3uB,OAAA,wDAAA8e,KAAAK,UAAAwP,Mb2ldM,SAAUzlC,EAAQD,GclndxB,QAAA23D,KACA,SAAA5gD,OAAA,mCAEA,QAAA6gD,KACA,SAAA7gD,OAAA,qCAsBA,QAAA8gD,GAAAr/C,GACA,GAAAs/C,IAAAviD,WAEA,MAAAA,YAAAiD,EAAA,EAGA,KAAAs/C,IAAAH,IAAAG,IAAAviD,WAEA,MADAuiD,GAAAviD,WACAA,WAAAiD,EAAA,EAEA,KAEA,MAAAs/C,GAAAt/C,EAAA,GACK,MAAArW,GACL,IAEA,MAAA21D,GAAAn3D,KAAA,KAAA6X,EAAA,GACS,MAAArW,GAET,MAAA21D,GAAAn3D,KAAAP,KAAAoY,EAAA,KAMA,QAAAu/C,GAAAC,GACA,GAAAC,IAAApoB,aAEA,MAAAA,cAAAmoB,EAGA,KAAAC,IAAAL,IAAAK,IAAApoB,aAEA,MADAooB,GAAApoB,aACAA,aAAAmoB,EAEA,KAEA,MAAAC,GAAAD,GACK,MAAA71D,GACL,IAEA,MAAA81D,GAAAt3D,KAAA,KAAAq3D,GACS,MAAA71D,GAGT,MAAA81D,GAAAt3D,KAAAP,KAAA43D,KAYA,QAAAE,KACArkD,GAAAskD,IAGAtkD,GAAA,EACAskD,EAAAn1D,OACAgR,EAAAmkD,EAAAt+C,OAAA7F,GAEAokD,GAAA,EAEApkD,EAAAhR,QACAq1D,KAIA,QAAAA,KACA,IAAAxkD,EAAA,CAGA,GAAA67B,GAAAmoB,EAAAK,EACArkD,IAAA,CAGA,KADA,GAAAE,GAAAC,EAAAhR,OACA+Q,GAAA,CAGA,IAFAokD,EAAAnkD,EACAA,OACAokD,EAAArkD,GACAokD,GACAA,EAAAC,GAAAE,KAGAF,IAAA,EACArkD,EAAAC,EAAAhR,OAEAm1D,EAAA,KACAtkD,GAAA,EACAkkD,EAAAroB,IAiBA,QAAA6oB,GAAA//C,EAAAtV,GACA9C,KAAAoY,MACApY,KAAA8C,QAYA,QAAAmT,MAhKA,GAOAyhD,GACAG,EARAxmD,EAAAxR,EAAAD,YAgBA,WACA,IAEA83D,EADA,kBAAAviD,YACAA,WAEAoiD,EAEK,MAAAx1D,GACL21D,EAAAH,EAEA,IAEAM,EADA,kBAAApoB,cACAA,aAEA+nB,EAEK,MAAAz1D,GACL81D,EAAAL,KAuDA,IAEAO,GAFAnkD,KACAH,GAAA,EAEAukD,GAAA,CAyCA3mD,GAAAmC,SAAA,SAAA4E,GACA,GAAAzV,GAAA,GAAAc,OAAA2I,UAAAxJ,OAAA,EACA,IAAAwJ,UAAAxJ,OAAA,EACA,OAAAvC,GAAA,EAAuBA,EAAA+L,UAAAxJ,OAAsBvC,IAC7CsC,EAAAtC,EAAA,GAAA+L,UAAA/L,EAGAuT,GAAA7N,KAAA,GAAAoyD,GAAA//C,EAAAzV,IACA,IAAAiR,EAAAhR,QAAA6Q,GACAgkD,EAAAQ,IASAE,EAAA32D,UAAA02D,IAAA,WACAl4D,KAAAoY,IAAA5V,MAAA,KAAAxC,KAAA8C,QAEAuO,EAAA+mD,MAAA,UACA/mD,EAAAgnD,SAAA,EACAhnD,EAAAinD,OACAjnD,EAAAknD,QACAlnD,EAAAk0B,QAAA,GACAl0B,EAAAmnD,YAIAnnD,EAAAoX,GAAAxS,EACA5E,EAAAmM,YAAAvH,EACA5E,EAAA8G,KAAAlC,EACA5E,EAAAonD,IAAAxiD,EACA5E,EAAAmX,eAAAvS,EACA5E,EAAAkX,mBAAAtS,EACA5E,EAAAqM,KAAAzH,EAEA5E,EAAAE,QAAA,SAAA3Q,GACA,SAAA+V,OAAA,qCAGAtF,EAAAqnD,IAAA,WAA2B,WAC3BrnD,EAAAsnD,MAAA,SAAAC,GACA,SAAAjiD,OAAA,mCAEAtF,EAAAwnD,MAAA,WAA4B,WdoodtB,SAAUh5D,EAAQD,IetzdxB,WACA,GAAAk5D,MAAkBr3D,eAClB8K,UAEA1M,GAAAD,QAAA,SAAAmI,EAAAgxD,GACA,GAAAn1D,GAAAqE,EAAAvH,EAAAwC,CACA+E,MACA/E,IACA,KAAAU,IAAAm1D,GACAD,EAAAv4D,KAAAw4D,EAAAn1D,KACAlD,EAAAq4D,EAAAn1D,GACA,SAAAA,IAGAqE,EAAAlC,KAAAnC,GACAV,EAAA6C,KAAArF,IAEA,OAAAmB,UAAAW,MAAA,KAAA+J,EAAAhM,KAAA0H,GAAAwR,QAAA1R,KAAAvF,MAAAu2D,EAAA,KAAA71D,MAGC3C,KAAAP,Of8zdK,SAAUH,EAAQD,IgB10dxB,WAEA,YAKA,SAAA2K,GAAA7J,GACA,wBAAAA,GAMA,QAAA2G,GAAA3G,GACA,yBAAAK,OAAAS,UAAAuC,SAAAxD,KAAAG,GAMA,QAAAs4D,GAAAt4D,GACA,MAAAA,aAAAuX,MACAvX,EAAAu4D,UACKv4D,YAAA+C,OACL/C,EAAAyB,IAAA62D,GAEAt4D,EAIA,QAAAS,GAAAwU,EAAA/R,GACA,MAAA+R,GAAAxU,IAAAwU,EAAAxU,IAAAyC,GACA+R,EAAA/R,GAMA,QAAAs1D,GAAAC,GACA,gBAAAr1C,EAAAC,GACA,IAAA1c,EAAA0c,OAAAnhB,OAAA,MAAAu2D,GAAAr1C,EAAAC,EACA,QAAA1jB,GAAA,EAAAe,EAAA2iB,EAAAnhB,OAAmCvC,EAAAe,EAAOf,IAAA,GAAA84D,EAAAr1C,EAAA3iB,EAAA4iB,EAAA1jB,IAAA,QAC1C,WAOA,QAAA+4D,GAAAD,GACA,gBAAAr1C,EAAAC,GACA,IAAA1c,EAAA0c,OAAAnhB,OAAA,MAAAu2D,GAAAr1C,EAAAC,EACA,QAAA1jB,GAAA,EAAAe,EAAA2iB,EAAAnhB,OAAmCvC,EAAAe,EAAOf,IAAA,IAAA84D,EAAAr1C,EAAA3iB,EAAA4iB,EAAA1jB,IAAA,QAC1C,WAIA,QAAAg5D,GAAAF,EAAAp1C,GACA,MAAAo1C,GAAAhoB,EAAAgoB,EAAAr1C,EAAAC,GA4QA,QAAAu1C,GAAAx2D,EAAAq2D,GAEA,OAAA94D,GAAA,EAAmBA,EAAAyC,EAAAF,OAAkBvC,IACrC,GAAAg5D,EAAAF,EAAAh4D,EAAA2B,EAAAzC,IACA,MAAAA,EAIA,UAMA,QAAAk5D,GAAAz1C,EAAAu1C,GACA,OAAYv1C,IAAAqtB,EAAAkoB,GAMZ,QAAAG,GAAA11C,EAAAC,GACA,GAAA7gB,KAGA,OAFAu2D,GAAA11C,EAAAD,EAAA2vB,EAAA,EAAAvwC,GAEA,IAAAA,EAAAN,OACAy2D,EAAAv1C,EAAA41C,GAAAx2D,EAAA,OAGAo2D,EAAAp2D,EAAA4gB,EAAA41C,IAMA,QAAAD,GAAAtnB,EAAAwnB,EAAA32D,EAAAE,GAEA,GAAAF,IAAA22D,EAAA/2D,QAAA,QAAAuvC,EAEA,WADAjvC,GAAA6C,KAAAosC,EAIA,IAAAsB,GAAAtyC,EAAAw4D,EAAA32D,EAKA,IAAAqE,EAAA8qC,IAAAqG,MAAA+F,OAAA9K,IACA,OAAApzC,GAAA,EAAAe,EAAA+wC,EAAAvvC,OAAyCvC,EAAAe,EAAOf,IAChDo5D,EAAAt4D,EAAAgxC,EAAA9xC,GAAAs5D,EAAA32D,EAAAE,OAGAu2D,GAAAt4D,EAAAgxC,EAAAsB,GAAAkmB,EAAA32D,EAAA,EAAAE,GAOA,QAAA02D,GAAAD,EAAA71C,GACA,OAAYA,GAAK2vB,EAAAkmB,EAAAD,GAAA51C,GAAoBqtB,EAAAqoB,GAOrC,QAAA9jC,GAAA7V,GACAA,EAAAm5C,EAAAn5C,KAEAA,GAAA,WAAAA,EAAArT,YAAAzI,YACA,mCAAA8b,EAAArT,YAAAzI,WAAAgO,QAAA,UAAAA,QAAA,YACA8N,GAAeg6C,IAAAh6C,GAGf,IAAAi6C,KAEA,QAAAl2D,KAAAic,GAAA,CACA,GAAAiE,GAAAjE,EAAAjc,EAEA,iBAAAA,EAEA,GAAAm2D,EAAAn2D,GACAo2D,EAAAp2D,KAAAkgB,EAAAk2C,EAAAp2D,GAAAkgB,EAAAjE,IACAi6C,EAAA/zD,KAAAwzD,EAAAP,EAAAl1C,GAAAi2C,EAAAn2D,SACO,CAEP,QAAAA,EAAA8rB,WAAA,GACA,SAAA/Y,OAAA,qBAAA/S,EAGAk2D,GAAA/zD,KAAA6zD,EAAAh2D,EAAAqd,MAAA,KAAAyU,EAAA5R,MAIA,WAAAg2C,EAAAl3D,OAAAk3D,EAAA,GAAAP,EAAAO,EAAAC,EAAAE,MAMA,QAAAC,GAAAr6C,EAAAhf,GACA,GAAAs4D,GAAAzjC,EAAA7V,EASA,OARAhf,KACAs4D,GACAr1C,EAAAq1C,EACAhoB,EAAA,SAAArtB,EAAAC,GACA,MAAAs1C,GAAAv1C,EAAAjjB,EAAAkjB,OAIAo1C,EAMA,QAAAgB,GAAAt6C,EAAA/c,EAAAjC,GASA,QAAAiW,GAAAiN,GACA,MAAAs1C,GAAAF,EAAAp1C,GARAxZ,EAAAzH,KACAjC,EAAAiC,EACAA,EAAA,OAGA,IAAAq2D,GAAAe,EAAAr6C,EAAAhf,EAMA,OAAAiC,GACAA,EAAAgU,UAGAA,EA/YA,GAAAijD,IAKAF,IAAAX,EAAA,SAAAp1C,EAAAC,GACA,MAAAD,GAAAC,KAMAq2C,IAAAhB,EAAA,SAAAt1C,EAAAC,GACA,OAAAD,EAAAC,KAMAs2C,IAAA,SAAAv2C,EAAAC,GACA,OAAA1jB,GAAA,EAAAe,EAAA0iB,EAAAlhB,OAAmCvC,EAAAe,EAAOf,IAAA,GAAAg5D,EAAAl4D,EAAA2iB,EAAAzjB,GAAA0jB,GAAA,QAC1C,WAMAu2C,IAAApB,EAAA,SAAAp1C,EAAAC,GACA,MAAAo2C,GAAAhxC,QAAA6vC,EAAAj1C,GAAAD,GAAA,IAMAy2C,KAAArB,EAAA,SAAAp1C,EAAAC,GACA,MAAAo2C,GAAAhxC,QAAA6vC,EAAAj1C,GAAAD,IAAA,IAMA02C,IAAAtB,EAAA,SAAAp1C,EAAAC,GACA,MAAAo2C,GAAAhxC,QAAA6vC,EAAAj1C,GAAAD,GAAA,IAMA22C,KAAAvB,EAAA,SAAAp1C,EAAAC,GACA,MAAAo2C,GAAAhxC,QAAA6vC,EAAAj1C,GAAAD,IAAA,IAMA42C,KAAAxB,EAAA,SAAAp1C,EAAAC,GACA,MAAAA,GAAAD,EAAA,IAAAA,EAAA,KAMA62C,IAAA,SAAA72C,EAAAC,GAEA,KAAAA,YAAAtgB,QAKA,SAAAqgB,EAAArC,QAAAu3C,EAAAj1C,GAJA,QAAA1jB,GAAA0jB,EAAAnhB,OAA8BvC,KAC9B,IAAAyjB,EAAArC,QAAAu3C,EAAA73D,EAAA4iB,EAAA1jB,KAAA,QAMA,WAMAu6D,KAAA,SAAA92C,EAAAC,GACA,OAAAg2C,EAAAY,IAAA72C,EAAAC,IAMA82C,KAAA,SAAA/2C,EAAAC,GACA,OAAAs1C,EAAAv1C,EAAAC,IAMA+2C,MAAA,SAAAh3C,EAAAC,GACA,eAAAA,gBAAAD,IAAAC,EAAAvX,aAAAsX,IAMAi3C,KAAA,SAAAj3C,EAAAC,GACA,MAAAg2C,GAAAE,KAAAn2C,EAAAC,IAMAi3C,MAAA,SAAAl3C,EAAAC,GACA,QAAAA,GAAAD,IAAAC,EAAAnhB,QAMAq4D,KAAA,SAAAn3C,EAAAC,GAEA,OAAA1jB,GAAA,EAAAe,EAAA0iB,EAAAlhB,OAAmCvC,EAAAe,EAAOf,IAAA,GAAAg5D,EAAAl4D,EAAA2iB,EAAAzjB,GAAA0jB,GAAA,QAC1C,WAMAk2C,KAAA,SAAAn2C,EAAAC,GACAA,SACA,QAAA1jB,GAAA,EAAAe,EAAA0iB,EAAAlhB,OAAmCvC,EAAAe,EAAOf,IAAA,IAAAg5D,EAAAl4D,EAAA2iB,EAAAzjB,GAAA0jB,GAAA,QAC1C,WAMAm3C,OAAAhC,EAAA,SAAAp1C,EAAAC,GACA,sBAAAA,IAAAD,EAAApZ,KAAAqZ,KAMAo3C,OAAA,SAAAr3C,EAAAC,GACA,MAAAD,GAAAvjB,KAAAwjB,MAMAq3C,WAAA,SAAAt3C,EAAAC,GACA,MAAA1c,GAAA0c,MAAAu1C,EAAAv1C,EAAAD,GACAu1C,EAAAv1C,EAAAC,IAMAs3C,QAAA,SAAAv3C,EAAAC,GACA,eAAAA,IAAAD,IAOAk2C,GAKAH,IAAA,SAAA/1C,GAEA,MAAAA,aAAAhS,QACA,SAAAiS,GACA,sBAAAA,IAAAD,EAAApZ,KAAAqZ,IAEOD,YAAAjiB,UACPiiB,EACOzc,EAAAyc,OAAAlhB,OAEP,SAAAmhB,GACA,MAAA1c,GAAA0c,OAAAnhB,QAEO,OAAAkhB,EACP,SAAAC,GAEA,aAAAA,GAIA,SAAAA,GACA,WAAAo2C,EAAAhxC,QAAA6vC,EAAAj1C,GAAAD,KAOAs2C,IAAA,SAAAt2C,GACA,MAAAk2C,GAAAH,IAAA/1C,IAMAm2C,KAAA,SAAAn2C,GACA,MAAAA,GAAA3hB,IAAAuzB,IAMAqlC,KAAA,SAAAj3C,GACA,MAAAk2C,GAAAC,KAAAn2C,IAMAu2C,IAAA,SAAAv2C,GACA,MAAAA,GAAA3hB,IAAAuzB,IAMAulC,KAAA,SAAAn3C,GACA,MAAAA,GAAA3hB,IAAAuzB,IAMAmlC,KAAA,SAAA/2C,GACA,MAAA4R,GAAA5R,IAMAo3C,OAAA,SAAAp3C,EAAAjE,GACA,UAAA/N,QAAAgS,EAAAjE,EAAAy7C,WAMAH,OAAA,SAAAr3C,GACA,sBAAAA,GAAA,GAAAjiB,UAAA,gBAAAiiB,MAMAs3C,WAAA,SAAAt3C,GACA,MAAA4R,GAAA5R,IAMAu3C,QAAA,SAAAv3C,GACA,QAAAA,GAmJAq2C,GAAAoB,IAAA,SAAA7K,GACA,GAAAnmD,EAAAmmD,GAAA,MAAAA,GAAAyJ,EACA,QAAAv2D,KAAA8sD,GACA,KAAA9sD,EAAA8rB,WAAA,KAAAqqC,EAAAn2D,GAAA8sD,EAAA9sD,KAOAu2D,EAAA14C,QAAA,SAAA5B,EAAA/c,EAAAjC,GACA,MAAAy4D,GAAAx2D,EAAAo3D,EAAAr6C,EAAAhf,KAMAs5D,EAAAhxC,QAAA,SAAArF,EAAAC,GACA,GAAAD,IAAAC,EAAA,QACA,UAAAD,UAAAC,GAAA,CACA,GAAAD,EAAAC,EAAA,QACA,IAAAD,EAAAC,EAAA,WAKA,mBAAAlkB,IAAA,mBAAAA,GAAAD,UACAC,EAAAD,QAAAu6D,GAGA,mBAAAn4D,UACAA,OAAAm4D,YhB41dM,SAAUt6D,EAAQD,EAASM,IiBv1ejC,SAAAP,GAGAE,EAAAD,QAAAD,KAgBC,SAAAkE,GAED,YA0BA,SAAA23D,GAAA5gD,EAAA64B,GACA,GAAA3vB,GAAAlJ,EAAA,GACAmJ,EAAAnJ,EAAA,GACAna,EAAAma,EAAA,GACAja,EAAAia,EAAA,EAEAkJ,KAAAC,EAAAtjB,GAAAsjB,EAAApjB,GAAA8yC,EAAA,eACA3vB,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACApjB,IAAAmjB,EAAAC,GAAAD,EAAArjB,GAAAgzC,EAAA,eACA9yC,MAAA,GAAAA,IAAA,IAAAmjB,EAAA,EACArjB,IAAAE,EAAAmjB,GAAAnjB,EAAAojB,GAAA0vB,EAAA,eACAhzC,MAAA,GAAAA,IAAA,IAAAE,EAAA,EACAojB,IAAAtjB,EAAAE,GAAAF,EAAAqjB,GAAA2vB,EAAA,gBACA1vB,MAAA,GAAAA,IAAA,IAAAtjB,EAAA,EACAqjB,IAAAC,EAAAtjB,GAAAsjB,EAAApjB,GAAA8yC,EAAA,eACA3vB,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACApjB,IAAAmjB,EAAAC,GAAAD,EAAArjB,GAAAgzC,EAAA,gBACA9yC,MAAA,GAAAA,IAAA,IAAAmjB,EAAA,EACArjB,IAAAE,EAAAmjB,GAAAnjB,EAAAojB,GAAA0vB,EAAA,gBACAhzC,MAAA,GAAAA,IAAA,IAAAE,EAAA,EACAojB,IAAAtjB,EAAAE,GAAAF,EAAAqjB,GAAA2vB,EAAA,cACA1vB,MAAA,GAAAA,IAAA,IAAAtjB,EAAA,EACAqjB,IAAAC,EAAAtjB,GAAAsjB,EAAApjB,GAAA8yC,EAAA,gBACA3vB,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACApjB,IAAAmjB,EAAAC,GAAAD,EAAArjB,GAAAgzC,EAAA,gBACA9yC,MAAA,GAAAA,IAAA,IAAAmjB,EAAA,EACArjB,IAAAE,EAAAmjB,GAAAnjB,EAAAojB,GAAA0vB,EAAA,YACAhzC,MAAA,GAAAA,IAAA,IAAAE,EAAA,EACAojB,IAAAtjB,EAAAE,GAAAF,EAAAqjB,GAAA2vB,EAAA,iBACA1vB,MAAA,GAAAA,IAAA,IAAAtjB,EAAA,EACAqjB,IAAAC,EAAAtjB,GAAAsjB,EAAApjB,GAAA8yC,EAAA,iBACA3vB,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACApjB,IAAAmjB,EAAAC,GAAAD,EAAArjB,GAAAgzC,EAAA,eACA9yC,MAAA,GAAAA,IAAA,IAAAmjB,EAAA,EACArjB,IAAAE,EAAAmjB,GAAAnjB,EAAAojB,GAAA0vB,EAAA,iBACAhzC,MAAA,GAAAA,IAAA,IAAAE,EAAA,EACAojB,IAAAtjB,EAAAE,GAAAF,EAAAqjB,GAAA2vB,EAAA,iBACA1vB,MAAA,GAAAA,IAAA,IAAAtjB,EAAA,EAEAqjB,IAAAC,EAAApjB,EAAAF,GAAAE,GAAA8yC,EAAA,eACA3vB,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACApjB,IAAAmjB,EAAArjB,EAAAsjB,GAAAtjB,GAAAgzC,EAAA,gBACA9yC,MAAA,EAAAA,IAAA,IAAAmjB,EAAA,EACArjB,IAAAE,EAAAojB,EAAAD,GAAAC,GAAA0vB,EAAA,gBACAhzC,MAAA,GAAAA,IAAA,IAAAE,EAAA,EACAojB,IAAAtjB,EAAAqjB,EAAAnjB,GAAAmjB,GAAA2vB,EAAA,eACA1vB,MAAA,GAAAA,IAAA,IAAAtjB,EAAA,EACAqjB,IAAAC,EAAApjB,EAAAF,GAAAE,GAAA8yC,EAAA,eACA3vB,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACApjB,IAAAmjB,EAAArjB,EAAAsjB,GAAAtjB,GAAAgzC,EAAA,eACA9yC,MAAA,EAAAA,IAAA,IAAAmjB,EAAA,EACArjB,IAAAE,EAAAojB,EAAAD,GAAAC,GAAA0vB,EAAA,gBACAhzC,MAAA,GAAAA,IAAA,IAAAE,EAAA,EACAojB,IAAAtjB,EAAAqjB,EAAAnjB,GAAAmjB,GAAA2vB,EAAA,eACA1vB,MAAA,GAAAA,IAAA,IAAAtjB,EAAA,EACAqjB,IAAAC,EAAApjB,EAAAF,GAAAE,GAAA8yC,EAAA,eACA3vB,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACApjB,IAAAmjB,EAAArjB,EAAAsjB,GAAAtjB,GAAAgzC,EAAA,iBACA9yC,MAAA,EAAAA,IAAA,IAAAmjB,EAAA,EACArjB,IAAAE,EAAAojB,EAAAD,GAAAC,GAAA0vB,EAAA,eACAhzC,MAAA,GAAAA,IAAA,IAAAE,EAAA,EACAojB,IAAAtjB,EAAAqjB,EAAAnjB,GAAAmjB,GAAA2vB,EAAA,gBACA1vB,MAAA,GAAAA,IAAA,IAAAtjB,EAAA,EACAqjB,IAAAC,EAAApjB,EAAAF,GAAAE,GAAA8yC,EAAA,iBACA3vB,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACApjB,IAAAmjB,EAAArjB,EAAAsjB,GAAAtjB,GAAAgzC,EAAA,cACA9yC,MAAA,EAAAA,IAAA,IAAAmjB,EAAA,EACArjB,IAAAE,EAAAojB,EAAAD,GAAAC,GAAA0vB,EAAA,gBACAhzC,MAAA,GAAAA,IAAA,IAAAE,EAAA,EACAojB,IAAAtjB,EAAAqjB,EAAAnjB,GAAAmjB,GAAA2vB,EAAA,iBACA1vB,MAAA,GAAAA,IAAA,IAAAtjB,EAAA,EAEAqjB,IAAAC,EAAAtjB,EAAAE,GAAA8yC,EAAA,YACA3vB,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACApjB,IAAAmjB,EAAAC,EAAAtjB,GAAAgzC,EAAA,gBACA9yC,MAAA,GAAAA,IAAA,IAAAmjB,EAAA,EACArjB,IAAAE,EAAAmjB,EAAAC,GAAA0vB,EAAA,iBACAhzC,MAAA,GAAAA,IAAA,IAAAE,EAAA,EACAojB,IAAAtjB,EAAAE,EAAAmjB,GAAA2vB,EAAA,eACA1vB,MAAA,GAAAA,IAAA,GAAAtjB,EAAA,EACAqjB,IAAAC,EAAAtjB,EAAAE,GAAA8yC,EAAA,gBACA3vB,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACApjB,IAAAmjB,EAAAC,EAAAtjB,GAAAgzC,EAAA,gBACA9yC,MAAA,GAAAA,IAAA,IAAAmjB,EAAA,EACArjB,IAAAE,EAAAmjB,EAAAC,GAAA0vB,EAAA,eACAhzC,MAAA,GAAAA,IAAA,IAAAE,EAAA,EACAojB,IAAAtjB,EAAAE,EAAAmjB,GAAA2vB,EAAA,iBACA1vB,MAAA,GAAAA,IAAA,GAAAtjB,EAAA,EACAqjB,IAAAC,EAAAtjB,EAAAE,GAAA8yC,EAAA,gBACA3vB,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACApjB,IAAAmjB,EAAAC,EAAAtjB,GAAAgzC,EAAA,eACA9yC,MAAA,GAAAA,IAAA,IAAAmjB,EAAA,EACArjB,IAAAE,EAAAmjB,EAAAC,GAAA0vB,EAAA,eACAhzC,MAAA,GAAAA,IAAA,IAAAE,EAAA,EACAojB,IAAAtjB,EAAAE,EAAAmjB,GAAA2vB,EAAA,cACA1vB,MAAA,GAAAA,IAAA,GAAAtjB,EAAA,EACAqjB,IAAAC,EAAAtjB,EAAAE,GAAA8yC,EAAA,eACA3vB,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACApjB,IAAAmjB,EAAAC,EAAAtjB,GAAAgzC,EAAA,gBACA9yC,MAAA,GAAAA,IAAA,IAAAmjB,EAAA,EACArjB,IAAAE,EAAAmjB,EAAAC,GAAA0vB,EAAA,gBACAhzC,MAAA,GAAAA,IAAA,IAAAE,EAAA,EACAojB,IAAAtjB,EAAAE,EAAAmjB,GAAA2vB,EAAA,eACA1vB,MAAA,GAAAA,IAAA,GAAAtjB,EAAA,EAEAqjB,IAAArjB,GAAAsjB,GAAApjB,IAAA8yC,EAAA,eACA3vB,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACApjB,IAAAojB,GAAAD,GAAArjB,IAAAgzC,EAAA,gBACA9yC,MAAA,GAAAA,IAAA,IAAAmjB,EAAA,EACArjB,IAAAqjB,GAAAnjB,GAAAojB,IAAA0vB,EAAA,iBACAhzC,MAAA,GAAAA,IAAA,IAAAE,EAAA,EACAojB,IAAApjB,GAAAF,GAAAqjB,IAAA2vB,EAAA,cACA1vB,MAAA,GAAAA,IAAA,IAAAtjB,EAAA,EACAqjB,IAAArjB,GAAAsjB,GAAApjB,IAAA8yC,EAAA,iBACA3vB,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACApjB,IAAAojB,GAAAD,GAAArjB,IAAAgzC,EAAA,gBACA9yC,MAAA,GAAAA,IAAA,IAAAmjB,EAAA,EACArjB,IAAAqjB,GAAAnjB,GAAAojB,IAAA0vB,EAAA,cACAhzC,MAAA,GAAAA,IAAA,IAAAE,EAAA,EACAojB,IAAApjB,GAAAF,GAAAqjB,IAAA2vB,EAAA,gBACA1vB,MAAA,GAAAA,IAAA,IAAAtjB,EAAA,EACAqjB,IAAArjB,GAAAsjB,GAAApjB,IAAA8yC,EAAA,gBACA3vB,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACApjB,IAAAojB,GAAAD,GAAArjB,IAAAgzC,EAAA,eACA9yC,MAAA,GAAAA,IAAA,IAAAmjB,EAAA,EACArjB,IAAAqjB,GAAAnjB,GAAAojB,IAAA0vB,EAAA,gBACAhzC,MAAA,GAAAA,IAAA,IAAAE,EAAA,EACAojB,IAAApjB,GAAAF,GAAAqjB,IAAA2vB,EAAA,iBACA1vB,MAAA,GAAAA,IAAA,IAAAtjB,EAAA,EACAqjB,IAAArjB,GAAAsjB,GAAApjB,IAAA8yC,EAAA,eACA3vB,MAAA,EAAAA,IAAA,IAAAC,EAAA,EACApjB,IAAAojB,GAAAD,GAAArjB,IAAAgzC,EAAA,iBACA9yC,MAAA,GAAAA,IAAA,IAAAmjB,EAAA,EACArjB,IAAAqjB,GAAAnjB,GAAAojB,IAAA0vB,EAAA,eACAhzC,MAAA,GAAAA,IAAA,IAAAE,EAAA,EACAojB,IAAApjB,GAAAF,GAAAqjB,IAAA2vB,EAAA,eACA1vB,MAAA,GAAAA,IAAA,IAAAtjB,EAAA,EAEAma,EAAA,GAAAkJ,EAAAlJ,EAAA,KACAA,EAAA,GAAAmJ,EAAAnJ,EAAA,KACAA,EAAA,GAAAna,EAAAma,EAAA,KACAA,EAAA,GAAAja,EAAAia,EAAA,KAGA,QAAA6gD,GAAA95D,GACA,GACAtB,GADAq7D,IAGA,KAAAr7D,EAAA,EAAmBA,EAAA,GAAQA,GAAA,EAC3Bq7D,EAAAr7D,GAAA,GAAAsB,EAAA+tB,WAAArvB,IAAAsB,EAAA+tB,WAAArvB,EAAA,QAAAsB,EAAA+tB,WAAArvB,EAAA,SAAAsB,EAAA+tB,WAAArvB,EAAA,OAEA,OAAAq7D,GAGA,QAAAC,GAAA73C,GACA,GACAzjB,GADAq7D,IAGA,KAAAr7D,EAAA,EAAmBA,EAAA,GAAQA,GAAA,EAC3Bq7D,EAAAr7D,GAAA,GAAAyjB,EAAAzjB,IAAAyjB,EAAAzjB,EAAA,QAAAyjB,EAAAzjB,EAAA,SAAAyjB,EAAAzjB,EAAA,OAEA,OAAAq7D,GAGA,QAAAE,GAAAj6D,GACA,GAEAtB,GACAuC,EACAi5D,EACAC,EACAC,EACAC,EAPA56D,EAAAO,EAAAiB,OACAiU,GAAA,4CAQA,KAAAxW,EAAA,GAAoBA,GAAAe,EAAQf,GAAA,GAC5Bm7D,EAAA3kD,EAAA4kD,EAAA95D,EAAAyY,UAAA/Z,EAAA,GAAAA,IAKA,KAHAsB,IAAAyY,UAAA/Z,EAAA,IACAuC,EAAAjB,EAAAiB,OACAi5D,GAAA,iCACAx7D,EAAA,EAAmBA,EAAAuC,EAAYvC,GAAA,EAC/Bw7D,EAAAx7D,GAAA,IAAAsB,EAAA+tB,WAAArvB,OAAA,KAGA,IADAw7D,EAAAx7D,GAAA,UAAAA,EAAA,MACAA,EAAA,GAEA,IADAm7D,EAAA3kD,EAAAglD,GACAx7D,EAAA,EAAuBA,EAAA,GAAQA,GAAA,EAC/Bw7D,EAAAx7D,GAAA,CAcA,OATAy7D,GAAA,EAAA16D,EACA06D,IAAA/3D,SAAA,IAAA+nB,MAAA,kBACAiwC,EAAAx9C,SAAAu9C,EAAA,OACAE,EAAAz9C,SAAAu9C,EAAA,UAEAD,EAAA,IAAAE,EACAF,EAAA,IAAAG,EAEAR,EAAA3kD,EAAAglD,GACAhlD,EAGA,QAAAolD,GAAAn4C,GACA,GAEAzjB,GACAuC,EACAi5D,EACAC,EACAC,EACAC,EAPA56D,EAAA0iB,EAAAlhB,OACAiU,GAAA,4CAQA,KAAAxW,EAAA,GAAoBA,GAAAe,EAAQf,GAAA,GAC5Bm7D,EAAA3kD,EAAA8kD,EAAA73C,EAAAo4C,SAAA77D,EAAA,GAAAA,IAWA,KAJAyjB,EAAAzjB,EAAA,GAAAe,EAAA0iB,EAAAo4C,SAAA77D,EAAA,OAAAwM,YAAA,GAEAjK,EAAAkhB,EAAAlhB,OACAi5D,GAAA,iCACAx7D,EAAA,EAAmBA,EAAAuC,EAAYvC,GAAA,EAC/Bw7D,EAAAx7D,GAAA,IAAAyjB,EAAAzjB,OAAA,KAIA,IADAw7D,EAAAx7D,GAAA,UAAAA,EAAA,MACAA,EAAA,GAEA,IADAm7D,EAAA3kD,EAAAglD,GACAx7D,EAAA,EAAuBA,EAAA,GAAQA,GAAA,EAC/Bw7D,EAAAx7D,GAAA,CAeA,OAVAy7D,GAAA,EAAA16D,EACA06D,IAAA/3D,SAAA,IAAA+nB,MAAA,kBACAiwC,EAAAx9C,SAAAu9C,EAAA,OACAE,EAAAz9C,SAAAu9C,EAAA,UAEAD,EAAA,IAAAE,EACAF,EAAA,IAAAG,EAEAR,EAAA3kD,EAAAglD,GAEAhlD,EAGA,QAAAslD,GAAA/6D,GACA,GACA+a,GADAxa,EAAA,EAEA,KAAAwa,EAAA,EAAmBA,EAAA,EAAOA,GAAA,EAC1Bxa,GAAAy6D,EAAAh7D,GAAA,EAAA+a,EAAA,MAAAigD,EAAAh7D,GAAA,EAAA+a,EAAA,GAEA,OAAAxa,GAGA,QAAAyoC,GAAAxvB,GACA,GAAAva,EACA,KAAAA,EAAA,EAAmBA,EAAAua,EAAAhY,OAAcvC,GAAA,EACjCua,EAAAva,GAAA87D,EAAAvhD,EAAAva,GAEA,OAAAua,GAAAwG,KAAA,IAmEA,QAAAi7C,GAAAv9C,GAKA,MAJA,kBAAApU,KAAAoU,KACAA,EAAA81B,SAAAnC,mBAAA3zB,KAGAA,EAGA,QAAAw9C,GAAAx9C,EAAAy9C,GACA,GAGAl8D,GAHAuC,EAAAkc,EAAAlc,OACA6U,EAAA,GAAArE,aAAAxQ,GACAmU,EAAA,GAAAlK,YAAA4K,EAGA,KAAApX,EAAA,EAAmBA,EAAAuC,EAAYvC,GAAA,EAC/B0W,EAAA1W,GAAAye,EAAA4Q,WAAArvB,EAGA,OAAAk8D,GAAAxlD,EAAAU,EAGA,QAAA+kD,GAAA/kD,GACA,MAAAlQ,QAAA4oB,aAAA3tB,MAAA,QAAAqK,YAAA4K,IAGA,QAAAglD,GAAAC,EAAAC,EAAAJ,GACA,GAAA/4D,GAAA,GAAAqJ,YAAA6vD,EAAA9vD,WAAA+vD,EAAA/vD,WAKA,OAHApJ,GAAAnB,IAAA,GAAAwK,YAAA6vD,IACAl5D,EAAAnB,IAAA,GAAAwK,YAAA8vD,GAAAD,EAAA9vD,YAEA2vD,EAAA/4D,IAAA8I,OAGA,QAAAswD,GAAAxyB,GACA,GAEAxvB,GAFAsV,KACAttB,EAAAwnC,EAAAxnC,MAGA,KAAAgY,EAAA,EAAmBA,EAAAhY,EAAA,EAAgBgY,GAAA,EACnCsV,EAAAnqB,KAAAwY,SAAA6rB,EAAA0I,OAAAl4B,EAAA,OAGA,OAAArT,QAAA4oB,aAAA3tB,MAAA+E,OAAA2oB,GAYA,QAAA2sC,KAEA78D,KAAA88D,QAjZA,GAAAC,GAAA,SAAAj5C,EAAAC,GACA,MAAAD,GAAAC,EAAA,YAEAq4C,GAAA,gEAssBA,OAhbA,qCAAAhyB,EAAAwxB,EAAA,YACAmB,EAAA,SAAAniD,EAAA+iC,GACA,GAAAqf,IAAA,MAAApiD,IAAA,MAAA+iC,GACAsf,GAAAriD,GAAA,KAAA+iC,GAAA,KAAAqf,GAAA,GACA,OAAAC,IAAA,SAAAD,IAYA,mBAAA5pD,0BAAA5R,UAAA+K,QACA,WACA,QAAA2wD,GAAA53B,EAAA1iC,GAGA,MAFA0iC,GAAA,EAAAA,GAAA,EAEAA,EAAA,EACA/yB,KAAAC,IAAA8yB,EAAA1iC,EAAA,GAGA2P,KAAAwJ,IAAAupB,EAAA1iC,GAGAwQ,YAAA5R,UAAA+K,MAAA,SAAA4d,EAAAC,GACA,GAGAkc,GACA5uB,EACAC,EACAC,EANAhV,EAAA5C,KAAA4M,WACAuwD,EAAAD,EAAA/yC,EAAAvnB,GACAyuB,EAAAzuB,CAUA,OAJAwnB,KAAAvmB,IACAwtB,EAAA6rC,EAAA9yC,EAAAxnB,IAGAu6D,EAAA9rC,EACA,GAAAje,aAAA,IAGAkzB,EAAAjV,EAAA8rC,EACAzlD,EAAA,GAAAtE,aAAAkzB,GACA3uB,EAAA,GAAA9K,YAAA6K,GAEAE,EAAA,GAAA/K,YAAA7M,KAAAm9D,EAAA72B,GACA3uB,EAAAtV,IAAAuV,GAEAF,OA+EAmlD,EAAAr7D,UAAA6tB,OAAA,SAAAvQ,GAKA,MAFA9e,MAAAwxB,aAAA6qC,EAAAv9C,IAEA9e,MAUA68D,EAAAr7D,UAAAgwB,aAAA,SAAA4rC,GACAp9D,KAAAq9D,OAAAD,EACAp9D,KAAAs9D,SAAAF,EAAAx6D,MAEA,IACAvC,GADAuC,EAAA5C,KAAAq9D,MAAAz6D,MAGA,KAAAvC,EAAA,GAAoBA,GAAAuC,EAAavC,GAAA,GACjCm7D,EAAAx7D,KAAAu9D,MAAA9B,EAAAz7D,KAAAq9D,MAAAjjD,UAAA/Z,EAAA,GAAAA,IAKA,OAFAL,MAAAq9D,MAAAr9D,KAAAq9D,MAAAjjD,UAAA/Z,EAAA,IAEAL,MAWA68D,EAAAr7D,UAAA6vB,IAAA,SAAAH,GACA,GAEA7wB,GAEAyjC,EAJArsB,EAAAzX,KAAAq9D,MACAz6D,EAAA6U,EAAA7U,OAEAi5D,GAAA,gCAGA,KAAAx7D,EAAA,EAAmBA,EAAAuC,EAAYvC,GAAA,EAC/Bw7D,EAAAx7D,GAAA,IAAAoX,EAAAiY,WAAArvB,OAAA,KAYA,OATAL,MAAAw9D,QAAA3B,EAAAj5D,GACAkhC,EAAAsG,EAAApqC,KAAAu9D,OAEArsC,IACA4S,EAAA84B,EAAA94B,IAGA9jC,KAAA88D,QAEAh5B,GAQA+4B,EAAAr7D,UAAAs7D,MAAA,WAKA,MAJA98D,MAAAq9D,MAAA,GACAr9D,KAAAs9D,QAAA,EACAt9D,KAAAu9D,OAAA,6CAEAv9D,MAQA68D,EAAAr7D,UAAAi8D,SAAA,WACA,OACAhmD,KAAAzX,KAAAq9D,MACAz6D,OAAA5C,KAAAs9D,QACAp3D,KAAAlG,KAAAu9D,QAWAV,EAAAr7D,UAAAk8D,SAAA,SAAA7mD,GAKA,MAJA7W,MAAAq9D,MAAAxmD,EAAAY,KACAzX,KAAAs9D,QAAAzmD,EAAAjU,OACA5C,KAAAu9D,MAAA1mD,EAAA3Q,KAEAlG,MAOA68D,EAAAr7D,UAAAswB,QAAA,iBACA9xB,MAAAu9D,YACAv9D,MAAAq9D,YACAr9D,MAAAs9D,SASAT,EAAAr7D,UAAAg8D,QAAA,SAAA3B,EAAAj5D,GACA,GACAk5D,GACAC,EACAC,EAHA37D,EAAAuC,CAMA,IADAi5D,EAAAx7D,GAAA,UAAAA,EAAA,MACAA,EAAA,GAEA,IADAm7D,EAAAx7D,KAAAu9D,MAAA1B,GACAx7D,EAAA,EAAuBA,EAAA,GAAQA,GAAA,EAC/Bw7D,EAAAx7D,GAAA,CAMAy7D,GAAA,EAAA97D,KAAAs9D,QACAxB,IAAA/3D,SAAA,IAAA+nB,MAAA,kBACAiwC,EAAAx9C,SAAAu9C,EAAA,OACAE,EAAAz9C,SAAAu9C,EAAA,UAEAD,EAAA,IAAAE,EACAF,EAAA,IAAAG,EACAR,EAAAx7D,KAAAu9D,MAAA1B,IAYAgB,EAAA32D,KAAA,SAAA4Y,EAAAoS,GAGA,MAAA2rC,GAAAc,WAAAtB,EAAAv9C,GAAAoS,IAWA2rC,EAAAc,WAAA,SAAAC,EAAA1sC,GACA,GAAAhrB,GAAA01D,EAAAgC,GACA95B,EAAAsG,EAAAlkC,EAEA,OAAAgrB,GAAA0rC,EAAA94B,MAUA+4B,EAAAzpD,YAAA,WAEApT,KAAA88D,SAUAD,EAAAzpD,YAAA5R,UAAA6tB,OAAA,SAAAtY,GACA,GAEA1W,GAFAoX,EAAAglD,EAAAz8D,KAAAq9D,MAAA/wD,OAAAyK,GAAA,GACAnU,EAAA6U,EAAA7U,MAKA,KAFA5C,KAAAs9D,SAAAvmD,EAAAnK,WAEAvM,EAAA,GAAoBA,GAAAuC,EAAavC,GAAA,GACjCm7D,EAAAx7D,KAAAu9D,MAAA5B,EAAAlkD,EAAAykD,SAAA77D,EAAA,GAAAA,IAKA,OAFAL,MAAAq9D,MAAAh9D,EAAA,GAAAuC,EAAA,GAAAiK,YAAA4K,EAAAnL,OAAAC,MAAAlM,EAAA,QAAAwM,YAAA,GAEA7M,MAWA68D,EAAAzpD,YAAA5R,UAAA6vB,IAAA,SAAAH,GACA,GAGA7wB,GACAyjC,EAJArsB,EAAAzX,KAAAq9D,MACAz6D,EAAA6U,EAAA7U,OACAi5D,GAAA,gCAIA,KAAAx7D,EAAA,EAAmBA,EAAAuC,EAAYvC,GAAA,EAC/Bw7D,EAAAx7D,GAAA,IAAAoX,EAAApX,OAAA,KAYA,OATAL,MAAAw9D,QAAA3B,EAAAj5D,GACAkhC,EAAAsG,EAAApqC,KAAAu9D,OAEArsC,IACA4S,EAAA84B,EAAA94B,IAGA9jC,KAAA88D,QAEAh5B,GAQA+4B,EAAAzpD,YAAA5R,UAAAs7D,MAAA,WAKA,MAJA98D,MAAAq9D,MAAA,GAAAxwD,YAAA,GACA7M,KAAAs9D,QAAA,EACAt9D,KAAAu9D,OAAA,6CAEAv9D,MAQA68D,EAAAzpD,YAAA5R,UAAAi8D,SAAA,WACA,GAAA5mD,GAAAgmD,EAAAr7D,UAAAi8D,SAAAl9D,KAAAP,KAKA,OAFA6W,GAAAY,KAAA+kD,EAAA3lD,EAAAY,MAEAZ,GAUAgmD,EAAAzpD,YAAA5R,UAAAk8D,SAAA,SAAA7mD,GAIA,MAFAA,GAAAY,KAAA6kD,EAAAzlD,EAAAY,MAAA,GAEAolD,EAAAr7D,UAAAk8D,SAAAn9D,KAAAP,KAAA6W,IAGAgmD,EAAAzpD,YAAA5R,UAAAswB,QAAA+qC,EAAAr7D,UAAAswB,QAEA+qC,EAAAzpD,YAAA5R,UAAAg8D,QAAAX,EAAAr7D,UAAAg8D,QAUAX,EAAAzpD,YAAAlN,KAAA,SAAA6Q,EAAAma,GACA,GAAAhrB,GAAA+1D,EAAA,GAAApvD,YAAAkK,IACA+sB,EAAAsG,EAAAlkC,EAEA,OAAAgrB,GAAA0rC,EAAA94B,MAGA+4B,KjB+1eM,SAAUh9D,EAAQD,EAASM,GAEjC,YkBvhgBA,SAAAwF,GAAAiQ,EAAArN,EAAAqxC,GACA,GAAAC,GAAAD,IAAA/2C,OAAA,EACA+S,KAAAikC,EAAAvlC,UAEAslC,EAAAj0C,MACAk0C,EAAAD,IAAA/2C,OAAA,GAEA,IAAAyR,GAAAulC,EAAAvlC,QACAwlC,EAAAD,EAAA52C,KACA,IAAAS,MAAA4D,QAAAgN,GACAA,EAAAtO,KAAA4P,OACG,IAAAkkC,IAAAvxC,EAAA1F,OAAA,GACH,GAAAgB,GAAA0E,EAAA5C,KACA2O,GAAAzQ,GAAA+R,MAEArN,GAAAvC,KAAA4P,GA/DA/V,EAAAk2B,UAAA,SAAAznB,GACA,GAAAuF,KACAA,GAAA7N,MAAc4P,IAAAtH,GAId,KAFA,GACAqjB,GAAA/b,EAAAwW,EAAAmZ,EAAAjlC,EAAAw9D,EAAA51D,EAAAwrC,EAAA7vC,EAAAlD,EAAAo9D,EADAvkD,EAAA,GAEAmY,EAAA9d,EAAAlO,OAKA,GAJAiQ,EAAA+b,EAAA/b,IACAwW,EAAAuF,EAAAvF,QAAA,GACAmZ,EAAA5T,EAAA4T,KAAA,GACA/rB,GAAA4S,EACAmZ,EACA/rB,GAAA+rB,MACK,oBAAA3vB,GACL4D,GAAA,mBAAA5D,GAAA,KAAA8f,KAAAK,UAAAngB,OACK,WAAAA,EACL4D,GAAA,WACK,IAAA9V,MAAA4D,QAAAsO,GAAA,CAEL,IADA/B,EAAA7N,MAAkBu/B,IAAA,MAClBjlC,EAAAsV,EAAA/S,OAAA,EAA8BvC,GAAA,EAAQA,IACtCw9D,EAAA,IAAAx9D,EAAA,OACAuT,EAAA7N,MAAoB4P,MAAAtV,GAAA8rB,OAAA0xC,GAEpBjqD,GAAA7N,MAAkBu/B,IAAA,UACb,CACLr9B,IACA,KAAAwrC,IAAA99B,GACAA,EAAAlU,eAAAgyC,IACAxrC,EAAAlC,KAAA0tC,EAIA,KADA7/B,EAAA7N,MAAkBu/B,IAAA,MAClBjlC,EAAA4H,EAAArF,OAAA,EAA+BvC,GAAA,EAAQA,IACvCuD,EAAAqE,EAAA5H,GACAK,EAAAiV,EAAA/R,GACAk6D,EAAAz9D,EAAA,SACAy9D,GAAAroC,KAAAK,UAAAlyB,GAAA,IACAgQ,EAAA7N,MAAoB4P,IAAAjV,EAAAyrB,OAAA2xC,GAEpBlqD,GAAA7N,MAAkBu/B,IAAA,MAGlB,MAAA/rB,IAyBA3Z,EAAA81B,MAAA,SAAA5W,GAOA,IANA,GAGAo5B,GAAA6B,EAAAgkB,EACAC,EAAAC,EAAAC,EAAAzkB,EACAQ,EAAAC,EALA5xC,KACAqxC,KACAt5C,EAAA,IAMA,GADA63C,EAAAp5B,EAAAze,KACA,MAAA63C,GACA,MAAAA,GACA,mBAAAA,GAQA,OAAAA,GACA,QACA,SACA,SACA,QACA,QACA,KACA,SACA73C,GAAA,EACAqF,EAAA,KAAA4C,EAAAqxC,EACA,MACA,SACAt5C,GAAA,EACAqF,GAAA,EAAA4C,EAAAqxC,EACA,MACA,SACAt5C,GAAA,EACAqF,GAAA,EAAA4C,EAAAqxC,EACA,MACA,SACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QACA,QAGA,IAFAI,EAAA,GACA15C,MACA,CAEA,GADA09D,EAAAj/C,EAAAze,MACA,cAAAqK,KAAAqzD,GAEW,CACX19D,GACA,OAHA05C,GAAAgkB,EAMAr4D,EAAAg0C,WAAAK,GAAAzxC,EAAAqxC,EACA,MACA,SAIA,IAHAqkB,EAAA,GACAC,EAAA,OACAC,EAAA,IACA,CAEA,GADAzkB,EAAA36B,EAAAze,KACA,MAAAo5C,IAAA,OAAAwkB,GACAC,EAAA,OASA,KARAF,IAAAvkB,EACAwkB,EAAAxkB,EACA,OAAAwkB,EACAC,IAEAA,EAAA,EAMAx4D,EAAA+vB,KAAAC,MAAA,IAAAsoC,EAAA,KAAA11D,EAAAqxC,EACA,MACA,SACAM,GAAwB5lC,WAAArR,MAAAsF,EAAA1F,QACxB0F,EAAAvC,KAAAk0C,EAAA5lC,SACAslC,EAAA5zC,KAAAk0C,EACA,MACA,SACAC,GAAsB7lC,WAAYrR,MAAAsF,EAAA1F,QAClC0F,EAAAvC,KAAAm0C,EAAA7lC,SACAslC,EAAA5zC,KAAAm0C,EACA,MACA,SACA,SAAAvjC,OACA,sCAAAuhC,OAtFA,CAGA,OAAA5vC,EAAA1F,OACA,MAAA0F,GAAA5C,KAEAA,GAAA4C,EAAA5C,MAAA4C,EAAAqxC,MlBuqgBM,SAAU95C,EAAQD,GmBhwgBxBC,EAAAD,QAAA,SAAAC,GAoBA,MAnBAA,GAAAs+D,kBACAt+D,EAAAu+D,UAAA,aACAv+D,EAAAglB,SAEAhlB,EAAAw+D,WAAAx+D,EAAAw+D,aACAt9D,OAAAC,eAAAnB,EAAA,UACAqB,YAAA,EACAC,IAAA,WACA,MAAAtB,GAAAS,KAGAS,OAAAC,eAAAnB,EAAA,MACAqB,YAAA,EACAC,IAAA,WACA,MAAAtB,GAAAQ,KAGAR,EAAAs+D,gBAAA,GAEAt+D,InBwwgBM,SAAUA,EAAQ4V,EAAqBvV,GAE7C,YAUA,SAASwV,GAAgBC,EAAK/R,EAAKlD,GAAiK,MAApJkD,KAAO+R,GAAO5U,OAAOC,eAAe2U,EAAK/R,GAAOlD,MAAOA,EAAOQ,YAAY,EAAMD,cAAc,EAAM2U,UAAU,IAAkBD,EAAI/R,GAAOlD,EAAgBiV,EAE3M,QAAS2oD,GAAgBC,EAAUC,GAAe,KAAMD,YAAoBC,IAAgB,KAAM,IAAI1O,WAAU,qCAXhH/uD,OAAOC,eAAeyU,EAAqB,cAAgB/U,OAAO,GAC7C,IAAI+9D,GAAgDv+D,EAAoB,GACpEw+D,EAAwDx+D,EAAoBkB,EAAEq9D,GAC9E1oD,EAA6C7V,EAAoB,GACjE8V,EAAqD9V,EAAoBkB,EAAE2U,GAC3E4oD,EAAuCz+D,EAAoB,EACnDA,GAAoBS,EAAE8U,EAAqB,aAAc,WAAa,MAAOkpD,GAAwC,GACtJ,IAAIC,GAAe,WAAc,QAASC,GAAiBnnD,EAAQjO,GAAS,IAAK,GAAIpJ,GAAI,EAAGA,EAAIoJ,EAAM7G,OAAQvC,IAAK,CAAE,GAAIy+D,GAAar1D,EAAMpJ,EAAIy+D,GAAW59D,WAAa49D,EAAW59D,aAAc,EAAO49D,EAAW79D,cAAe,EAAU,SAAW69D,KAAYA,EAAWlpD,UAAW,GAAM7U,OAAOC,eAAe0W,EAAQonD,EAAWl7D,IAAKk7D,IAAiB,MAAO,UAAUN,EAAaO,EAAYC,GAAiJ,MAA9HD,IAAYF,EAAiBL,EAAYh9D,UAAWu9D,GAAiBC,GAAaH,EAAiBL,EAAaQ,GAAqBR,MoBnxgB5hBS,SAKEC,EpBwygBO,WoBlygBX,QAAAA,KAAyB,GAAAC,GAAAn/D,KAAbo/D,EAAahzD,UAAAxJ,OAAA,GAAAiB,SAAAuI,UAAA,GAAAA,UAAA,KAAAkyD,GAAAt+D,KAAAk/D,EAGvB,IAAMG,IACJ,SACA,UACA,UAYF,IARAr/D,KAAKs/D,QAAUF,EAAOG,OAGtBv/D,KAAKw/D,QACLx/D,KAAKy/D,UACLz/D,KAAK0/D,WAGAN,EAAOG,OACV,KAAM,IAAI5oD,OAAM,gEASlB,IALIyoD,EAAOO,SACT3pD,IAAMhW,KAAMo/D,EAAOO,SAIhBP,EAAOQ,QAAQpzD,cAAgB/I,OAAW27D,EAAOQ,QAAQh9D,OAAS,EACrE,IAAK,GAAIvC,GAAI,EAAGA,EAAI++D,EAAOQ,QAAQh9D,OAAQvC,GAAK,EAC9Cq+D,EAAA56C,EAAQ4sC,OAAO0O,EAAOQ,QAAQv/D,GAKlCU,QAAOkH,KAAKm3D,GAAQl7D,QAAQ,SAAC27D,GAE3B,MAAIR,GAAY59C,QAAQo+C,MAAY,EAAY,KAGzCV,EAAKW,QAAQD,EAAQ7pD,OAE1BopD,EAAOG,OACPH,EAAOS,OpBo/gBb,MAvMAjB,GAAaM,IACXt7D,IAAK,WACLlD,MAAO,SoBzygBAm/D,EAAQE,GACf,GAAM/8D,GAAQ9C,EAAAG,EAAAs+D,EAAA,GAAa3+D,KAAK0/D,OAAOG,GAASE,GAC1CxgD,EAAQvf,KAAK0/D,OAAOG,GAAQ78D,EAG9Buc,IAAOA,EAAInI,MAAQ2oD,GACrB//D,KAAK0/D,OAAOG,GAAQl6D,OAAO3C,EAAO,MpBgzgBpCY,IAAK,UACLlD,MAAO,SoB5ygBDm/D,EAAQz9C,GACd,GAAMpf,GAAQ9C,EAAAG,EAAAs+D,EAAA,GAAa3+D,KAAK0/D,OAAOG,GAASz9C,EAAOhL,KACjDmI,EAAQvf,KAAK0/D,OAAOG,GAAQ78D,EAG9Buc,IAAOA,EAAInI,MAAQgL,EAAOhL,IAE5B6nD,EAAI58D,IAAIrC,KAAK0/D,OAAOG,GAAS78D,EAAOof,IAGpCpiB,KAAK0/D,OAAOG,GAAQl6D,OAAO3C,EAAO,MAElCi8D,EAAI58D,IAAIrC,KAAK0/D,OAAOG,GAAS78D,EAAOof,OpBuzgBtCxe,IAAK,SACLlD,MAAO,SoB/ygBFouC,GACL,MAAOH,OAAS3uC,KAAKs/D,QAAQU,OAAtB,IAAgClxB,EAAQO,IAC7Cr5B,KACEm5B,YAAa,UACbH,SAAWsH,eAAgB,qBAC1BxH,GAAWnY,KAAMlB,KAAKK,UAAUgZ,EAAQnY,SAC1C3d,KAAK,SAAA41B,GAAA,MAAYA,GAAS/Y,YpB2zgB7BjyB,IAAK,UACLlD,MAAO,SoBlzgBDm/D,GAAqB,GAAAI,GAAAjgE,KAAbu/D,EAAanzD,UAAAxJ,OAAA,GAAAiB,SAAAuI,UAAA,GAAAA,UAAA,KAE3B,OAAIpM,MAAKw/D,KAAKK,GACL7/D,KAAKw/D,KAAKK,GAIfN,EAAOW,YACTlgE,KAAKw/D,KAAKK,GAAU,GAAInB,GAAA56C,EACnBy7C,EAAOS,OADQ,IACEH,EACpBN,EAAOzwB,SAEF9uC,KAAKw/D,KAAKK,KAInB7/D,KAAKw/D,KAAKK,GAAU,GAAInB,GAAA56C,EAAQ+7C,EAAQN,EAAOzwB,SAG/C9uC,KAAKw/D,KAAKK,GAAQrpB,QAAQ+oB,EAAO/oB,SAASx9B,KAAK,SAAC/T,GAC9C,MAAOg6D,GAAI58D,IAAI49D,EAAKP,OAAQG,EAAQ56D,EAAKimB,KAAK/oB,IAAI,SAACk1B;AAAD,MAASA,GAAI9X,SAIjEm/C,EAAA56C,EAAQkpC,KACN6S,EACGN,EAAOS,OAFZ,IAEsBH,EACpBN,EAAOvS,MAIThtD,KAAKmgE,aAAaN,EAAQN,GAGnBv/D,KAAKw/D,KAAKK,OpBozgBjBj8D,IAAK,eACLlD,MAAO,SoBlzgBIm/D,EAAQN,GAAQ,GAAAa,GAAApgE,KAErBqgE,EAAYrgE,KAAKw/D,KAAKK,GAAQ52C,QAAQs2C,EAAOt2C,SAASR,GAAG,SAAU,SAAC1I,GAMxE,MALIA,GAAOyD,QACT48C,EAAK52C,SAASq2C,EAAQ9/C,EAAOzE,IAE7B8kD,EAAKE,QAAQT,EAAQ9/C,EAAOR,KAEvBggD,EAAOgB,WAAahB,EAAOgB,UAAUxgD,KAC3C0I,GAAG,WAAY,SAACH,GAUjB,MATIA,GAASpN,SACXoN,EAASpN,QAAQhX,QAAQ,SAAC6b,GACpBA,EAAOyD,QACT48C,EAAK52C,SAASq2C,EAAQ9/C,EAAOzE,IAE7B8kD,EAAKE,QAAQT,EAAQ9/C,EAAOR,OAI3BggD,EAAOpQ,YAAcoQ,EAAOpQ,WAAW7mC,KAC7CG,GAAG,QAAS82C,EAAOntB,SAAWusB,EAAA,GAChCl2C,GAAG,SAAU82C,EAAOiB,UAAY7B,EAAA,GAChCl2C,GAAG,SAAU82C,EAAOkB,UAAY9B,EAAA,GAChCl2C,GAAG,SAAU82C,EAAOmB,UAAY/B,EAAA,EASjC,OANAY,GAAOl3C,QAAUk3C,EAAOl3C,OAAOg4C,EAAUh4C,QAGzCroB,KAAKy/D,OAAOI,GAAUQ,EAGfrgE,KAAKy/D,OAAOI,MpByzgBnBj8D,IAAK,KASLlD,MAAO,SoBrygBNm/D,GAAqB,GAAbN,GAAanzD,UAAAxJ,OAAA,GAAAiB,SAAAuI,UAAA,GAAAA,UAAA,KACtB,OAAOpM,MAAK8/D,QAAQD,EAAQ7pD,OAAUhW,KAAKs/D,QAASC,OpBizgBpD37D,IAAK,UACLlD,MAAO,SoB1ygBDm/D,GAAQ,GAAAc,GAAA3gE,IAEd,OAAKA,MAAKw/D,KAAKK,GAEX7/D,KAAKw/D,KAAKK,GAAQnmD,QAAgB,KAE/B,GAAIhH,SAAQ,SAACW,EAASsF,GAE3BgoD,EAAKnB,KAAKK,GAAQt8B,QAAQvqB,KAAK,SAAC41B,GAU9B,MARA+xB,GAAKlB,OAAOI,GAAQx3C,eAEbs4C,GAAKnB,KAAKK,GAEjBZ,EAAIpyC,OAAO8zC,EAAKjB,OAAQG,SAEjBc,GAAKlB,OAAOI,GAEZxsD,EAAQu7B,KACdvjB,MAAM1S,KAjBoB,QpBi0gB/B/U,IAAK,QACLzC,IAAK,WoBn2gBL,MAAOnB,MAAK0/D,QpB22gBZr9D,IAAK,SoBr2gBG3B,GACR0d,QAAQvB,MAAR,4IpB22gBKqiD,IoBjzgBTzpD,GAAA,SAEEypD,SAGA0B,QALa,SAKLC,GAsBN,QAASnqD,KAAW,GAAAoqD,GAAA9gE,IAElB,KAAKA,KAAKs7D,SAASyF,QAAS,MAAO,KAFjB,IAIVA,GAAY/gE,KAAKs7D,SAAjByF,OAER,OAAO/qD,KAAMhW,MACX0W,SAAU3V,OAAOkH,KAAK84D,GAASvqD,OAAO,SAACC,EAAIwD,GAAL,MAAcjE,KAAMS,EAANf,KACjDuE,EAAO/Z,EAAAG,EAAAs+D,EAAA,GAAOoC,EAAQ9mD,OAAf6mD,YAQd,QAASE,KAEP,GAAMlyB,GAAU9uC,KAAKs7D,QAEjBxsB,GAAQmyB,QAEVjhE,KAAK4W,QAAUk4B,EAAQmyB,OAEvBC,EAAelhE,KAAK4W,QAAS,SAAUk4B,EAAQmyB,OAAOvB,SAC7C5wB,EAAQtoB,QAAUsoB,EAAQtoB,OAAO5P,UAE1C5W,KAAK4W,QAAUk4B,EAAQtoB,OAAO5P,SAOlC,QAAS8yB,KAIP,MAFAhzB,GAASnW,KAAKP,MAETA,KAAK0W,SAEH1W,KAAK4W,QAAQH,GAAGzW,KAAK0W,SAAS9V,KAAMZ,KAAK0W,SAASo4B,SAF9B,KAQ7B,QAASqyB,KAEP,MAAKnhE,MAAK0W,SAEH1W,KAAK4W,QAAQwqD,QAAQphE,KAAK0W,SAAS9V,MAFf,KAnE7B,GAAIq+D,EACF,KAAM,IAAItoD,OACR,8EAKJsoD,GAAM4B,CAVM,IAaJK,GAAmBjC,EAAIoC,KAAvBH,eAGF37B,EAAUgZ,OAAO0gB,EAAI15B,QAAQtkB,MAAM,KAAK,GA4D9C,IAAIskB,GAAW,EAAG,CAChB,GAAM+7B,GAAWrC,EAAIM,OAAOgC,gBAAgB9/C,QAAQ,SAAU,CAC9Dw9C,GAAIuC,MAAMF,GACRlgC,KAAe4/B,EACfS,QAAe/3B,EACfg4B,cAAeP,IAEfQ,aAAeX,EACfS,QAAe/3B,EACfk4B,UAAel4B,EACfm4B,YAAeV,EACfO,cAAeP,SAEZ,WAGL,GAAMW,GAAQ7C,EAAIz9D,UAAUsgE,KAE5B7C,GAAIz9D,UAAUsgE,MAAQ,WAA+B,GAAdhzB,GAAc1iC,UAAAxJ,OAAA,GAAAiB,SAAAuI,UAAA,GAAAA,UAAA,KACnD0iC,GAAQ1N,KAAO0N,EAAQ1N,MAClB4/B,GAAYvnD,OAAOq1B,EAAQ1N,MAC5B4/B,EACJc,EAAMvhE,KAAKP,KAAM8uC","file":"build.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine(\"vue-pouch-db\", [], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"vue-pouch-db\"] = factory();\n\telse\n\t\troot[\"vue-pouch-db\"] = factory();\n})(this, function() {\nreturn \n\n\n// WEBPACK FOOTER //\n// webpack/universalModuleDefinition","(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine(\"vue-pouch-db\", [], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"vue-pouch-db\"] = factory();\n\telse\n\t\troot[\"vue-pouch-db\"] = factory();\n})(this, function() {\nreturn /******/ (function(modules) { // webpackBootstrap\n/******/ \t// The module cache\n/******/ \tvar installedModules = {};\n/******/\n/******/ \t// The require function\n/******/ \tfunction __webpack_require__(moduleId) {\n/******/\n/******/ \t\t// Check if module is in cache\n/******/ \t\tif(installedModules[moduleId])\n/******/ \t\t\treturn installedModules[moduleId].exports;\n/******/\n/******/ \t\t// Create a new module (and put it into the cache)\n/******/ \t\tvar module = installedModules[moduleId] = {\n/******/ \t\t\ti: moduleId,\n/******/ \t\t\tl: false,\n/******/ \t\t\texports: {}\n/******/ \t\t};\n/******/\n/******/ \t\t// Execute the module function\n/******/ \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n/******/\n/******/ \t\t// Flag the module as loaded\n/******/ \t\tmodule.l = true;\n/******/\n/******/ \t\t// Return the exports of the module\n/******/ \t\treturn module.exports;\n/******/ \t}\n/******/\n/******/\n/******/ \t// expose the modules object (__webpack_modules__)\n/******/ \t__webpack_require__.m = modules;\n/******/\n/******/ \t// expose the module cache\n/******/ \t__webpack_require__.c = installedModules;\n/******/\n/******/ \t// identity function for calling harmony imports with the correct context\n/******/ \t__webpack_require__.i = function(value) { return value; };\n/******/\n/******/ \t// define getter function for harmony exports\n/******/ \t__webpack_require__.d = function(exports, name, getter) {\n/******/ \t\tif(!__webpack_require__.o(exports, name)) {\n/******/ \t\t\tObject.defineProperty(exports, name, {\n/******/ \t\t\t\tconfigurable: false,\n/******/ \t\t\t\tenumerable: true,\n/******/ \t\t\t\tget: getter\n/******/ \t\t\t});\n/******/ \t\t}\n/******/ \t};\n/******/\n/******/ \t// getDefaultExport function for compatibility with non-harmony modules\n/******/ \t__webpack_require__.n = function(module) {\n/******/ \t\tvar getter = module && module.__esModule ?\n/******/ \t\t\tfunction getDefault() { return module['default']; } :\n/******/ \t\t\tfunction getModuleExports() { return module; };\n/******/ \t\t__webpack_require__.d(getter, 'a', getter);\n/******/ \t\treturn getter;\n/******/ \t};\n/******/\n/******/ \t// Object.prototype.hasOwnProperty.call\n/******/ \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n/******/\n/******/ \t// __webpack_public_path__\n/******/ \t__webpack_require__.p = \"\";\n/******/\n/******/ \t// Load entry module and return exports\n/******/ \treturn __webpack_require__(__webpack_require__.s = 18);\n/******/ })\n/************************************************************************/\n/******/ ([\n/* 0 */\n/***/ (function(module, exports) {\n\nvar g;\r\n\r\n// This works in non-strict mode\r\ng = (function() {\r\n\treturn this;\r\n})();\r\n\r\ntry {\r\n\t// This works if eval is allowed (see CSP)\r\n\tg = g || Function(\"return this\")() || (1,eval)(\"this\");\r\n} catch(e) {\r\n\t// This works if the window reference is available\r\n\tif(typeof window === \"object\")\r\n\t\tg = window;\r\n}\r\n\r\n// g can still be undefined, but nothing to do about it...\r\n// We return undefined, instead of nothing here, so it's\r\n// easier to handle this case. if(!global) { ...}\r\n\r\nmodule.exports = g;\r\n\n\n/***/ }),\n/* 1 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(global, module) {/**\n * lodash (Custom Build) <https://lodash.com/>\n * Build: `lodash modularize exports=\"npm\" -o ./`\n * Copyright jQuery Foundation and other contributors <https://jquery.org/>\n * Released under MIT license <https://lodash.com/license>\n * Based on Underscore.js 1.8.3 <http://underscorejs.org/LICENSE>\n * Copyright Jeremy Ashkenas, DocumentCloud and Investigative Reporters & Editors\n */\n\n/** Used as the size to enable large array optimizations. */\nvar LARGE_ARRAY_SIZE = 200;\n\n/** Used to stand-in for `undefined` hash values. */\nvar HASH_UNDEFINED = '__lodash_hash_undefined__';\n\n/** Used as references for various `Number` constants. */\nvar MAX_SAFE_INTEGER = 9007199254740991;\n\n/** `Object#toString` result references. */\nvar argsTag = '[object Arguments]',\n    arrayTag = '[object Array]',\n    boolTag = '[object Boolean]',\n    dateTag = '[object Date]',\n    errorTag = '[object Error]',\n    funcTag = '[object Function]',\n    genTag = '[object GeneratorFunction]',\n    mapTag = '[object Map]',\n    numberTag = '[object Number]',\n    objectTag = '[object Object]',\n    promiseTag = '[object Promise]',\n    regexpTag = '[object RegExp]',\n    setTag = '[object Set]',\n    stringTag = '[object String]',\n    symbolTag = '[object Symbol]',\n    weakMapTag = '[object WeakMap]';\n\nvar arrayBufferTag = '[object ArrayBuffer]',\n    dataViewTag = '[object DataView]',\n    float32Tag = '[object Float32Array]',\n    float64Tag = '[object Float64Array]',\n    int8Tag = '[object Int8Array]',\n    int16Tag = '[object Int16Array]',\n    int32Tag = '[object Int32Array]',\n    uint8Tag = '[object Uint8Array]',\n    uint8ClampedTag = '[object Uint8ClampedArray]',\n    uint16Tag = '[object Uint16Array]',\n    uint32Tag = '[object Uint32Array]';\n\n/**\n * Used to match `RegExp`\n * [syntax characters](http://ecma-international.org/ecma-262/7.0/#sec-patterns).\n */\nvar reRegExpChar = /[\\\\^$.*+?()[\\]{}|]/g;\n\n/** Used to match `RegExp` flags from their coerced string values. */\nvar reFlags = /\\w*$/;\n\n/** Used to detect host constructors (Safari). */\nvar reIsHostCtor = /^\\[object .+?Constructor\\]$/;\n\n/** Used to detect unsigned integer values. */\nvar reIsUint = /^(?:0|[1-9]\\d*)$/;\n\n/** Used to identify `toStringTag` values of typed arrays. */\nvar typedArrayTags = {};\ntypedArrayTags[float32Tag] = typedArrayTags[float64Tag] =\ntypedArrayTags[int8Tag] = typedArrayTags[int16Tag] =\ntypedArrayTags[int32Tag] = typedArrayTags[uint8Tag] =\ntypedArrayTags[uint8ClampedTag] = typedArrayTags[uint16Tag] =\ntypedArrayTags[uint32Tag] = true;\ntypedArrayTags[argsTag] = typedArrayTags[arrayTag] =\ntypedArrayTags[arrayBufferTag] = typedArrayTags[boolTag] =\ntypedArrayTags[dataViewTag] = typedArrayTags[dateTag] =\ntypedArrayTags[errorTag] = typedArrayTags[funcTag] =\ntypedArrayTags[mapTag] = typedArrayTags[numberTag] =\ntypedArrayTags[objectTag] = typedArrayTags[regexpTag] =\ntypedArrayTags[setTag] = typedArrayTags[stringTag] =\ntypedArrayTags[weakMapTag] = false;\n\n/** Used to identify `toStringTag` values supported by `_.clone`. */\nvar cloneableTags = {};\ncloneableTags[argsTag] = cloneableTags[arrayTag] =\ncloneableTags[arrayBufferTag] = cloneableTags[dataViewTag] =\ncloneableTags[boolTag] = cloneableTags[dateTag] =\ncloneableTags[float32Tag] = cloneableTags[float64Tag] =\ncloneableTags[int8Tag] = cloneableTags[int16Tag] =\ncloneableTags[int32Tag] = cloneableTags[mapTag] =\ncloneableTags[numberTag] = cloneableTags[objectTag] =\ncloneableTags[regexpTag] = cloneableTags[setTag] =\ncloneableTags[stringTag] = cloneableTags[symbolTag] =\ncloneableTags[uint8Tag] = cloneableTags[uint8ClampedTag] =\ncloneableTags[uint16Tag] = cloneableTags[uint32Tag] = true;\ncloneableTags[errorTag] = cloneableTags[funcTag] =\ncloneableTags[weakMapTag] = false;\n\n/** Detect free variable `global` from Node.js. */\nvar freeGlobal = typeof global == 'object' && global && global.Object === Object && global;\n\n/** Detect free variable `self`. */\nvar freeSelf = typeof self == 'object' && self && self.Object === Object && self;\n\n/** Used as a reference to the global object. */\nvar root = freeGlobal || freeSelf || Function('return this')();\n\n/** Detect free variable `exports`. */\nvar freeExports = typeof exports == 'object' && exports && !exports.nodeType && exports;\n\n/** Detect free variable `module`. */\nvar freeModule = freeExports && typeof module == 'object' && module && !module.nodeType && module;\n\n/** Detect the popular CommonJS extension `module.exports`. */\nvar moduleExports = freeModule && freeModule.exports === freeExports;\n\n/** Detect free variable `process` from Node.js. */\nvar freeProcess = moduleExports && freeGlobal.process;\n\n/** Used to access faster Node.js helpers. */\nvar nodeUtil = (function() {\n  try {\n    return freeProcess && freeProcess.binding('util');\n  } catch (e) {}\n}());\n\n/* Node.js helper references. */\nvar nodeIsTypedArray = nodeUtil && nodeUtil.isTypedArray;\n\n/**\n * Adds the key-value `pair` to `map`.\n *\n * @private\n * @param {Object} map The map to modify.\n * @param {Array} pair The key-value pair to add.\n * @returns {Object} Returns `map`.\n */\nfunction addMapEntry(map, pair) {\n  // Don't return `map.set` because it's not chainable in IE 11.\n  map.set(pair[0], pair[1]);\n  return map;\n}\n\n/**\n * Adds `value` to `set`.\n *\n * @private\n * @param {Object} set The set to modify.\n * @param {*} value The value to add.\n * @returns {Object} Returns `set`.\n */\nfunction addSetEntry(set, value) {\n  // Don't return `set.add` because it's not chainable in IE 11.\n  set.add(value);\n  return set;\n}\n\n/**\n * A faster alternative to `Function#apply`, this function invokes `func`\n * with the `this` binding of `thisArg` and the arguments of `args`.\n *\n * @private\n * @param {Function} func The function to invoke.\n * @param {*} thisArg The `this` binding of `func`.\n * @param {Array} args The arguments to invoke `func` with.\n * @returns {*} Returns the result of `func`.\n */\nfunction apply(func, thisArg, args) {\n  switch (args.length) {\n    case 0: return func.call(thisArg);\n    case 1: return func.call(thisArg, args[0]);\n    case 2: return func.call(thisArg, args[0], args[1]);\n    case 3: return func.call(thisArg, args[0], args[1], args[2]);\n  }\n  return func.apply(thisArg, args);\n}\n\n/**\n * A specialized version of `_.forEach` for arrays without support for\n * iteratee shorthands.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} iteratee The function invoked per iteration.\n * @returns {Array} Returns `array`.\n */\nfunction arrayEach(array, iteratee) {\n  var index = -1,\n      length = array ? array.length : 0;\n\n  while (++index < length) {\n    if (iteratee(array[index], index, array) === false) {\n      break;\n    }\n  }\n  return array;\n}\n\n/**\n * Appends the elements of `values` to `array`.\n *\n * @private\n * @param {Array} array The array to modify.\n * @param {Array} values The values to append.\n * @returns {Array} Returns `array`.\n */\nfunction arrayPush(array, values) {\n  var index = -1,\n      length = values.length,\n      offset = array.length;\n\n  while (++index < length) {\n    array[offset + index] = values[index];\n  }\n  return array;\n}\n\n/**\n * A specialized version of `_.reduce` for arrays without support for\n * iteratee shorthands.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} iteratee The function invoked per iteration.\n * @param {*} [accumulator] The initial value.\n * @param {boolean} [initAccum] Specify using the first element of `array` as\n *  the initial value.\n * @returns {*} Returns the accumulated value.\n */\nfunction arrayReduce(array, iteratee, accumulator, initAccum) {\n  var index = -1,\n      length = array ? array.length : 0;\n\n  if (initAccum && length) {\n    accumulator = array[++index];\n  }\n  while (++index < length) {\n    accumulator = iteratee(accumulator, array[index], index, array);\n  }\n  return accumulator;\n}\n\n/**\n * The base implementation of `_.times` without support for iteratee shorthands\n * or max array length checks.\n *\n * @private\n * @param {number} n The number of times to invoke `iteratee`.\n * @param {Function} iteratee The function invoked per iteration.\n * @returns {Array} Returns the array of results.\n */\nfunction baseTimes(n, iteratee) {\n  var index = -1,\n      result = Array(n);\n\n  while (++index < n) {\n    result[index] = iteratee(index);\n  }\n  return result;\n}\n\n/**\n * The base implementation of `_.unary` without support for storing metadata.\n *\n * @private\n * @param {Function} func The function to cap arguments for.\n * @returns {Function} Returns the new capped function.\n */\nfunction baseUnary(func) {\n  return function(value) {\n    return func(value);\n  };\n}\n\n/**\n * Gets the value at `key` of `object`.\n *\n * @private\n * @param {Object} [object] The object to query.\n * @param {string} key The key of the property to get.\n * @returns {*} Returns the property value.\n */\nfunction getValue(object, key) {\n  return object == null ? undefined : object[key];\n}\n\n/**\n * Checks if `value` is a host object in IE < 9.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a host object, else `false`.\n */\nfunction isHostObject(value) {\n  // Many host objects are `Object` objects that can coerce to strings\n  // despite having improperly defined `toString` methods.\n  var result = false;\n  if (value != null && typeof value.toString != 'function') {\n    try {\n      result = !!(value + '');\n    } catch (e) {}\n  }\n  return result;\n}\n\n/**\n * Converts `map` to its key-value pairs.\n *\n * @private\n * @param {Object} map The map to convert.\n * @returns {Array} Returns the key-value pairs.\n */\nfunction mapToArray(map) {\n  var index = -1,\n      result = Array(map.size);\n\n  map.forEach(function(value, key) {\n    result[++index] = [key, value];\n  });\n  return result;\n}\n\n/**\n * Creates a unary function that invokes `func` with its argument transformed.\n *\n * @private\n * @param {Function} func The function to wrap.\n * @param {Function} transform The argument transform.\n * @returns {Function} Returns the new function.\n */\nfunction overArg(func, transform) {\n  return function(arg) {\n    return func(transform(arg));\n  };\n}\n\n/**\n * Converts `set` to an array of its values.\n *\n * @private\n * @param {Object} set The set to convert.\n * @returns {Array} Returns the values.\n */\nfunction setToArray(set) {\n  var index = -1,\n      result = Array(set.size);\n\n  set.forEach(function(value) {\n    result[++index] = value;\n  });\n  return result;\n}\n\n/** Used for built-in method references. */\nvar arrayProto = Array.prototype,\n    funcProto = Function.prototype,\n    objectProto = Object.prototype;\n\n/** Used to detect overreaching core-js shims. */\nvar coreJsData = root['__core-js_shared__'];\n\n/** Used to detect methods masquerading as native. */\nvar maskSrcKey = (function() {\n  var uid = /[^.]+$/.exec(coreJsData && coreJsData.keys && coreJsData.keys.IE_PROTO || '');\n  return uid ? ('Symbol(src)_1.' + uid) : '';\n}());\n\n/** Used to resolve the decompiled source of functions. */\nvar funcToString = funcProto.toString;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/** Used to infer the `Object` constructor. */\nvar objectCtorString = funcToString.call(Object);\n\n/**\n * Used to resolve the\n * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)\n * of values.\n */\nvar objectToString = objectProto.toString;\n\n/** Used to detect if a method is native. */\nvar reIsNative = RegExp('^' +\n  funcToString.call(hasOwnProperty).replace(reRegExpChar, '\\\\$&')\n  .replace(/hasOwnProperty|(function).*?(?=\\\\\\()| for .+?(?=\\\\\\])/g, '$1.*?') + '$'\n);\n\n/** Built-in value references. */\nvar Buffer = moduleExports ? root.Buffer : undefined,\n    Symbol = root.Symbol,\n    Uint8Array = root.Uint8Array,\n    getPrototype = overArg(Object.getPrototypeOf, Object),\n    objectCreate = Object.create,\n    propertyIsEnumerable = objectProto.propertyIsEnumerable,\n    splice = arrayProto.splice;\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeGetSymbols = Object.getOwnPropertySymbols,\n    nativeIsBuffer = Buffer ? Buffer.isBuffer : undefined,\n    nativeKeys = overArg(Object.keys, Object),\n    nativeMax = Math.max;\n\n/* Built-in method references that are verified to be native. */\nvar DataView = getNative(root, 'DataView'),\n    Map = getNative(root, 'Map'),\n    Promise = getNative(root, 'Promise'),\n    Set = getNative(root, 'Set'),\n    WeakMap = getNative(root, 'WeakMap'),\n    nativeCreate = getNative(Object, 'create');\n\n/** Used to detect maps, sets, and weakmaps. */\nvar dataViewCtorString = toSource(DataView),\n    mapCtorString = toSource(Map),\n    promiseCtorString = toSource(Promise),\n    setCtorString = toSource(Set),\n    weakMapCtorString = toSource(WeakMap);\n\n/** Used to convert symbols to primitives and strings. */\nvar symbolProto = Symbol ? Symbol.prototype : undefined,\n    symbolValueOf = symbolProto ? symbolProto.valueOf : undefined;\n\n/**\n * Creates a hash object.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction Hash(entries) {\n  var index = -1,\n      length = entries ? entries.length : 0;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n/**\n * Removes all key-value entries from the hash.\n *\n * @private\n * @name clear\n * @memberOf Hash\n */\nfunction hashClear() {\n  this.__data__ = nativeCreate ? nativeCreate(null) : {};\n}\n\n/**\n * Removes `key` and its value from the hash.\n *\n * @private\n * @name delete\n * @memberOf Hash\n * @param {Object} hash The hash to modify.\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction hashDelete(key) {\n  return this.has(key) && delete this.__data__[key];\n}\n\n/**\n * Gets the hash value for `key`.\n *\n * @private\n * @name get\n * @memberOf Hash\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction hashGet(key) {\n  var data = this.__data__;\n  if (nativeCreate) {\n    var result = data[key];\n    return result === HASH_UNDEFINED ? undefined : result;\n  }\n  return hasOwnProperty.call(data, key) ? data[key] : undefined;\n}\n\n/**\n * Checks if a hash value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf Hash\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction hashHas(key) {\n  var data = this.__data__;\n  return nativeCreate ? data[key] !== undefined : hasOwnProperty.call(data, key);\n}\n\n/**\n * Sets the hash `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf Hash\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the hash instance.\n */\nfunction hashSet(key, value) {\n  var data = this.__data__;\n  data[key] = (nativeCreate && value === undefined) ? HASH_UNDEFINED : value;\n  return this;\n}\n\n// Add methods to `Hash`.\nHash.prototype.clear = hashClear;\nHash.prototype['delete'] = hashDelete;\nHash.prototype.get = hashGet;\nHash.prototype.has = hashHas;\nHash.prototype.set = hashSet;\n\n/**\n * Creates an list cache object.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction ListCache(entries) {\n  var index = -1,\n      length = entries ? entries.length : 0;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n/**\n * Removes all key-value entries from the list cache.\n *\n * @private\n * @name clear\n * @memberOf ListCache\n */\nfunction listCacheClear() {\n  this.__data__ = [];\n}\n\n/**\n * Removes `key` and its value from the list cache.\n *\n * @private\n * @name delete\n * @memberOf ListCache\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction listCacheDelete(key) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  if (index < 0) {\n    return false;\n  }\n  var lastIndex = data.length - 1;\n  if (index == lastIndex) {\n    data.pop();\n  } else {\n    splice.call(data, index, 1);\n  }\n  return true;\n}\n\n/**\n * Gets the list cache value for `key`.\n *\n * @private\n * @name get\n * @memberOf ListCache\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction listCacheGet(key) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  return index < 0 ? undefined : data[index][1];\n}\n\n/**\n * Checks if a list cache value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf ListCache\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction listCacheHas(key) {\n  return assocIndexOf(this.__data__, key) > -1;\n}\n\n/**\n * Sets the list cache `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf ListCache\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the list cache instance.\n */\nfunction listCacheSet(key, value) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  if (index < 0) {\n    data.push([key, value]);\n  } else {\n    data[index][1] = value;\n  }\n  return this;\n}\n\n// Add methods to `ListCache`.\nListCache.prototype.clear = listCacheClear;\nListCache.prototype['delete'] = listCacheDelete;\nListCache.prototype.get = listCacheGet;\nListCache.prototype.has = listCacheHas;\nListCache.prototype.set = listCacheSet;\n\n/**\n * Creates a map cache object to store key-value pairs.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction MapCache(entries) {\n  var index = -1,\n      length = entries ? entries.length : 0;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n/**\n * Removes all key-value entries from the map.\n *\n * @private\n * @name clear\n * @memberOf MapCache\n */\nfunction mapCacheClear() {\n  this.__data__ = {\n    'hash': new Hash,\n    'map': new (Map || ListCache),\n    'string': new Hash\n  };\n}\n\n/**\n * Removes `key` and its value from the map.\n *\n * @private\n * @name delete\n * @memberOf MapCache\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction mapCacheDelete(key) {\n  return getMapData(this, key)['delete'](key);\n}\n\n/**\n * Gets the map value for `key`.\n *\n * @private\n * @name get\n * @memberOf MapCache\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction mapCacheGet(key) {\n  return getMapData(this, key).get(key);\n}\n\n/**\n * Checks if a map value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf MapCache\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction mapCacheHas(key) {\n  return getMapData(this, key).has(key);\n}\n\n/**\n * Sets the map `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf MapCache\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the map cache instance.\n */\nfunction mapCacheSet(key, value) {\n  getMapData(this, key).set(key, value);\n  return this;\n}\n\n// Add methods to `MapCache`.\nMapCache.prototype.clear = mapCacheClear;\nMapCache.prototype['delete'] = mapCacheDelete;\nMapCache.prototype.get = mapCacheGet;\nMapCache.prototype.has = mapCacheHas;\nMapCache.prototype.set = mapCacheSet;\n\n/**\n * Creates a stack cache object to store key-value pairs.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction Stack(entries) {\n  this.__data__ = new ListCache(entries);\n}\n\n/**\n * Removes all key-value entries from the stack.\n *\n * @private\n * @name clear\n * @memberOf Stack\n */\nfunction stackClear() {\n  this.__data__ = new ListCache;\n}\n\n/**\n * Removes `key` and its value from the stack.\n *\n * @private\n * @name delete\n * @memberOf Stack\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction stackDelete(key) {\n  return this.__data__['delete'](key);\n}\n\n/**\n * Gets the stack value for `key`.\n *\n * @private\n * @name get\n * @memberOf Stack\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction stackGet(key) {\n  return this.__data__.get(key);\n}\n\n/**\n * Checks if a stack value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf Stack\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction stackHas(key) {\n  return this.__data__.has(key);\n}\n\n/**\n * Sets the stack `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf Stack\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the stack cache instance.\n */\nfunction stackSet(key, value) {\n  var cache = this.__data__;\n  if (cache instanceof ListCache) {\n    var pairs = cache.__data__;\n    if (!Map || (pairs.length < LARGE_ARRAY_SIZE - 1)) {\n      pairs.push([key, value]);\n      return this;\n    }\n    cache = this.__data__ = new MapCache(pairs);\n  }\n  cache.set(key, value);\n  return this;\n}\n\n// Add methods to `Stack`.\nStack.prototype.clear = stackClear;\nStack.prototype['delete'] = stackDelete;\nStack.prototype.get = stackGet;\nStack.prototype.has = stackHas;\nStack.prototype.set = stackSet;\n\n/**\n * Creates an array of the enumerable property names of the array-like `value`.\n *\n * @private\n * @param {*} value The value to query.\n * @param {boolean} inherited Specify returning inherited property names.\n * @returns {Array} Returns the array of property names.\n */\nfunction arrayLikeKeys(value, inherited) {\n  // Safari 8.1 makes `arguments.callee` enumerable in strict mode.\n  // Safari 9 makes `arguments.length` enumerable in strict mode.\n  var result = (isArray(value) || isArguments(value))\n    ? baseTimes(value.length, String)\n    : [];\n\n  var length = result.length,\n      skipIndexes = !!length;\n\n  for (var key in value) {\n    if ((inherited || hasOwnProperty.call(value, key)) &&\n        !(skipIndexes && (key == 'length' || isIndex(key, length)))) {\n      result.push(key);\n    }\n  }\n  return result;\n}\n\n/**\n * This function is like `assignValue` except that it doesn't assign\n * `undefined` values.\n *\n * @private\n * @param {Object} object The object to modify.\n * @param {string} key The key of the property to assign.\n * @param {*} value The value to assign.\n */\nfunction assignMergeValue(object, key, value) {\n  if ((value !== undefined && !eq(object[key], value)) ||\n      (typeof key == 'number' && value === undefined && !(key in object))) {\n    object[key] = value;\n  }\n}\n\n/**\n * Assigns `value` to `key` of `object` if the existing value is not equivalent\n * using [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons.\n *\n * @private\n * @param {Object} object The object to modify.\n * @param {string} key The key of the property to assign.\n * @param {*} value The value to assign.\n */\nfunction assignValue(object, key, value) {\n  var objValue = object[key];\n  if (!(hasOwnProperty.call(object, key) && eq(objValue, value)) ||\n      (value === undefined && !(key in object))) {\n    object[key] = value;\n  }\n}\n\n/**\n * Gets the index at which the `key` is found in `array` of key-value pairs.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {*} key The key to search for.\n * @returns {number} Returns the index of the matched value, else `-1`.\n */\nfunction assocIndexOf(array, key) {\n  var length = array.length;\n  while (length--) {\n    if (eq(array[length][0], key)) {\n      return length;\n    }\n  }\n  return -1;\n}\n\n/**\n * The base implementation of `_.assign` without support for multiple sources\n * or `customizer` functions.\n *\n * @private\n * @param {Object} object The destination object.\n * @param {Object} source The source object.\n * @returns {Object} Returns `object`.\n */\nfunction baseAssign(object, source) {\n  return object && copyObject(source, keys(source), object);\n}\n\n/**\n * The base implementation of `_.clone` and `_.cloneDeep` which tracks\n * traversed objects.\n *\n * @private\n * @param {*} value The value to clone.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @param {boolean} [isFull] Specify a clone including symbols.\n * @param {Function} [customizer] The function to customize cloning.\n * @param {string} [key] The key of `value`.\n * @param {Object} [object] The parent object of `value`.\n * @param {Object} [stack] Tracks traversed objects and their clone counterparts.\n * @returns {*} Returns the cloned value.\n */\nfunction baseClone(value, isDeep, isFull, customizer, key, object, stack) {\n  var result;\n  if (customizer) {\n    result = object ? customizer(value, key, object, stack) : customizer(value);\n  }\n  if (result !== undefined) {\n    return result;\n  }\n  if (!isObject(value)) {\n    return value;\n  }\n  var isArr = isArray(value);\n  if (isArr) {\n    result = initCloneArray(value);\n    if (!isDeep) {\n      return copyArray(value, result);\n    }\n  } else {\n    var tag = getTag(value),\n        isFunc = tag == funcTag || tag == genTag;\n\n    if (isBuffer(value)) {\n      return cloneBuffer(value, isDeep);\n    }\n    if (tag == objectTag || tag == argsTag || (isFunc && !object)) {\n      if (isHostObject(value)) {\n        return object ? value : {};\n      }\n      result = initCloneObject(isFunc ? {} : value);\n      if (!isDeep) {\n        return copySymbols(value, baseAssign(result, value));\n      }\n    } else {\n      if (!cloneableTags[tag]) {\n        return object ? value : {};\n      }\n      result = initCloneByTag(value, tag, baseClone, isDeep);\n    }\n  }\n  // Check for circular references and return its corresponding clone.\n  stack || (stack = new Stack);\n  var stacked = stack.get(value);\n  if (stacked) {\n    return stacked;\n  }\n  stack.set(value, result);\n\n  if (!isArr) {\n    var props = isFull ? getAllKeys(value) : keys(value);\n  }\n  arrayEach(props || value, function(subValue, key) {\n    if (props) {\n      key = subValue;\n      subValue = value[key];\n    }\n    // Recursively populate clone (susceptible to call stack limits).\n    assignValue(result, key, baseClone(subValue, isDeep, isFull, customizer, key, value, stack));\n  });\n  return result;\n}\n\n/**\n * The base implementation of `_.create` without support for assigning\n * properties to the created object.\n *\n * @private\n * @param {Object} prototype The object to inherit from.\n * @returns {Object} Returns the new object.\n */\nfunction baseCreate(proto) {\n  return isObject(proto) ? objectCreate(proto) : {};\n}\n\n/**\n * The base implementation of `getAllKeys` and `getAllKeysIn` which uses\n * `keysFunc` and `symbolsFunc` to get the enumerable property names and\n * symbols of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @param {Function} keysFunc The function to get the keys of `object`.\n * @param {Function} symbolsFunc The function to get the symbols of `object`.\n * @returns {Array} Returns the array of property names and symbols.\n */\nfunction baseGetAllKeys(object, keysFunc, symbolsFunc) {\n  var result = keysFunc(object);\n  return isArray(object) ? result : arrayPush(result, symbolsFunc(object));\n}\n\n/**\n * The base implementation of `getTag`.\n *\n * @private\n * @param {*} value The value to query.\n * @returns {string} Returns the `toStringTag`.\n */\nfunction baseGetTag(value) {\n  return objectToString.call(value);\n}\n\n/**\n * The base implementation of `_.isNative` without bad shim checks.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a native function,\n *  else `false`.\n */\nfunction baseIsNative(value) {\n  if (!isObject(value) || isMasked(value)) {\n    return false;\n  }\n  var pattern = (isFunction(value) || isHostObject(value)) ? reIsNative : reIsHostCtor;\n  return pattern.test(toSource(value));\n}\n\n/**\n * The base implementation of `_.isTypedArray` without Node.js optimizations.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a typed array, else `false`.\n */\nfunction baseIsTypedArray(value) {\n  return isObjectLike(value) &&\n    isLength(value.length) && !!typedArrayTags[objectToString.call(value)];\n}\n\n/**\n * The base implementation of `_.keys` which doesn't treat sparse arrays as dense.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n */\nfunction baseKeys(object) {\n  if (!isPrototype(object)) {\n    return nativeKeys(object);\n  }\n  var result = [];\n  for (var key in Object(object)) {\n    if (hasOwnProperty.call(object, key) && key != 'constructor') {\n      result.push(key);\n    }\n  }\n  return result;\n}\n\n/**\n * The base implementation of `_.keysIn` which doesn't treat sparse arrays as dense.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n */\nfunction baseKeysIn(object) {\n  if (!isObject(object)) {\n    return nativeKeysIn(object);\n  }\n  var isProto = isPrototype(object),\n      result = [];\n\n  for (var key in object) {\n    if (!(key == 'constructor' && (isProto || !hasOwnProperty.call(object, key)))) {\n      result.push(key);\n    }\n  }\n  return result;\n}\n\n/**\n * The base implementation of `_.merge` without support for multiple sources.\n *\n * @private\n * @param {Object} object The destination object.\n * @param {Object} source The source object.\n * @param {number} srcIndex The index of `source`.\n * @param {Function} [customizer] The function to customize merged values.\n * @param {Object} [stack] Tracks traversed source values and their merged\n *  counterparts.\n */\nfunction baseMerge(object, source, srcIndex, customizer, stack) {\n  if (object === source) {\n    return;\n  }\n  if (!(isArray(source) || isTypedArray(source))) {\n    var props = baseKeysIn(source);\n  }\n  arrayEach(props || source, function(srcValue, key) {\n    if (props) {\n      key = srcValue;\n      srcValue = source[key];\n    }\n    if (isObject(srcValue)) {\n      stack || (stack = new Stack);\n      baseMergeDeep(object, source, key, srcIndex, baseMerge, customizer, stack);\n    }\n    else {\n      var newValue = customizer\n        ? customizer(object[key], srcValue, (key + ''), object, source, stack)\n        : undefined;\n\n      if (newValue === undefined) {\n        newValue = srcValue;\n      }\n      assignMergeValue(object, key, newValue);\n    }\n  });\n}\n\n/**\n * A specialized version of `baseMerge` for arrays and objects which performs\n * deep merges and tracks traversed objects enabling objects with circular\n * references to be merged.\n *\n * @private\n * @param {Object} object The destination object.\n * @param {Object} source The source object.\n * @param {string} key The key of the value to merge.\n * @param {number} srcIndex The index of `source`.\n * @param {Function} mergeFunc The function to merge values.\n * @param {Function} [customizer] The function to customize assigned values.\n * @param {Object} [stack] Tracks traversed source values and their merged\n *  counterparts.\n */\nfunction baseMergeDeep(object, source, key, srcIndex, mergeFunc, customizer, stack) {\n  var objValue = object[key],\n      srcValue = source[key],\n      stacked = stack.get(srcValue);\n\n  if (stacked) {\n    assignMergeValue(object, key, stacked);\n    return;\n  }\n  var newValue = customizer\n    ? customizer(objValue, srcValue, (key + ''), object, source, stack)\n    : undefined;\n\n  var isCommon = newValue === undefined;\n\n  if (isCommon) {\n    newValue = srcValue;\n    if (isArray(srcValue) || isTypedArray(srcValue)) {\n      if (isArray(objValue)) {\n        newValue = objValue;\n      }\n      else if (isArrayLikeObject(objValue)) {\n        newValue = copyArray(objValue);\n      }\n      else {\n        isCommon = false;\n        newValue = baseClone(srcValue, true);\n      }\n    }\n    else if (isPlainObject(srcValue) || isArguments(srcValue)) {\n      if (isArguments(objValue)) {\n        newValue = toPlainObject(objValue);\n      }\n      else if (!isObject(objValue) || (srcIndex && isFunction(objValue))) {\n        isCommon = false;\n        newValue = baseClone(srcValue, true);\n      }\n      else {\n        newValue = objValue;\n      }\n    }\n    else {\n      isCommon = false;\n    }\n  }\n  if (isCommon) {\n    // Recursively merge objects and arrays (susceptible to call stack limits).\n    stack.set(srcValue, newValue);\n    mergeFunc(newValue, srcValue, srcIndex, customizer, stack);\n    stack['delete'](srcValue);\n  }\n  assignMergeValue(object, key, newValue);\n}\n\n/**\n * The base implementation of `_.rest` which doesn't validate or coerce arguments.\n *\n * @private\n * @param {Function} func The function to apply a rest parameter to.\n * @param {number} [start=func.length-1] The start position of the rest parameter.\n * @returns {Function} Returns the new function.\n */\nfunction baseRest(func, start) {\n  start = nativeMax(start === undefined ? (func.length - 1) : start, 0);\n  return function() {\n    var args = arguments,\n        index = -1,\n        length = nativeMax(args.length - start, 0),\n        array = Array(length);\n\n    while (++index < length) {\n      array[index] = args[start + index];\n    }\n    index = -1;\n    var otherArgs = Array(start + 1);\n    while (++index < start) {\n      otherArgs[index] = args[index];\n    }\n    otherArgs[start] = array;\n    return apply(func, this, otherArgs);\n  };\n}\n\n/**\n * Creates a clone of  `buffer`.\n *\n * @private\n * @param {Buffer} buffer The buffer to clone.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Buffer} Returns the cloned buffer.\n */\nfunction cloneBuffer(buffer, isDeep) {\n  if (isDeep) {\n    return buffer.slice();\n  }\n  var result = new buffer.constructor(buffer.length);\n  buffer.copy(result);\n  return result;\n}\n\n/**\n * Creates a clone of `arrayBuffer`.\n *\n * @private\n * @param {ArrayBuffer} arrayBuffer The array buffer to clone.\n * @returns {ArrayBuffer} Returns the cloned array buffer.\n */\nfunction cloneArrayBuffer(arrayBuffer) {\n  var result = new arrayBuffer.constructor(arrayBuffer.byteLength);\n  new Uint8Array(result).set(new Uint8Array(arrayBuffer));\n  return result;\n}\n\n/**\n * Creates a clone of `dataView`.\n *\n * @private\n * @param {Object} dataView The data view to clone.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Object} Returns the cloned data view.\n */\nfunction cloneDataView(dataView, isDeep) {\n  var buffer = isDeep ? cloneArrayBuffer(dataView.buffer) : dataView.buffer;\n  return new dataView.constructor(buffer, dataView.byteOffset, dataView.byteLength);\n}\n\n/**\n * Creates a clone of `map`.\n *\n * @private\n * @param {Object} map The map to clone.\n * @param {Function} cloneFunc The function to clone values.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Object} Returns the cloned map.\n */\nfunction cloneMap(map, isDeep, cloneFunc) {\n  var array = isDeep ? cloneFunc(mapToArray(map), true) : mapToArray(map);\n  return arrayReduce(array, addMapEntry, new map.constructor);\n}\n\n/**\n * Creates a clone of `regexp`.\n *\n * @private\n * @param {Object} regexp The regexp to clone.\n * @returns {Object} Returns the cloned regexp.\n */\nfunction cloneRegExp(regexp) {\n  var result = new regexp.constructor(regexp.source, reFlags.exec(regexp));\n  result.lastIndex = regexp.lastIndex;\n  return result;\n}\n\n/**\n * Creates a clone of `set`.\n *\n * @private\n * @param {Object} set The set to clone.\n * @param {Function} cloneFunc The function to clone values.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Object} Returns the cloned set.\n */\nfunction cloneSet(set, isDeep, cloneFunc) {\n  var array = isDeep ? cloneFunc(setToArray(set), true) : setToArray(set);\n  return arrayReduce(array, addSetEntry, new set.constructor);\n}\n\n/**\n * Creates a clone of the `symbol` object.\n *\n * @private\n * @param {Object} symbol The symbol object to clone.\n * @returns {Object} Returns the cloned symbol object.\n */\nfunction cloneSymbol(symbol) {\n  return symbolValueOf ? Object(symbolValueOf.call(symbol)) : {};\n}\n\n/**\n * Creates a clone of `typedArray`.\n *\n * @private\n * @param {Object} typedArray The typed array to clone.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Object} Returns the cloned typed array.\n */\nfunction cloneTypedArray(typedArray, isDeep) {\n  var buffer = isDeep ? cloneArrayBuffer(typedArray.buffer) : typedArray.buffer;\n  return new typedArray.constructor(buffer, typedArray.byteOffset, typedArray.length);\n}\n\n/**\n * Copies the values of `source` to `array`.\n *\n * @private\n * @param {Array} source The array to copy values from.\n * @param {Array} [array=[]] The array to copy values to.\n * @returns {Array} Returns `array`.\n */\nfunction copyArray(source, array) {\n  var index = -1,\n      length = source.length;\n\n  array || (array = Array(length));\n  while (++index < length) {\n    array[index] = source[index];\n  }\n  return array;\n}\n\n/**\n * Copies properties of `source` to `object`.\n *\n * @private\n * @param {Object} source The object to copy properties from.\n * @param {Array} props The property identifiers to copy.\n * @param {Object} [object={}] The object to copy properties to.\n * @param {Function} [customizer] The function to customize copied values.\n * @returns {Object} Returns `object`.\n */\nfunction copyObject(source, props, object, customizer) {\n  object || (object = {});\n\n  var index = -1,\n      length = props.length;\n\n  while (++index < length) {\n    var key = props[index];\n\n    var newValue = customizer\n      ? customizer(object[key], source[key], key, object, source)\n      : undefined;\n\n    assignValue(object, key, newValue === undefined ? source[key] : newValue);\n  }\n  return object;\n}\n\n/**\n * Copies own symbol properties of `source` to `object`.\n *\n * @private\n * @param {Object} source The object to copy symbols from.\n * @param {Object} [object={}] The object to copy symbols to.\n * @returns {Object} Returns `object`.\n */\nfunction copySymbols(source, object) {\n  return copyObject(source, getSymbols(source), object);\n}\n\n/**\n * Creates a function like `_.assign`.\n *\n * @private\n * @param {Function} assigner The function to assign values.\n * @returns {Function} Returns the new assigner function.\n */\nfunction createAssigner(assigner) {\n  return baseRest(function(object, sources) {\n    var index = -1,\n        length = sources.length,\n        customizer = length > 1 ? sources[length - 1] : undefined,\n        guard = length > 2 ? sources[2] : undefined;\n\n    customizer = (assigner.length > 3 && typeof customizer == 'function')\n      ? (length--, customizer)\n      : undefined;\n\n    if (guard && isIterateeCall(sources[0], sources[1], guard)) {\n      customizer = length < 3 ? undefined : customizer;\n      length = 1;\n    }\n    object = Object(object);\n    while (++index < length) {\n      var source = sources[index];\n      if (source) {\n        assigner(object, source, index, customizer);\n      }\n    }\n    return object;\n  });\n}\n\n/**\n * Creates an array of own enumerable property names and symbols of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names and symbols.\n */\nfunction getAllKeys(object) {\n  return baseGetAllKeys(object, keys, getSymbols);\n}\n\n/**\n * Gets the data for `map`.\n *\n * @private\n * @param {Object} map The map to query.\n * @param {string} key The reference key.\n * @returns {*} Returns the map data.\n */\nfunction getMapData(map, key) {\n  var data = map.__data__;\n  return isKeyable(key)\n    ? data[typeof key == 'string' ? 'string' : 'hash']\n    : data.map;\n}\n\n/**\n * Gets the native function at `key` of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @param {string} key The key of the method to get.\n * @returns {*} Returns the function if it's native, else `undefined`.\n */\nfunction getNative(object, key) {\n  var value = getValue(object, key);\n  return baseIsNative(value) ? value : undefined;\n}\n\n/**\n * Creates an array of the own enumerable symbol properties of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of symbols.\n */\nvar getSymbols = nativeGetSymbols ? overArg(nativeGetSymbols, Object) : stubArray;\n\n/**\n * Gets the `toStringTag` of `value`.\n *\n * @private\n * @param {*} value The value to query.\n * @returns {string} Returns the `toStringTag`.\n */\nvar getTag = baseGetTag;\n\n// Fallback for data views, maps, sets, and weak maps in IE 11,\n// for data views in Edge < 14, and promises in Node.js.\nif ((DataView && getTag(new DataView(new ArrayBuffer(1))) != dataViewTag) ||\n    (Map && getTag(new Map) != mapTag) ||\n    (Promise && getTag(Promise.resolve()) != promiseTag) ||\n    (Set && getTag(new Set) != setTag) ||\n    (WeakMap && getTag(new WeakMap) != weakMapTag)) {\n  getTag = function(value) {\n    var result = objectToString.call(value),\n        Ctor = result == objectTag ? value.constructor : undefined,\n        ctorString = Ctor ? toSource(Ctor) : undefined;\n\n    if (ctorString) {\n      switch (ctorString) {\n        case dataViewCtorString: return dataViewTag;\n        case mapCtorString: return mapTag;\n        case promiseCtorString: return promiseTag;\n        case setCtorString: return setTag;\n        case weakMapCtorString: return weakMapTag;\n      }\n    }\n    return result;\n  };\n}\n\n/**\n * Initializes an array clone.\n *\n * @private\n * @param {Array} array The array to clone.\n * @returns {Array} Returns the initialized clone.\n */\nfunction initCloneArray(array) {\n  var length = array.length,\n      result = array.constructor(length);\n\n  // Add properties assigned by `RegExp#exec`.\n  if (length && typeof array[0] == 'string' && hasOwnProperty.call(array, 'index')) {\n    result.index = array.index;\n    result.input = array.input;\n  }\n  return result;\n}\n\n/**\n * Initializes an object clone.\n *\n * @private\n * @param {Object} object The object to clone.\n * @returns {Object} Returns the initialized clone.\n */\nfunction initCloneObject(object) {\n  return (typeof object.constructor == 'function' && !isPrototype(object))\n    ? baseCreate(getPrototype(object))\n    : {};\n}\n\n/**\n * Initializes an object clone based on its `toStringTag`.\n *\n * **Note:** This function only supports cloning values with tags of\n * `Boolean`, `Date`, `Error`, `Number`, `RegExp`, or `String`.\n *\n * @private\n * @param {Object} object The object to clone.\n * @param {string} tag The `toStringTag` of the object to clone.\n * @param {Function} cloneFunc The function to clone values.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Object} Returns the initialized clone.\n */\nfunction initCloneByTag(object, tag, cloneFunc, isDeep) {\n  var Ctor = object.constructor;\n  switch (tag) {\n    case arrayBufferTag:\n      return cloneArrayBuffer(object);\n\n    case boolTag:\n    case dateTag:\n      return new Ctor(+object);\n\n    case dataViewTag:\n      return cloneDataView(object, isDeep);\n\n    case float32Tag: case float64Tag:\n    case int8Tag: case int16Tag: case int32Tag:\n    case uint8Tag: case uint8ClampedTag: case uint16Tag: case uint32Tag:\n      return cloneTypedArray(object, isDeep);\n\n    case mapTag:\n      return cloneMap(object, isDeep, cloneFunc);\n\n    case numberTag:\n    case stringTag:\n      return new Ctor(object);\n\n    case regexpTag:\n      return cloneRegExp(object);\n\n    case setTag:\n      return cloneSet(object, isDeep, cloneFunc);\n\n    case symbolTag:\n      return cloneSymbol(object);\n  }\n}\n\n/**\n * Checks if `value` is a valid array-like index.\n *\n * @private\n * @param {*} value The value to check.\n * @param {number} [length=MAX_SAFE_INTEGER] The upper bounds of a valid index.\n * @returns {boolean} Returns `true` if `value` is a valid index, else `false`.\n */\nfunction isIndex(value, length) {\n  length = length == null ? MAX_SAFE_INTEGER : length;\n  return !!length &&\n    (typeof value == 'number' || reIsUint.test(value)) &&\n    (value > -1 && value % 1 == 0 && value < length);\n}\n\n/**\n * Checks if the given arguments are from an iteratee call.\n *\n * @private\n * @param {*} value The potential iteratee value argument.\n * @param {*} index The potential iteratee index or key argument.\n * @param {*} object The potential iteratee object argument.\n * @returns {boolean} Returns `true` if the arguments are from an iteratee call,\n *  else `false`.\n */\nfunction isIterateeCall(value, index, object) {\n  if (!isObject(object)) {\n    return false;\n  }\n  var type = typeof index;\n  if (type == 'number'\n        ? (isArrayLike(object) && isIndex(index, object.length))\n        : (type == 'string' && index in object)\n      ) {\n    return eq(object[index], value);\n  }\n  return false;\n}\n\n/**\n * Checks if `value` is suitable for use as unique object key.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is suitable, else `false`.\n */\nfunction isKeyable(value) {\n  var type = typeof value;\n  return (type == 'string' || type == 'number' || type == 'symbol' || type == 'boolean')\n    ? (value !== '__proto__')\n    : (value === null);\n}\n\n/**\n * Checks if `func` has its source masked.\n *\n * @private\n * @param {Function} func The function to check.\n * @returns {boolean} Returns `true` if `func` is masked, else `false`.\n */\nfunction isMasked(func) {\n  return !!maskSrcKey && (maskSrcKey in func);\n}\n\n/**\n * Checks if `value` is likely a prototype object.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a prototype, else `false`.\n */\nfunction isPrototype(value) {\n  var Ctor = value && value.constructor,\n      proto = (typeof Ctor == 'function' && Ctor.prototype) || objectProto;\n\n  return value === proto;\n}\n\n/**\n * This function is like\n * [`Object.keys`](http://ecma-international.org/ecma-262/7.0/#sec-object.keys)\n * except that it includes inherited enumerable properties.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n */\nfunction nativeKeysIn(object) {\n  var result = [];\n  if (object != null) {\n    for (var key in Object(object)) {\n      result.push(key);\n    }\n  }\n  return result;\n}\n\n/**\n * Converts `func` to its source code.\n *\n * @private\n * @param {Function} func The function to process.\n * @returns {string} Returns the source code.\n */\nfunction toSource(func) {\n  if (func != null) {\n    try {\n      return funcToString.call(func);\n    } catch (e) {}\n    try {\n      return (func + '');\n    } catch (e) {}\n  }\n  return '';\n}\n\n/**\n * Performs a\n * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * comparison between two values to determine if they are equivalent.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to compare.\n * @param {*} other The other value to compare.\n * @returns {boolean} Returns `true` if the values are equivalent, else `false`.\n * @example\n *\n * var object = { 'a': 1 };\n * var other = { 'a': 1 };\n *\n * _.eq(object, object);\n * // => true\n *\n * _.eq(object, other);\n * // => false\n *\n * _.eq('a', 'a');\n * // => true\n *\n * _.eq('a', Object('a'));\n * // => false\n *\n * _.eq(NaN, NaN);\n * // => true\n */\nfunction eq(value, other) {\n  return value === other || (value !== value && other !== other);\n}\n\n/**\n * Checks if `value` is likely an `arguments` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an `arguments` object,\n *  else `false`.\n * @example\n *\n * _.isArguments(function() { return arguments; }());\n * // => true\n *\n * _.isArguments([1, 2, 3]);\n * // => false\n */\nfunction isArguments(value) {\n  // Safari 8.1 makes `arguments.callee` enumerable in strict mode.\n  return isArrayLikeObject(value) && hasOwnProperty.call(value, 'callee') &&\n    (!propertyIsEnumerable.call(value, 'callee') || objectToString.call(value) == argsTag);\n}\n\n/**\n * Checks if `value` is classified as an `Array` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an array, else `false`.\n * @example\n *\n * _.isArray([1, 2, 3]);\n * // => true\n *\n * _.isArray(document.body.children);\n * // => false\n *\n * _.isArray('abc');\n * // => false\n *\n * _.isArray(_.noop);\n * // => false\n */\nvar isArray = Array.isArray;\n\n/**\n * Checks if `value` is array-like. A value is considered array-like if it's\n * not a function and has a `value.length` that's an integer greater than or\n * equal to `0` and less than or equal to `Number.MAX_SAFE_INTEGER`.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is array-like, else `false`.\n * @example\n *\n * _.isArrayLike([1, 2, 3]);\n * // => true\n *\n * _.isArrayLike(document.body.children);\n * // => true\n *\n * _.isArrayLike('abc');\n * // => true\n *\n * _.isArrayLike(_.noop);\n * // => false\n */\nfunction isArrayLike(value) {\n  return value != null && isLength(value.length) && !isFunction(value);\n}\n\n/**\n * This method is like `_.isArrayLike` except that it also checks if `value`\n * is an object.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an array-like object,\n *  else `false`.\n * @example\n *\n * _.isArrayLikeObject([1, 2, 3]);\n * // => true\n *\n * _.isArrayLikeObject(document.body.children);\n * // => true\n *\n * _.isArrayLikeObject('abc');\n * // => false\n *\n * _.isArrayLikeObject(_.noop);\n * // => false\n */\nfunction isArrayLikeObject(value) {\n  return isObjectLike(value) && isArrayLike(value);\n}\n\n/**\n * Checks if `value` is a buffer.\n *\n * @static\n * @memberOf _\n * @since 4.3.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a buffer, else `false`.\n * @example\n *\n * _.isBuffer(new Buffer(2));\n * // => true\n *\n * _.isBuffer(new Uint8Array(2));\n * // => false\n */\nvar isBuffer = nativeIsBuffer || stubFalse;\n\n/**\n * Checks if `value` is classified as a `Function` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a function, else `false`.\n * @example\n *\n * _.isFunction(_);\n * // => true\n *\n * _.isFunction(/abc/);\n * // => false\n */\nfunction isFunction(value) {\n  // The use of `Object#toString` avoids issues with the `typeof` operator\n  // in Safari 8-9 which returns 'object' for typed array and other constructors.\n  var tag = isObject(value) ? objectToString.call(value) : '';\n  return tag == funcTag || tag == genTag;\n}\n\n/**\n * Checks if `value` is a valid array-like length.\n *\n * **Note:** This method is loosely based on\n * [`ToLength`](http://ecma-international.org/ecma-262/7.0/#sec-tolength).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a valid length, else `false`.\n * @example\n *\n * _.isLength(3);\n * // => true\n *\n * _.isLength(Number.MIN_VALUE);\n * // => false\n *\n * _.isLength(Infinity);\n * // => false\n *\n * _.isLength('3');\n * // => false\n */\nfunction isLength(value) {\n  return typeof value == 'number' &&\n    value > -1 && value % 1 == 0 && value <= MAX_SAFE_INTEGER;\n}\n\n/**\n * Checks if `value` is the\n * [language type](http://www.ecma-international.org/ecma-262/7.0/#sec-ecmascript-language-types)\n * of `Object`. (e.g. arrays, functions, objects, regexes, `new Number(0)`, and `new String('')`)\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an object, else `false`.\n * @example\n *\n * _.isObject({});\n * // => true\n *\n * _.isObject([1, 2, 3]);\n * // => true\n *\n * _.isObject(_.noop);\n * // => true\n *\n * _.isObject(null);\n * // => false\n */\nfunction isObject(value) {\n  var type = typeof value;\n  return !!value && (type == 'object' || type == 'function');\n}\n\n/**\n * Checks if `value` is object-like. A value is object-like if it's not `null`\n * and has a `typeof` result of \"object\".\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is object-like, else `false`.\n * @example\n *\n * _.isObjectLike({});\n * // => true\n *\n * _.isObjectLike([1, 2, 3]);\n * // => true\n *\n * _.isObjectLike(_.noop);\n * // => false\n *\n * _.isObjectLike(null);\n * // => false\n */\nfunction isObjectLike(value) {\n  return !!value && typeof value == 'object';\n}\n\n/**\n * Checks if `value` is a plain object, that is, an object created by the\n * `Object` constructor or one with a `[[Prototype]]` of `null`.\n *\n * @static\n * @memberOf _\n * @since 0.8.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a plain object, else `false`.\n * @example\n *\n * function Foo() {\n *   this.a = 1;\n * }\n *\n * _.isPlainObject(new Foo);\n * // => false\n *\n * _.isPlainObject([1, 2, 3]);\n * // => false\n *\n * _.isPlainObject({ 'x': 0, 'y': 0 });\n * // => true\n *\n * _.isPlainObject(Object.create(null));\n * // => true\n */\nfunction isPlainObject(value) {\n  if (!isObjectLike(value) ||\n      objectToString.call(value) != objectTag || isHostObject(value)) {\n    return false;\n  }\n  var proto = getPrototype(value);\n  if (proto === null) {\n    return true;\n  }\n  var Ctor = hasOwnProperty.call(proto, 'constructor') && proto.constructor;\n  return (typeof Ctor == 'function' &&\n    Ctor instanceof Ctor && funcToString.call(Ctor) == objectCtorString);\n}\n\n/**\n * Checks if `value` is classified as a typed array.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a typed array, else `false`.\n * @example\n *\n * _.isTypedArray(new Uint8Array);\n * // => true\n *\n * _.isTypedArray([]);\n * // => false\n */\nvar isTypedArray = nodeIsTypedArray ? baseUnary(nodeIsTypedArray) : baseIsTypedArray;\n\n/**\n * Converts `value` to a plain object flattening inherited enumerable string\n * keyed properties of `value` to own properties of the plain object.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category Lang\n * @param {*} value The value to convert.\n * @returns {Object} Returns the converted plain object.\n * @example\n *\n * function Foo() {\n *   this.b = 2;\n * }\n *\n * Foo.prototype.c = 3;\n *\n * _.assign({ 'a': 1 }, new Foo);\n * // => { 'a': 1, 'b': 2 }\n *\n * _.assign({ 'a': 1 }, _.toPlainObject(new Foo));\n * // => { 'a': 1, 'b': 2, 'c': 3 }\n */\nfunction toPlainObject(value) {\n  return copyObject(value, keysIn(value));\n}\n\n/**\n * Creates an array of the own enumerable property names of `object`.\n *\n * **Note:** Non-object values are coerced to objects. See the\n * [ES spec](http://ecma-international.org/ecma-262/7.0/#sec-object.keys)\n * for more details.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Object\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n * @example\n *\n * function Foo() {\n *   this.a = 1;\n *   this.b = 2;\n * }\n *\n * Foo.prototype.c = 3;\n *\n * _.keys(new Foo);\n * // => ['a', 'b'] (iteration order is not guaranteed)\n *\n * _.keys('hi');\n * // => ['0', '1']\n */\nfunction keys(object) {\n  return isArrayLike(object) ? arrayLikeKeys(object) : baseKeys(object);\n}\n\n/**\n * Creates an array of the own and inherited enumerable property names of `object`.\n *\n * **Note:** Non-object values are coerced to objects.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category Object\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n * @example\n *\n * function Foo() {\n *   this.a = 1;\n *   this.b = 2;\n * }\n *\n * Foo.prototype.c = 3;\n *\n * _.keysIn(new Foo);\n * // => ['a', 'b', 'c'] (iteration order is not guaranteed)\n */\nfunction keysIn(object) {\n  return isArrayLike(object) ? arrayLikeKeys(object, true) : baseKeysIn(object);\n}\n\n/**\n * This method is like `_.assign` except that it recursively merges own and\n * inherited enumerable string keyed properties of source objects into the\n * destination object. Source properties that resolve to `undefined` are\n * skipped if a destination value exists. Array and plain object properties\n * are merged recursively. Other objects and value types are overridden by\n * assignment. Source objects are applied from left to right. Subsequent\n * sources overwrite property assignments of previous sources.\n *\n * **Note:** This method mutates `object`.\n *\n * @static\n * @memberOf _\n * @since 0.5.0\n * @category Object\n * @param {Object} object The destination object.\n * @param {...Object} [sources] The source objects.\n * @returns {Object} Returns `object`.\n * @example\n *\n * var object = {\n *   'a': [{ 'b': 2 }, { 'd': 4 }]\n * };\n *\n * var other = {\n *   'a': [{ 'c': 3 }, { 'e': 5 }]\n * };\n *\n * _.merge(object, other);\n * // => { 'a': [{ 'b': 2, 'c': 3 }, { 'd': 4, 'e': 5 }] }\n */\nvar merge = createAssigner(function(object, source, srcIndex) {\n  baseMerge(object, source, srcIndex);\n});\n\n/**\n * This method returns a new empty array.\n *\n * @static\n * @memberOf _\n * @since 4.13.0\n * @category Util\n * @returns {Array} Returns the new empty array.\n * @example\n *\n * var arrays = _.times(2, _.stubArray);\n *\n * console.log(arrays);\n * // => [[], []]\n *\n * console.log(arrays[0] === arrays[1]);\n * // => false\n */\nfunction stubArray() {\n  return [];\n}\n\n/**\n * This method returns `false`.\n *\n * @static\n * @memberOf _\n * @since 4.13.0\n * @category Util\n * @returns {boolean} Returns `false`.\n * @example\n *\n * _.times(2, _.stubFalse);\n * // => [false, false]\n */\nfunction stubFalse() {\n  return false;\n}\n\nmodule.exports = merge;\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(0), __webpack_require__(17)(module)))\n\n/***/ }),\n/* 2 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/* WEBPACK VAR INJECTION */(function(global) {\nvar Mutation = global.MutationObserver || global.WebKitMutationObserver;\n\nvar scheduleDrain;\n\n{\n  if (Mutation) {\n    var called = 0;\n    var observer = new Mutation(nextTick);\n    var element = global.document.createTextNode('');\n    observer.observe(element, {\n      characterData: true\n    });\n    scheduleDrain = function () {\n      element.data = (called = ++called % 2);\n    };\n  } else if (!global.setImmediate && typeof global.MessageChannel !== 'undefined') {\n    var channel = new global.MessageChannel();\n    channel.port1.onmessage = nextTick;\n    scheduleDrain = function () {\n      channel.port2.postMessage(0);\n    };\n  } else if ('document' in global && 'onreadystatechange' in global.document.createElement('script')) {\n    scheduleDrain = function () {\n\n      // Create a <script> element; its readystatechange event will be fired asynchronously once it is inserted\n      // into the document. Do so, thus queuing up the task. Remember to clean up once it's been called.\n      var scriptEl = global.document.createElement('script');\n      scriptEl.onreadystatechange = function () {\n        nextTick();\n\n        scriptEl.onreadystatechange = null;\n        scriptEl.parentNode.removeChild(scriptEl);\n        scriptEl = null;\n      };\n      global.document.documentElement.appendChild(scriptEl);\n    };\n  } else {\n    scheduleDrain = function () {\n      setTimeout(nextTick, 0);\n    };\n  }\n}\n\nvar draining;\nvar queue = [];\n//named nextTick for less confusing stack traces\nfunction nextTick() {\n  draining = true;\n  var i, oldQueue;\n  var len = queue.length;\n  while (len) {\n    oldQueue = queue;\n    queue = [];\n    i = -1;\n    while (++i < len) {\n      oldQueue[i]();\n    }\n    len = queue.length;\n  }\n  draining = false;\n}\n\nmodule.exports = immediate;\nfunction immediate(task) {\n  if (queue.push(task) === 1 && !draining) {\n    scheduleDrain();\n  }\n}\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(0)))\n\n/***/ }),\n/* 3 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_sift__ = __webpack_require__(14);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_sift___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_0_sift__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_1_lodash_merge__ = __webpack_require__(1);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_1_lodash_merge___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_1_lodash_merge__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"b\", function() { return noop; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"d\", function() { return expand; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"c\", function() { return mapQueries; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"a\", function() { return binarySearch; });\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\n/**\n * Importing\n */\n\n\n\n/**\n * Noop Function\n */\nvar noop = function noop() {};\n\n/**\n * Executes a function based on context, and returns the value\n */\nvar expand = function expand(fn) {\n  var context = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n\n  return typeof fn === 'function' ? fn.call(context) : fn;\n};\n\n/**\n * Maps Databases to an Object list\n * @param queries\n * @returns {*}\n */\nvar mapQueries = function mapQueries(queries) {\n  return Object.keys(queries).reduce(function (db, name) {\n    return __WEBPACK_IMPORTED_MODULE_1_lodash_merge___default()(db, _defineProperty({}, name, function computedQueries() {\n      // If dbsetup does not exist, throw Error!\n      if (!this.$dbsetup) throw new Error('[VuePouch] dbsetup{} does not exist!');\n      // Setting up the Queries\n      return (this.$bucket.state[expand(this.$dbsetup.name, this)] || []).filter(__WEBPACK_IMPORTED_MODULE_0_sift___default()(expand(queries[name], this) || {}));\n    }));\n  }, {});\n};\n\n/**\n * Binary Search for Arrays\n */\nvar binarySearch = function binarySearch(arr, docId) {\n  var low = 0;\n  var high = arr.length;\n  var mid = void 0;\n  // traverse\n  while (low < high) {\n    mid = low + high >>> 1;\n    arr[mid]._id < docId ? low = mid + 1 : high = mid;\n  }\n  return low;\n};\n\n/***/ }),\n/* 4 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n/* WEBPACK VAR INJECTION */(function(global) {\n\nfunction _interopDefault (ex) { return (ex && (typeof ex === 'object') && 'default' in ex) ? ex['default'] : ex; }\n\nvar lie = _interopDefault(__webpack_require__(10));\nvar getArguments = _interopDefault(__webpack_require__(5));\nvar debug = _interopDefault(__webpack_require__(6));\nvar events = __webpack_require__(8);\nvar inherits = _interopDefault(__webpack_require__(9));\nvar nextTick = _interopDefault(__webpack_require__(2));\nvar scopedEval = _interopDefault(__webpack_require__(13));\nvar Md5 = _interopDefault(__webpack_require__(15));\nvar vuvuzela = _interopDefault(__webpack_require__(16));\n\n/* istanbul ignore next */\nvar PouchPromise$1 = typeof Promise === 'function' ? Promise : lie;\n\nfunction isBinaryObject(object) {\n  return (typeof ArrayBuffer !== 'undefined' && object instanceof ArrayBuffer) ||\n    (typeof Blob !== 'undefined' && object instanceof Blob);\n}\n\nfunction cloneArrayBuffer(buff) {\n  if (typeof buff.slice === 'function') {\n    return buff.slice(0);\n  }\n  // IE10-11 slice() polyfill\n  var target = new ArrayBuffer(buff.byteLength);\n  var targetArray = new Uint8Array(target);\n  var sourceArray = new Uint8Array(buff);\n  targetArray.set(sourceArray);\n  return target;\n}\n\nfunction cloneBinaryObject(object) {\n  if (object instanceof ArrayBuffer) {\n    return cloneArrayBuffer(object);\n  }\n  var size = object.size;\n  var type = object.type;\n  // Blob\n  if (typeof object.slice === 'function') {\n    return object.slice(0, size, type);\n  }\n  // PhantomJS slice() replacement\n  return object.webkitSlice(0, size, type);\n}\n\n// most of this is borrowed from lodash.isPlainObject:\n// https://github.com/fis-components/lodash.isplainobject/\n// blob/29c358140a74f252aeb08c9eb28bef86f2217d4a/index.js\n\nvar funcToString = Function.prototype.toString;\nvar objectCtorString = funcToString.call(Object);\n\nfunction isPlainObject(value) {\n  var proto = Object.getPrototypeOf(value);\n  /* istanbul ignore if */\n  if (proto === null) { // not sure when this happens, but I guess it can\n    return true;\n  }\n  var Ctor = proto.constructor;\n  return (typeof Ctor == 'function' &&\n    Ctor instanceof Ctor && funcToString.call(Ctor) == objectCtorString);\n}\n\nfunction clone(object) {\n  var newObject;\n  var i;\n  var len;\n\n  if (!object || typeof object !== 'object') {\n    return object;\n  }\n\n  if (Array.isArray(object)) {\n    newObject = [];\n    for (i = 0, len = object.length; i < len; i++) {\n      newObject[i] = clone(object[i]);\n    }\n    return newObject;\n  }\n\n  // special case: to avoid inconsistencies between IndexedDB\n  // and other backends, we automatically stringify Dates\n  if (object instanceof Date) {\n    return object.toISOString();\n  }\n\n  if (isBinaryObject(object)) {\n    return cloneBinaryObject(object);\n  }\n\n  if (!isPlainObject(object)) {\n    return object; // don't clone objects like Workers\n  }\n\n  newObject = {};\n  for (i in object) {\n    /* istanbul ignore else */\n    if (Object.prototype.hasOwnProperty.call(object, i)) {\n      var value = clone(object[i]);\n      if (typeof value !== 'undefined') {\n        newObject[i] = value;\n      }\n    }\n  }\n  return newObject;\n}\n\nfunction once(fun) {\n  var called = false;\n  return getArguments(function (args) {\n    /* istanbul ignore if */\n    if (called) {\n      // this is a smoke test and should never actually happen\n      throw new Error('once called more than once');\n    } else {\n      called = true;\n      fun.apply(this, args);\n    }\n  });\n}\n\nfunction toPromise(func) {\n  //create the function we will be returning\n  return getArguments(function (args) {\n    // Clone arguments\n    args = clone(args);\n    var self = this;\n    // if the last argument is a function, assume its a callback\n    var usedCB = (typeof args[args.length - 1] === 'function') ? args.pop() : false;\n    var promise = new PouchPromise$1(function (fulfill, reject) {\n      var resp;\n      try {\n        var callback = once(function (err, mesg) {\n          if (err) {\n            reject(err);\n          } else {\n            fulfill(mesg);\n          }\n        });\n        // create a callback for this invocation\n        // apply the function in the orig context\n        args.push(callback);\n        resp = func.apply(self, args);\n        if (resp && typeof resp.then === 'function') {\n          fulfill(resp);\n        }\n      } catch (e) {\n        reject(e);\n      }\n    });\n    // if there is a callback, call it back\n    if (usedCB) {\n      promise.then(function (result) {\n        usedCB(null, result);\n      }, usedCB);\n    }\n    return promise;\n  });\n}\n\nvar log = debug('pouchdb:api');\n\nfunction adapterFun(name, callback) {\n  function logApiCall(self, name, args) {\n    /* istanbul ignore if */\n    if (log.enabled) {\n      var logArgs = [self.name, name];\n      for (var i = 0; i < args.length - 1; i++) {\n        logArgs.push(args[i]);\n      }\n      log.apply(null, logArgs);\n\n      // override the callback itself to log the response\n      var origCallback = args[args.length - 1];\n      args[args.length - 1] = function (err, res) {\n        var responseArgs = [self.name, name];\n        responseArgs = responseArgs.concat(\n          err ? ['error', err] : ['success', res]\n        );\n        log.apply(null, responseArgs);\n        origCallback(err, res);\n      };\n    }\n  }\n\n  return toPromise(getArguments(function (args) {\n    if (this._closed) {\n      return PouchPromise$1.reject(new Error('database is closed'));\n    }\n    if (this._destroyed) {\n      return PouchPromise$1.reject(new Error('database is destroyed'));\n    }\n    var self = this;\n    logApiCall(self, name, args);\n    if (!this.taskqueue.isReady) {\n      return new PouchPromise$1(function (fulfill, reject) {\n        self.taskqueue.addTask(function (failed) {\n          if (failed) {\n            reject(failed);\n          } else {\n            fulfill(self[name].apply(self, args));\n          }\n        });\n      });\n    }\n    return callback.apply(this, args);\n  }));\n}\n\n// like underscore/lodash _.pick()\nfunction pick(obj, arr) {\n  var res = {};\n  for (var i = 0, len = arr.length; i < len; i++) {\n    var prop = arr[i];\n    if (prop in obj) {\n      res[prop] = obj[prop];\n    }\n  }\n  return res;\n}\n\nfunction mangle(key) {\n  return '$' + key;\n}\nfunction unmangle(key) {\n  return key.substring(1);\n}\nfunction Map$1() {\n  this._store = {};\n}\nMap$1.prototype.get = function (key) {\n  var mangled = mangle(key);\n  return this._store[mangled];\n};\nMap$1.prototype.set = function (key, value) {\n  var mangled = mangle(key);\n  this._store[mangled] = value;\n  return true;\n};\nMap$1.prototype.has = function (key) {\n  var mangled = mangle(key);\n  return mangled in this._store;\n};\nMap$1.prototype.delete = function (key) {\n  var mangled = mangle(key);\n  var res = mangled in this._store;\n  delete this._store[mangled];\n  return res;\n};\nMap$1.prototype.forEach = function (cb) {\n  var keys = Object.keys(this._store);\n  for (var i = 0, len = keys.length; i < len; i++) {\n    var key = keys[i];\n    var value = this._store[key];\n    key = unmangle(key);\n    cb(value, key);\n  }\n};\nObject.defineProperty(Map$1.prototype, 'size', {\n  get: function () {\n    return Object.keys(this._store).length;\n  }\n});\n\nfunction Set$1(array) {\n  this._store = new Map$1();\n\n  // init with an array\n  if (array && Array.isArray(array)) {\n    for (var i = 0, len = array.length; i < len; i++) {\n      this.add(array[i]);\n    }\n  }\n}\nSet$1.prototype.add = function (key) {\n  return this._store.set(key, true);\n};\nSet$1.prototype.has = function (key) {\n  return this._store.has(key);\n};\nSet$1.prototype.forEach = function (cb) {\n  this._store.forEach(function (value, key) {\n    cb(key);\n  });\n};\nObject.defineProperty(Set$1.prototype, 'size', {\n  get: function () {\n    return this._store.size;\n  }\n});\n\n/* global Map,Set,Symbol */\n// Based on https://kangax.github.io/compat-table/es6/ we can sniff out\n// incomplete Map/Set implementations which would otherwise cause our tests to fail.\n// Notably they fail in IE11 and iOS 8.4, which this prevents.\nfunction supportsMapAndSet() {\n  if (typeof Symbol === 'undefined' || typeof Map === 'undefined' || typeof Set === 'undefined') {\n    return false;\n  }\n  var prop = Object.getOwnPropertyDescriptor(Map, Symbol.species);\n  return prop && 'get' in prop && Map[Symbol.species] === Map;\n}\n\n// based on https://github.com/montagejs/collections\n/* global Map,Set */\n\nvar ExportedSet;\nvar ExportedMap;\n\n{\n  if (supportsMapAndSet()) { // prefer built-in Map/Set\n    ExportedSet = Set;\n    ExportedMap = Map;\n  } else { // fall back to our polyfill\n    ExportedSet = Set$1;\n    ExportedMap = Map$1;\n  }\n}\n\n// Most browsers throttle concurrent requests at 6, so it's silly\n// to shim _bulk_get by trying to launch potentially hundreds of requests\n// and then letting the majority time out. We can handle this ourselves.\nvar MAX_NUM_CONCURRENT_REQUESTS = 6;\n\nfunction identityFunction(x) {\n  return x;\n}\n\nfunction formatResultForOpenRevsGet(result) {\n  return [{\n    ok: result\n  }];\n}\n\n// shim for P/CouchDB adapters that don't directly implement _bulk_get\nfunction bulkGet(db, opts, callback) {\n  var requests = opts.docs;\n\n  // consolidate into one request per doc if possible\n  var requestsById = new ExportedMap();\n  requests.forEach(function (request) {\n    if (requestsById.has(request.id)) {\n      requestsById.get(request.id).push(request);\n    } else {\n      requestsById.set(request.id, [request]);\n    }\n  });\n\n  var numDocs = requestsById.size;\n  var numDone = 0;\n  var perDocResults = new Array(numDocs);\n\n  function collapseResultsAndFinish() {\n    var results = [];\n    perDocResults.forEach(function (res) {\n      res.docs.forEach(function (info) {\n        results.push({\n          id: res.id,\n          docs: [info]\n        });\n      });\n    });\n    callback(null, {results: results});\n  }\n\n  function checkDone() {\n    if (++numDone === numDocs) {\n      collapseResultsAndFinish();\n    }\n  }\n\n  function gotResult(docIndex, id, docs) {\n    perDocResults[docIndex] = {id: id, docs: docs};\n    checkDone();\n  }\n\n  var allRequests = [];\n  requestsById.forEach(function (value, key) {\n    allRequests.push(key);\n  });\n\n  var i = 0;\n\n  function nextBatch() {\n\n    if (i >= allRequests.length) {\n      return;\n    }\n\n    var upTo = Math.min(i + MAX_NUM_CONCURRENT_REQUESTS, allRequests.length);\n    var batch = allRequests.slice(i, upTo);\n    processBatch(batch, i);\n    i += batch.length;\n  }\n\n  function processBatch(batch, offset) {\n    batch.forEach(function (docId, j) {\n      var docIdx = offset + j;\n      var docRequests = requestsById.get(docId);\n\n      // just use the first request as the \"template\"\n      // TODO: The _bulk_get API allows for more subtle use cases than this,\n      // but for now it is unlikely that there will be a mix of different\n      // \"atts_since\" or \"attachments\" in the same request, since it's just\n      // replicate.js that is using this for the moment.\n      // Also, atts_since is aspirational, since we don't support it yet.\n      var docOpts = pick(docRequests[0], ['atts_since', 'attachments']);\n      docOpts.open_revs = docRequests.map(function (request) {\n        // rev is optional, open_revs disallowed\n        return request.rev;\n      });\n\n      // remove falsey / undefined revisions\n      docOpts.open_revs = docOpts.open_revs.filter(identityFunction);\n\n      var formatResult = identityFunction;\n\n      if (docOpts.open_revs.length === 0) {\n        delete docOpts.open_revs;\n\n        // when fetching only the \"winning\" leaf,\n        // transform the result so it looks like an open_revs\n        // request\n        formatResult = formatResultForOpenRevsGet;\n      }\n\n      // globally-supplied options\n      ['revs', 'attachments', 'binary', 'ajax', 'latest'].forEach(function (param) {\n        if (param in opts) {\n          docOpts[param] = opts[param];\n        }\n      });\n      db.get(docId, docOpts, function (err, res) {\n        var result;\n        /* istanbul ignore if */\n        if (err) {\n          result = [{error: err}];\n        } else {\n          result = formatResult(res);\n        }\n        gotResult(docIdx, docId, result);\n        nextBatch();\n      });\n    });\n  }\n\n  nextBatch();\n\n}\n\nfunction isChromeApp() {\n  return (typeof chrome !== \"undefined\" &&\n    typeof chrome.storage !== \"undefined\" &&\n    typeof chrome.storage.local !== \"undefined\");\n}\n\nvar hasLocal;\n\nif (isChromeApp()) {\n  hasLocal = false;\n} else {\n  try {\n    localStorage.setItem('_pouch_check_localstorage', 1);\n    hasLocal = !!localStorage.getItem('_pouch_check_localstorage');\n  } catch (e) {\n    hasLocal = false;\n  }\n}\n\nfunction hasLocalStorage() {\n  return hasLocal;\n}\n\ninherits(Changes, events.EventEmitter);\n\n/* istanbul ignore next */\nfunction attachBrowserEvents(self) {\n  if (isChromeApp()) {\n    chrome.storage.onChanged.addListener(function (e) {\n      // make sure it's event addressed to us\n      if (e.db_name != null) {\n        //object only has oldValue, newValue members\n        self.emit(e.dbName.newValue);\n      }\n    });\n  } else if (hasLocalStorage()) {\n    if (typeof addEventListener !== 'undefined') {\n      addEventListener(\"storage\", function (e) {\n        self.emit(e.key);\n      });\n    } else { // old IE\n      window.attachEvent(\"storage\", function (e) {\n        self.emit(e.key);\n      });\n    }\n  }\n}\n\nfunction Changes() {\n  events.EventEmitter.call(this);\n  this._listeners = {};\n\n  attachBrowserEvents(this);\n}\nChanges.prototype.addListener = function (dbName, id, db, opts) {\n  /* istanbul ignore if */\n  if (this._listeners[id]) {\n    return;\n  }\n  var self = this;\n  var inprogress = false;\n  function eventFunction() {\n    /* istanbul ignore if */\n    if (!self._listeners[id]) {\n      return;\n    }\n    if (inprogress) {\n      inprogress = 'waiting';\n      return;\n    }\n    inprogress = true;\n    var changesOpts = pick(opts, [\n      'style', 'include_docs', 'attachments', 'conflicts', 'filter',\n      'doc_ids', 'view', 'since', 'query_params', 'binary'\n    ]);\n\n    /* istanbul ignore next */\n    function onError() {\n      inprogress = false;\n    }\n\n    db.changes(changesOpts).on('change', function (c) {\n      if (c.seq > opts.since && !opts.cancelled) {\n        opts.since = c.seq;\n        opts.onChange(c);\n      }\n    }).on('complete', function () {\n      if (inprogress === 'waiting') {\n        nextTick(eventFunction);\n      }\n      inprogress = false;\n    }).on('error', onError);\n  }\n  this._listeners[id] = eventFunction;\n  this.on(dbName, eventFunction);\n};\n\nChanges.prototype.removeListener = function (dbName, id) {\n  /* istanbul ignore if */\n  if (!(id in this._listeners)) {\n    return;\n  }\n  events.EventEmitter.prototype.removeListener.call(this, dbName,\n    this._listeners[id]);\n  delete this._listeners[id];\n};\n\n\n/* istanbul ignore next */\nChanges.prototype.notifyLocalWindows = function (dbName) {\n  //do a useless change on a storage thing\n  //in order to get other windows's listeners to activate\n  if (isChromeApp()) {\n    chrome.storage.local.set({dbName: dbName});\n  } else if (hasLocalStorage()) {\n    localStorage[dbName] = (localStorage[dbName] === \"a\") ? \"b\" : \"a\";\n  }\n};\n\nChanges.prototype.notify = function (dbName) {\n  this.emit(dbName);\n  this.notifyLocalWindows(dbName);\n};\n\nfunction guardedConsole(method) {\n  /* istanbul ignore else */\n  if (console !== 'undefined' && method in console) {\n    var args = Array.prototype.slice.call(arguments, 1);\n    console[method].apply(console, args);\n  }\n}\n\nfunction randomNumber(min, max) {\n  var maxTimeout = 600000; // Hard-coded default of 10 minutes\n  min = parseInt(min, 10) || 0;\n  max = parseInt(max, 10);\n  if (max !== max || max <= min) {\n    max = (min || 1) << 1; //doubling\n  } else {\n    max = max + 1;\n  }\n  // In order to not exceed maxTimeout, pick a random value between half of maxTimeout and maxTimeout\n  if(max > maxTimeout) {\n    min = maxTimeout >> 1; // divide by two\n    max = maxTimeout;\n  }\n  var ratio = Math.random();\n  var range = max - min;\n\n  return ~~(range * ratio + min); // ~~ coerces to an int, but fast.\n}\n\nfunction defaultBackOff(min) {\n  var max = 0;\n  if (!min) {\n    max = 2000;\n  }\n  return randomNumber(min, max);\n}\n\n// designed to give info to browser users, who are disturbed\n// when they see http errors in the console\nfunction explainError(status, str) {\n  guardedConsole('info', 'The above ' + status + ' is totally normal. ' + str);\n}\n\nvar assign;\n{\n  if (typeof Object.assign === 'function') {\n    assign = Object.assign;\n  } else {\n    // lite Object.assign polyfill based on\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/assign\n    assign = function (target) {\n      var to = Object(target);\n\n      for (var index = 1; index < arguments.length; index++) {\n        var nextSource = arguments[index];\n\n        if (nextSource != null) { // Skip over if undefined or null\n          for (var nextKey in nextSource) {\n            // Avoid bugs when hasOwnProperty is shadowed\n            if (Object.prototype.hasOwnProperty.call(nextSource, nextKey)) {\n              to[nextKey] = nextSource[nextKey];\n            }\n          }\n        }\n      }\n      return to;\n    };\n  }\n}\n\nvar assign$1 = assign;\n\ninherits(PouchError, Error);\n\nfunction PouchError(status, error, reason) {\n  Error.call(this, reason);\n  this.status = status;\n  this.name = error;\n  this.message = reason;\n  this.error = true;\n}\n\nPouchError.prototype.toString = function () {\n  return JSON.stringify({\n    status: this.status,\n    name: this.name,\n    message: this.message,\n    reason: this.reason\n  });\n};\n\nvar UNAUTHORIZED = new PouchError(401, 'unauthorized', \"Name or password is incorrect.\");\nvar MISSING_BULK_DOCS = new PouchError(400, 'bad_request', \"Missing JSON list of 'docs'\");\nvar MISSING_DOC = new PouchError(404, 'not_found', 'missing');\nvar REV_CONFLICT = new PouchError(409, 'conflict', 'Document update conflict');\nvar INVALID_ID = new PouchError(400, 'bad_request', '_id field must contain a string');\nvar MISSING_ID = new PouchError(412, 'missing_id', '_id is required for puts');\nvar RESERVED_ID = new PouchError(400, 'bad_request', 'Only reserved document ids may start with underscore.');\nvar NOT_OPEN = new PouchError(412, 'precondition_failed', 'Database not open');\nvar UNKNOWN_ERROR = new PouchError(500, 'unknown_error', 'Database encountered an unknown error');\nvar BAD_ARG = new PouchError(500, 'badarg', 'Some query argument is invalid');\nvar INVALID_REQUEST = new PouchError(400, 'invalid_request', 'Request was invalid');\nvar QUERY_PARSE_ERROR = new PouchError(400, 'query_parse_error', 'Some query parameter is invalid');\nvar DOC_VALIDATION = new PouchError(500, 'doc_validation', 'Bad special document member');\nvar BAD_REQUEST = new PouchError(400, 'bad_request', 'Something wrong with the request');\nvar NOT_AN_OBJECT = new PouchError(400, 'bad_request', 'Document must be a JSON object');\nvar DB_MISSING = new PouchError(404, 'not_found', 'Database not found');\nvar IDB_ERROR = new PouchError(500, 'indexed_db_went_bad', 'unknown');\nvar WSQ_ERROR = new PouchError(500, 'web_sql_went_bad', 'unknown');\nvar LDB_ERROR = new PouchError(500, 'levelDB_went_went_bad', 'unknown');\nvar FORBIDDEN = new PouchError(403, 'forbidden', 'Forbidden by design doc validate_doc_update function');\nvar INVALID_REV = new PouchError(400, 'bad_request', 'Invalid rev format');\nvar FILE_EXISTS = new PouchError(412, 'file_exists', 'The database could not be created, the file already exists.');\nvar MISSING_STUB = new PouchError(412, 'missing_stub', 'A pre-existing attachment stub wasn\\'t found');\nvar INVALID_URL = new PouchError(413, 'invalid_url', 'Provided URL is invalid');\n\nfunction createError(error, reason) {\n  function CustomPouchError(reason) {\n    // inherit error properties from our parent error manually\n    // so as to allow proper JSON parsing.\n    /* jshint ignore:start */\n    for (var p in error) {\n      if (typeof error[p] !== 'function') {\n        this[p] = error[p];\n      }\n    }\n    /* jshint ignore:end */\n    if (reason !== undefined) {\n      this.reason = reason;\n    }\n  }\n  CustomPouchError.prototype = PouchError.prototype;\n  return new CustomPouchError(reason);\n}\n\nfunction generateErrorFromResponse(err) {\n\n  if (typeof err !== 'object') {\n    var data = err;\n    err = UNKNOWN_ERROR;\n    err.data = data;\n  }\n\n  if ('error' in err && err.error === 'conflict') {\n    err.name = 'conflict';\n    err.status = 409;\n  }\n\n  if (!('name' in err)) {\n    err.name = err.error || 'unknown';\n  }\n\n  if (!('status' in err)) {\n    err.status = 500;\n  }\n\n  if (!('message' in err)) {\n    err.message = err.message || err.reason;\n  }\n\n  return err;\n}\n\nfunction tryFilter(filter, doc, req) {\n  try {\n    return !filter(doc, req);\n  } catch (err) {\n    var msg = 'Filter function threw: ' + err.toString();\n    return createError(BAD_REQUEST, msg);\n  }\n}\n\nfunction filterChange(opts) {\n  var req = {};\n  var hasFilter = opts.filter && typeof opts.filter === 'function';\n  req.query = opts.query_params;\n\n  return function filter(change) {\n    if (!change.doc) {\n      // CSG sends events on the changes feed that don't have documents,\n      // this hack makes a whole lot of existing code robust.\n      change.doc = {};\n    }\n\n    var filterReturn = hasFilter && tryFilter(opts.filter, change.doc, req);\n\n    if (typeof filterReturn === 'object') {\n      return filterReturn;\n    }\n\n    if (filterReturn) {\n      return false;\n    }\n\n    if (!opts.include_docs) {\n      delete change.doc;\n    } else if (!opts.attachments) {\n      for (var att in change.doc._attachments) {\n        /* istanbul ignore else */\n        if (change.doc._attachments.hasOwnProperty(att)) {\n          change.doc._attachments[att].stub = true;\n        }\n      }\n    }\n    return true;\n  };\n}\n\nfunction flatten(arrs) {\n  var res = [];\n  for (var i = 0, len = arrs.length; i < len; i++) {\n    res = res.concat(arrs[i]);\n  }\n  return res;\n}\n\n// shim for Function.prototype.name,\n// for browsers that don't support it like IE\n\n/* istanbul ignore next */\nfunction f() {}\n\nvar hasName = f.name;\nvar res;\n\n// We dont run coverage in IE\n/* istanbul ignore else */\nif (hasName) {\n  res = function (fun) {\n    return fun.name;\n  };\n} else {\n  res = function (fun) {\n    return fun.toString().match(/^\\s*function\\s*(\\S*)\\s*\\(/)[1];\n  };\n}\n\n// Determine id an ID is valid\n//   - invalid IDs begin with an underescore that does not begin '_design' or\n//     '_local'\n//   - any other string value is a valid id\n// Returns the specific error object for each case\nfunction invalidIdError(id) {\n  var err;\n  if (!id) {\n    err = createError(MISSING_ID);\n  } else if (typeof id !== 'string') {\n    err = createError(INVALID_ID);\n  } else if (/^_/.test(id) && !(/^_(design|local)/).test(id)) {\n    err = createError(RESERVED_ID);\n  }\n  if (err) {\n    throw err;\n  }\n}\n\nfunction listenerCount(ee, type) {\n  return 'listenerCount' in ee ? ee.listenerCount(type) :\n                                 events.EventEmitter.listenerCount(ee, type);\n}\n\n// Custom nextTick() shim for browsers. In node, this will just be process.nextTick(). We\n// avoid using process.nextTick() directly because the polyfill is very large and we don't\n// need all of it (see: https://github.com/defunctzombie/node-process).\n// \"immediate\" 3.0.8 is used by lie, and it's a smaller version of the latest \"immediate\"\n// package, so it's the one we use.\n// When we use nextTick() in our codebase, we only care about not releasing Zalgo\n// (see: http://blog.izs.me/post/59142742143/designing-apis-for-asynchrony).\n// Microtask vs macrotask doesn't matter to us. So we're free to use the fastest\n// (least latency) option, which is \"immediate\" due to use of microtasks.\n// All of our nextTicks are isolated to this one function so we can easily swap out one\n// implementation for another.\n\nfunction parseDesignDocFunctionName(s) {\n  if (!s) {\n    return null;\n  }\n  var parts = s.split('/');\n  if (parts.length === 2) {\n    return parts;\n  }\n  if (parts.length === 1) {\n    return [s, s];\n  }\n  return null;\n}\n\nfunction normalizeDesignDocFunctionName(s) {\n  var normalized = parseDesignDocFunctionName(s);\n  return normalized ? normalized.join('/') : null;\n}\n\n// originally parseUri 1.2.2, now patched by us\n// (c) Steven Levithan <stevenlevithan.com>\n// MIT License\nvar keys = [\"source\", \"protocol\", \"authority\", \"userInfo\", \"user\", \"password\",\n    \"host\", \"port\", \"relative\", \"path\", \"directory\", \"file\", \"query\", \"anchor\"];\nvar qName =\"queryKey\";\nvar qParser = /(?:^|&)([^&=]*)=?([^&]*)/g;\n\n// use the \"loose\" parser\n/* jshint maxlen: false */\nvar parser = /^(?:(?![^:@]+:[^:@\\/]*@)([^:\\/?#.]+):)?(?:\\/\\/)?((?:(([^:@]*)(?::([^:@]*))?)?@)?([^:\\/?#]*)(?::(\\d*))?)(((\\/(?:[^?#](?![^?#\\/]*\\.[^?#\\/.]+(?:[?#]|$)))*\\/?)?([^?#\\/]*))(?:\\?([^#]*))?(?:#(.*))?)/;\n\nfunction parseUri(str) {\n  var m = parser.exec(str);\n  var uri = {};\n  var i = 14;\n\n  while (i--) {\n    var key = keys[i];\n    var value = m[i] || \"\";\n    var encoded = ['user', 'password'].indexOf(key) !== -1;\n    uri[key] = encoded ? decodeURIComponent(value) : value;\n  }\n\n  uri[qName] = {};\n  uri[keys[12]].replace(qParser, function ($0, $1, $2) {\n    if ($1) {\n      uri[qName][$1] = $2;\n    }\n  });\n\n  return uri;\n}\n\n// this is essentially the \"update sugar\" function from daleharvey/pouchdb#1388\n// the diffFun tells us what delta to apply to the doc.  it either returns\n// the doc, or false if it doesn't need to do an update after all\nfunction upsert(db, docId, diffFun) {\n  return new PouchPromise$1(function (fulfill, reject) {\n    db.get(docId, function (err, doc) {\n      if (err) {\n        /* istanbul ignore next */\n        if (err.status !== 404) {\n          return reject(err);\n        }\n        doc = {};\n      }\n\n      // the user might change the _rev, so save it for posterity\n      var docRev = doc._rev;\n      var newDoc = diffFun(doc);\n\n      if (!newDoc) {\n        // if the diffFun returns falsy, we short-circuit as\n        // an optimization\n        return fulfill({updated: false, rev: docRev});\n      }\n\n      // users aren't allowed to modify these values,\n      // so reset them here\n      newDoc._id = docId;\n      newDoc._rev = docRev;\n      fulfill(tryAndPut(db, newDoc, diffFun));\n    });\n  });\n}\n\nfunction tryAndPut(db, doc, diffFun) {\n  return db.put(doc).then(function (res) {\n    return {\n      updated: true,\n      rev: res.rev\n    };\n  }, function (err) {\n    /* istanbul ignore next */\n    if (err.status !== 409) {\n      throw err;\n    }\n    return upsert(db, doc._id, diffFun);\n  });\n}\n\n// BEGIN Math.uuid.js\n\n/*!\nMath.uuid.js (v1.4)\nhttp://www.broofa.com\nmailto:robert@broofa.com\n\nCopyright (c) 2010 Robert Kieffer\nDual licensed under the MIT and GPL licenses.\n*/\n\n/*\n * Generate a random uuid.\n *\n * USAGE: Math.uuid(length, radix)\n *   length - the desired number of characters\n *   radix  - the number of allowable values for each character.\n *\n * EXAMPLES:\n *   // No arguments  - returns RFC4122, version 4 ID\n *   >>> Math.uuid()\n *   \"92329D39-6F5C-4520-ABFC-AAB64544E172\"\n *\n *   // One argument - returns ID of the specified length\n *   >>> Math.uuid(15)     // 15 character ID (default base=62)\n *   \"VcydxgltxrVZSTV\"\n *\n *   // Two arguments - returns ID of the specified length, and radix. \n *   // (Radix must be <= 62)\n *   >>> Math.uuid(8, 2)  // 8 character ID (base=2)\n *   \"01001010\"\n *   >>> Math.uuid(8, 10) // 8 character ID (base=10)\n *   \"47473046\"\n *   >>> Math.uuid(8, 16) // 8 character ID (base=16)\n *   \"098F4D35\"\n */\nvar chars = (\n  '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ' +\n  'abcdefghijklmnopqrstuvwxyz'\n).split('');\nfunction getValue(radix) {\n  return 0 | Math.random() * radix;\n}\nfunction uuid(len, radix) {\n  radix = radix || chars.length;\n  var out = '';\n  var i = -1;\n\n  if (len) {\n    // Compact form\n    while (++i < len) {\n      out += chars[getValue(radix)];\n    }\n    return out;\n  }\n    // rfc4122, version 4 form\n    // Fill in random data.  At i==19 set the high bits of clock sequence as\n    // per rfc4122, sec. 4.1.5\n  while (++i < 36) {\n    switch (i) {\n      case 8:\n      case 13:\n      case 18:\n      case 23:\n        out += '-';\n        break;\n      case 19:\n        out += chars[(getValue(16) & 0x3) | 0x8];\n        break;\n      default:\n        out += chars[getValue(16)];\n    }\n  }\n\n  return out;\n}\n\n// We fetch all leafs of the revision tree, and sort them based on tree length\n// and whether they were deleted, undeleted documents with the longest revision\n// tree (most edits) win\n// The final sort algorithm is slightly documented in a sidebar here:\n// http://guide.couchdb.org/draft/conflicts.html\nfunction winningRev(metadata) {\n  var winningId;\n  var winningPos;\n  var winningDeleted;\n  var toVisit = metadata.rev_tree.slice();\n  var node;\n  while ((node = toVisit.pop())) {\n    var tree = node.ids;\n    var branches = tree[2];\n    var pos = node.pos;\n    if (branches.length) { // non-leaf\n      for (var i = 0, len = branches.length; i < len; i++) {\n        toVisit.push({pos: pos + 1, ids: branches[i]});\n      }\n      continue;\n    }\n    var deleted = !!tree[1].deleted;\n    var id = tree[0];\n    // sort by deleted, then pos, then id\n    if (!winningId || (winningDeleted !== deleted ? winningDeleted :\n        winningPos !== pos ? winningPos < pos : winningId < id)) {\n      winningId = id;\n      winningPos = pos;\n      winningDeleted = deleted;\n    }\n  }\n\n  return winningPos + '-' + winningId;\n}\n\n// Pretty much all below can be combined into a higher order function to\n// traverse revisions\n// The return value from the callback will be passed as context to all\n// children of that node\nfunction traverseRevTree(revs, callback) {\n  var toVisit = revs.slice();\n\n  var node;\n  while ((node = toVisit.pop())) {\n    var pos = node.pos;\n    var tree = node.ids;\n    var branches = tree[2];\n    var newCtx =\n      callback(branches.length === 0, pos, tree[0], node.ctx, tree[1]);\n    for (var i = 0, len = branches.length; i < len; i++) {\n      toVisit.push({pos: pos + 1, ids: branches[i], ctx: newCtx});\n    }\n  }\n}\n\nfunction sortByPos(a, b) {\n  return a.pos - b.pos;\n}\n\nfunction collectLeaves(revs) {\n  var leaves = [];\n  traverseRevTree(revs, function (isLeaf, pos, id, acc, opts) {\n    if (isLeaf) {\n      leaves.push({rev: pos + \"-\" + id, pos: pos, opts: opts});\n    }\n  });\n  leaves.sort(sortByPos).reverse();\n  for (var i = 0, len = leaves.length; i < len; i++) {\n    delete leaves[i].pos;\n  }\n  return leaves;\n}\n\n// returns revs of all conflicts that is leaves such that\n// 1. are not deleted and\n// 2. are different than winning revision\nfunction collectConflicts(metadata) {\n  var win = winningRev(metadata);\n  var leaves = collectLeaves(metadata.rev_tree);\n  var conflicts = [];\n  for (var i = 0, len = leaves.length; i < len; i++) {\n    var leaf = leaves[i];\n    if (leaf.rev !== win && !leaf.opts.deleted) {\n      conflicts.push(leaf.rev);\n    }\n  }\n  return conflicts;\n}\n\n// compact a tree by marking its non-leafs as missing,\n// and return a list of revs to delete\nfunction compactTree(metadata) {\n  var revs = [];\n  traverseRevTree(metadata.rev_tree, function (isLeaf, pos,\n                                               revHash, ctx, opts) {\n    if (opts.status === 'available' && !isLeaf) {\n      revs.push(pos + '-' + revHash);\n      opts.status = 'missing';\n    }\n  });\n  return revs;\n}\n\n// build up a list of all the paths to the leafs in this revision tree\nfunction rootToLeaf(revs) {\n  var paths = [];\n  var toVisit = revs.slice();\n  var node;\n  while ((node = toVisit.pop())) {\n    var pos = node.pos;\n    var tree = node.ids;\n    var id = tree[0];\n    var opts = tree[1];\n    var branches = tree[2];\n    var isLeaf = branches.length === 0;\n\n    var history = node.history ? node.history.slice() : [];\n    history.push({id: id, opts: opts});\n    if (isLeaf) {\n      paths.push({pos: (pos + 1 - history.length), ids: history});\n    }\n    for (var i = 0, len = branches.length; i < len; i++) {\n      toVisit.push({pos: pos + 1, ids: branches[i], history: history});\n    }\n  }\n  return paths.reverse();\n}\n\n// for a better overview of what this is doing, read:\n// https://github.com/apache/couchdb-couch/blob/master/src/couch_key_tree.erl\n//\n// But for a quick intro, CouchDB uses a revision tree to store a documents\n// history, A -> B -> C, when a document has conflicts, that is a branch in the\n// tree, A -> (B1 | B2 -> C), We store these as a nested array in the format\n//\n// KeyTree = [Path ... ]\n// Path = {pos: position_from_root, ids: Tree}\n// Tree = [Key, Opts, [Tree, ...]], in particular single node: [Key, []]\n\nfunction sortByPos$1(a, b) {\n  return a.pos - b.pos;\n}\n\n// classic binary search\nfunction binarySearch(arr, item, comparator) {\n  var low = 0;\n  var high = arr.length;\n  var mid;\n  while (low < high) {\n    mid = (low + high) >>> 1;\n    if (comparator(arr[mid], item) < 0) {\n      low = mid + 1;\n    } else {\n      high = mid;\n    }\n  }\n  return low;\n}\n\n// assuming the arr is sorted, insert the item in the proper place\nfunction insertSorted(arr, item, comparator) {\n  var idx = binarySearch(arr, item, comparator);\n  arr.splice(idx, 0, item);\n}\n\n// Turn a path as a flat array into a tree with a single branch.\n// If any should be stemmed from the beginning of the array, that's passed\n// in as the second argument\nfunction pathToTree(path, numStemmed) {\n  var root;\n  var leaf;\n  for (var i = numStemmed, len = path.length; i < len; i++) {\n    var node = path[i];\n    var currentLeaf = [node.id, node.opts, []];\n    if (leaf) {\n      leaf[2].push(currentLeaf);\n      leaf = currentLeaf;\n    } else {\n      root = leaf = currentLeaf;\n    }\n  }\n  return root;\n}\n\n// compare the IDs of two trees\nfunction compareTree(a, b) {\n  return a[0] < b[0] ? -1 : 1;\n}\n\n// Merge two trees together\n// The roots of tree1 and tree2 must be the same revision\nfunction mergeTree(in_tree1, in_tree2) {\n  var queue = [{tree1: in_tree1, tree2: in_tree2}];\n  var conflicts = false;\n  while (queue.length > 0) {\n    var item = queue.pop();\n    var tree1 = item.tree1;\n    var tree2 = item.tree2;\n\n    if (tree1[1].status || tree2[1].status) {\n      tree1[1].status =\n        (tree1[1].status ===  'available' ||\n        tree2[1].status === 'available') ? 'available' : 'missing';\n    }\n\n    for (var i = 0; i < tree2[2].length; i++) {\n      if (!tree1[2][0]) {\n        conflicts = 'new_leaf';\n        tree1[2][0] = tree2[2][i];\n        continue;\n      }\n\n      var merged = false;\n      for (var j = 0; j < tree1[2].length; j++) {\n        if (tree1[2][j][0] === tree2[2][i][0]) {\n          queue.push({tree1: tree1[2][j], tree2: tree2[2][i]});\n          merged = true;\n        }\n      }\n      if (!merged) {\n        conflicts = 'new_branch';\n        insertSorted(tree1[2], tree2[2][i], compareTree);\n      }\n    }\n  }\n  return {conflicts: conflicts, tree: in_tree1};\n}\n\nfunction doMerge(tree, path, dontExpand) {\n  var restree = [];\n  var conflicts = false;\n  var merged = false;\n  var res;\n\n  if (!tree.length) {\n    return {tree: [path], conflicts: 'new_leaf'};\n  }\n\n  for (var i = 0, len = tree.length; i < len; i++) {\n    var branch = tree[i];\n    if (branch.pos === path.pos && branch.ids[0] === path.ids[0]) {\n      // Paths start at the same position and have the same root, so they need\n      // merged\n      res = mergeTree(branch.ids, path.ids);\n      restree.push({pos: branch.pos, ids: res.tree});\n      conflicts = conflicts || res.conflicts;\n      merged = true;\n    } else if (dontExpand !== true) {\n      // The paths start at a different position, take the earliest path and\n      // traverse up until it as at the same point from root as the path we\n      // want to merge.  If the keys match we return the longer path with the\n      // other merged After stemming we dont want to expand the trees\n\n      var t1 = branch.pos < path.pos ? branch : path;\n      var t2 = branch.pos < path.pos ? path : branch;\n      var diff = t2.pos - t1.pos;\n\n      var candidateParents = [];\n\n      var trees = [];\n      trees.push({ids: t1.ids, diff: diff, parent: null, parentIdx: null});\n      while (trees.length > 0) {\n        var item = trees.pop();\n        if (item.diff === 0) {\n          if (item.ids[0] === t2.ids[0]) {\n            candidateParents.push(item);\n          }\n          continue;\n        }\n        var elements = item.ids[2];\n        for (var j = 0, elementsLen = elements.length; j < elementsLen; j++) {\n          trees.push({\n            ids: elements[j],\n            diff: item.diff - 1,\n            parent: item.ids,\n            parentIdx: j\n          });\n        }\n      }\n\n      var el = candidateParents[0];\n\n      if (!el) {\n        restree.push(branch);\n      } else {\n        res = mergeTree(el.ids, t2.ids);\n        el.parent[2][el.parentIdx] = res.tree;\n        restree.push({pos: t1.pos, ids: t1.ids});\n        conflicts = conflicts || res.conflicts;\n        merged = true;\n      }\n    } else {\n      restree.push(branch);\n    }\n  }\n\n  // We didnt find\n  if (!merged) {\n    restree.push(path);\n  }\n\n  restree.sort(sortByPos$1);\n\n  return {\n    tree: restree,\n    conflicts: conflicts || 'internal_node'\n  };\n}\n\n// To ensure we dont grow the revision tree infinitely, we stem old revisions\nfunction stem(tree, depth) {\n  // First we break out the tree into a complete list of root to leaf paths\n  var paths = rootToLeaf(tree);\n  var maybeStem = {};\n\n  var result;\n  for (var i = 0, len = paths.length; i < len; i++) {\n    // Then for each path, we cut off the start of the path based on the\n    // `depth` to stem to, and generate a new set of flat trees\n    var path = paths[i];\n    var stemmed = path.ids;\n    var numStemmed = Math.max(0, stemmed.length - depth);\n    var stemmedNode = {\n      pos: path.pos + numStemmed,\n      ids: pathToTree(stemmed, numStemmed)\n    };\n\n    for (var s = 0; s < numStemmed; s++) {\n      var rev = (path.pos + s) + '-' + stemmed[s].id;\n      maybeStem[rev] = true;\n    }\n\n    // Then we remerge all those flat trees together, ensuring that we dont\n    // connect trees that would go beyond the depth limit\n    if (result) {\n      result = doMerge(result, stemmedNode, true).tree;\n    } else {\n      result = [stemmedNode];\n    }\n  }\n\n  traverseRevTree(result, function (isLeaf, pos, revHash) {\n    // some revisions may have been removed in a branch but not in another\n    delete maybeStem[pos + '-' + revHash];\n  });\n\n  return {\n    tree: result,\n    revs: Object.keys(maybeStem)\n  };\n}\n\nfunction merge(tree, path, depth) {\n  var newTree = doMerge(tree, path);\n  var stemmed = stem(newTree.tree, depth);\n  return {\n    tree: stemmed.tree,\n    stemmedRevs: stemmed.revs,\n    conflicts: newTree.conflicts\n  };\n}\n\n// return true if a rev exists in the rev tree, false otherwise\nfunction revExists(revs, rev) {\n  var toVisit = revs.slice();\n  var splitRev = rev.split('-');\n  var targetPos = parseInt(splitRev[0], 10);\n  var targetId = splitRev[1];\n\n  var node;\n  while ((node = toVisit.pop())) {\n    if (node.pos === targetPos && node.ids[0] === targetId) {\n      return true;\n    }\n    var branches = node.ids[2];\n    for (var i = 0, len = branches.length; i < len; i++) {\n      toVisit.push({pos: node.pos + 1, ids: branches[i]});\n    }\n  }\n  return false;\n}\n\nfunction getTrees(node) {\n  return node.ids;\n}\n\n// check if a specific revision of a doc has been deleted\n//  - metadata: the metadata object from the doc store\n//  - rev: (optional) the revision to check. defaults to winning revision\nfunction isDeleted(metadata, rev) {\n  if (!rev) {\n    rev = winningRev(metadata);\n  }\n  var id = rev.substring(rev.indexOf('-') + 1);\n  var toVisit = metadata.rev_tree.map(getTrees);\n\n  var tree;\n  while ((tree = toVisit.pop())) {\n    if (tree[0] === id) {\n      return !!tree[1].deleted;\n    }\n    toVisit = toVisit.concat(tree[2]);\n  }\n}\n\nfunction isLocalId(id) {\n  return (/^_local/).test(id);\n}\n\n// returns the current leaf node for a given revision\nfunction latest(rev, metadata) {\n  var toVisit = metadata.rev_tree.slice();\n  var node;\n  while ((node = toVisit.pop())) {\n    var pos = node.pos;\n    var tree = node.ids;\n    var id = tree[0];\n    var opts = tree[1];\n    var branches = tree[2];\n    var isLeaf = branches.length === 0;\n\n    var history = node.history ? node.history.slice() : [];\n    history.push({id: id, pos: pos, opts: opts});\n\n    if (isLeaf) {\n      for (var i = 0, len = history.length; i < len; i++) {\n        var historyNode = history[i];\n        var historyRev = historyNode.pos + '-' + historyNode.id;\n\n        if (historyRev === rev) {\n          // return the rev of this leaf\n          return pos + '-' + id;\n        }\n      }\n    }\n\n    for (var j = 0, l = branches.length; j < l; j++) {\n      toVisit.push({pos: pos + 1, ids: branches[j], history: history});\n    }\n  }\n\n  /* istanbul ignore next */\n  throw new Error('Unable to resolve latest revision for id ' + metadata.id + ', rev ' + rev);\n}\n\nfunction evalFilter(input) {\n  return scopedEval('\"use strict\";\\nreturn ' + input + ';', {});\n}\n\nfunction evalView(input) {\n  var code = [\n    'return function(doc) {',\n    '  \"use strict\";',\n    '  var emitted = false;',\n    '  var emit = function (a, b) {',\n    '    emitted = true;',\n    '  };',\n    '  var view = ' + input + ';',\n    '  view(doc);',\n    '  if (emitted) {',\n    '    return true;',\n    '  }',\n    '};'\n  ].join('\\n');\n\n  return scopedEval(code, {});\n}\n\ninherits(Changes$2, events.EventEmitter);\n\nfunction tryCatchInChangeListener(self, change) {\n  // isolate try/catches to avoid V8 deoptimizations\n  try {\n    self.emit('change', change);\n  } catch (e) {\n    guardedConsole('error', 'Error in .on(\"change\", function):', e);\n  }\n}\n\nfunction Changes$2(db, opts, callback) {\n  events.EventEmitter.call(this);\n  var self = this;\n  this.db = db;\n  opts = opts ? clone(opts) : {};\n  var complete = opts.complete = once(function (err, resp) {\n    if (err) {\n      if (listenerCount(self, 'error') > 0) {\n        self.emit('error', err);\n      }\n    } else {\n      self.emit('complete', resp);\n    }\n    self.removeAllListeners();\n    db.removeListener('destroyed', onDestroy);\n  });\n  if (callback) {\n    self.on('complete', function (resp) {\n      callback(null, resp);\n    });\n    self.on('error', callback);\n  }\n  function onDestroy() {\n    self.cancel();\n  }\n  db.once('destroyed', onDestroy);\n\n  opts.onChange = function (change) {\n    /* istanbul ignore if */\n    if (self.isCancelled) {\n      return;\n    }\n    tryCatchInChangeListener(self, change);\n  };\n\n  var promise = new PouchPromise$1(function (fulfill, reject) {\n    opts.complete = function (err, res) {\n      if (err) {\n        reject(err);\n      } else {\n        fulfill(res);\n      }\n    };\n  });\n  self.once('cancel', function () {\n    db.removeListener('destroyed', onDestroy);\n    opts.complete(null, {status: 'cancelled'});\n  });\n  this.then = promise.then.bind(promise);\n  this['catch'] = promise['catch'].bind(promise);\n  this.then(function (result) {\n    complete(null, result);\n  }, complete);\n\n\n\n  if (!db.taskqueue.isReady) {\n    db.taskqueue.addTask(function (failed) {\n      if (failed) {\n        opts.complete(failed);\n      } else if (self.isCancelled) {\n        self.emit('cancel');\n      } else {\n        self.doChanges(opts);\n      }\n    });\n  } else {\n    self.doChanges(opts);\n  }\n}\nChanges$2.prototype.cancel = function () {\n  this.isCancelled = true;\n  if (this.db.taskqueue.isReady) {\n    this.emit('cancel');\n  }\n};\nfunction processChange(doc, metadata, opts) {\n  var changeList = [{rev: doc._rev}];\n  if (opts.style === 'all_docs') {\n    changeList = collectLeaves(metadata.rev_tree)\n    .map(function (x) { return {rev: x.rev}; });\n  }\n  var change = {\n    id: metadata.id,\n    changes: changeList,\n    doc: doc\n  };\n\n  if (isDeleted(metadata, doc._rev)) {\n    change.deleted = true;\n  }\n  if (opts.conflicts) {\n    change.doc._conflicts = collectConflicts(metadata);\n    if (!change.doc._conflicts.length) {\n      delete change.doc._conflicts;\n    }\n  }\n  return change;\n}\n\nChanges$2.prototype.doChanges = function (opts) {\n  var self = this;\n  var callback = opts.complete;\n\n  opts = clone(opts);\n  if ('live' in opts && !('continuous' in opts)) {\n    opts.continuous = opts.live;\n  }\n  opts.processChange = processChange;\n\n  if (opts.since === 'latest') {\n    opts.since = 'now';\n  }\n  if (!opts.since) {\n    opts.since = 0;\n  }\n  if (opts.since === 'now') {\n    this.db.info().then(function (info) {\n      /* istanbul ignore if */\n      if (self.isCancelled) {\n        callback(null, {status: 'cancelled'});\n        return;\n      }\n      opts.since = info.update_seq;\n      self.doChanges(opts);\n    }, callback);\n    return;\n  }\n\n\n  if (opts.view && !opts.filter) {\n    opts.filter = '_view';\n  }\n\n  if (opts.filter && typeof opts.filter === 'string') {\n    if (opts.filter === '_view') {\n      opts.view = normalizeDesignDocFunctionName(opts.view);\n    } else {\n      opts.filter = normalizeDesignDocFunctionName(opts.filter);\n    }\n\n    if (this.db.type() !== 'http' && !opts.doc_ids) {\n      return this.filterChanges(opts);\n    }\n  }\n\n  if (!('descending' in opts)) {\n    opts.descending = false;\n  }\n\n  // 0 and 1 should return 1 document\n  opts.limit = opts.limit === 0 ? 1 : opts.limit;\n  opts.complete = callback;\n  var newPromise = this.db._changes(opts);\n  /* istanbul ignore else */\n  if (newPromise && typeof newPromise.cancel === 'function') {\n    var cancel = self.cancel;\n    self.cancel = getArguments(function (args) {\n      newPromise.cancel();\n      cancel.apply(this, args);\n    });\n  }\n};\n\nChanges$2.prototype.filterChanges = function (opts) {\n  var self = this;\n  var callback = opts.complete;\n  if (opts.filter === '_view') {\n    if (!opts.view || typeof opts.view !== 'string') {\n      var err = createError(BAD_REQUEST,\n        '`view` filter parameter not found or invalid.');\n      return callback(err);\n    }\n    // fetch a view from a design doc, make it behave like a filter\n    var viewName = parseDesignDocFunctionName(opts.view);\n    this.db.get('_design/' + viewName[0], function (err, ddoc) {\n      /* istanbul ignore if */\n      if (self.isCancelled) {\n        return callback(null, {status: 'cancelled'});\n      }\n      /* istanbul ignore next */\n      if (err) {\n        return callback(generateErrorFromResponse(err));\n      }\n      var mapFun = ddoc && ddoc.views && ddoc.views[viewName[1]] &&\n        ddoc.views[viewName[1]].map;\n      if (!mapFun) {\n        return callback(createError(MISSING_DOC,\n          (ddoc.views ? 'missing json key: ' + viewName[1] :\n            'missing json key: views')));\n      }\n      opts.filter = evalView(mapFun);\n      self.doChanges(opts);\n    });\n  } else {\n    // fetch a filter from a design doc\n    var filterName = parseDesignDocFunctionName(opts.filter);\n    if (!filterName) {\n      return self.doChanges(opts);\n    }\n    this.db.get('_design/' + filterName[0], function (err, ddoc) {\n      /* istanbul ignore if */\n      if (self.isCancelled) {\n        return callback(null, {status: 'cancelled'});\n      }\n      /* istanbul ignore next */\n      if (err) {\n        return callback(generateErrorFromResponse(err));\n      }\n      var filterFun = ddoc && ddoc.filters && ddoc.filters[filterName[1]];\n      if (!filterFun) {\n        return callback(createError(MISSING_DOC,\n          ((ddoc && ddoc.filters) ? 'missing json key: ' + filterName[1]\n            : 'missing json key: filters')));\n      }\n      opts.filter = evalFilter(filterFun);\n      self.doChanges(opts);\n    });\n  }\n};\n\n/*\n * A generic pouch adapter\n */\n\nfunction compare(left, right) {\n  return left < right ? -1 : left > right ? 1 : 0;\n}\n\n// Wrapper for functions that call the bulkdocs api with a single doc,\n// if the first result is an error, return an error\nfunction yankError(callback) {\n  return function (err, results) {\n    if (err || (results[0] && results[0].error)) {\n      callback(err || results[0]);\n    } else {\n      callback(null, results.length ? results[0]  : results);\n    }\n  };\n}\n\n// clean docs given to us by the user\nfunction cleanDocs(docs) {\n  for (var i = 0; i < docs.length; i++) {\n    var doc = docs[i];\n    if (doc._deleted) {\n      delete doc._attachments; // ignore atts for deleted docs\n    } else if (doc._attachments) {\n      // filter out extraneous keys from _attachments\n      var atts = Object.keys(doc._attachments);\n      for (var j = 0; j < atts.length; j++) {\n        var att = atts[j];\n        doc._attachments[att] = pick(doc._attachments[att],\n          ['data', 'digest', 'content_type', 'length', 'revpos', 'stub']);\n      }\n    }\n  }\n}\n\n// compare two docs, first by _id then by _rev\nfunction compareByIdThenRev(a, b) {\n  var idCompare = compare(a._id, b._id);\n  if (idCompare !== 0) {\n    return idCompare;\n  }\n  var aStart = a._revisions ? a._revisions.start : 0;\n  var bStart = b._revisions ? b._revisions.start : 0;\n  return compare(aStart, bStart);\n}\n\n// for every node in a revision tree computes its distance from the closest\n// leaf\nfunction computeHeight(revs) {\n  var height = {};\n  var edges = [];\n  traverseRevTree(revs, function (isLeaf, pos, id, prnt) {\n    var rev = pos + \"-\" + id;\n    if (isLeaf) {\n      height[rev] = 0;\n    }\n    if (prnt !== undefined) {\n      edges.push({from: prnt, to: rev});\n    }\n    return rev;\n  });\n\n  edges.reverse();\n  edges.forEach(function (edge) {\n    if (height[edge.from] === undefined) {\n      height[edge.from] = 1 + height[edge.to];\n    } else {\n      height[edge.from] = Math.min(height[edge.from], 1 + height[edge.to]);\n    }\n  });\n  return height;\n}\n\nfunction allDocsKeysQuery(api, opts, callback) {\n  var keys =  ('limit' in opts) ?\n      opts.keys.slice(opts.skip, opts.limit + opts.skip) :\n      (opts.skip > 0) ? opts.keys.slice(opts.skip) : opts.keys;\n  if (opts.descending) {\n    keys.reverse();\n  }\n  if (!keys.length) {\n    return api._allDocs({limit: 0}, callback);\n  }\n  var finalResults = {\n    offset: opts.skip\n  };\n  return PouchPromise$1.all(keys.map(function (key) {\n    var subOpts = assign$1({key: key, deleted: 'ok'}, opts);\n    ['limit', 'skip', 'keys'].forEach(function (optKey) {\n      delete subOpts[optKey];\n    });\n    return new PouchPromise$1(function (resolve, reject) {\n      api._allDocs(subOpts, function (err, res) {\n        /* istanbul ignore if */\n        if (err) {\n          return reject(err);\n        }\n        finalResults.total_rows = res.total_rows;\n        resolve(res.rows[0] || {key: key, error: 'not_found'});\n      });\n    });\n  })).then(function (results) {\n    finalResults.rows = results;\n    return finalResults;\n  });\n}\n\n// all compaction is done in a queue, to avoid attaching\n// too many listeners at once\nfunction doNextCompaction(self) {\n  var task = self._compactionQueue[0];\n  var opts = task.opts;\n  var callback = task.callback;\n  self.get('_local/compaction').catch(function () {\n    return false;\n  }).then(function (doc) {\n    if (doc && doc.last_seq) {\n      opts.last_seq = doc.last_seq;\n    }\n    self._compact(opts, function (err, res) {\n      /* istanbul ignore if */\n      if (err) {\n        callback(err);\n      } else {\n        callback(null, res);\n      }\n      nextTick(function () {\n        self._compactionQueue.shift();\n        if (self._compactionQueue.length) {\n          doNextCompaction(self);\n        }\n      });\n    });\n  });\n}\n\nfunction attachmentNameError(name) {\n  if (name.charAt(0) === '_') {\n    return name + 'is not a valid attachment name, attachment ' +\n      'names cannot start with \\'_\\'';\n  }\n  return false;\n}\n\ninherits(AbstractPouchDB, events.EventEmitter);\n\nfunction AbstractPouchDB() {\n  events.EventEmitter.call(this);\n}\n\nAbstractPouchDB.prototype.post =\n  adapterFun('post', function (doc, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  if (typeof doc !== 'object' || Array.isArray(doc)) {\n    return callback(createError(NOT_AN_OBJECT));\n  }\n  this.bulkDocs({docs: [doc]}, opts, yankError(callback));\n});\n\nAbstractPouchDB.prototype.put = adapterFun('put', function (doc, opts, cb) {\n  if (typeof opts === 'function') {\n    cb = opts;\n    opts = {};\n  }\n  if (typeof doc !== 'object' || Array.isArray(doc)) {\n    return cb(createError(NOT_AN_OBJECT));\n  }\n  invalidIdError(doc._id);\n  if (isLocalId(doc._id) && typeof this._putLocal === 'function') {\n    if (doc._deleted) {\n      return this._removeLocal(doc, cb);\n    } else {\n      return this._putLocal(doc, cb);\n    }\n  }\n  if (typeof this._put === 'function' && opts.new_edits !== false) {\n    this._put(doc, opts, cb);\n  } else {\n    this.bulkDocs({docs: [doc]}, opts, yankError(cb));\n  }\n});\n\nAbstractPouchDB.prototype.putAttachment =\n  adapterFun('putAttachment', function (docId, attachmentId, rev,\n                                              blob, type) {\n  var api = this;\n  if (typeof type === 'function') {\n    type = blob;\n    blob = rev;\n    rev = null;\n  }\n  // Lets fix in https://github.com/pouchdb/pouchdb/issues/3267\n  /* istanbul ignore if */\n  if (typeof type === 'undefined') {\n    type = blob;\n    blob = rev;\n    rev = null;\n  }\n  if (!type) {\n    guardedConsole('warn', 'Attachment', attachmentId, 'on document', docId, 'is missing content_type');\n  }\n\n  function createAttachment(doc) {\n    var prevrevpos = '_rev' in doc ? parseInt(doc._rev, 10) : 0;\n    doc._attachments = doc._attachments || {};\n    doc._attachments[attachmentId] = {\n      content_type: type,\n      data: blob,\n      revpos: ++prevrevpos\n    };\n    return api.put(doc);\n  }\n\n  return api.get(docId).then(function (doc) {\n    if (doc._rev !== rev) {\n      throw createError(REV_CONFLICT);\n    }\n\n    return createAttachment(doc);\n  }, function (err) {\n     // create new doc\n    /* istanbul ignore else */\n    if (err.reason === MISSING_DOC.message) {\n      return createAttachment({_id: docId});\n    } else {\n      throw err;\n    }\n  });\n});\n\nAbstractPouchDB.prototype.removeAttachment =\n  adapterFun('removeAttachment', function (docId, attachmentId, rev,\n                                                 callback) {\n  var self = this;\n  self.get(docId, function (err, obj) {\n    /* istanbul ignore if */\n    if (err) {\n      callback(err);\n      return;\n    }\n    if (obj._rev !== rev) {\n      callback(createError(REV_CONFLICT));\n      return;\n    }\n    /* istanbul ignore if */\n    if (!obj._attachments) {\n      return callback();\n    }\n    delete obj._attachments[attachmentId];\n    if (Object.keys(obj._attachments).length === 0) {\n      delete obj._attachments;\n    }\n    self.put(obj, callback);\n  });\n});\n\nAbstractPouchDB.prototype.remove =\n  adapterFun('remove', function (docOrId, optsOrRev, opts, callback) {\n  var doc;\n  if (typeof optsOrRev === 'string') {\n    // id, rev, opts, callback style\n    doc = {\n      _id: docOrId,\n      _rev: optsOrRev\n    };\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n  } else {\n    // doc, opts, callback style\n    doc = docOrId;\n    if (typeof optsOrRev === 'function') {\n      callback = optsOrRev;\n      opts = {};\n    } else {\n      callback = opts;\n      opts = optsOrRev;\n    }\n  }\n  opts = opts || {};\n  opts.was_delete = true;\n  var newDoc = {_id: doc._id, _rev: (doc._rev || opts.rev)};\n  newDoc._deleted = true;\n  if (isLocalId(newDoc._id) && typeof this._removeLocal === 'function') {\n    return this._removeLocal(doc, callback);\n  }\n  this.bulkDocs({docs: [newDoc]}, opts, yankError(callback));\n});\n\nAbstractPouchDB.prototype.revsDiff =\n  adapterFun('revsDiff', function (req, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  var ids = Object.keys(req);\n\n  if (!ids.length) {\n    return callback(null, {});\n  }\n\n  var count = 0;\n  var missing = new ExportedMap();\n\n  function addToMissing(id, revId) {\n    if (!missing.has(id)) {\n      missing.set(id, {missing: []});\n    }\n    missing.get(id).missing.push(revId);\n  }\n\n  function processDoc(id, rev_tree) {\n    // Is this fast enough? Maybe we should switch to a set simulated by a map\n    var missingForId = req[id].slice(0);\n    traverseRevTree(rev_tree, function (isLeaf, pos, revHash, ctx,\n      opts) {\n        var rev = pos + '-' + revHash;\n        var idx = missingForId.indexOf(rev);\n        if (idx === -1) {\n          return;\n        }\n\n        missingForId.splice(idx, 1);\n        /* istanbul ignore if */\n        if (opts.status !== 'available') {\n          addToMissing(id, rev);\n        }\n      });\n\n    // Traversing the tree is synchronous, so now `missingForId` contains\n    // revisions that were not found in the tree\n    missingForId.forEach(function (rev) {\n      addToMissing(id, rev);\n    });\n  }\n\n  ids.map(function (id) {\n    this._getRevisionTree(id, function (err, rev_tree) {\n      if (err && err.status === 404 && err.message === 'missing') {\n        missing.set(id, {missing: req[id]});\n      } else if (err) {\n        /* istanbul ignore next */\n        return callback(err);\n      } else {\n        processDoc(id, rev_tree);\n      }\n\n      if (++count === ids.length) {\n        // convert LazyMap to object\n        var missingObj = {};\n        missing.forEach(function (value, key) {\n          missingObj[key] = value;\n        });\n        return callback(null, missingObj);\n      }\n    });\n  }, this);\n});\n\n// _bulk_get API for faster replication, as described in\n// https://github.com/apache/couchdb-chttpd/pull/33\n// At the \"abstract\" level, it will just run multiple get()s in\n// parallel, because this isn't much of a performance cost\n// for local databases (except the cost of multiple transactions, which is\n// small). The http adapter overrides this in order\n// to do a more efficient single HTTP request.\nAbstractPouchDB.prototype.bulkGet =\n  adapterFun('bulkGet', function (opts, callback) {\n  bulkGet(this, opts, callback);\n});\n\n// compact one document and fire callback\n// by compacting we mean removing all revisions which\n// are further from the leaf in revision tree than max_height\nAbstractPouchDB.prototype.compactDocument =\n  adapterFun('compactDocument', function (docId, maxHeight, callback) {\n  var self = this;\n  this._getRevisionTree(docId, function (err, revTree) {\n    /* istanbul ignore if */\n    if (err) {\n      return callback(err);\n    }\n    var height = computeHeight(revTree);\n    var candidates = [];\n    var revs = [];\n    Object.keys(height).forEach(function (rev) {\n      if (height[rev] > maxHeight) {\n        candidates.push(rev);\n      }\n    });\n\n    traverseRevTree(revTree, function (isLeaf, pos, revHash, ctx, opts) {\n      var rev = pos + '-' + revHash;\n      if (opts.status === 'available' && candidates.indexOf(rev) !== -1) {\n        revs.push(rev);\n      }\n    });\n    self._doCompaction(docId, revs, callback);\n  });\n});\n\n// compact the whole database using single document\n// compaction\nAbstractPouchDB.prototype.compact =\n  adapterFun('compact', function (opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n\n  var self = this;\n  opts = opts || {};\n\n  self._compactionQueue = self._compactionQueue || [];\n  self._compactionQueue.push({opts: opts, callback: callback});\n  if (self._compactionQueue.length === 1) {\n    doNextCompaction(self);\n  }\n});\nAbstractPouchDB.prototype._compact = function (opts, callback) {\n  var self = this;\n  var changesOpts = {\n    return_docs: false,\n    last_seq: opts.last_seq || 0\n  };\n  var promises = [];\n\n  function onChange(row) {\n    promises.push(self.compactDocument(row.id, 0));\n  }\n  function onComplete(resp) {\n    var lastSeq = resp.last_seq;\n    PouchPromise$1.all(promises).then(function () {\n      return upsert(self, '_local/compaction', function deltaFunc(doc) {\n        if (!doc.last_seq || doc.last_seq < lastSeq) {\n          doc.last_seq = lastSeq;\n          return doc;\n        }\n        return false; // somebody else got here first, don't update\n      });\n    }).then(function () {\n      callback(null, {ok: true});\n    }).catch(callback);\n  }\n  self.changes(changesOpts)\n    .on('change', onChange)\n    .on('complete', onComplete)\n    .on('error', callback);\n};\n\n/* Begin api wrappers. Specific functionality to storage belongs in the\n   _[method] */\nAbstractPouchDB.prototype.get = adapterFun('get', function (id, opts, cb) {\n  if (typeof opts === 'function') {\n    cb = opts;\n    opts = {};\n  }\n  if (typeof id !== 'string') {\n    return cb(createError(INVALID_ID));\n  }\n  if (isLocalId(id) && typeof this._getLocal === 'function') {\n    return this._getLocal(id, cb);\n  }\n  var leaves = [], self = this;\n\n  function finishOpenRevs() {\n    var result = [];\n    var count = leaves.length;\n    /* istanbul ignore if */\n    if (!count) {\n      return cb(null, result);\n    }\n\n    // order with open_revs is unspecified\n    leaves.forEach(function (leaf) {\n      self.get(id, {\n        rev: leaf,\n        revs: opts.revs,\n        latest: opts.latest,\n        attachments: opts.attachments\n      }, function (err, doc) {\n        if (!err) {\n          // using latest=true can produce duplicates\n          var existing;\n          for (var i = 0, l = result.length; i < l; i++) {\n            if (result[i].ok && result[i].ok._rev === doc._rev) {\n              existing = true;\n              break;\n            }\n          }\n          if (!existing) {\n            result.push({ok: doc});\n          }\n        } else {\n          result.push({missing: leaf});\n        }\n        count--;\n        if (!count) {\n          cb(null, result);\n        }\n      });\n    });\n  }\n\n  if (opts.open_revs) {\n    if (opts.open_revs === \"all\") {\n      this._getRevisionTree(id, function (err, rev_tree) {\n        if (err) {\n          return cb(err);\n        }\n        leaves = collectLeaves(rev_tree).map(function (leaf) {\n          return leaf.rev;\n        });\n        finishOpenRevs();\n      });\n    } else {\n      if (Array.isArray(opts.open_revs)) {\n        leaves = opts.open_revs;\n        for (var i = 0; i < leaves.length; i++) {\n          var l = leaves[i];\n          // looks like it's the only thing couchdb checks\n          if (!(typeof (l) === \"string\" && /^\\d+-/.test(l))) {\n            return cb(createError(INVALID_REV));\n          }\n        }\n        finishOpenRevs();\n      } else {\n        return cb(createError(UNKNOWN_ERROR, 'function_clause'));\n      }\n    }\n    return; // open_revs does not like other options\n  }\n\n  return this._get(id, opts, function (err, result) {\n    if (err) {\n      return cb(err);\n    }\n\n    var doc = result.doc;\n    var metadata = result.metadata;\n    var ctx = result.ctx;\n\n    if (opts.conflicts) {\n      var conflicts = collectConflicts(metadata);\n      if (conflicts.length) {\n        doc._conflicts = conflicts;\n      }\n    }\n\n    if (isDeleted(metadata, doc._rev)) {\n      doc._deleted = true;\n    }\n\n    if (opts.revs || opts.revs_info) {\n      var splittedRev = doc._rev.split('-');\n      var revNo       = parseInt(splittedRev[0], 10);\n      var revHash     = splittedRev[1];\n\n      var paths = rootToLeaf(metadata.rev_tree);\n      var path = null;\n\n      for (var i = 0; i < paths.length; i++) {\n        var currentPath = paths[i];\n        var hashIndex = currentPath.ids.map(function (x) { return x.id; })\n          .indexOf(revHash);\n        var hashFoundAtRevPos = hashIndex === (revNo - 1);\n\n        if (hashFoundAtRevPos || (!path && hashIndex !== -1)) {\n          path = currentPath;\n        }\n      }\n\n      var indexOfRev = path.ids.map(function (x) { return x.id; })\n        .indexOf(doc._rev.split('-')[1]) + 1;\n      var howMany = path.ids.length - indexOfRev;\n      path.ids.splice(indexOfRev, howMany);\n      path.ids.reverse();\n\n      if (opts.revs) {\n        doc._revisions = {\n          start: (path.pos + path.ids.length) - 1,\n          ids: path.ids.map(function (rev) {\n            return rev.id;\n          })\n        };\n      }\n      if (opts.revs_info) {\n        var pos =  path.pos + path.ids.length;\n        doc._revs_info = path.ids.map(function (rev) {\n          pos--;\n          return {\n            rev: pos + '-' + rev.id,\n            status: rev.opts.status\n          };\n        });\n      }\n    }\n\n    if (opts.attachments && doc._attachments) {\n      var attachments = doc._attachments;\n      var count = Object.keys(attachments).length;\n      if (count === 0) {\n        return cb(null, doc);\n      }\n      Object.keys(attachments).forEach(function (key) {\n        this._getAttachment(doc._id, key, attachments[key], {\n          // Previously the revision handling was done in adapter.js\n          // getAttachment, however since idb-next doesnt we need to\n          // pass the rev through\n          rev: doc._rev,\n          binary: opts.binary,\n          ctx: ctx\n        }, function (err, data) {\n          var att = doc._attachments[key];\n          att.data = data;\n          delete att.stub;\n          delete att.length;\n          if (!--count) {\n            cb(null, doc);\n          }\n        });\n      }, self);\n    } else {\n      if (doc._attachments) {\n        for (var key in doc._attachments) {\n          /* istanbul ignore else */\n          if (doc._attachments.hasOwnProperty(key)) {\n            doc._attachments[key].stub = true;\n          }\n        }\n      }\n      cb(null, doc);\n    }\n  });\n});\n\n// TODO: I dont like this, it forces an extra read for every\n// attachment read and enforces a confusing api between\n// adapter.js and the adapter implementation\nAbstractPouchDB.prototype.getAttachment =\n  adapterFun('getAttachment', function (docId, attachmentId, opts, callback) {\n  var self = this;\n  if (opts instanceof Function) {\n    callback = opts;\n    opts = {};\n  }\n  this._get(docId, opts, function (err, res) {\n    if (err) {\n      return callback(err);\n    }\n    if (res.doc._attachments && res.doc._attachments[attachmentId]) {\n      opts.ctx = res.ctx;\n      opts.binary = true;\n      self._getAttachment(docId, attachmentId,\n                          res.doc._attachments[attachmentId], opts, callback);\n    } else {\n      return callback(createError(MISSING_DOC));\n    }\n  });\n});\n\nAbstractPouchDB.prototype.allDocs =\n  adapterFun('allDocs', function (opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  opts.skip = typeof opts.skip !== 'undefined' ? opts.skip : 0;\n  if (opts.start_key) {\n    opts.startkey = opts.start_key;\n  }\n  if (opts.end_key) {\n    opts.endkey = opts.end_key;\n  }\n  if ('keys' in opts) {\n    if (!Array.isArray(opts.keys)) {\n      return callback(new TypeError('options.keys must be an array'));\n    }\n    var incompatibleOpt =\n      ['startkey', 'endkey', 'key'].filter(function (incompatibleOpt) {\n      return incompatibleOpt in opts;\n    })[0];\n    if (incompatibleOpt) {\n      callback(createError(QUERY_PARSE_ERROR,\n        'Query parameter `' + incompatibleOpt +\n        '` is not compatible with multi-get'\n      ));\n      return;\n    }\n    if (this.type() !== 'http') {\n      return allDocsKeysQuery(this, opts, callback);\n    }\n  }\n\n  return this._allDocs(opts, callback);\n});\n\nAbstractPouchDB.prototype.changes = function (opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  return new Changes$2(this, opts, callback);\n};\n\nAbstractPouchDB.prototype.close = adapterFun('close', function (callback) {\n  this._closed = true;\n  this.emit('closed');\n  return this._close(callback);\n});\n\nAbstractPouchDB.prototype.info = adapterFun('info', function (callback) {\n  var self = this;\n  this._info(function (err, info) {\n    if (err) {\n      return callback(err);\n    }\n    // assume we know better than the adapter, unless it informs us\n    info.db_name = info.db_name || self.name;\n    info.auto_compaction = !!(self.auto_compaction && self.type() !== 'http');\n    info.adapter = self.type();\n    callback(null, info);\n  });\n});\n\nAbstractPouchDB.prototype.id = adapterFun('id', function (callback) {\n  return this._id(callback);\n});\n\n/* istanbul ignore next */\nAbstractPouchDB.prototype.type = function () {\n  return (typeof this._type === 'function') ? this._type() : this.adapter;\n};\n\nAbstractPouchDB.prototype.bulkDocs =\n  adapterFun('bulkDocs', function (req, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n\n  opts = opts || {};\n\n  if (Array.isArray(req)) {\n    req = {\n      docs: req\n    };\n  }\n\n  if (!req || !req.docs || !Array.isArray(req.docs)) {\n    return callback(createError(MISSING_BULK_DOCS));\n  }\n\n  for (var i = 0; i < req.docs.length; ++i) {\n    if (typeof req.docs[i] !== 'object' || Array.isArray(req.docs[i])) {\n      return callback(createError(NOT_AN_OBJECT));\n    }\n  }\n\n  var attachmentError;\n  req.docs.forEach(function (doc) {\n    if (doc._attachments) {\n      Object.keys(doc._attachments).forEach(function (name) {\n        attachmentError = attachmentError || attachmentNameError(name);\n        if (!doc._attachments[name].content_type) {\n          guardedConsole('warn', 'Attachment', name, 'on document', doc._id, 'is missing content_type');\n        }\n      });\n    }\n  });\n\n  if (attachmentError) {\n    return callback(createError(BAD_REQUEST, attachmentError));\n  }\n\n  if (!('new_edits' in opts)) {\n    if ('new_edits' in req) {\n      opts.new_edits = req.new_edits;\n    } else {\n      opts.new_edits = true;\n    }\n  }\n\n  var adapter = this;\n  if (!opts.new_edits && adapter.type() !== 'http') {\n    // ensure revisions of the same doc are sorted, so that\n    // the local adapter processes them correctly (#2935)\n    req.docs.sort(compareByIdThenRev);\n  }\n\n  cleanDocs(req.docs);\n\n  // in the case of conflicts, we want to return the _ids to the user\n  // however, the underlying adapter may destroy the docs array, so\n  // create a copy here\n  var ids = req.docs.map(function (doc) {\n    return doc._id;\n  });\n\n  return this._bulkDocs(req, opts, function (err, res) {\n    if (err) {\n      return callback(err);\n    }\n    if (!opts.new_edits) {\n      // this is what couch does when new_edits is false\n      res = res.filter(function (x) {\n        return x.error;\n      });\n    }\n    // add ids for error/conflict responses (not required for CouchDB)\n    if (adapter.type() !== 'http') {\n      for (var i = 0, l = res.length; i < l; i++) {\n        res[i].id = res[i].id || ids[i];\n      }\n    }\n\n    callback(null, res);\n  });\n});\n\nAbstractPouchDB.prototype.registerDependentDatabase =\n  adapterFun('registerDependentDatabase', function (dependentDb,\n                                                          callback) {\n  var depDB = new this.constructor(dependentDb, this.__opts);\n\n  function diffFun(doc) {\n    doc.dependentDbs = doc.dependentDbs || {};\n    if (doc.dependentDbs[dependentDb]) {\n      return false; // no update required\n    }\n    doc.dependentDbs[dependentDb] = true;\n    return doc;\n  }\n  upsert(this, '_local/_pouch_dependentDbs', diffFun)\n    .then(function () {\n      callback(null, {db: depDB});\n    }).catch(callback);\n});\n\nAbstractPouchDB.prototype.destroy =\n  adapterFun('destroy', function (opts, callback) {\n\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n\n  var self = this;\n  var usePrefix = 'use_prefix' in self ? self.use_prefix : true;\n\n  function destroyDb() {\n    // call destroy method of the particular adaptor\n    self._destroy(opts, function (err, resp) {\n      if (err) {\n        return callback(err);\n      }\n      self._destroyed = true;\n      self.emit('destroyed');\n      callback(null, resp || { 'ok': true });\n    });\n  }\n\n  if (self.type() === 'http') {\n    // no need to check for dependent DBs if it's a remote DB\n    return destroyDb();\n  }\n\n  self.get('_local/_pouch_dependentDbs', function (err, localDoc) {\n    if (err) {\n      /* istanbul ignore if */\n      if (err.status !== 404) {\n        return callback(err);\n      } else { // no dependencies\n        return destroyDb();\n      }\n    }\n    var dependentDbs = localDoc.dependentDbs;\n    var PouchDB = self.constructor;\n    var deletedMap = Object.keys(dependentDbs).map(function (name) {\n      // use_prefix is only false in the browser\n      /* istanbul ignore next */\n      var trueName = usePrefix ?\n        name.replace(new RegExp('^' + PouchDB.prefix), '') : name;\n      return new PouchDB(trueName, self.__opts).destroy();\n    });\n    PouchPromise$1.all(deletedMap).then(destroyDb, callback);\n  });\n});\n\nfunction TaskQueue$1() {\n  this.isReady = false;\n  this.failed = false;\n  this.queue = [];\n}\n\nTaskQueue$1.prototype.execute = function () {\n  var fun;\n  if (this.failed) {\n    while ((fun = this.queue.shift())) {\n      fun(this.failed);\n    }\n  } else {\n    while ((fun = this.queue.shift())) {\n      fun();\n    }\n  }\n};\n\nTaskQueue$1.prototype.fail = function (err) {\n  this.failed = err;\n  this.execute();\n};\n\nTaskQueue$1.prototype.ready = function (db) {\n  this.isReady = true;\n  this.db = db;\n  this.execute();\n};\n\nTaskQueue$1.prototype.addTask = function (fun) {\n  this.queue.push(fun);\n  if (this.failed) {\n    this.execute();\n  }\n};\n\nfunction parseAdapter(name, opts) {\n  var match = name.match(/([a-z\\-]*):\\/\\/(.*)/);\n  if (match) {\n    // the http adapter expects the fully qualified name\n    return {\n      name: /https?/.test(match[1]) ? match[1] + '://' + match[2] : match[2],\n      adapter: match[1]\n    };\n  }\n\n  var adapters = PouchDB$3.adapters;\n  var preferredAdapters = PouchDB$3.preferredAdapters;\n  var prefix = PouchDB$3.prefix;\n  var adapterName = opts.adapter;\n\n  if (!adapterName) { // automatically determine adapter\n    for (var i = 0; i < preferredAdapters.length; ++i) {\n      adapterName = preferredAdapters[i];\n      // check for browsers that have been upgraded from websql-only to websql+idb\n      /* istanbul ignore if */\n      if (adapterName === 'idb' && 'websql' in adapters &&\n          hasLocalStorage() && localStorage['_pouch__websqldb_' + prefix + name]) {\n        // log it, because this can be confusing during development\n        guardedConsole('log', 'PouchDB is downgrading \"' + name + '\" to WebSQL to' +\n          ' avoid data loss, because it was already opened with WebSQL.');\n        continue; // keep using websql to avoid user data loss\n      }\n      break;\n    }\n  }\n\n  var adapter = adapters[adapterName];\n\n  // if adapter is invalid, then an error will be thrown later\n  var usePrefix = (adapter && 'use_prefix' in adapter) ?\n    adapter.use_prefix : true;\n\n  return {\n    name: usePrefix ? (prefix + name) : name,\n    adapter: adapterName\n  };\n}\n\n// OK, so here's the deal. Consider this code:\n//     var db1 = new PouchDB('foo');\n//     var db2 = new PouchDB('foo');\n//     db1.destroy();\n// ^ these two both need to emit 'destroyed' events,\n// as well as the PouchDB constructor itself.\n// So we have one db object (whichever one got destroy() called on it)\n// responsible for emitting the initial event, which then gets emitted\n// by the constructor, which then broadcasts it to any other dbs\n// that may have been created with the same name.\nfunction prepareForDestruction(self) {\n\n  var destructionListeners = self.constructor._destructionListeners;\n\n  function onDestroyed() {\n    self.removeListener('closed', onClosed);\n    self.constructor.emit('destroyed', self.name);\n  }\n\n  function onConstructorDestroyed() {\n    self.removeListener('destroyed', onDestroyed);\n    self.removeListener('closed', onClosed);\n    self.emit('destroyed');\n  }\n\n  function onClosed() {\n    self.removeListener('destroyed', onDestroyed);\n    destructionListeners.delete(self.name);\n  }\n\n  self.once('destroyed', onDestroyed);\n  self.once('closed', onClosed);\n\n  // in setup.js, the constructor is primed to listen for destroy events\n  if (!destructionListeners.has(self.name)) {\n    destructionListeners.set(self.name, []);\n  }\n  destructionListeners.get(self.name).push(onConstructorDestroyed);\n}\n\ninherits(PouchDB$3, AbstractPouchDB);\nfunction PouchDB$3(name, opts) {\n  // In Node our test suite only tests this for PouchAlt unfortunately\n  /* istanbul ignore if */\n  if (!(this instanceof PouchDB$3)) {\n    return new PouchDB$3(name, opts);\n  }\n\n  var self = this;\n  opts = opts || {};\n\n  if (name && typeof name === 'object') {\n    opts = name;\n    name = opts.name;\n    delete opts.name;\n  }\n\n  this.__opts = opts = clone(opts);\n\n  self.auto_compaction = opts.auto_compaction;\n  self.prefix = PouchDB$3.prefix;\n\n  if (typeof name !== 'string') {\n    throw new Error('Missing/invalid DB name');\n  }\n\n  var prefixedName = (opts.prefix || '') + name;\n  var backend = parseAdapter(prefixedName, opts);\n\n  opts.name = backend.name;\n  opts.adapter = opts.adapter || backend.adapter;\n\n  self.name = name;\n  self._adapter = opts.adapter;\n  debug('pouchdb:adapter')('Picked adapter: ' + opts.adapter);\n\n  if (!PouchDB$3.adapters[opts.adapter] ||\n      !PouchDB$3.adapters[opts.adapter].valid()) {\n    throw new Error('Invalid Adapter: ' + opts.adapter);\n  }\n\n  AbstractPouchDB.call(self);\n  self.taskqueue = new TaskQueue$1();\n\n  self.adapter = opts.adapter;\n\n  PouchDB$3.adapters[opts.adapter].call(self, opts, function (err) {\n    if (err) {\n      return self.taskqueue.fail(err);\n    }\n    prepareForDestruction(self);\n\n    self.emit('created', self);\n    PouchDB$3.emit('created', self.name);\n    self.taskqueue.ready(self);\n  });\n\n}\n\nPouchDB$3.debug = debug;\n\nPouchDB$3.adapters = {};\nPouchDB$3.preferredAdapters = [];\n\nPouchDB$3.prefix = '_pouch_';\n\nvar eventEmitter = new events.EventEmitter();\n\nfunction setUpEventEmitter(Pouch) {\n  Object.keys(events.EventEmitter.prototype).forEach(function (key) {\n    if (typeof events.EventEmitter.prototype[key] === 'function') {\n      Pouch[key] = eventEmitter[key].bind(eventEmitter);\n    }\n  });\n\n  // these are created in constructor.js, and allow us to notify each DB with\n  // the same name that it was destroyed, via the constructor object\n  var destructListeners = Pouch._destructionListeners = new ExportedMap();\n  Pouch.on('destroyed', function onConstructorDestroyed(name) {\n    destructListeners.get(name).forEach(function (callback) {\n      callback();\n    });\n    destructListeners.delete(name);\n  });\n}\n\nsetUpEventEmitter(PouchDB$3);\n\nPouchDB$3.adapter = function (id, obj, addToPreferredAdapters) {\n  /* istanbul ignore else */\n  if (obj.valid()) {\n    PouchDB$3.adapters[id] = obj;\n    if (addToPreferredAdapters) {\n      PouchDB$3.preferredAdapters.push(id);\n    }\n  }\n};\n\nPouchDB$3.plugin = function (obj) {\n  if (typeof obj === 'function') { // function style for plugins\n    obj(PouchDB$3);\n  } else if (typeof obj !== 'object' || Object.keys(obj).length === 0){\n    throw new Error('Invalid plugin: got \\\"' + obj + '\\\", expected an object or a function');\n  } else {\n    Object.keys(obj).forEach(function (id) { // object style for plugins\n      PouchDB$3.prototype[id] = obj[id];\n    });\n  }\n  return PouchDB$3;\n};\n\nPouchDB$3.defaults = function (defaultOpts) {\n  function PouchAlt(name, opts) {\n    if (!(this instanceof PouchAlt)) {\n      return new PouchAlt(name, opts);\n    }\n\n    opts = opts || {};\n\n    if (name && typeof name === 'object') {\n      opts = name;\n      name = opts.name;\n      delete opts.name;\n    }\n\n    opts = assign$1({}, PouchAlt.__defaults, opts);\n    PouchDB$3.call(this, name, opts);\n  }\n\n  inherits(PouchAlt, PouchDB$3);\n\n  PouchAlt.preferredAdapters = PouchDB$3.preferredAdapters.slice();\n  Object.keys(PouchDB$3).forEach(function (key) {\n    if (!(key in PouchAlt)) {\n      PouchAlt[key] = PouchDB$3[key];\n    }\n  });\n\n  // make default options transitive\n  // https://github.com/pouchdb/pouchdb/issues/5922\n  PouchAlt.__defaults = assign$1({}, this.__defaults, defaultOpts);\n\n  return PouchAlt;\n};\n\n// managed automatically by set-version.js\nvar version = \"6.1.1\";\n\nPouchDB$3.version = version;\n\nfunction toObject(array) {\n  return array.reduce(function (obj, item) {\n    obj[item] = true;\n    return obj;\n  }, {});\n}\n// List of top level reserved words for doc\nvar reservedWords = toObject([\n  '_id',\n  '_rev',\n  '_attachments',\n  '_deleted',\n  '_revisions',\n  '_revs_info',\n  '_conflicts',\n  '_deleted_conflicts',\n  '_local_seq',\n  '_rev_tree',\n  //replication documents\n  '_replication_id',\n  '_replication_state',\n  '_replication_state_time',\n  '_replication_state_reason',\n  '_replication_stats',\n  // Specific to Couchbase Sync Gateway\n  '_removed'\n]);\n\n// List of reserved words that should end up the document\nvar dataWords = toObject([\n  '_attachments',\n  //replication documents\n  '_replication_id',\n  '_replication_state',\n  '_replication_state_time',\n  '_replication_state_reason',\n  '_replication_stats'\n]);\n\nfunction parseRevisionInfo(rev) {\n  if (!/^\\d+\\-./.test(rev)) {\n    return createError(INVALID_REV);\n  }\n  var idx = rev.indexOf('-');\n  var left = rev.substring(0, idx);\n  var right = rev.substring(idx + 1);\n  return {\n    prefix: parseInt(left, 10),\n    id: right\n  };\n}\n\nfunction makeRevTreeFromRevisions(revisions, opts) {\n  var pos = revisions.start - revisions.ids.length + 1;\n\n  var revisionIds = revisions.ids;\n  var ids = [revisionIds[0], opts, []];\n\n  for (var i = 1, len = revisionIds.length; i < len; i++) {\n    ids = [revisionIds[i], {status: 'missing'}, [ids]];\n  }\n\n  return [{\n    pos: pos,\n    ids: ids\n  }];\n}\n\n// Preprocess documents, parse their revisions, assign an id and a\n// revision for new writes that are missing them, etc\nfunction parseDoc(doc, newEdits) {\n\n  var nRevNum;\n  var newRevId;\n  var revInfo;\n  var opts = {status: 'available'};\n  if (doc._deleted) {\n    opts.deleted = true;\n  }\n\n  if (newEdits) {\n    if (!doc._id) {\n      doc._id = uuid();\n    }\n    newRevId = uuid(32, 16).toLowerCase();\n    if (doc._rev) {\n      revInfo = parseRevisionInfo(doc._rev);\n      if (revInfo.error) {\n        return revInfo;\n      }\n      doc._rev_tree = [{\n        pos: revInfo.prefix,\n        ids: [revInfo.id, {status: 'missing'}, [[newRevId, opts, []]]]\n      }];\n      nRevNum = revInfo.prefix + 1;\n    } else {\n      doc._rev_tree = [{\n        pos: 1,\n        ids : [newRevId, opts, []]\n      }];\n      nRevNum = 1;\n    }\n  } else {\n    if (doc._revisions) {\n      doc._rev_tree = makeRevTreeFromRevisions(doc._revisions, opts);\n      nRevNum = doc._revisions.start;\n      newRevId = doc._revisions.ids[0];\n    }\n    if (!doc._rev_tree) {\n      revInfo = parseRevisionInfo(doc._rev);\n      if (revInfo.error) {\n        return revInfo;\n      }\n      nRevNum = revInfo.prefix;\n      newRevId = revInfo.id;\n      doc._rev_tree = [{\n        pos: nRevNum,\n        ids: [newRevId, opts, []]\n      }];\n    }\n  }\n\n  invalidIdError(doc._id);\n\n  doc._rev = nRevNum + '-' + newRevId;\n\n  var result = {metadata : {}, data : {}};\n  for (var key in doc) {\n    /* istanbul ignore else */\n    if (Object.prototype.hasOwnProperty.call(doc, key)) {\n      var specialKey = key[0] === '_';\n      if (specialKey && !reservedWords[key]) {\n        var error = createError(DOC_VALIDATION, key);\n        error.message = DOC_VALIDATION.message + ': ' + key;\n        throw error;\n      } else if (specialKey && !dataWords[key]) {\n        result.metadata[key.slice(1)] = doc[key];\n      } else {\n        result.data[key] = doc[key];\n      }\n    }\n  }\n  return result;\n}\n\nvar thisAtob = function (str) {\n  return atob(str);\n};\n\nvar thisBtoa = function (str) {\n  return btoa(str);\n};\n\n// Abstracts constructing a Blob object, so it also works in older\n// browsers that don't support the native Blob constructor (e.g.\n// old QtWebKit versions, Android < 4.4).\nfunction createBlob(parts, properties) {\n  /* global BlobBuilder,MSBlobBuilder,MozBlobBuilder,WebKitBlobBuilder */\n  parts = parts || [];\n  properties = properties || {};\n  try {\n    return new Blob(parts, properties);\n  } catch (e) {\n    if (e.name !== \"TypeError\") {\n      throw e;\n    }\n    var Builder = typeof BlobBuilder !== 'undefined' ? BlobBuilder :\n                  typeof MSBlobBuilder !== 'undefined' ? MSBlobBuilder :\n                  typeof MozBlobBuilder !== 'undefined' ? MozBlobBuilder :\n                  WebKitBlobBuilder;\n    var builder = new Builder();\n    for (var i = 0; i < parts.length; i += 1) {\n      builder.append(parts[i]);\n    }\n    return builder.getBlob(properties.type);\n  }\n}\n\n// From http://stackoverflow.com/questions/14967647/ (continues on next line)\n// encode-decode-image-with-base64-breaks-image (2013-04-21)\nfunction binaryStringToArrayBuffer(bin) {\n  var length = bin.length;\n  var buf = new ArrayBuffer(length);\n  var arr = new Uint8Array(buf);\n  for (var i = 0; i < length; i++) {\n    arr[i] = bin.charCodeAt(i);\n  }\n  return buf;\n}\n\nfunction binStringToBluffer(binString, type) {\n  return createBlob([binaryStringToArrayBuffer(binString)], {type: type});\n}\n\nfunction b64ToBluffer(b64, type) {\n  return binStringToBluffer(thisAtob(b64), type);\n}\n\n//Can't find original post, but this is close\n//http://stackoverflow.com/questions/6965107/ (continues on next line)\n//converting-between-strings-and-arraybuffers\nfunction arrayBufferToBinaryString(buffer) {\n  var binary = '';\n  var bytes = new Uint8Array(buffer);\n  var length = bytes.byteLength;\n  for (var i = 0; i < length; i++) {\n    binary += String.fromCharCode(bytes[i]);\n  }\n  return binary;\n}\n\n// shim for browsers that don't support it\nfunction readAsBinaryString(blob, callback) {\n  if (typeof FileReader === 'undefined') {\n    // fix for Firefox in a web worker\n    // https://bugzilla.mozilla.org/show_bug.cgi?id=901097\n    return callback(arrayBufferToBinaryString(\n      new FileReaderSync().readAsArrayBuffer(blob)));\n  }\n\n  var reader = new FileReader();\n  var hasBinaryString = typeof reader.readAsBinaryString === 'function';\n  reader.onloadend = function (e) {\n    var result = e.target.result || '';\n    if (hasBinaryString) {\n      return callback(result);\n    }\n    callback(arrayBufferToBinaryString(result));\n  };\n  if (hasBinaryString) {\n    reader.readAsBinaryString(blob);\n  } else {\n    reader.readAsArrayBuffer(blob);\n  }\n}\n\nfunction blobToBinaryString(blobOrBuffer, callback) {\n  readAsBinaryString(blobOrBuffer, function (bin) {\n    callback(bin);\n  });\n}\n\nfunction blobToBase64(blobOrBuffer, callback) {\n  blobToBinaryString(blobOrBuffer, function (base64) {\n    callback(thisBtoa(base64));\n  });\n}\n\n// simplified API. universal browser support is assumed\nfunction readAsArrayBuffer(blob, callback) {\n  if (typeof FileReader === 'undefined') {\n    // fix for Firefox in a web worker:\n    // https://bugzilla.mozilla.org/show_bug.cgi?id=901097\n    return callback(new FileReaderSync().readAsArrayBuffer(blob));\n  }\n\n  var reader = new FileReader();\n  reader.onloadend = function (e) {\n    var result = e.target.result || new ArrayBuffer(0);\n    callback(result);\n  };\n  reader.readAsArrayBuffer(blob);\n}\n\n// this is not used in the browser\n\nvar setImmediateShim = global.setImmediate || global.setTimeout;\nvar MD5_CHUNK_SIZE = 32768;\n\nfunction rawToBase64(raw) {\n  return thisBtoa(raw);\n}\n\nfunction sliceBlob(blob$$1, start, end) {\n  if (blob$$1.webkitSlice) {\n    return blob$$1.webkitSlice(start, end);\n  }\n  return blob$$1.slice(start, end);\n}\n\nfunction appendBlob(buffer, blob$$1, start, end, callback) {\n  if (start > 0 || end < blob$$1.size) {\n    // only slice blob if we really need to\n    blob$$1 = sliceBlob(blob$$1, start, end);\n  }\n  readAsArrayBuffer(blob$$1, function (arrayBuffer) {\n    buffer.append(arrayBuffer);\n    callback();\n  });\n}\n\nfunction appendString(buffer, string, start, end, callback) {\n  if (start > 0 || end < string.length) {\n    // only create a substring if we really need to\n    string = string.substring(start, end);\n  }\n  buffer.appendBinary(string);\n  callback();\n}\n\nfunction binaryMd5(data, callback) {\n  var inputIsString = typeof data === 'string';\n  var len = inputIsString ? data.length : data.size;\n  var chunkSize = Math.min(MD5_CHUNK_SIZE, len);\n  var chunks = Math.ceil(len / chunkSize);\n  var currentChunk = 0;\n  var buffer = inputIsString ? new Md5() : new Md5.ArrayBuffer();\n\n  var append = inputIsString ? appendString : appendBlob;\n\n  function next() {\n    setImmediateShim(loadNextChunk);\n  }\n\n  function done() {\n    var raw = buffer.end(true);\n    var base64 = rawToBase64(raw);\n    callback(base64);\n    buffer.destroy();\n  }\n\n  function loadNextChunk() {\n    var start = currentChunk * chunkSize;\n    var end = start + chunkSize;\n    currentChunk++;\n    if (currentChunk < chunks) {\n      append(buffer, data, start, end, next);\n    } else {\n      append(buffer, data, start, end, done);\n    }\n  }\n  loadNextChunk();\n}\n\nfunction stringMd5(string) {\n  return Md5.hash(string);\n}\n\nfunction parseBase64(data) {\n  try {\n    return thisAtob(data);\n  } catch (e) {\n    var err = createError(BAD_ARG,\n      'Attachment is not a valid base64 string');\n    return {error: err};\n  }\n}\n\nfunction preprocessString(att, blobType, callback) {\n  var asBinary = parseBase64(att.data);\n  if (asBinary.error) {\n    return callback(asBinary.error);\n  }\n\n  att.length = asBinary.length;\n  if (blobType === 'blob') {\n    att.data = binStringToBluffer(asBinary, att.content_type);\n  } else if (blobType === 'base64') {\n    att.data = thisBtoa(asBinary);\n  } else { // binary\n    att.data = asBinary;\n  }\n  binaryMd5(asBinary, function (result) {\n    att.digest = 'md5-' + result;\n    callback();\n  });\n}\n\nfunction preprocessBlob(att, blobType, callback) {\n  binaryMd5(att.data, function (md5) {\n    att.digest = 'md5-' + md5;\n    // size is for blobs (browser), length is for buffers (node)\n    att.length = att.data.size || att.data.length || 0;\n    if (blobType === 'binary') {\n      blobToBinaryString(att.data, function (binString) {\n        att.data = binString;\n        callback();\n      });\n    } else if (blobType === 'base64') {\n      blobToBase64(att.data, function (b64) {\n        att.data = b64;\n        callback();\n      });\n    } else {\n      callback();\n    }\n  });\n}\n\nfunction preprocessAttachment(att, blobType, callback) {\n  if (att.stub) {\n    return callback();\n  }\n  if (typeof att.data === 'string') { // input is a base64 string\n    preprocessString(att, blobType, callback);\n  } else { // input is a blob\n    preprocessBlob(att, blobType, callback);\n  }\n}\n\nfunction preprocessAttachments(docInfos, blobType, callback) {\n\n  if (!docInfos.length) {\n    return callback();\n  }\n\n  var docv = 0;\n  var overallErr;\n\n  docInfos.forEach(function (docInfo) {\n    var attachments = docInfo.data && docInfo.data._attachments ?\n      Object.keys(docInfo.data._attachments) : [];\n    var recv = 0;\n\n    if (!attachments.length) {\n      return done();\n    }\n\n    function processedAttachment(err) {\n      overallErr = err;\n      recv++;\n      if (recv === attachments.length) {\n        done();\n      }\n    }\n\n    for (var key in docInfo.data._attachments) {\n      if (docInfo.data._attachments.hasOwnProperty(key)) {\n        preprocessAttachment(docInfo.data._attachments[key],\n          blobType, processedAttachment);\n      }\n    }\n  });\n\n  function done() {\n    docv++;\n    if (docInfos.length === docv) {\n      if (overallErr) {\n        callback(overallErr);\n      } else {\n        callback();\n      }\n    }\n  }\n}\n\nfunction updateDoc(revLimit, prev, docInfo, results,\n                   i, cb, writeDoc, newEdits) {\n\n  if (revExists(prev.rev_tree, docInfo.metadata.rev)) {\n    results[i] = docInfo;\n    return cb();\n  }\n\n  // sometimes this is pre-calculated. historically not always\n  var previousWinningRev = prev.winningRev || winningRev(prev);\n  var previouslyDeleted = 'deleted' in prev ? prev.deleted :\n    isDeleted(prev, previousWinningRev);\n  var deleted = 'deleted' in docInfo.metadata ? docInfo.metadata.deleted :\n    isDeleted(docInfo.metadata);\n  var isRoot = /^1-/.test(docInfo.metadata.rev);\n\n  if (previouslyDeleted && !deleted && newEdits && isRoot) {\n    var newDoc = docInfo.data;\n    newDoc._rev = previousWinningRev;\n    newDoc._id = docInfo.metadata.id;\n    docInfo = parseDoc(newDoc, newEdits);\n  }\n\n  var merged = merge(prev.rev_tree, docInfo.metadata.rev_tree[0], revLimit);\n\n  var inConflict = newEdits && (((previouslyDeleted && deleted) ||\n    (!previouslyDeleted && merged.conflicts !== 'new_leaf') ||\n    (previouslyDeleted && !deleted && merged.conflicts === 'new_branch')));\n\n  if (inConflict) {\n    var err = createError(REV_CONFLICT);\n    results[i] = err;\n    return cb();\n  }\n\n  var newRev = docInfo.metadata.rev;\n  docInfo.metadata.rev_tree = merged.tree;\n  docInfo.stemmedRevs = merged.stemmedRevs || [];\n  /* istanbul ignore else */\n  if (prev.rev_map) {\n    docInfo.metadata.rev_map = prev.rev_map; // used only by leveldb\n  }\n\n  // recalculate\n  var winningRev$$1 = winningRev(docInfo.metadata);\n  var winningRevIsDeleted = isDeleted(docInfo.metadata, winningRev$$1);\n\n  // calculate the total number of documents that were added/removed,\n  // from the perspective of total_rows/doc_count\n  var delta = (previouslyDeleted === winningRevIsDeleted) ? 0 :\n    previouslyDeleted < winningRevIsDeleted ? -1 : 1;\n\n  var newRevIsDeleted;\n  if (newRev === winningRev$$1) {\n    // if the new rev is the same as the winning rev, we can reuse that value\n    newRevIsDeleted = winningRevIsDeleted;\n  } else {\n    // if they're not the same, then we need to recalculate\n    newRevIsDeleted = isDeleted(docInfo.metadata, newRev);\n  }\n\n  writeDoc(docInfo, winningRev$$1, winningRevIsDeleted, newRevIsDeleted,\n    true, delta, i, cb);\n}\n\nfunction rootIsMissing(docInfo) {\n  return docInfo.metadata.rev_tree[0].ids[1].status === 'missing';\n}\n\nfunction processDocs(revLimit, docInfos, api, fetchedDocs, tx, results,\n                     writeDoc, opts, overallCallback) {\n\n  // Default to 1000 locally\n  revLimit = revLimit || 1000;\n\n  function insertDoc(docInfo, resultsIdx, callback) {\n    // Cant insert new deleted documents\n    var winningRev$$1 = winningRev(docInfo.metadata);\n    var deleted = isDeleted(docInfo.metadata, winningRev$$1);\n    if ('was_delete' in opts && deleted) {\n      results[resultsIdx] = createError(MISSING_DOC, 'deleted');\n      return callback();\n    }\n\n    // 4712 - detect whether a new document was inserted with a _rev\n    var inConflict = newEdits && rootIsMissing(docInfo);\n\n    if (inConflict) {\n      var err = createError(REV_CONFLICT);\n      results[resultsIdx] = err;\n      return callback();\n    }\n\n    var delta = deleted ? 0 : 1;\n\n    writeDoc(docInfo, winningRev$$1, deleted, deleted, false,\n      delta, resultsIdx, callback);\n  }\n\n  var newEdits = opts.new_edits;\n  var idsToDocs = new ExportedMap();\n\n  var docsDone = 0;\n  var docsToDo = docInfos.length;\n\n  function checkAllDocsDone() {\n    if (++docsDone === docsToDo && overallCallback) {\n      overallCallback();\n    }\n  }\n\n  docInfos.forEach(function (currentDoc, resultsIdx) {\n\n    if (currentDoc._id && isLocalId(currentDoc._id)) {\n      var fun = currentDoc._deleted ? '_removeLocal' : '_putLocal';\n      api[fun](currentDoc, {ctx: tx}, function (err, res) {\n        results[resultsIdx] = err || res;\n        checkAllDocsDone();\n      });\n      return;\n    }\n\n    var id = currentDoc.metadata.id;\n    if (idsToDocs.has(id)) {\n      docsToDo--; // duplicate\n      idsToDocs.get(id).push([currentDoc, resultsIdx]);\n    } else {\n      idsToDocs.set(id, [[currentDoc, resultsIdx]]);\n    }\n  });\n\n  // in the case of new_edits, the user can provide multiple docs\n  // with the same id. these need to be processed sequentially\n  idsToDocs.forEach(function (docs, id) {\n    var numDone = 0;\n\n    function docWritten() {\n      if (++numDone < docs.length) {\n        nextDoc();\n      } else {\n        checkAllDocsDone();\n      }\n    }\n    function nextDoc() {\n      var value = docs[numDone];\n      var currentDoc = value[0];\n      var resultsIdx = value[1];\n\n      if (fetchedDocs.has(id)) {\n        updateDoc(revLimit, fetchedDocs.get(id), currentDoc, results,\n          resultsIdx, docWritten, writeDoc, newEdits);\n      } else {\n        // Ensure stemming applies to new writes as well\n        var merged = merge([], currentDoc.metadata.rev_tree[0], revLimit);\n        currentDoc.metadata.rev_tree = merged.tree;\n        currentDoc.stemmedRevs = merged.stemmedRevs || [];\n        insertDoc(currentDoc, resultsIdx, docWritten);\n      }\n    }\n    nextDoc();\n  });\n}\n\n// IndexedDB requires a versioned database structure, so we use the\n// version here to manage migrations.\nvar ADAPTER_VERSION = 5;\n\n// The object stores created for each database\n// DOC_STORE stores the document meta data, its revision history and state\n// Keyed by document id\nvar DOC_STORE = 'document-store';\n// BY_SEQ_STORE stores a particular version of a document, keyed by its\n// sequence id\nvar BY_SEQ_STORE = 'by-sequence';\n// Where we store attachments\nvar ATTACH_STORE = 'attach-store';\n// Where we store many-to-many relations\n// between attachment digests and seqs\nvar ATTACH_AND_SEQ_STORE = 'attach-seq-store';\n\n// Where we store database-wide meta data in a single record\n// keyed by id: META_STORE\nvar META_STORE = 'meta-store';\n// Where we store local documents\nvar LOCAL_STORE = 'local-store';\n// Where we detect blob support\nvar DETECT_BLOB_SUPPORT_STORE = 'detect-blob-support';\n\nfunction safeJsonParse(str) {\n  // This try/catch guards against stack overflow errors.\n  // JSON.parse() is faster than vuvuzela.parse() but vuvuzela\n  // cannot overflow.\n  try {\n    return JSON.parse(str);\n  } catch (e) {\n    /* istanbul ignore next */\n    return vuvuzela.parse(str);\n  }\n}\n\nfunction safeJsonStringify(json) {\n  try {\n    return JSON.stringify(json);\n  } catch (e) {\n    /* istanbul ignore next */\n    return vuvuzela.stringify(json);\n  }\n}\n\nfunction idbError(callback) {\n  return function (evt) {\n    var message = 'unknown_error';\n    if (evt.target && evt.target.error) {\n      message = evt.target.error.name || evt.target.error.message;\n    }\n    callback(createError(IDB_ERROR, message, evt.type));\n  };\n}\n\n// Unfortunately, the metadata has to be stringified\n// when it is put into the database, because otherwise\n// IndexedDB can throw errors for deeply-nested objects.\n// Originally we just used JSON.parse/JSON.stringify; now\n// we use this custom vuvuzela library that avoids recursion.\n// If we could do it all over again, we'd probably use a\n// format for the revision trees other than JSON.\nfunction encodeMetadata(metadata, winningRev, deleted) {\n  return {\n    data: safeJsonStringify(metadata),\n    winningRev: winningRev,\n    deletedOrLocal: deleted ? '1' : '0',\n    seq: metadata.seq, // highest seq for this doc\n    id: metadata.id\n  };\n}\n\nfunction decodeMetadata(storedObject) {\n  if (!storedObject) {\n    return null;\n  }\n  var metadata = safeJsonParse(storedObject.data);\n  metadata.winningRev = storedObject.winningRev;\n  metadata.deleted = storedObject.deletedOrLocal === '1';\n  metadata.seq = storedObject.seq;\n  return metadata;\n}\n\n// read the doc back out from the database. we don't store the\n// _id or _rev because we already have _doc_id_rev.\nfunction decodeDoc(doc) {\n  if (!doc) {\n    return doc;\n  }\n  var idx = doc._doc_id_rev.lastIndexOf(':');\n  doc._id = doc._doc_id_rev.substring(0, idx - 1);\n  doc._rev = doc._doc_id_rev.substring(idx + 1);\n  delete doc._doc_id_rev;\n  return doc;\n}\n\n// Read a blob from the database, encoding as necessary\n// and translating from base64 if the IDB doesn't support\n// native Blobs\nfunction readBlobData(body, type, asBlob, callback) {\n  if (asBlob) {\n    if (!body) {\n      callback(createBlob([''], {type: type}));\n    } else if (typeof body !== 'string') { // we have blob support\n      callback(body);\n    } else { // no blob support\n      callback(b64ToBluffer(body, type));\n    }\n  } else { // as base64 string\n    if (!body) {\n      callback('');\n    } else if (typeof body !== 'string') { // we have blob support\n      readAsBinaryString(body, function (binary) {\n        callback(thisBtoa(binary));\n      });\n    } else { // no blob support\n      callback(body);\n    }\n  }\n}\n\nfunction fetchAttachmentsIfNecessary(doc, opts, txn, cb) {\n  var attachments = Object.keys(doc._attachments || {});\n  if (!attachments.length) {\n    return cb && cb();\n  }\n  var numDone = 0;\n\n  function checkDone() {\n    if (++numDone === attachments.length && cb) {\n      cb();\n    }\n  }\n\n  function fetchAttachment(doc, att) {\n    var attObj = doc._attachments[att];\n    var digest = attObj.digest;\n    var req = txn.objectStore(ATTACH_STORE).get(digest);\n    req.onsuccess = function (e) {\n      attObj.body = e.target.result.body;\n      checkDone();\n    };\n  }\n\n  attachments.forEach(function (att) {\n    if (opts.attachments && opts.include_docs) {\n      fetchAttachment(doc, att);\n    } else {\n      doc._attachments[att].stub = true;\n      checkDone();\n    }\n  });\n}\n\n// IDB-specific postprocessing necessary because\n// we don't know whether we stored a true Blob or\n// a base64-encoded string, and if it's a Blob it\n// needs to be read outside of the transaction context\nfunction postProcessAttachments(results, asBlob) {\n  return PouchPromise$1.all(results.map(function (row) {\n    if (row.doc && row.doc._attachments) {\n      var attNames = Object.keys(row.doc._attachments);\n      return PouchPromise$1.all(attNames.map(function (att) {\n        var attObj = row.doc._attachments[att];\n        if (!('body' in attObj)) { // already processed\n          return;\n        }\n        var body = attObj.body;\n        var type = attObj.content_type;\n        return new PouchPromise$1(function (resolve) {\n          readBlobData(body, type, asBlob, function (data) {\n            row.doc._attachments[att] = assign$1(\n              pick(attObj, ['digest', 'content_type']),\n              {data: data}\n            );\n            resolve();\n          });\n        });\n      }));\n    }\n  }));\n}\n\nfunction compactRevs(revs, docId, txn) {\n\n  var possiblyOrphanedDigests = [];\n  var seqStore = txn.objectStore(BY_SEQ_STORE);\n  var attStore = txn.objectStore(ATTACH_STORE);\n  var attAndSeqStore = txn.objectStore(ATTACH_AND_SEQ_STORE);\n  var count = revs.length;\n\n  function checkDone() {\n    count--;\n    if (!count) { // done processing all revs\n      deleteOrphanedAttachments();\n    }\n  }\n\n  function deleteOrphanedAttachments() {\n    if (!possiblyOrphanedDigests.length) {\n      return;\n    }\n    possiblyOrphanedDigests.forEach(function (digest) {\n      var countReq = attAndSeqStore.index('digestSeq').count(\n        IDBKeyRange.bound(\n          digest + '::', digest + '::\\uffff', false, false));\n      countReq.onsuccess = function (e) {\n        var count = e.target.result;\n        if (!count) {\n          // orphaned\n          attStore.delete(digest);\n        }\n      };\n    });\n  }\n\n  revs.forEach(function (rev) {\n    var index = seqStore.index('_doc_id_rev');\n    var key = docId + \"::\" + rev;\n    index.getKey(key).onsuccess = function (e) {\n      var seq = e.target.result;\n      if (typeof seq !== 'number') {\n        return checkDone();\n      }\n      seqStore.delete(seq);\n\n      var cursor = attAndSeqStore.index('seq')\n        .openCursor(IDBKeyRange.only(seq));\n\n      cursor.onsuccess = function (event) {\n        var cursor = event.target.result;\n        if (cursor) {\n          var digest = cursor.value.digestSeq.split('::')[0];\n          possiblyOrphanedDigests.push(digest);\n          attAndSeqStore.delete(cursor.primaryKey);\n          cursor.continue();\n        } else { // done\n          checkDone();\n        }\n      };\n    };\n  });\n}\n\nfunction openTransactionSafely(idb, stores, mode) {\n  try {\n    return {\n      txn: idb.transaction(stores, mode)\n    };\n  } catch (err) {\n    return {\n      error: err\n    };\n  }\n}\n\nvar changesHandler$$1 = new Changes();\n\nfunction idbBulkDocs(dbOpts, req, opts, api, idb, callback) {\n  var docInfos = req.docs;\n  var txn;\n  var docStore;\n  var bySeqStore;\n  var attachStore;\n  var attachAndSeqStore;\n  var metaStore;\n  var docInfoError;\n  var metaDoc;\n\n  for (var i = 0, len = docInfos.length; i < len; i++) {\n    var doc = docInfos[i];\n    if (doc._id && isLocalId(doc._id)) {\n      continue;\n    }\n    doc = docInfos[i] = parseDoc(doc, opts.new_edits);\n    if (doc.error && !docInfoError) {\n      docInfoError = doc;\n    }\n  }\n\n  if (docInfoError) {\n    return callback(docInfoError);\n  }\n\n  var allDocsProcessed = false;\n  var docCountDelta = 0;\n  var results = new Array(docInfos.length);\n  var fetchedDocs = new ExportedMap();\n  var preconditionErrored = false;\n  var blobType = api._meta.blobSupport ? 'blob' : 'base64';\n\n  preprocessAttachments(docInfos, blobType, function (err) {\n    if (err) {\n      return callback(err);\n    }\n    startTransaction();\n  });\n\n  function startTransaction() {\n\n    var stores = [\n      DOC_STORE, BY_SEQ_STORE,\n      ATTACH_STORE,\n      LOCAL_STORE, ATTACH_AND_SEQ_STORE,\n      META_STORE\n    ];\n    var txnResult = openTransactionSafely(idb, stores, 'readwrite');\n    if (txnResult.error) {\n      return callback(txnResult.error);\n    }\n    txn = txnResult.txn;\n    txn.onabort = idbError(callback);\n    txn.ontimeout = idbError(callback);\n    txn.oncomplete = complete;\n    docStore = txn.objectStore(DOC_STORE);\n    bySeqStore = txn.objectStore(BY_SEQ_STORE);\n    attachStore = txn.objectStore(ATTACH_STORE);\n    attachAndSeqStore = txn.objectStore(ATTACH_AND_SEQ_STORE);\n    metaStore = txn.objectStore(META_STORE);\n\n    metaStore.get(META_STORE).onsuccess = function (e) {\n      metaDoc = e.target.result;\n      updateDocCountIfReady();\n    };\n\n    verifyAttachments(function (err) {\n      if (err) {\n        preconditionErrored = true;\n        return callback(err);\n      }\n      fetchExistingDocs();\n    });\n  }\n\n  function onAllDocsProcessed() {\n    allDocsProcessed = true;\n    updateDocCountIfReady();\n  }\n\n  function idbProcessDocs() {\n    processDocs(dbOpts.revs_limit, docInfos, api, fetchedDocs,\n                txn, results, writeDoc, opts, onAllDocsProcessed);\n  }\n\n  function updateDocCountIfReady() {\n    if (!metaDoc || !allDocsProcessed) {\n      return;\n    }\n    // caching the docCount saves a lot of time in allDocs() and\n    // info(), which is why we go to all the trouble of doing this\n    metaDoc.docCount += docCountDelta;\n    metaStore.put(metaDoc);\n  }\n\n  function fetchExistingDocs() {\n\n    if (!docInfos.length) {\n      return;\n    }\n\n    var numFetched = 0;\n\n    function checkDone() {\n      if (++numFetched === docInfos.length) {\n        idbProcessDocs();\n      }\n    }\n\n    function readMetadata(event) {\n      var metadata = decodeMetadata(event.target.result);\n\n      if (metadata) {\n        fetchedDocs.set(metadata.id, metadata);\n      }\n      checkDone();\n    }\n\n    for (var i = 0, len = docInfos.length; i < len; i++) {\n      var docInfo = docInfos[i];\n      if (docInfo._id && isLocalId(docInfo._id)) {\n        checkDone(); // skip local docs\n        continue;\n      }\n      var req = docStore.get(docInfo.metadata.id);\n      req.onsuccess = readMetadata;\n    }\n  }\n\n  function complete() {\n    if (preconditionErrored) {\n      return;\n    }\n\n    changesHandler$$1.notify(api._meta.name);\n    callback(null, results);\n  }\n\n  function verifyAttachment(digest, callback) {\n\n    var req = attachStore.get(digest);\n    req.onsuccess = function (e) {\n      if (!e.target.result) {\n        var err = createError(MISSING_STUB,\n          'unknown stub attachment with digest ' +\n          digest);\n        err.status = 412;\n        callback(err);\n      } else {\n        callback();\n      }\n    };\n  }\n\n  function verifyAttachments(finish) {\n\n\n    var digests = [];\n    docInfos.forEach(function (docInfo) {\n      if (docInfo.data && docInfo.data._attachments) {\n        Object.keys(docInfo.data._attachments).forEach(function (filename) {\n          var att = docInfo.data._attachments[filename];\n          if (att.stub) {\n            digests.push(att.digest);\n          }\n        });\n      }\n    });\n    if (!digests.length) {\n      return finish();\n    }\n    var numDone = 0;\n    var err;\n\n    function checkDone() {\n      if (++numDone === digests.length) {\n        finish(err);\n      }\n    }\n    digests.forEach(function (digest) {\n      verifyAttachment(digest, function (attErr) {\n        if (attErr && !err) {\n          err = attErr;\n        }\n        checkDone();\n      });\n    });\n  }\n\n  function writeDoc(docInfo, winningRev$$1, winningRevIsDeleted, newRevIsDeleted,\n                    isUpdate, delta, resultsIdx, callback) {\n\n    docInfo.metadata.winningRev = winningRev$$1;\n    docInfo.metadata.deleted = winningRevIsDeleted;\n\n    var doc = docInfo.data;\n    doc._id = docInfo.metadata.id;\n    doc._rev = docInfo.metadata.rev;\n\n    if (newRevIsDeleted) {\n      doc._deleted = true;\n    }\n\n    var hasAttachments = doc._attachments &&\n      Object.keys(doc._attachments).length;\n    if (hasAttachments) {\n      return writeAttachments(docInfo, winningRev$$1, winningRevIsDeleted,\n        isUpdate, resultsIdx, callback);\n    }\n\n    docCountDelta += delta;\n    updateDocCountIfReady();\n\n    finishDoc(docInfo, winningRev$$1, winningRevIsDeleted,\n      isUpdate, resultsIdx, callback);\n  }\n\n  function finishDoc(docInfo, winningRev$$1, winningRevIsDeleted,\n                     isUpdate, resultsIdx, callback) {\n\n    var doc = docInfo.data;\n    var metadata = docInfo.metadata;\n\n    doc._doc_id_rev = metadata.id + '::' + metadata.rev;\n    delete doc._id;\n    delete doc._rev;\n\n    function afterPutDoc(e) {\n      var revsToDelete = docInfo.stemmedRevs || [];\n\n      if (isUpdate && api.auto_compaction) {\n        revsToDelete = revsToDelete.concat(compactTree(docInfo.metadata));\n      }\n\n      if (revsToDelete && revsToDelete.length) {\n        compactRevs(revsToDelete, docInfo.metadata.id, txn);\n      }\n\n      metadata.seq = e.target.result;\n      // Current _rev is calculated from _rev_tree on read\n      // delete metadata.rev;\n      var metadataToStore = encodeMetadata(metadata, winningRev$$1,\n        winningRevIsDeleted);\n      var metaDataReq = docStore.put(metadataToStore);\n      metaDataReq.onsuccess = afterPutMetadata;\n    }\n\n    function afterPutDocError(e) {\n      // ConstraintError, need to update, not put (see #1638 for details)\n      e.preventDefault(); // avoid transaction abort\n      e.stopPropagation(); // avoid transaction onerror\n      var index = bySeqStore.index('_doc_id_rev');\n      var getKeyReq = index.getKey(doc._doc_id_rev);\n      getKeyReq.onsuccess = function (e) {\n        var putReq = bySeqStore.put(doc, e.target.result);\n        putReq.onsuccess = afterPutDoc;\n      };\n    }\n\n    function afterPutMetadata() {\n      results[resultsIdx] = {\n        ok: true,\n        id: metadata.id,\n        rev: metadata.rev\n      };\n      fetchedDocs.set(docInfo.metadata.id, docInfo.metadata);\n      insertAttachmentMappings(docInfo, metadata.seq, callback);\n    }\n\n    var putReq = bySeqStore.put(doc);\n\n    putReq.onsuccess = afterPutDoc;\n    putReq.onerror = afterPutDocError;\n  }\n\n  function writeAttachments(docInfo, winningRev$$1, winningRevIsDeleted,\n                            isUpdate, resultsIdx, callback) {\n\n\n    var doc = docInfo.data;\n\n    var numDone = 0;\n    var attachments = Object.keys(doc._attachments);\n\n    function collectResults() {\n      if (numDone === attachments.length) {\n        finishDoc(docInfo, winningRev$$1, winningRevIsDeleted,\n          isUpdate, resultsIdx, callback);\n      }\n    }\n\n    function attachmentSaved() {\n      numDone++;\n      collectResults();\n    }\n\n    attachments.forEach(function (key) {\n      var att = docInfo.data._attachments[key];\n      if (!att.stub) {\n        var data = att.data;\n        delete att.data;\n        att.revpos = parseInt(winningRev$$1, 10);\n        var digest = att.digest;\n        saveAttachment(digest, data, attachmentSaved);\n      } else {\n        numDone++;\n        collectResults();\n      }\n    });\n  }\n\n  // map seqs to attachment digests, which\n  // we will need later during compaction\n  function insertAttachmentMappings(docInfo, seq, callback) {\n\n    var attsAdded = 0;\n    var attsToAdd = Object.keys(docInfo.data._attachments || {});\n\n    if (!attsToAdd.length) {\n      return callback();\n    }\n\n    function checkDone() {\n      if (++attsAdded === attsToAdd.length) {\n        callback();\n      }\n    }\n\n    function add(att) {\n      var digest = docInfo.data._attachments[att].digest;\n      var req = attachAndSeqStore.put({\n        seq: seq,\n        digestSeq: digest + '::' + seq\n      });\n\n      req.onsuccess = checkDone;\n      req.onerror = function (e) {\n        // this callback is for a constaint error, which we ignore\n        // because this docid/rev has already been associated with\n        // the digest (e.g. when new_edits == false)\n        e.preventDefault(); // avoid transaction abort\n        e.stopPropagation(); // avoid transaction onerror\n        checkDone();\n      };\n    }\n    for (var i = 0; i < attsToAdd.length; i++) {\n      add(attsToAdd[i]); // do in parallel\n    }\n  }\n\n  function saveAttachment(digest, data, callback) {\n\n\n    var getKeyReq = attachStore.count(digest);\n    getKeyReq.onsuccess = function (e) {\n      var count = e.target.result;\n      if (count) {\n        return callback(); // already exists\n      }\n      var newAtt = {\n        digest: digest,\n        body: data\n      };\n      var putReq = attachStore.put(newAtt);\n      putReq.onsuccess = callback;\n    };\n  }\n}\n\n// Abstraction over IDBCursor and getAll()/getAllKeys() that allows us to batch our operations\n// while falling back to a normal IDBCursor operation on browsers that don't support getAll() or\n// getAllKeys(). This allows for a much faster implementation than just straight-up cursors, because\n// we're not processing each document one-at-a-time.\nfunction runBatchedCursor(objectStore, keyRange, descending, batchSize, onBatch) {\n\n  // Bail out of getAll()/getAllKeys() in the following cases:\n  // 1) either method is unsupported - we need both\n  // 2) batchSize is 1 (might as well use IDBCursor), or batchSize is -1 (i.e. batchSize unlimited,\n  //    not really clear the user wants a batched approach where the entire DB is read into memory,\n  //    perhaps they are filtering on a per-doc basis)\n  // 3) descending  no real way to do this via getAll()/getAllKeys()\n\n  var useGetAll = typeof objectStore.getAll === 'function' &&\n    typeof objectStore.getAllKeys === 'function' &&\n    batchSize > 1 && !descending;\n\n  var keysBatch;\n  var valuesBatch;\n  var pseudoCursor;\n\n  function onGetAll(e) {\n    valuesBatch = e.target.result;\n    if (keysBatch) {\n      onBatch(keysBatch, valuesBatch, pseudoCursor);\n    }\n  }\n\n  function onGetAllKeys(e) {\n    keysBatch = e.target.result;\n    if (valuesBatch) {\n      onBatch(keysBatch, valuesBatch, pseudoCursor);\n    }\n  }\n\n  function continuePseudoCursor() {\n    if (!keysBatch.length) { // no more results\n      return onBatch();\n    }\n    // fetch next batch, exclusive start\n    var lastKey = keysBatch[keysBatch.length - 1];\n    var newKeyRange;\n    if (keyRange && keyRange.upper) {\n      try {\n        newKeyRange = IDBKeyRange.bound(lastKey, keyRange.upper,\n          true, keyRange.upperOpen);\n      } catch (e) {\n        if (e.name === \"DataError\" && e.code === 0) {\n          return onBatch(); // we're done, startkey and endkey are equal\n        }\n      }\n    } else {\n      newKeyRange = IDBKeyRange.lowerBound(lastKey, true);\n    }\n    keyRange = newKeyRange;\n    keysBatch = null;\n    valuesBatch = null;\n    objectStore.getAll(keyRange, batchSize).onsuccess = onGetAll;\n    objectStore.getAllKeys(keyRange, batchSize).onsuccess = onGetAllKeys;\n  }\n\n  function onCursor(e) {\n    var cursor = e.target.result;\n    if (!cursor) { // done\n      return onBatch();\n    }\n    // regular IDBCursor acts like a batch where batch size is always 1\n    onBatch([cursor.key], [cursor.value], cursor);\n  }\n\n  if (useGetAll) {\n    pseudoCursor = {\"continue\": continuePseudoCursor};\n    objectStore.getAll(keyRange, batchSize).onsuccess = onGetAll;\n    objectStore.getAllKeys(keyRange, batchSize).onsuccess = onGetAllKeys;\n  } else if (descending) {\n    objectStore.openCursor(keyRange, 'prev').onsuccess = onCursor;\n  } else {\n    objectStore.openCursor(keyRange).onsuccess = onCursor;\n  }\n}\n\n// simple shim for objectStore.getAll(), falling back to IDBCursor\nfunction getAll(objectStore, keyRange, onSuccess) {\n  if (typeof objectStore.getAll === 'function') {\n    // use native getAll\n    objectStore.getAll(keyRange).onsuccess = onSuccess;\n    return;\n  }\n  // fall back to cursors\n  var values = [];\n\n  function onCursor(e) {\n    var cursor = e.target.result;\n    if (cursor) {\n      values.push(cursor.value);\n      cursor.continue();\n    } else {\n      onSuccess({\n        target: {\n          result: values\n        }\n      });\n    }\n  }\n\n  objectStore.openCursor(keyRange).onsuccess = onCursor;\n}\n\nfunction createKeyRange(start, end, inclusiveEnd, key, descending) {\n  try {\n    if (start && end) {\n      if (descending) {\n        return IDBKeyRange.bound(end, start, !inclusiveEnd, false);\n      } else {\n        return IDBKeyRange.bound(start, end, false, !inclusiveEnd);\n      }\n    } else if (start) {\n      if (descending) {\n        return IDBKeyRange.upperBound(start);\n      } else {\n        return IDBKeyRange.lowerBound(start);\n      }\n    } else if (end) {\n      if (descending) {\n        return IDBKeyRange.lowerBound(end, !inclusiveEnd);\n      } else {\n        return IDBKeyRange.upperBound(end, !inclusiveEnd);\n      }\n    } else if (key) {\n      return IDBKeyRange.only(key);\n    }\n  } catch (e) {\n    return {error: e};\n  }\n  return null;\n}\n\nfunction idbAllDocs(opts, idb, callback) {\n  var start = 'startkey' in opts ? opts.startkey : false;\n  var end = 'endkey' in opts ? opts.endkey : false;\n  var key = 'key' in opts ? opts.key : false;\n  var skip = opts.skip || 0;\n  var limit = typeof opts.limit === 'number' ? opts.limit : -1;\n  var inclusiveEnd = opts.inclusive_end !== false;\n\n  var keyRange = createKeyRange(start, end, inclusiveEnd, key, opts.descending);\n  var keyRangeError = keyRange && keyRange.error;\n  if (keyRangeError && !(keyRangeError.name === \"DataError\" &&\n      keyRangeError.code === 0)) {\n    // DataError with error code 0 indicates start is less than end, so\n    // can just do an empty query. Else need to throw\n    return callback(createError(IDB_ERROR,\n      keyRangeError.name, keyRangeError.message));\n  }\n\n  var stores = [DOC_STORE, BY_SEQ_STORE, META_STORE];\n\n  if (opts.attachments) {\n    stores.push(ATTACH_STORE);\n  }\n  var txnResult = openTransactionSafely(idb, stores, 'readonly');\n  if (txnResult.error) {\n    return callback(txnResult.error);\n  }\n  var txn = txnResult.txn;\n  txn.oncomplete = onTxnComplete;\n  txn.onabort = idbError(callback);\n  var docStore = txn.objectStore(DOC_STORE);\n  var seqStore = txn.objectStore(BY_SEQ_STORE);\n  var metaStore = txn.objectStore(META_STORE);\n  var docIdRevIndex = seqStore.index('_doc_id_rev');\n  var results = [];\n  var docCount;\n\n  metaStore.get(META_STORE).onsuccess = function (e) {\n    docCount = e.target.result.docCount;\n  };\n\n  // if the user specifies include_docs=true, then we don't\n  // want to block the main cursor while we're fetching the doc\n  function fetchDocAsynchronously(metadata, row, winningRev$$1) {\n    var key = metadata.id + \"::\" + winningRev$$1;\n    docIdRevIndex.get(key).onsuccess =  function onGetDoc(e) {\n      row.doc = decodeDoc(e.target.result);\n      if (opts.conflicts) {\n        var conflicts = collectConflicts(metadata);\n        if (conflicts.length) {\n          row.doc._conflicts = conflicts;\n        }\n      }\n      fetchAttachmentsIfNecessary(row.doc, opts, txn);\n    };\n  }\n\n  function allDocsInner(winningRev$$1, metadata) {\n    var row = {\n      id: metadata.id,\n      key: metadata.id,\n      value: {\n        rev: winningRev$$1\n      }\n    };\n    var deleted = metadata.deleted;\n    if (opts.deleted === 'ok') {\n      results.push(row);\n      // deleted docs are okay with \"keys\" requests\n      if (deleted) {\n        row.value.deleted = true;\n        row.doc = null;\n      } else if (opts.include_docs) {\n        fetchDocAsynchronously(metadata, row, winningRev$$1);\n      }\n    } else if (!deleted && skip-- <= 0) {\n      results.push(row);\n      if (opts.include_docs) {\n        fetchDocAsynchronously(metadata, row, winningRev$$1);\n      }\n    }\n  }\n\n  function processBatch(batchValues) {\n    for (var i = 0, len = batchValues.length; i < len; i++) {\n      if (results.length === limit) {\n        break;\n      }\n      var batchValue = batchValues[i];\n      var metadata = decodeMetadata(batchValue);\n      var winningRev$$1 = metadata.winningRev;\n      allDocsInner(winningRev$$1, metadata);\n    }\n  }\n\n  function onBatch(batchKeys, batchValues, cursor) {\n    if (!cursor) {\n      return;\n    }\n    processBatch(batchValues);\n    if (results.length < limit) {\n      cursor.continue();\n    }\n  }\n\n  function onGetAll(e) {\n    var values = e.target.result;\n    if (opts.descending) {\n      values = values.reverse();\n    }\n    processBatch(values);\n  }\n\n  function onResultsReady() {\n    callback(null, {\n      total_rows: docCount,\n      offset: opts.skip,\n      rows: results\n    });\n  }\n\n  function onTxnComplete() {\n    if (opts.attachments) {\n      postProcessAttachments(results, opts.binary).then(onResultsReady);\n    } else {\n      onResultsReady();\n    }\n  }\n\n  // don't bother doing any requests if start > end or limit === 0\n  if (keyRangeError || limit === 0) {\n    return;\n  }\n  if (limit === -1) { // just fetch everything\n    return getAll(docStore, keyRange, onGetAll);\n  }\n  // else do a cursor\n  // choose a batch size based on the skip, since we'll need to skip that many\n  runBatchedCursor(docStore, keyRange, opts.descending, limit + skip, onBatch);\n}\n\n//\n// Blobs are not supported in all versions of IndexedDB, notably\n// Chrome <37 and Android <5. In those versions, storing a blob will throw.\n//\n// Various other blob bugs exist in Chrome v37-42 (inclusive).\n// Detecting them is expensive and confusing to users, and Chrome 37-42\n// is at very low usage worldwide, so we do a hacky userAgent check instead.\n//\n// content-type bug: https://code.google.com/p/chromium/issues/detail?id=408120\n// 404 bug: https://code.google.com/p/chromium/issues/detail?id=447916\n// FileReader bug: https://code.google.com/p/chromium/issues/detail?id=447836\n//\nfunction checkBlobSupport(txn) {\n  return new PouchPromise$1(function (resolve) {\n    var blob$$1 = createBlob(['']);\n    var req = txn.objectStore(DETECT_BLOB_SUPPORT_STORE).put(blob$$1, 'key');\n\n    req.onsuccess = function () {\n      var matchedChrome = navigator.userAgent.match(/Chrome\\/(\\d+)/);\n      var matchedEdge = navigator.userAgent.match(/Edge\\//);\n      // MS Edge pretends to be Chrome 42:\n      // https://msdn.microsoft.com/en-us/library/hh869301%28v=vs.85%29.aspx\n      resolve(matchedEdge || !matchedChrome ||\n        parseInt(matchedChrome[1], 10) >= 43);\n    };\n\n    txn.onabort = function (e) {\n      // If the transaction aborts now its due to not being able to\n      // write to the database, likely due to the disk being full\n      e.preventDefault();\n      e.stopPropagation();\n      resolve(false);\n    };\n  }).catch(function () {\n    return false; // error, so assume unsupported\n  });\n}\n\nfunction countDocs(txn, cb) {\n  var index = txn.objectStore(DOC_STORE).index('deletedOrLocal');\n  index.count(IDBKeyRange.only('0')).onsuccess = function (e) {\n    cb(e.target.result);\n  };\n}\n\n// This task queue ensures that IDB open calls are done in their own tick\n// and sequentially - i.e. we wait for the async IDB open to *fully* complete\n// before calling the next one. This works around IE/Edge race conditions in IDB.\n\nvar running = false;\nvar queue = [];\n\nfunction tryCode(fun, err, res, PouchDB) {\n  try {\n    fun(err, res);\n  } catch (err) {\n    // Shouldn't happen, but in some odd cases\n    // IndexedDB implementations might throw a sync\n    // error, in which case this will at least log it.\n    PouchDB.emit('error', err);\n  }\n}\n\nfunction applyNext() {\n  if (running || !queue.length) {\n    return;\n  }\n  running = true;\n  queue.shift()();\n}\n\nfunction enqueueTask(action, callback, PouchDB) {\n  queue.push(function runAction() {\n    action(function runCallback(err, res) {\n      tryCode(callback, err, res, PouchDB);\n      running = false;\n      nextTick(function runNext() {\n        applyNext(PouchDB);\n      });\n    });\n  });\n  applyNext();\n}\n\nfunction changes(opts, api, dbName, idb) {\n  opts = clone(opts);\n\n  if (opts.continuous) {\n    var id = dbName + ':' + uuid();\n    changesHandler$$1.addListener(dbName, id, api, opts);\n    changesHandler$$1.notify(dbName);\n    return {\n      cancel: function () {\n        changesHandler$$1.removeListener(dbName, id);\n      }\n    };\n  }\n\n  var docIds = opts.doc_ids && new ExportedSet(opts.doc_ids);\n\n  opts.since = opts.since || 0;\n  var lastSeq = opts.since;\n\n  var limit = 'limit' in opts ? opts.limit : -1;\n  if (limit === 0) {\n    limit = 1; // per CouchDB _changes spec\n  }\n  var returnDocs;\n  if ('return_docs' in opts) {\n    returnDocs = opts.return_docs;\n  } else if ('returnDocs' in opts) {\n    // TODO: Remove 'returnDocs' in favor of 'return_docs' in a future release\n    returnDocs = opts.returnDocs;\n  } else {\n    returnDocs = true;\n  }\n\n  var results = [];\n  var numResults = 0;\n  var filter = filterChange(opts);\n  var docIdsToMetadata = new ExportedMap();\n\n  var txn;\n  var bySeqStore;\n  var docStore;\n  var docIdRevIndex;\n\n  function onBatch(batchKeys, batchValues, cursor) {\n    if (!cursor || !batchKeys.length) { // done\n      return;\n    }\n\n    var winningDocs = new Array(batchKeys.length);\n    var metadatas = new Array(batchKeys.length);\n\n    function processMetadataAndWinningDoc(metadata, winningDoc) {\n      var change = opts.processChange(winningDoc, metadata, opts);\n      lastSeq = change.seq = metadata.seq;\n\n      var filtered = filter(change);\n      if (typeof filtered === 'object') { // anything but true/false indicates error\n        return opts.complete(filtered);\n      }\n\n      if (filtered) {\n        numResults++;\n        if (returnDocs) {\n          results.push(change);\n        }\n        // process the attachment immediately\n        // for the benefit of live listeners\n        if (opts.attachments && opts.include_docs) {\n          fetchAttachmentsIfNecessary(winningDoc, opts, txn, function () {\n            postProcessAttachments([change], opts.binary).then(function () {\n              opts.onChange(change);\n            });\n          });\n        } else {\n          opts.onChange(change);\n        }\n      }\n    }\n\n    function onBatchDone() {\n      for (var i = 0, len = winningDocs.length; i < len; i++) {\n        if (numResults === limit) {\n          break;\n        }\n        var winningDoc = winningDocs[i];\n        if (!winningDoc) {\n          continue;\n        }\n        var metadata = metadatas[i];\n        processMetadataAndWinningDoc(metadata, winningDoc);\n      }\n\n      if (numResults !== limit) {\n        cursor.continue();\n      }\n    }\n\n    // Fetch all metadatas/winningdocs from this batch in parallel, then process\n    // them all only once all data has been collected. This is done in parallel\n    // because it's faster than doing it one-at-a-time.\n    var numDone = 0;\n    batchValues.forEach(function (value, i) {\n      var doc = decodeDoc(value);\n      var seq = batchKeys[i];\n      fetchWinningDocAndMetadata(doc, seq, function (metadata, winningDoc) {\n        metadatas[i] = metadata;\n        winningDocs[i] = winningDoc;\n        if (++numDone === batchKeys.length) {\n          onBatchDone();\n        }\n      });\n    });\n  }\n\n  function onGetMetadata(doc, seq, metadata, cb) {\n    if (metadata.seq !== seq) {\n      // some other seq is later\n      return cb();\n    }\n\n    if (metadata.winningRev === doc._rev) {\n      // this is the winning doc\n      return cb(metadata, doc);\n    }\n\n    // fetch winning doc in separate request\n    var docIdRev = doc._id + '::' + metadata.winningRev;\n    var req = docIdRevIndex.get(docIdRev);\n    req.onsuccess = function (e) {\n      cb(metadata, decodeDoc(e.target.result));\n    };\n  }\n\n  function fetchWinningDocAndMetadata(doc, seq, cb) {\n    if (docIds && !docIds.has(doc._id)) {\n      return cb();\n    }\n\n    var metadata = docIdsToMetadata.get(doc._id);\n    if (metadata) { // cached\n      return onGetMetadata(doc, seq, metadata, cb);\n    }\n    // metadata not cached, have to go fetch it\n    docStore.get(doc._id).onsuccess = function (e) {\n      metadata = decodeMetadata(e.target.result);\n      docIdsToMetadata.set(doc._id, metadata);\n      onGetMetadata(doc, seq, metadata, cb);\n    };\n  }\n\n  function finish() {\n    opts.complete(null, {\n      results: results,\n      last_seq: lastSeq\n    });\n  }\n\n  function onTxnComplete() {\n    if (!opts.continuous && opts.attachments) {\n      // cannot guarantee that postProcessing was already done,\n      // so do it again\n      postProcessAttachments(results).then(finish);\n    } else {\n      finish();\n    }\n  }\n\n  var objectStores = [DOC_STORE, BY_SEQ_STORE];\n  if (opts.attachments) {\n    objectStores.push(ATTACH_STORE);\n  }\n  var txnResult = openTransactionSafely(idb, objectStores, 'readonly');\n  if (txnResult.error) {\n    return opts.complete(txnResult.error);\n  }\n  txn = txnResult.txn;\n  txn.onabort = idbError(opts.complete);\n  txn.oncomplete = onTxnComplete;\n\n  bySeqStore = txn.objectStore(BY_SEQ_STORE);\n  docStore = txn.objectStore(DOC_STORE);\n  docIdRevIndex = bySeqStore.index('_doc_id_rev');\n\n  var keyRange = (opts.since && !opts.descending) ?\n    IDBKeyRange.lowerBound(opts.since, true) : null;\n\n  runBatchedCursor(bySeqStore, keyRange, opts.descending, limit, onBatch);\n}\n\nvar cachedDBs = new ExportedMap();\nvar blobSupportPromise;\nvar openReqList = new ExportedMap();\n\nfunction IdbPouch(opts, callback) {\n  var api = this;\n\n  enqueueTask(function (thisCallback) {\n    init(api, opts, thisCallback);\n  }, callback, api.constructor);\n}\n\nfunction init(api, opts, callback) {\n\n  var dbName = opts.name;\n\n  var idb = null;\n  api._meta = null;\n\n  // called when creating a fresh new database\n  function createSchema(db) {\n    var docStore = db.createObjectStore(DOC_STORE, {keyPath : 'id'});\n    db.createObjectStore(BY_SEQ_STORE, {autoIncrement: true})\n      .createIndex('_doc_id_rev', '_doc_id_rev', {unique: true});\n    db.createObjectStore(ATTACH_STORE, {keyPath: 'digest'});\n    db.createObjectStore(META_STORE, {keyPath: 'id', autoIncrement: false});\n    db.createObjectStore(DETECT_BLOB_SUPPORT_STORE);\n\n    // added in v2\n    docStore.createIndex('deletedOrLocal', 'deletedOrLocal', {unique : false});\n\n    // added in v3\n    db.createObjectStore(LOCAL_STORE, {keyPath: '_id'});\n\n    // added in v4\n    var attAndSeqStore = db.createObjectStore(ATTACH_AND_SEQ_STORE,\n      {autoIncrement: true});\n    attAndSeqStore.createIndex('seq', 'seq');\n    attAndSeqStore.createIndex('digestSeq', 'digestSeq', {unique: true});\n  }\n\n  // migration to version 2\n  // unfortunately \"deletedOrLocal\" is a misnomer now that we no longer\n  // store local docs in the main doc-store, but whaddyagonnado\n  function addDeletedOrLocalIndex(txn, callback) {\n    var docStore = txn.objectStore(DOC_STORE);\n    docStore.createIndex('deletedOrLocal', 'deletedOrLocal', {unique : false});\n\n    docStore.openCursor().onsuccess = function (event) {\n      var cursor = event.target.result;\n      if (cursor) {\n        var metadata = cursor.value;\n        var deleted = isDeleted(metadata);\n        metadata.deletedOrLocal = deleted ? \"1\" : \"0\";\n        docStore.put(metadata);\n        cursor.continue();\n      } else {\n        callback();\n      }\n    };\n  }\n\n  // migration to version 3 (part 1)\n  function createLocalStoreSchema(db) {\n    db.createObjectStore(LOCAL_STORE, {keyPath: '_id'})\n      .createIndex('_doc_id_rev', '_doc_id_rev', {unique: true});\n  }\n\n  // migration to version 3 (part 2)\n  function migrateLocalStore(txn, cb) {\n    var localStore = txn.objectStore(LOCAL_STORE);\n    var docStore = txn.objectStore(DOC_STORE);\n    var seqStore = txn.objectStore(BY_SEQ_STORE);\n\n    var cursor = docStore.openCursor();\n    cursor.onsuccess = function (event) {\n      var cursor = event.target.result;\n      if (cursor) {\n        var metadata = cursor.value;\n        var docId = metadata.id;\n        var local = isLocalId(docId);\n        var rev = winningRev(metadata);\n        if (local) {\n          var docIdRev = docId + \"::\" + rev;\n          // remove all seq entries\n          // associated with this docId\n          var start = docId + \"::\";\n          var end = docId + \"::~\";\n          var index = seqStore.index('_doc_id_rev');\n          var range = IDBKeyRange.bound(start, end, false, false);\n          var seqCursor = index.openCursor(range);\n          seqCursor.onsuccess = function (e) {\n            seqCursor = e.target.result;\n            if (!seqCursor) {\n              // done\n              docStore.delete(cursor.primaryKey);\n              cursor.continue();\n            } else {\n              var data = seqCursor.value;\n              if (data._doc_id_rev === docIdRev) {\n                localStore.put(data);\n              }\n              seqStore.delete(seqCursor.primaryKey);\n              seqCursor.continue();\n            }\n          };\n        } else {\n          cursor.continue();\n        }\n      } else if (cb) {\n        cb();\n      }\n    };\n  }\n\n  // migration to version 4 (part 1)\n  function addAttachAndSeqStore(db) {\n    var attAndSeqStore = db.createObjectStore(ATTACH_AND_SEQ_STORE,\n      {autoIncrement: true});\n    attAndSeqStore.createIndex('seq', 'seq');\n    attAndSeqStore.createIndex('digestSeq', 'digestSeq', {unique: true});\n  }\n\n  // migration to version 4 (part 2)\n  function migrateAttsAndSeqs(txn, callback) {\n    var seqStore = txn.objectStore(BY_SEQ_STORE);\n    var attStore = txn.objectStore(ATTACH_STORE);\n    var attAndSeqStore = txn.objectStore(ATTACH_AND_SEQ_STORE);\n\n    // need to actually populate the table. this is the expensive part,\n    // so as an optimization, check first that this database even\n    // contains attachments\n    var req = attStore.count();\n    req.onsuccess = function (e) {\n      var count = e.target.result;\n      if (!count) {\n        return callback(); // done\n      }\n\n      seqStore.openCursor().onsuccess = function (e) {\n        var cursor = e.target.result;\n        if (!cursor) {\n          return callback(); // done\n        }\n        var doc = cursor.value;\n        var seq = cursor.primaryKey;\n        var atts = Object.keys(doc._attachments || {});\n        var digestMap = {};\n        for (var j = 0; j < atts.length; j++) {\n          var att = doc._attachments[atts[j]];\n          digestMap[att.digest] = true; // uniq digests, just in case\n        }\n        var digests = Object.keys(digestMap);\n        for (j = 0; j < digests.length; j++) {\n          var digest = digests[j];\n          attAndSeqStore.put({\n            seq: seq,\n            digestSeq: digest + '::' + seq\n          });\n        }\n        cursor.continue();\n      };\n    };\n  }\n\n  // migration to version 5\n  // Instead of relying on on-the-fly migration of metadata,\n  // this brings the doc-store to its modern form:\n  // - metadata.winningrev\n  // - metadata.seq\n  // - stringify the metadata when storing it\n  function migrateMetadata(txn) {\n\n    function decodeMetadataCompat(storedObject) {\n      if (!storedObject.data) {\n        // old format, when we didn't store it stringified\n        storedObject.deleted = storedObject.deletedOrLocal === '1';\n        return storedObject;\n      }\n      return decodeMetadata(storedObject);\n    }\n\n    // ensure that every metadata has a winningRev and seq,\n    // which was previously created on-the-fly but better to migrate\n    var bySeqStore = txn.objectStore(BY_SEQ_STORE);\n    var docStore = txn.objectStore(DOC_STORE);\n    var cursor = docStore.openCursor();\n    cursor.onsuccess = function (e) {\n      var cursor = e.target.result;\n      if (!cursor) {\n        return; // done\n      }\n      var metadata = decodeMetadataCompat(cursor.value);\n\n      metadata.winningRev = metadata.winningRev ||\n        winningRev(metadata);\n\n      function fetchMetadataSeq() {\n        // metadata.seq was added post-3.2.0, so if it's missing,\n        // we need to fetch it manually\n        var start = metadata.id + '::';\n        var end = metadata.id + '::\\uffff';\n        var req = bySeqStore.index('_doc_id_rev').openCursor(\n          IDBKeyRange.bound(start, end));\n\n        var metadataSeq = 0;\n        req.onsuccess = function (e) {\n          var cursor = e.target.result;\n          if (!cursor) {\n            metadata.seq = metadataSeq;\n            return onGetMetadataSeq();\n          }\n          var seq = cursor.primaryKey;\n          if (seq > metadataSeq) {\n            metadataSeq = seq;\n          }\n          cursor.continue();\n        };\n      }\n\n      function onGetMetadataSeq() {\n        var metadataToStore = encodeMetadata(metadata,\n          metadata.winningRev, metadata.deleted);\n\n        var req = docStore.put(metadataToStore);\n        req.onsuccess = function () {\n          cursor.continue();\n        };\n      }\n\n      if (metadata.seq) {\n        return onGetMetadataSeq();\n      }\n\n      fetchMetadataSeq();\n    };\n\n  }\n\n  api.type = function () {\n    return 'idb';\n  };\n\n  api._id = toPromise(function (callback) {\n    callback(null, api._meta.instanceId);\n  });\n\n  api._bulkDocs = function idb_bulkDocs(req, reqOpts, callback) {\n    idbBulkDocs(opts, req, reqOpts, api, idb, callback);\n  };\n\n  // First we look up the metadata in the ids database, then we fetch the\n  // current revision(s) from the by sequence store\n  api._get = function idb_get(id, opts, callback) {\n    var doc;\n    var metadata;\n    var err;\n    var txn = opts.ctx;\n    if (!txn) {\n      var txnResult = openTransactionSafely(idb,\n        [DOC_STORE, BY_SEQ_STORE, ATTACH_STORE], 'readonly');\n      if (txnResult.error) {\n        return callback(txnResult.error);\n      }\n      txn = txnResult.txn;\n    }\n\n    function finish() {\n      callback(err, {doc: doc, metadata: metadata, ctx: txn});\n    }\n\n    txn.objectStore(DOC_STORE).get(id).onsuccess = function (e) {\n      metadata = decodeMetadata(e.target.result);\n      // we can determine the result here if:\n      // 1. there is no such document\n      // 2. the document is deleted and we don't ask about specific rev\n      // When we ask with opts.rev we expect the answer to be either\n      // doc (possibly with _deleted=true) or missing error\n      if (!metadata) {\n        err = createError(MISSING_DOC, 'missing');\n        return finish();\n      }\n\n      var rev;\n      if(!opts.rev) {\n        rev = metadata.winningRev;\n        var deleted = isDeleted(metadata);\n        if (deleted) {\n          err = createError(MISSING_DOC, \"deleted\");\n          return finish();\n        }\n      } else {\n        rev = opts.latest ? latest(opts.rev, metadata) : opts.rev;\n      }\n\n      var objectStore = txn.objectStore(BY_SEQ_STORE);\n      var key = metadata.id + '::' + rev;\n\n      objectStore.index('_doc_id_rev').get(key).onsuccess = function (e) {\n        doc = e.target.result;\n        if (doc) {\n          doc = decodeDoc(doc);\n        }\n        if (!doc) {\n          err = createError(MISSING_DOC, 'missing');\n          return finish();\n        }\n        finish();\n      };\n    };\n  };\n\n  api._getAttachment = function (docId, attachId, attachment, opts, callback) {\n    var txn;\n    if (opts.ctx) {\n      txn = opts.ctx;\n    } else {\n      var txnResult = openTransactionSafely(idb,\n        [DOC_STORE, BY_SEQ_STORE, ATTACH_STORE], 'readonly');\n      if (txnResult.error) {\n        return callback(txnResult.error);\n      }\n      txn = txnResult.txn;\n    }\n    var digest = attachment.digest;\n    var type = attachment.content_type;\n\n    txn.objectStore(ATTACH_STORE).get(digest).onsuccess = function (e) {\n      var body = e.target.result.body;\n      readBlobData(body, type, opts.binary, function (blobData) {\n        callback(null, blobData);\n      });\n    };\n  };\n\n  api._info = function idb_info(callback) {\n    var updateSeq;\n    var docCount;\n\n    var txnResult = openTransactionSafely(idb, [META_STORE, BY_SEQ_STORE], 'readonly');\n    if (txnResult.error) {\n      return callback(txnResult.error);\n    }\n    var txn = txnResult.txn;\n    txn.objectStore(META_STORE).get(META_STORE).onsuccess = function (e) {\n      docCount = e.target.result.docCount;\n    };\n    txn.objectStore(BY_SEQ_STORE).openCursor(null, 'prev').onsuccess = function (e) {\n      var cursor = e.target.result;\n      updateSeq = cursor ? cursor.key : 0;\n    };\n\n    txn.oncomplete = function () {\n      callback(null, {\n        doc_count: docCount,\n        update_seq: updateSeq,\n        // for debugging\n        idb_attachment_format: (api._meta.blobSupport ? 'binary' : 'base64')\n      });\n    };\n  };\n\n  api._allDocs = function idb_allDocs(opts, callback) {\n    idbAllDocs(opts, idb, callback);\n  };\n\n  api._changes = function idbChanges(opts) {\n    changes(opts, api, dbName, idb);\n  };\n\n  api._close = function (callback) {\n    // https://developer.mozilla.org/en-US/docs/IndexedDB/IDBDatabase#close\n    // \"Returns immediately and closes the connection in a separate thread...\"\n    idb.close();\n    cachedDBs.delete(dbName);\n    callback();\n  };\n\n  api._getRevisionTree = function (docId, callback) {\n    var txnResult = openTransactionSafely(idb, [DOC_STORE], 'readonly');\n    if (txnResult.error) {\n      return callback(txnResult.error);\n    }\n    var txn = txnResult.txn;\n    var req = txn.objectStore(DOC_STORE).get(docId);\n    req.onsuccess = function (event) {\n      var doc = decodeMetadata(event.target.result);\n      if (!doc) {\n        callback(createError(MISSING_DOC));\n      } else {\n        callback(null, doc.rev_tree);\n      }\n    };\n  };\n\n  // This function removes revisions of document docId\n  // which are listed in revs and sets this document\n  // revision to to rev_tree\n  api._doCompaction = function (docId, revs, callback) {\n    var stores = [\n      DOC_STORE,\n      BY_SEQ_STORE,\n      ATTACH_STORE,\n      ATTACH_AND_SEQ_STORE\n    ];\n    var txnResult = openTransactionSafely(idb, stores, 'readwrite');\n    if (txnResult.error) {\n      return callback(txnResult.error);\n    }\n    var txn = txnResult.txn;\n\n    var docStore = txn.objectStore(DOC_STORE);\n\n    docStore.get(docId).onsuccess = function (event) {\n      var metadata = decodeMetadata(event.target.result);\n      traverseRevTree(metadata.rev_tree, function (isLeaf, pos,\n                                                         revHash, ctx, opts) {\n        var rev = pos + '-' + revHash;\n        if (revs.indexOf(rev) !== -1) {\n          opts.status = 'missing';\n        }\n      });\n      compactRevs(revs, docId, txn);\n      var winningRev$$1 = metadata.winningRev;\n      var deleted = metadata.deleted;\n      txn.objectStore(DOC_STORE).put(\n        encodeMetadata(metadata, winningRev$$1, deleted));\n    };\n    txn.onabort = idbError(callback);\n    txn.oncomplete = function () {\n      callback();\n    };\n  };\n\n\n  api._getLocal = function (id, callback) {\n    var txnResult = openTransactionSafely(idb, [LOCAL_STORE], 'readonly');\n    if (txnResult.error) {\n      return callback(txnResult.error);\n    }\n    var tx = txnResult.txn;\n    var req = tx.objectStore(LOCAL_STORE).get(id);\n\n    req.onerror = idbError(callback);\n    req.onsuccess = function (e) {\n      var doc = e.target.result;\n      if (!doc) {\n        callback(createError(MISSING_DOC));\n      } else {\n        delete doc['_doc_id_rev']; // for backwards compat\n        callback(null, doc);\n      }\n    };\n  };\n\n  api._putLocal = function (doc, opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    delete doc._revisions; // ignore this, trust the rev\n    var oldRev = doc._rev;\n    var id = doc._id;\n    if (!oldRev) {\n      doc._rev = '0-1';\n    } else {\n      doc._rev = '0-' + (parseInt(oldRev.split('-')[1], 10) + 1);\n    }\n\n    var tx = opts.ctx;\n    var ret;\n    if (!tx) {\n      var txnResult = openTransactionSafely(idb, [LOCAL_STORE], 'readwrite');\n      if (txnResult.error) {\n        return callback(txnResult.error);\n      }\n      tx = txnResult.txn;\n      tx.onerror = idbError(callback);\n      tx.oncomplete = function () {\n        if (ret) {\n          callback(null, ret);\n        }\n      };\n    }\n\n    var oStore = tx.objectStore(LOCAL_STORE);\n    var req;\n    if (oldRev) {\n      req = oStore.get(id);\n      req.onsuccess = function (e) {\n        var oldDoc = e.target.result;\n        if (!oldDoc || oldDoc._rev !== oldRev) {\n          callback(createError(REV_CONFLICT));\n        } else { // update\n          var req = oStore.put(doc);\n          req.onsuccess = function () {\n            ret = {ok: true, id: doc._id, rev: doc._rev};\n            if (opts.ctx) { // return immediately\n              callback(null, ret);\n            }\n          };\n        }\n      };\n    } else { // new doc\n      req = oStore.add(doc);\n      req.onerror = function (e) {\n        // constraint error, already exists\n        callback(createError(REV_CONFLICT));\n        e.preventDefault(); // avoid transaction abort\n        e.stopPropagation(); // avoid transaction onerror\n      };\n      req.onsuccess = function () {\n        ret = {ok: true, id: doc._id, rev: doc._rev};\n        if (opts.ctx) { // return immediately\n          callback(null, ret);\n        }\n      };\n    }\n  };\n\n  api._removeLocal = function (doc, opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    var tx = opts.ctx;\n    if (!tx) {\n      var txnResult = openTransactionSafely(idb, [LOCAL_STORE], 'readwrite');\n      if (txnResult.error) {\n        return callback(txnResult.error);\n      }\n      tx = txnResult.txn;\n      tx.oncomplete = function () {\n        if (ret) {\n          callback(null, ret);\n        }\n      };\n    }\n    var ret;\n    var id = doc._id;\n    var oStore = tx.objectStore(LOCAL_STORE);\n    var req = oStore.get(id);\n\n    req.onerror = idbError(callback);\n    req.onsuccess = function (e) {\n      var oldDoc = e.target.result;\n      if (!oldDoc || oldDoc._rev !== doc._rev) {\n        callback(createError(MISSING_DOC));\n      } else {\n        oStore.delete(id);\n        ret = {ok: true, id: id, rev: '0-0'};\n        if (opts.ctx) { // return immediately\n          callback(null, ret);\n        }\n      }\n    };\n  };\n\n  api._destroy = function (opts, callback) {\n    changesHandler$$1.removeAllListeners(dbName);\n\n    //Close open request for \"dbName\" database to fix ie delay.\n    var openReq = openReqList.get(dbName);\n    if (openReq && openReq.result) {\n      openReq.result.close();\n      cachedDBs.delete(dbName);\n    }\n    var req = indexedDB.deleteDatabase(dbName);\n\n    req.onsuccess = function () {\n      //Remove open request from the list.\n      openReqList.delete(dbName);\n      if (hasLocalStorage() && (dbName in localStorage)) {\n        delete localStorage[dbName];\n      }\n      callback(null, { 'ok': true });\n    };\n\n    req.onerror = idbError(callback);\n  };\n\n  var cached = cachedDBs.get(dbName);\n\n  if (cached) {\n    idb = cached.idb;\n    api._meta = cached.global;\n    return nextTick(function () {\n      callback(null, api);\n    });\n  }\n\n  var req;\n  if (opts.storage) {\n    req = tryStorageOption(dbName, opts.storage);\n  } else {\n    req = indexedDB.open(dbName, ADAPTER_VERSION);\n  }\n\n  openReqList.set(dbName, req);\n\n  req.onupgradeneeded = function (e) {\n    var db = e.target.result;\n    if (e.oldVersion < 1) {\n      return createSchema(db); // new db, initial schema\n    }\n    // do migrations\n\n    var txn = e.currentTarget.transaction;\n    // these migrations have to be done in this function, before\n    // control is returned to the event loop, because IndexedDB\n\n    if (e.oldVersion < 3) {\n      createLocalStoreSchema(db); // v2 -> v3\n    }\n    if (e.oldVersion < 4) {\n      addAttachAndSeqStore(db); // v3 -> v4\n    }\n\n    var migrations = [\n      addDeletedOrLocalIndex, // v1 -> v2\n      migrateLocalStore,      // v2 -> v3\n      migrateAttsAndSeqs,     // v3 -> v4\n      migrateMetadata         // v4 -> v5\n    ];\n\n    var i = e.oldVersion;\n\n    function next() {\n      var migration = migrations[i - 1];\n      i++;\n      if (migration) {\n        migration(txn, next);\n      }\n    }\n\n    next();\n  };\n\n  req.onsuccess = function (e) {\n\n    idb = e.target.result;\n\n    idb.onversionchange = function () {\n      idb.close();\n      cachedDBs.delete(dbName);\n    };\n\n    idb.onabort = function (e) {\n      guardedConsole('error', 'Database has a global failure', e.target.error);\n      idb.close();\n      cachedDBs.delete(dbName);\n    };\n\n    // Do a few setup operations (in parallel as much as possible):\n    // 1. Fetch meta doc\n    // 2. Check blob support\n    // 3. Calculate docCount\n    // 4. Generate an instanceId if necessary\n    // 5. Store docCount and instanceId on meta doc\n\n    var txn = idb.transaction([\n      META_STORE,\n      DETECT_BLOB_SUPPORT_STORE,\n      DOC_STORE\n    ], 'readwrite');\n\n    var storedMetaDoc = false;\n    var metaDoc;\n    var docCount;\n    var blobSupport;\n    var instanceId;\n\n    function completeSetup() {\n      if (typeof blobSupport === 'undefined' || !storedMetaDoc) {\n        return;\n      }\n      api._meta = {\n        name: dbName,\n        instanceId: instanceId,\n        blobSupport: blobSupport\n      };\n\n      cachedDBs.set(dbName, {\n        idb: idb,\n        global: api._meta\n      });\n      callback(null, api);\n    }\n\n    function storeMetaDocIfReady() {\n      if (typeof docCount === 'undefined' || typeof metaDoc === 'undefined') {\n        return;\n      }\n      var instanceKey = dbName + '_id';\n      if (instanceKey in metaDoc) {\n        instanceId = metaDoc[instanceKey];\n      } else {\n        metaDoc[instanceKey] = instanceId = uuid();\n      }\n      metaDoc.docCount = docCount;\n      txn.objectStore(META_STORE).put(metaDoc);\n    }\n\n    //\n    // fetch or generate the instanceId\n    //\n    txn.objectStore(META_STORE).get(META_STORE).onsuccess = function (e) {\n      metaDoc = e.target.result || { id: META_STORE };\n      storeMetaDocIfReady();\n    };\n\n    //\n    // countDocs\n    //\n    countDocs(txn, function (count) {\n      docCount = count;\n      storeMetaDocIfReady();\n    });\n\n    //\n    // check blob support\n    //\n    if (!blobSupportPromise) {\n      // make sure blob support is only checked once\n      blobSupportPromise = checkBlobSupport(txn);\n    }\n\n    blobSupportPromise.then(function (val) {\n      blobSupport = val;\n      completeSetup();\n    });\n\n    // only when the metadata put transaction has completed,\n    // consider the setup done\n    txn.oncomplete = function () {\n      storedMetaDoc = true;\n      completeSetup();\n    };\n  };\n\n  req.onerror = function () {\n    var msg = 'Failed to open indexedDB, are you in private browsing mode?';\n    guardedConsole('error', msg);\n    callback(createError(IDB_ERROR, msg));\n  };\n}\n\nIdbPouch.valid = function () {\n  // Issue #2533, we finally gave up on doing bug\n  // detection instead of browser sniffing. Safari brought us\n  // to our knees.\n  var isSafari = typeof openDatabase !== 'undefined' &&\n    /(Safari|iPhone|iPad|iPod)/.test(navigator.userAgent) &&\n    !/Chrome/.test(navigator.userAgent) &&\n    !/BlackBerry/.test(navigator.platform);\n\n  // some outdated implementations of IDB that appear on Samsung\n  // and HTC Android devices <4.4 are missing IDBKeyRange\n  return !isSafari && typeof indexedDB !== 'undefined' &&\n    typeof IDBKeyRange !== 'undefined';\n};\n\nfunction tryStorageOption(dbName, storage) {\n  try { // option only available in Firefox 26+\n    return indexedDB.open(dbName, {\n      version: ADAPTER_VERSION,\n      storage: storage\n    });\n  } catch(err) {\n      return indexedDB.open(dbName, ADAPTER_VERSION);\n  }\n}\n\nvar IDBPouch = function (PouchDB) {\n  PouchDB.adapter('idb', IdbPouch, true);\n};\n\n//\n// Parsing hex strings. Yeah.\n//\n// So basically we need this because of a bug in WebSQL:\n// https://code.google.com/p/chromium/issues/detail?id=422690\n// https://bugs.webkit.org/show_bug.cgi?id=137637\n//\n// UTF-8 and UTF-16 are provided as separate functions\n// for meager performance improvements\n//\n\nfunction decodeUtf8(str) {\n  return decodeURIComponent(escape(str));\n}\n\nfunction hexToInt(charCode) {\n  // '0'-'9' is 48-57\n  // 'A'-'F' is 65-70\n  // SQLite will only give us uppercase hex\n  return charCode < 65 ? (charCode - 48) : (charCode - 55);\n}\n\n\n// Example:\n// pragma encoding=utf8;\n// select hex('A');\n// returns '41'\nfunction parseHexUtf8(str, start, end) {\n  var result = '';\n  while (start < end) {\n    result += String.fromCharCode(\n      (hexToInt(str.charCodeAt(start++)) << 4) |\n        hexToInt(str.charCodeAt(start++)));\n  }\n  return result;\n}\n\n// Example:\n// pragma encoding=utf16;\n// select hex('A');\n// returns '4100'\n// notice that the 00 comes after the 41 (i.e. it's swizzled)\nfunction parseHexUtf16(str, start, end) {\n  var result = '';\n  while (start < end) {\n    // UTF-16, so swizzle the bytes\n    result += String.fromCharCode(\n      (hexToInt(str.charCodeAt(start + 2)) << 12) |\n        (hexToInt(str.charCodeAt(start + 3)) << 8) |\n        (hexToInt(str.charCodeAt(start)) << 4) |\n        hexToInt(str.charCodeAt(start + 1)));\n    start += 4;\n  }\n  return result;\n}\n\nfunction parseHexString(str, encoding) {\n  if (encoding === 'UTF-8') {\n    return decodeUtf8(parseHexUtf8(str, 0, str.length));\n  } else {\n    return parseHexUtf16(str, 0, str.length);\n  }\n}\n\nfunction quote(str) {\n  return \"'\" + str + \"'\";\n}\n\nvar ADAPTER_VERSION$1 = 7; // used to manage migrations\n\n// The object stores created for each database\n// DOC_STORE stores the document meta data, its revision history and state\nvar DOC_STORE$1 = quote('document-store');\n// BY_SEQ_STORE stores a particular version of a document, keyed by its\n// sequence id\nvar BY_SEQ_STORE$1 = quote('by-sequence');\n// Where we store attachments\nvar ATTACH_STORE$1 = quote('attach-store');\nvar LOCAL_STORE$1 = quote('local-store');\nvar META_STORE$1 = quote('metadata-store');\n// where we store many-to-many relations between attachment\n// digests and seqs\nvar ATTACH_AND_SEQ_STORE$1 = quote('attach-seq-store');\n\n// escapeBlob and unescapeBlob are workarounds for a websql bug:\n// https://code.google.com/p/chromium/issues/detail?id=422690\n// https://bugs.webkit.org/show_bug.cgi?id=137637\n// The goal is to never actually insert the \\u0000 character\n// in the database.\nfunction escapeBlob(str) {\n  return str\n    .replace(/\\u0002/g, '\\u0002\\u0002')\n    .replace(/\\u0001/g, '\\u0001\\u0002')\n    .replace(/\\u0000/g, '\\u0001\\u0001');\n}\n\nfunction unescapeBlob(str) {\n  return str\n    .replace(/\\u0001\\u0001/g, '\\u0000')\n    .replace(/\\u0001\\u0002/g, '\\u0001')\n    .replace(/\\u0002\\u0002/g, '\\u0002');\n}\n\nfunction stringifyDoc(doc) {\n  // don't bother storing the id/rev. it uses lots of space,\n  // in persistent map/reduce especially\n  delete doc._id;\n  delete doc._rev;\n  return JSON.stringify(doc);\n}\n\nfunction unstringifyDoc(doc, id, rev) {\n  doc = JSON.parse(doc);\n  doc._id = id;\n  doc._rev = rev;\n  return doc;\n}\n\n// question mark groups IN queries, e.g. 3 -> '(?,?,?)'\nfunction qMarks(num) {\n  var s = '(';\n  while (num--) {\n    s += '?';\n    if (num) {\n      s += ',';\n    }\n  }\n  return s + ')';\n}\n\nfunction select(selector, table, joiner, where, orderBy) {\n  return 'SELECT ' + selector + ' FROM ' +\n    (typeof table === 'string' ? table : table.join(' JOIN ')) +\n    (joiner ? (' ON ' + joiner) : '') +\n    (where ? (' WHERE ' +\n    (typeof where === 'string' ? where : where.join(' AND '))) : '') +\n    (orderBy ? (' ORDER BY ' + orderBy) : '');\n}\n\nfunction compactRevs$1(revs, docId, tx) {\n\n  if (!revs.length) {\n    return;\n  }\n\n  var numDone = 0;\n  var seqs = [];\n\n  function checkDone() {\n    if (++numDone === revs.length) { // done\n      deleteOrphans();\n    }\n  }\n\n  function deleteOrphans() {\n    // find orphaned attachment digests\n\n    if (!seqs.length) {\n      return;\n    }\n\n    var sql = 'SELECT DISTINCT digest AS digest FROM ' +\n      ATTACH_AND_SEQ_STORE$1 + ' WHERE seq IN ' + qMarks(seqs.length);\n\n    tx.executeSql(sql, seqs, function (tx, res) {\n\n      var digestsToCheck = [];\n      for (var i = 0; i < res.rows.length; i++) {\n        digestsToCheck.push(res.rows.item(i).digest);\n      }\n      if (!digestsToCheck.length) {\n        return;\n      }\n\n      var sql = 'DELETE FROM ' + ATTACH_AND_SEQ_STORE$1 +\n        ' WHERE seq IN (' +\n        seqs.map(function () { return '?'; }).join(',') +\n        ')';\n      tx.executeSql(sql, seqs, function (tx) {\n\n        var sql = 'SELECT digest FROM ' + ATTACH_AND_SEQ_STORE$1 +\n          ' WHERE digest IN (' +\n          digestsToCheck.map(function () { return '?'; }).join(',') +\n          ')';\n        tx.executeSql(sql, digestsToCheck, function (tx, res) {\n          var nonOrphanedDigests = new ExportedSet();\n          for (var i = 0; i < res.rows.length; i++) {\n            nonOrphanedDigests.add(res.rows.item(i).digest);\n          }\n          digestsToCheck.forEach(function (digest) {\n            if (nonOrphanedDigests.has(digest)) {\n              return;\n            }\n            tx.executeSql(\n              'DELETE FROM ' + ATTACH_AND_SEQ_STORE$1 + ' WHERE digest=?',\n              [digest]);\n            tx.executeSql(\n              'DELETE FROM ' + ATTACH_STORE$1 + ' WHERE digest=?', [digest]);\n          });\n        });\n      });\n    });\n  }\n\n  // update by-seq and attach stores in parallel\n  revs.forEach(function (rev) {\n    var sql = 'SELECT seq FROM ' + BY_SEQ_STORE$1 +\n      ' WHERE doc_id=? AND rev=?';\n\n    tx.executeSql(sql, [docId, rev], function (tx, res) {\n      if (!res.rows.length) { // already deleted\n        return checkDone();\n      }\n      var seq = res.rows.item(0).seq;\n      seqs.push(seq);\n\n      tx.executeSql(\n        'DELETE FROM ' + BY_SEQ_STORE$1 + ' WHERE seq=?', [seq], checkDone);\n    });\n  });\n}\n\nfunction websqlError(callback) {\n  return function (event) {\n    guardedConsole('error', 'WebSQL threw an error', event);\n    // event may actually be a SQLError object, so report is as such\n    var errorNameMatch = event && event.constructor.toString()\n        .match(/function ([^\\(]+)/);\n    var errorName = (errorNameMatch && errorNameMatch[1]) || event.type;\n    var errorReason = event.target || event.message;\n    callback(createError(WSQ_ERROR, errorReason, errorName));\n  };\n}\n\nfunction getSize(opts) {\n  if ('size' in opts) {\n    // triggers immediate popup in iOS, fixes #2347\n    // e.g. 5000001 asks for 5 MB, 10000001 asks for 10 MB,\n    return opts.size * 1000000;\n  }\n  // In iOS, doesn't matter as long as it's <= 5000000.\n  // Except that if you request too much, our tests fail\n  // because of the native \"do you accept?\" popup.\n  // In Android <=4.3, this value is actually used as an\n  // honest-to-god ceiling for data, so we need to\n  // set it to a decently high number.\n  var isAndroid = typeof navigator !== 'undefined' &&\n    /Android/.test(navigator.userAgent);\n  return isAndroid ? 5000000 : 1; // in PhantomJS, if you use 0 it will crash\n}\n\nfunction websqlBulkDocs(dbOpts, req, opts, api, db, websqlChanges, callback) {\n  var newEdits = opts.new_edits;\n  var userDocs = req.docs;\n\n  // Parse the docs, give them a sequence number for the result\n  var docInfos = userDocs.map(function (doc) {\n    if (doc._id && isLocalId(doc._id)) {\n      return doc;\n    }\n    var newDoc = parseDoc(doc, newEdits);\n    return newDoc;\n  });\n\n  var docInfoErrors = docInfos.filter(function (docInfo) {\n    return docInfo.error;\n  });\n  if (docInfoErrors.length) {\n    return callback(docInfoErrors[0]);\n  }\n\n  var tx;\n  var results = new Array(docInfos.length);\n  var fetchedDocs = new ExportedMap();\n\n  var preconditionErrored;\n  function complete() {\n    if (preconditionErrored) {\n      return callback(preconditionErrored);\n    }\n    websqlChanges.notify(api._name);\n    callback(null, results);\n  }\n\n  function verifyAttachment(digest, callback) {\n    var sql = 'SELECT count(*) as cnt FROM ' + ATTACH_STORE$1 +\n      ' WHERE digest=?';\n    tx.executeSql(sql, [digest], function (tx, result) {\n      if (result.rows.item(0).cnt === 0) {\n        var err = createError(MISSING_STUB,\n          'unknown stub attachment with digest ' +\n          digest);\n        callback(err);\n      } else {\n        callback();\n      }\n    });\n  }\n\n  function verifyAttachments(finish) {\n    var digests = [];\n    docInfos.forEach(function (docInfo) {\n      if (docInfo.data && docInfo.data._attachments) {\n        Object.keys(docInfo.data._attachments).forEach(function (filename) {\n          var att = docInfo.data._attachments[filename];\n          if (att.stub) {\n            digests.push(att.digest);\n          }\n        });\n      }\n    });\n    if (!digests.length) {\n      return finish();\n    }\n    var numDone = 0;\n    var err;\n\n    function checkDone() {\n      if (++numDone === digests.length) {\n        finish(err);\n      }\n    }\n    digests.forEach(function (digest) {\n      verifyAttachment(digest, function (attErr) {\n        if (attErr && !err) {\n          err = attErr;\n        }\n        checkDone();\n      });\n    });\n  }\n\n  function writeDoc(docInfo, winningRev$$1, winningRevIsDeleted, newRevIsDeleted,\n                    isUpdate, delta, resultsIdx, callback) {\n\n    function finish() {\n      var data = docInfo.data;\n      var deletedInt = newRevIsDeleted ? 1 : 0;\n\n      var id = data._id;\n      var rev = data._rev;\n      var json = stringifyDoc(data);\n      var sql = 'INSERT INTO ' + BY_SEQ_STORE$1 +\n        ' (doc_id, rev, json, deleted) VALUES (?, ?, ?, ?);';\n      var sqlArgs = [id, rev, json, deletedInt];\n\n      // map seqs to attachment digests, which\n      // we will need later during compaction\n      function insertAttachmentMappings(seq, callback) {\n        var attsAdded = 0;\n        var attsToAdd = Object.keys(data._attachments || {});\n\n        if (!attsToAdd.length) {\n          return callback();\n        }\n        function checkDone() {\n          if (++attsAdded === attsToAdd.length) {\n            callback();\n          }\n          return false; // ack handling a constraint error\n        }\n        function add(att) {\n          var sql = 'INSERT INTO ' + ATTACH_AND_SEQ_STORE$1 +\n            ' (digest, seq) VALUES (?,?)';\n          var sqlArgs = [data._attachments[att].digest, seq];\n          tx.executeSql(sql, sqlArgs, checkDone, checkDone);\n          // second callback is for a constaint error, which we ignore\n          // because this docid/rev has already been associated with\n          // the digest (e.g. when new_edits == false)\n        }\n        for (var i = 0; i < attsToAdd.length; i++) {\n          add(attsToAdd[i]); // do in parallel\n        }\n      }\n\n      tx.executeSql(sql, sqlArgs, function (tx, result) {\n        var seq = result.insertId;\n        insertAttachmentMappings(seq, function () {\n          dataWritten(tx, seq);\n        });\n      }, function () {\n        // constraint error, recover by updating instead (see #1638)\n        var fetchSql = select('seq', BY_SEQ_STORE$1, null,\n          'doc_id=? AND rev=?');\n        tx.executeSql(fetchSql, [id, rev], function (tx, res) {\n          var seq = res.rows.item(0).seq;\n          var sql = 'UPDATE ' + BY_SEQ_STORE$1 +\n            ' SET json=?, deleted=? WHERE doc_id=? AND rev=?;';\n          var sqlArgs = [json, deletedInt, id, rev];\n          tx.executeSql(sql, sqlArgs, function (tx) {\n            insertAttachmentMappings(seq, function () {\n              dataWritten(tx, seq);\n            });\n          });\n        });\n        return false; // ack that we've handled the error\n      });\n    }\n\n    function collectResults(attachmentErr) {\n      if (!err) {\n        if (attachmentErr) {\n          err = attachmentErr;\n          callback(err);\n        } else if (recv === attachments.length) {\n          finish();\n        }\n      }\n    }\n\n    var err = null;\n    var recv = 0;\n\n    docInfo.data._id = docInfo.metadata.id;\n    docInfo.data._rev = docInfo.metadata.rev;\n    var attachments = Object.keys(docInfo.data._attachments || {});\n\n\n    if (newRevIsDeleted) {\n      docInfo.data._deleted = true;\n    }\n\n    function attachmentSaved(err) {\n      recv++;\n      collectResults(err);\n    }\n\n    attachments.forEach(function (key) {\n      var att = docInfo.data._attachments[key];\n      if (!att.stub) {\n        var data = att.data;\n        delete att.data;\n        att.revpos = parseInt(winningRev$$1, 10);\n        var digest = att.digest;\n        saveAttachment(digest, data, attachmentSaved);\n      } else {\n        recv++;\n        collectResults();\n      }\n    });\n\n    if (!attachments.length) {\n      finish();\n    }\n\n    function dataWritten(tx, seq) {\n      var id = docInfo.metadata.id;\n\n      var revsToCompact = docInfo.stemmedRevs || [];\n      if (isUpdate && api.auto_compaction) {\n        revsToCompact = compactTree(docInfo.metadata).concat(revsToCompact);\n      }\n      if (revsToCompact.length) {\n        compactRevs$1(revsToCompact, id, tx);\n      }\n\n      docInfo.metadata.seq = seq;\n      var rev = docInfo.metadata.rev;\n      delete docInfo.metadata.rev;\n\n      var sql = isUpdate ?\n      'UPDATE ' + DOC_STORE$1 +\n      ' SET json=?, max_seq=?, winningseq=' +\n      '(SELECT seq FROM ' + BY_SEQ_STORE$1 +\n      ' WHERE doc_id=' + DOC_STORE$1 + '.id AND rev=?) WHERE id=?'\n        : 'INSERT INTO ' + DOC_STORE$1 +\n      ' (id, winningseq, max_seq, json) VALUES (?,?,?,?);';\n      var metadataStr = safeJsonStringify(docInfo.metadata);\n      var params = isUpdate ?\n        [metadataStr, seq, winningRev$$1, id] :\n        [id, seq, seq, metadataStr];\n      tx.executeSql(sql, params, function () {\n        results[resultsIdx] = {\n          ok: true,\n          id: docInfo.metadata.id,\n          rev: rev\n        };\n        fetchedDocs.set(id, docInfo.metadata);\n        callback();\n      });\n    }\n  }\n\n  function websqlProcessDocs() {\n    processDocs(dbOpts.revs_limit, docInfos, api, fetchedDocs, tx,\n                results, writeDoc, opts);\n  }\n\n  function fetchExistingDocs(callback) {\n    if (!docInfos.length) {\n      return callback();\n    }\n\n    var numFetched = 0;\n\n    function checkDone() {\n      if (++numFetched === docInfos.length) {\n        callback();\n      }\n    }\n\n    docInfos.forEach(function (docInfo) {\n      if (docInfo._id && isLocalId(docInfo._id)) {\n        return checkDone(); // skip local docs\n      }\n      var id = docInfo.metadata.id;\n      tx.executeSql('SELECT json FROM ' + DOC_STORE$1 +\n      ' WHERE id = ?', [id], function (tx, result) {\n        if (result.rows.length) {\n          var metadata = safeJsonParse(result.rows.item(0).json);\n          fetchedDocs.set(id, metadata);\n        }\n        checkDone();\n      });\n    });\n  }\n\n  function saveAttachment(digest, data, callback) {\n    var sql = 'SELECT digest FROM ' + ATTACH_STORE$1 + ' WHERE digest=?';\n    tx.executeSql(sql, [digest], function (tx, result) {\n      if (result.rows.length) { // attachment already exists\n        return callback();\n      }\n      // we could just insert before selecting and catch the error,\n      // but my hunch is that it's cheaper not to serialize the blob\n      // from JS to C if we don't have to (TODO: confirm this)\n      sql = 'INSERT INTO ' + ATTACH_STORE$1 +\n      ' (digest, body, escaped) VALUES (?,?,1)';\n      tx.executeSql(sql, [digest, escapeBlob(data)], function () {\n        callback();\n      }, function () {\n        // ignore constaint errors, means it already exists\n        callback();\n        return false; // ack we handled the error\n      });\n    });\n  }\n\n  preprocessAttachments(docInfos, 'binary', function (err) {\n    if (err) {\n      return callback(err);\n    }\n    db.transaction(function (txn) {\n      tx = txn;\n      verifyAttachments(function (err) {\n        if (err) {\n          preconditionErrored = err;\n        } else {\n          fetchExistingDocs(websqlProcessDocs);\n        }\n      });\n    }, websqlError(callback), complete);\n  });\n}\n\nvar cachedDatabases = new ExportedMap();\n\n// openDatabase passed in through opts (e.g. for node-websql)\nfunction openDatabaseWithOpts(opts) {\n  return opts.websql(opts.name, opts.version, opts.description, opts.size);\n}\n\nfunction openDBSafely(opts) {\n  try {\n    return {\n      db: openDatabaseWithOpts(opts)\n    };\n  } catch (err) {\n    return {\n      error: err\n    };\n  }\n}\n\nfunction openDB$1(opts) {\n  var cachedResult = cachedDatabases.get(opts.name);\n  if (!cachedResult) {\n    cachedResult = openDBSafely(opts);\n    cachedDatabases.set(opts.name, cachedResult);\n  }\n  return cachedResult;\n}\n\nvar websqlChanges = new Changes();\n\nfunction fetchAttachmentsIfNecessary$1(doc, opts, api, txn, cb) {\n  var attachments = Object.keys(doc._attachments || {});\n  if (!attachments.length) {\n    return cb && cb();\n  }\n  var numDone = 0;\n\n  function checkDone() {\n    if (++numDone === attachments.length && cb) {\n      cb();\n    }\n  }\n\n  function fetchAttachment(doc, att) {\n    var attObj = doc._attachments[att];\n    var attOpts = {binary: opts.binary, ctx: txn};\n    api._getAttachment(doc._id, att, attObj, attOpts, function (_, data) {\n      doc._attachments[att] = assign$1(\n        pick(attObj, ['digest', 'content_type']),\n        { data: data }\n      );\n      checkDone();\n    });\n  }\n\n  attachments.forEach(function (att) {\n    if (opts.attachments && opts.include_docs) {\n      fetchAttachment(doc, att);\n    } else {\n      doc._attachments[att].stub = true;\n      checkDone();\n    }\n  });\n}\n\nvar POUCH_VERSION = 1;\n\n// these indexes cover the ground for most allDocs queries\nvar BY_SEQ_STORE_DELETED_INDEX_SQL =\n  'CREATE INDEX IF NOT EXISTS \\'by-seq-deleted-idx\\' ON ' +\n  BY_SEQ_STORE$1 + ' (seq, deleted)';\nvar BY_SEQ_STORE_DOC_ID_REV_INDEX_SQL =\n  'CREATE UNIQUE INDEX IF NOT EXISTS \\'by-seq-doc-id-rev\\' ON ' +\n    BY_SEQ_STORE$1 + ' (doc_id, rev)';\nvar DOC_STORE_WINNINGSEQ_INDEX_SQL =\n  'CREATE INDEX IF NOT EXISTS \\'doc-winningseq-idx\\' ON ' +\n  DOC_STORE$1 + ' (winningseq)';\nvar ATTACH_AND_SEQ_STORE_SEQ_INDEX_SQL =\n  'CREATE INDEX IF NOT EXISTS \\'attach-seq-seq-idx\\' ON ' +\n    ATTACH_AND_SEQ_STORE$1 + ' (seq)';\nvar ATTACH_AND_SEQ_STORE_ATTACH_INDEX_SQL =\n  'CREATE UNIQUE INDEX IF NOT EXISTS \\'attach-seq-digest-idx\\' ON ' +\n    ATTACH_AND_SEQ_STORE$1 + ' (digest, seq)';\n\nvar DOC_STORE_AND_BY_SEQ_JOINER = BY_SEQ_STORE$1 +\n  '.seq = ' + DOC_STORE$1 + '.winningseq';\n\nvar SELECT_DOCS = BY_SEQ_STORE$1 + '.seq AS seq, ' +\n  BY_SEQ_STORE$1 + '.deleted AS deleted, ' +\n  BY_SEQ_STORE$1 + '.json AS data, ' +\n  BY_SEQ_STORE$1 + '.rev AS rev, ' +\n  DOC_STORE$1 + '.json AS metadata';\n\nfunction WebSqlPouch$1(opts, callback) {\n  var api = this;\n  var instanceId = null;\n  var size = getSize(opts);\n  var idRequests = [];\n  var encoding;\n\n  api._name = opts.name;\n\n  // extend the options here, because sqlite plugin has a ton of options\n  // and they are constantly changing, so it's more prudent to allow anything\n  var websqlOpts = assign$1({}, opts, {\n    version: POUCH_VERSION,\n    description: opts.name,\n    size: size\n  });\n  var openDBResult = openDB$1(websqlOpts);\n  if (openDBResult.error) {\n    return websqlError(callback)(openDBResult.error);\n  }\n  var db = openDBResult.db;\n  if (typeof db.readTransaction !== 'function') {\n    // doesn't exist in sqlite plugin\n    db.readTransaction = db.transaction;\n  }\n\n  function dbCreated() {\n    // note the db name in case the browser upgrades to idb\n    if (hasLocalStorage()) {\n      window.localStorage['_pouch__websqldb_' + api._name] = true;\n    }\n    callback(null, api);\n  }\n\n  // In this migration, we added the 'deleted' and 'local' columns to the\n  // by-seq and doc store tables.\n  // To preserve existing user data, we re-process all the existing JSON\n  // and add these values.\n  // Called migration2 because it corresponds to adapter version (db_version) #2\n  function runMigration2(tx, callback) {\n    // index used for the join in the allDocs query\n    tx.executeSql(DOC_STORE_WINNINGSEQ_INDEX_SQL);\n\n    tx.executeSql('ALTER TABLE ' + BY_SEQ_STORE$1 +\n      ' ADD COLUMN deleted TINYINT(1) DEFAULT 0', [], function () {\n      tx.executeSql(BY_SEQ_STORE_DELETED_INDEX_SQL);\n      tx.executeSql('ALTER TABLE ' + DOC_STORE$1 +\n        ' ADD COLUMN local TINYINT(1) DEFAULT 0', [], function () {\n        tx.executeSql('CREATE INDEX IF NOT EXISTS \\'doc-store-local-idx\\' ON ' +\n          DOC_STORE$1 + ' (local, id)');\n\n        var sql = 'SELECT ' + DOC_STORE$1 + '.winningseq AS seq, ' + DOC_STORE$1 +\n          '.json AS metadata FROM ' + BY_SEQ_STORE$1 + ' JOIN ' + DOC_STORE$1 +\n          ' ON ' + BY_SEQ_STORE$1 + '.seq = ' + DOC_STORE$1 + '.winningseq';\n\n        tx.executeSql(sql, [], function (tx, result) {\n\n          var deleted = [];\n          var local = [];\n\n          for (var i = 0; i < result.rows.length; i++) {\n            var item = result.rows.item(i);\n            var seq = item.seq;\n            var metadata = JSON.parse(item.metadata);\n            if (isDeleted(metadata)) {\n              deleted.push(seq);\n            }\n            if (isLocalId(metadata.id)) {\n              local.push(metadata.id);\n            }\n          }\n          tx.executeSql('UPDATE ' + DOC_STORE$1 + 'SET local = 1 WHERE id IN ' +\n            qMarks(local.length), local, function () {\n            tx.executeSql('UPDATE ' + BY_SEQ_STORE$1 +\n              ' SET deleted = 1 WHERE seq IN ' +\n              qMarks(deleted.length), deleted, callback);\n          });\n        });\n      });\n    });\n  }\n\n  // in this migration, we make all the local docs unversioned\n  function runMigration3(tx, callback) {\n    var local = 'CREATE TABLE IF NOT EXISTS ' + LOCAL_STORE$1 +\n      ' (id UNIQUE, rev, json)';\n    tx.executeSql(local, [], function () {\n      var sql = 'SELECT ' + DOC_STORE$1 + '.id AS id, ' +\n        BY_SEQ_STORE$1 + '.json AS data ' +\n        'FROM ' + BY_SEQ_STORE$1 + ' JOIN ' +\n        DOC_STORE$1 + ' ON ' + BY_SEQ_STORE$1 + '.seq = ' +\n        DOC_STORE$1 + '.winningseq WHERE local = 1';\n      tx.executeSql(sql, [], function (tx, res) {\n        var rows = [];\n        for (var i = 0; i < res.rows.length; i++) {\n          rows.push(res.rows.item(i));\n        }\n        function doNext() {\n          if (!rows.length) {\n            return callback(tx);\n          }\n          var row = rows.shift();\n          var rev = JSON.parse(row.data)._rev;\n          tx.executeSql('INSERT INTO ' + LOCAL_STORE$1 +\n              ' (id, rev, json) VALUES (?,?,?)',\n              [row.id, rev, row.data], function (tx) {\n            tx.executeSql('DELETE FROM ' + DOC_STORE$1 + ' WHERE id=?',\n                [row.id], function (tx) {\n              tx.executeSql('DELETE FROM ' + BY_SEQ_STORE$1 + ' WHERE seq=?',\n                  [row.seq], function () {\n                doNext();\n              });\n            });\n          });\n        }\n        doNext();\n      });\n    });\n  }\n\n  // in this migration, we remove doc_id_rev and just use rev\n  function runMigration4(tx, callback) {\n\n    function updateRows(rows) {\n      function doNext() {\n        if (!rows.length) {\n          return callback(tx);\n        }\n        var row = rows.shift();\n        var doc_id_rev = parseHexString(row.hex, encoding);\n        var idx = doc_id_rev.lastIndexOf('::');\n        var doc_id = doc_id_rev.substring(0, idx);\n        var rev = doc_id_rev.substring(idx + 2);\n        var sql = 'UPDATE ' + BY_SEQ_STORE$1 +\n          ' SET doc_id=?, rev=? WHERE doc_id_rev=?';\n        tx.executeSql(sql, [doc_id, rev, doc_id_rev], function () {\n          doNext();\n        });\n      }\n      doNext();\n    }\n\n    var sql = 'ALTER TABLE ' + BY_SEQ_STORE$1 + ' ADD COLUMN doc_id';\n    tx.executeSql(sql, [], function (tx) {\n      var sql = 'ALTER TABLE ' + BY_SEQ_STORE$1 + ' ADD COLUMN rev';\n      tx.executeSql(sql, [], function (tx) {\n        tx.executeSql(BY_SEQ_STORE_DOC_ID_REV_INDEX_SQL, [], function (tx) {\n          var sql = 'SELECT hex(doc_id_rev) as hex FROM ' + BY_SEQ_STORE$1;\n          tx.executeSql(sql, [], function (tx, res) {\n            var rows = [];\n            for (var i = 0; i < res.rows.length; i++) {\n              rows.push(res.rows.item(i));\n            }\n            updateRows(rows);\n          });\n        });\n      });\n    });\n  }\n\n  // in this migration, we add the attach_and_seq table\n  // for issue #2818\n  function runMigration5(tx, callback) {\n\n    function migrateAttsAndSeqs(tx) {\n      // need to actually populate the table. this is the expensive part,\n      // so as an optimization, check first that this database even\n      // contains attachments\n      var sql = 'SELECT COUNT(*) AS cnt FROM ' + ATTACH_STORE$1;\n      tx.executeSql(sql, [], function (tx, res) {\n        var count = res.rows.item(0).cnt;\n        if (!count) {\n          return callback(tx);\n        }\n\n        var offset = 0;\n        var pageSize = 10;\n        function nextPage() {\n          var sql = select(\n            SELECT_DOCS + ', ' + DOC_STORE$1 + '.id AS id',\n            [DOC_STORE$1, BY_SEQ_STORE$1],\n            DOC_STORE_AND_BY_SEQ_JOINER,\n            null,\n            DOC_STORE$1 + '.id '\n          );\n          sql += ' LIMIT ' + pageSize + ' OFFSET ' + offset;\n          offset += pageSize;\n          tx.executeSql(sql, [], function (tx, res) {\n            if (!res.rows.length) {\n              return callback(tx);\n            }\n            var digestSeqs = {};\n            function addDigestSeq(digest, seq) {\n              // uniq digest/seq pairs, just in case there are dups\n              var seqs = digestSeqs[digest] = (digestSeqs[digest] || []);\n              if (seqs.indexOf(seq) === -1) {\n                seqs.push(seq);\n              }\n            }\n            for (var i = 0; i < res.rows.length; i++) {\n              var row = res.rows.item(i);\n              var doc = unstringifyDoc(row.data, row.id, row.rev);\n              var atts = Object.keys(doc._attachments || {});\n              for (var j = 0; j < atts.length; j++) {\n                var att = doc._attachments[atts[j]];\n                addDigestSeq(att.digest, row.seq);\n              }\n            }\n            var digestSeqPairs = [];\n            Object.keys(digestSeqs).forEach(function (digest) {\n              var seqs = digestSeqs[digest];\n              seqs.forEach(function (seq) {\n                digestSeqPairs.push([digest, seq]);\n              });\n            });\n            if (!digestSeqPairs.length) {\n              return nextPage();\n            }\n            var numDone = 0;\n            digestSeqPairs.forEach(function (pair) {\n              var sql = 'INSERT INTO ' + ATTACH_AND_SEQ_STORE$1 +\n                ' (digest, seq) VALUES (?,?)';\n              tx.executeSql(sql, pair, function () {\n                if (++numDone === digestSeqPairs.length) {\n                  nextPage();\n                }\n              });\n            });\n          });\n        }\n        nextPage();\n      });\n    }\n\n    var attachAndRev = 'CREATE TABLE IF NOT EXISTS ' +\n      ATTACH_AND_SEQ_STORE$1 + ' (digest, seq INTEGER)';\n    tx.executeSql(attachAndRev, [], function (tx) {\n      tx.executeSql(\n        ATTACH_AND_SEQ_STORE_ATTACH_INDEX_SQL, [], function (tx) {\n          tx.executeSql(\n            ATTACH_AND_SEQ_STORE_SEQ_INDEX_SQL, [],\n            migrateAttsAndSeqs);\n        });\n    });\n  }\n\n  // in this migration, we use escapeBlob() and unescapeBlob()\n  // instead of reading out the binary as HEX, which is slow\n  function runMigration6(tx, callback) {\n    var sql = 'ALTER TABLE ' + ATTACH_STORE$1 +\n      ' ADD COLUMN escaped TINYINT(1) DEFAULT 0';\n    tx.executeSql(sql, [], callback);\n  }\n\n  // issue #3136, in this migration we need a \"latest seq\" as well\n  // as the \"winning seq\" in the doc store\n  function runMigration7(tx, callback) {\n    var sql = 'ALTER TABLE ' + DOC_STORE$1 +\n      ' ADD COLUMN max_seq INTEGER';\n    tx.executeSql(sql, [], function (tx) {\n      var sql = 'UPDATE ' + DOC_STORE$1 + ' SET max_seq=(SELECT MAX(seq) FROM ' +\n        BY_SEQ_STORE$1 + ' WHERE doc_id=id)';\n      tx.executeSql(sql, [], function (tx) {\n        // add unique index after filling, else we'll get a constraint\n        // error when we do the ALTER TABLE\n        var sql =\n          'CREATE UNIQUE INDEX IF NOT EXISTS \\'doc-max-seq-idx\\' ON ' +\n          DOC_STORE$1 + ' (max_seq)';\n        tx.executeSql(sql, [], callback);\n      });\n    });\n  }\n\n  function checkEncoding(tx, cb) {\n    // UTF-8 on chrome/android, UTF-16 on safari < 7.1\n    tx.executeSql('SELECT HEX(\"a\") AS hex', [], function (tx, res) {\n        var hex = res.rows.item(0).hex;\n        encoding = hex.length === 2 ? 'UTF-8' : 'UTF-16';\n        cb();\n      }\n    );\n  }\n\n  function onGetInstanceId() {\n    while (idRequests.length > 0) {\n      var idCallback = idRequests.pop();\n      idCallback(null, instanceId);\n    }\n  }\n\n  function onGetVersion(tx, dbVersion) {\n    if (dbVersion === 0) {\n      // initial schema\n\n      var meta = 'CREATE TABLE IF NOT EXISTS ' + META_STORE$1 +\n        ' (dbid, db_version INTEGER)';\n      var attach = 'CREATE TABLE IF NOT EXISTS ' + ATTACH_STORE$1 +\n        ' (digest UNIQUE, escaped TINYINT(1), body BLOB)';\n      var attachAndRev = 'CREATE TABLE IF NOT EXISTS ' +\n        ATTACH_AND_SEQ_STORE$1 + ' (digest, seq INTEGER)';\n      // TODO: migrate winningseq to INTEGER\n      var doc = 'CREATE TABLE IF NOT EXISTS ' + DOC_STORE$1 +\n        ' (id unique, json, winningseq, max_seq INTEGER UNIQUE)';\n      var seq = 'CREATE TABLE IF NOT EXISTS ' + BY_SEQ_STORE$1 +\n        ' (seq INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT, ' +\n        'json, deleted TINYINT(1), doc_id, rev)';\n      var local = 'CREATE TABLE IF NOT EXISTS ' + LOCAL_STORE$1 +\n        ' (id UNIQUE, rev, json)';\n\n      // creates\n      tx.executeSql(attach);\n      tx.executeSql(local);\n      tx.executeSql(attachAndRev, [], function () {\n        tx.executeSql(ATTACH_AND_SEQ_STORE_SEQ_INDEX_SQL);\n        tx.executeSql(ATTACH_AND_SEQ_STORE_ATTACH_INDEX_SQL);\n      });\n      tx.executeSql(doc, [], function () {\n        tx.executeSql(DOC_STORE_WINNINGSEQ_INDEX_SQL);\n        tx.executeSql(seq, [], function () {\n          tx.executeSql(BY_SEQ_STORE_DELETED_INDEX_SQL);\n          tx.executeSql(BY_SEQ_STORE_DOC_ID_REV_INDEX_SQL);\n          tx.executeSql(meta, [], function () {\n            // mark the db version, and new dbid\n            var initSeq = 'INSERT INTO ' + META_STORE$1 +\n              ' (db_version, dbid) VALUES (?,?)';\n            instanceId = uuid();\n            var initSeqArgs = [ADAPTER_VERSION$1, instanceId];\n            tx.executeSql(initSeq, initSeqArgs, function () {\n              onGetInstanceId();\n            });\n          });\n        });\n      });\n    } else { // version > 0\n\n      var setupDone = function () {\n        var migrated = dbVersion < ADAPTER_VERSION$1;\n        if (migrated) {\n          // update the db version within this transaction\n          tx.executeSql('UPDATE ' + META_STORE$1 + ' SET db_version = ' +\n            ADAPTER_VERSION$1);\n        }\n        // notify db.id() callers\n        var sql = 'SELECT dbid FROM ' + META_STORE$1;\n        tx.executeSql(sql, [], function (tx, result) {\n          instanceId = result.rows.item(0).dbid;\n          onGetInstanceId();\n        });\n      };\n\n      // would love to use promises here, but then websql\n      // ends the transaction early\n      var tasks = [\n        runMigration2,\n        runMigration3,\n        runMigration4,\n        runMigration5,\n        runMigration6,\n        runMigration7,\n        setupDone\n      ];\n\n      // run each migration sequentially\n      var i = dbVersion;\n      var nextMigration = function (tx) {\n        tasks[i - 1](tx, nextMigration);\n        i++;\n      };\n      nextMigration(tx);\n    }\n  }\n\n  function setup() {\n    db.transaction(function (tx) {\n      // first check the encoding\n      checkEncoding(tx, function () {\n        // then get the version\n        fetchVersion(tx);\n      });\n    }, websqlError(callback), dbCreated);\n  }\n\n  function fetchVersion(tx) {\n    var sql = 'SELECT sql FROM sqlite_master WHERE tbl_name = ' + META_STORE$1;\n    tx.executeSql(sql, [], function (tx, result) {\n      if (!result.rows.length) {\n        // database hasn't even been created yet (version 0)\n        onGetVersion(tx, 0);\n      } else if (!/db_version/.test(result.rows.item(0).sql)) {\n        // table was created, but without the new db_version column,\n        // so add it.\n        tx.executeSql('ALTER TABLE ' + META_STORE$1 +\n          ' ADD COLUMN db_version INTEGER', [], function () {\n          // before version 2, this column didn't even exist\n          onGetVersion(tx, 1);\n        });\n      } else { // column exists, we can safely get it\n        tx.executeSql('SELECT db_version FROM ' + META_STORE$1,\n          [], function (tx, result) {\n          var dbVersion = result.rows.item(0).db_version;\n          onGetVersion(tx, dbVersion);\n        });\n      }\n    });\n  }\n\n  setup();\n\n  function getMaxSeq(tx, callback) {\n    var sql = 'SELECT MAX(seq) AS seq FROM ' + BY_SEQ_STORE$1;\n    tx.executeSql(sql, [], function (tx, res) {\n      var updateSeq = res.rows.item(0).seq || 0;\n      callback(updateSeq);\n    });\n  }\n\n  function countDocs(tx, callback) {\n    // count the total rows\n    var sql = select(\n      'COUNT(' + DOC_STORE$1 + '.id) AS \\'num\\'',\n      [DOC_STORE$1, BY_SEQ_STORE$1],\n      DOC_STORE_AND_BY_SEQ_JOINER,\n      BY_SEQ_STORE$1 + '.deleted=0');\n\n    tx.executeSql(sql, [], function (tx, result) {\n      callback(result.rows.item(0).num);\n    });\n  }\n\n  api.type = function () {\n    return 'websql';\n  };\n\n  api._id = toPromise(function (callback) {\n    callback(null, instanceId);\n  });\n\n  api._info = function (callback) {\n    var seq;\n    var docCount;\n    db.readTransaction(function (tx) {\n      getMaxSeq(tx, function (theSeq) {\n        seq = theSeq;\n      });\n      countDocs(tx, function (theDocCount) {\n        docCount = theDocCount;\n      });\n    }, websqlError(callback), function () {\n      callback(null, {\n        doc_count: docCount,\n        update_seq: seq,\n        websql_encoding: encoding\n      });\n    });\n  };\n\n  api._bulkDocs = function (req, reqOpts, callback) {\n    websqlBulkDocs(opts, req, reqOpts, api, db, websqlChanges, callback);\n  };\n\n  function latest$$1(tx, id, rev, callback, finish) {\n    var sql = select(\n        SELECT_DOCS,\n        [DOC_STORE$1, BY_SEQ_STORE$1],\n        DOC_STORE_AND_BY_SEQ_JOINER,\n        DOC_STORE$1 + '.id=?');\n    var sqlArgs = [id];\n\n    tx.executeSql(sql, sqlArgs, function (a, results) {\n      if (!results.rows.length) {\n        var err = createError(MISSING_DOC, 'missing');\n        return finish(err);\n      }\n      var item = results.rows.item(0);\n      var metadata = safeJsonParse(item.metadata);\n      callback(latest(rev, metadata));\n    });\n  }\n\n  api._get = function (id, opts, callback) {\n    var doc;\n    var metadata;\n    var tx = opts.ctx;\n    if (!tx) {\n      return db.readTransaction(function (txn) {\n        api._get(id, assign$1({ctx: txn}, opts), callback);\n      });\n    }\n\n    function finish(err) {\n      callback(err, {doc: doc, metadata: metadata, ctx: tx});\n    }\n\n    var sql;\n    var sqlArgs;\n\n    if(!opts.rev) {\n      sql = select(\n        SELECT_DOCS,\n        [DOC_STORE$1, BY_SEQ_STORE$1],\n        DOC_STORE_AND_BY_SEQ_JOINER,\n        DOC_STORE$1 + '.id=?');\n      sqlArgs = [id];\n    } else if (opts.latest) {\n      latest$$1(tx, id, opts.rev, function (latestRev) {\n        opts.latest = false;\n        opts.rev = latestRev;\n        api._get(id, opts, callback);\n      }, finish);\n      return;\n    } else {\n      sql = select(\n        SELECT_DOCS,\n        [DOC_STORE$1, BY_SEQ_STORE$1],\n        DOC_STORE$1 + '.id=' + BY_SEQ_STORE$1 + '.doc_id',\n        [BY_SEQ_STORE$1 + '.doc_id=?', BY_SEQ_STORE$1 + '.rev=?']);\n      sqlArgs = [id, opts.rev];\n    }\n\n    tx.executeSql(sql, sqlArgs, function (a, results) {\n      if (!results.rows.length) {\n        var missingErr = createError(MISSING_DOC, 'missing');\n        return finish(missingErr);\n      }\n      var item = results.rows.item(0);\n      metadata = safeJsonParse(item.metadata);\n      if (item.deleted && !opts.rev) {\n        var deletedErr = createError(MISSING_DOC, 'deleted');\n        return finish(deletedErr);\n      }\n      doc = unstringifyDoc(item.data, metadata.id, item.rev);\n      finish();\n    });\n  };\n\n  api._allDocs = function (opts, callback) {\n    var results = [];\n    var totalRows;\n\n    var start = 'startkey' in opts ? opts.startkey : false;\n    var end = 'endkey' in opts ? opts.endkey : false;\n    var key = 'key' in opts ? opts.key : false;\n    var descending = 'descending' in opts ? opts.descending : false;\n    var limit = 'limit' in opts ? opts.limit : -1;\n    var offset = 'skip' in opts ? opts.skip : 0;\n    var inclusiveEnd = opts.inclusive_end !== false;\n\n    var sqlArgs = [];\n    var criteria = [];\n\n    if (key !== false) {\n      criteria.push(DOC_STORE$1 + '.id = ?');\n      sqlArgs.push(key);\n    } else if (start !== false || end !== false) {\n      if (start !== false) {\n        criteria.push(DOC_STORE$1 + '.id ' + (descending ? '<=' : '>=') + ' ?');\n        sqlArgs.push(start);\n      }\n      if (end !== false) {\n        var comparator = descending ? '>' : '<';\n        if (inclusiveEnd) {\n          comparator += '=';\n        }\n        criteria.push(DOC_STORE$1 + '.id ' + comparator + ' ?');\n        sqlArgs.push(end);\n      }\n      if (key !== false) {\n        criteria.push(DOC_STORE$1 + '.id = ?');\n        sqlArgs.push(key);\n      }\n    }\n\n    if (opts.deleted !== 'ok') {\n      // report deleted if keys are specified\n      criteria.push(BY_SEQ_STORE$1 + '.deleted = 0');\n    }\n\n    db.readTransaction(function (tx) {\n      // count the docs in parallel to other operations\n      countDocs(tx, function (docCount) {\n        totalRows = docCount;\n      });\n\n      if (limit === 0) {\n        return;\n      }\n\n      // do a single query to fetch the documents\n      var sql = select(\n        SELECT_DOCS,\n        [DOC_STORE$1, BY_SEQ_STORE$1],\n        DOC_STORE_AND_BY_SEQ_JOINER,\n        criteria,\n        DOC_STORE$1 + '.id ' + (descending ? 'DESC' : 'ASC')\n        );\n      sql += ' LIMIT ' + limit + ' OFFSET ' + offset;\n\n      tx.executeSql(sql, sqlArgs, function (tx, result) {\n        for (var i = 0, l = result.rows.length; i < l; i++) {\n          var item = result.rows.item(i);\n          var metadata = safeJsonParse(item.metadata);\n          var id = metadata.id;\n          var data = unstringifyDoc(item.data, id, item.rev);\n          var winningRev$$1 = data._rev;\n          var doc = {\n            id: id,\n            key: id,\n            value: {rev: winningRev$$1}\n          };\n          if (opts.include_docs) {\n            doc.doc = data;\n            doc.doc._rev = winningRev$$1;\n            if (opts.conflicts) {\n              var conflicts = collectConflicts(metadata);\n              if (conflicts.length) {\n                doc.doc._conflicts = conflicts;\n              }\n            }\n            fetchAttachmentsIfNecessary$1(doc.doc, opts, api, tx);\n          }\n          if (item.deleted) {\n            if (opts.deleted === 'ok') {\n              doc.value.deleted = true;\n              doc.doc = null;\n            } else {\n              continue;\n            }\n          }\n          results.push(doc);\n        }\n      });\n    }, websqlError(callback), function () {\n      callback(null, {\n        total_rows: totalRows,\n        offset: opts.skip,\n        rows: results\n      });\n    });\n  };\n\n  api._changes = function (opts) {\n    opts = clone(opts);\n\n    if (opts.continuous) {\n      var id = api._name + ':' + uuid();\n      websqlChanges.addListener(api._name, id, api, opts);\n      websqlChanges.notify(api._name);\n      return {\n        cancel: function () {\n          websqlChanges.removeListener(api._name, id);\n        }\n      };\n    }\n\n    var descending = opts.descending;\n\n    // Ignore the `since` parameter when `descending` is true\n    opts.since = opts.since && !descending ? opts.since : 0;\n\n    var limit = 'limit' in opts ? opts.limit : -1;\n    if (limit === 0) {\n      limit = 1; // per CouchDB _changes spec\n    }\n\n    var returnDocs;\n    if ('return_docs' in opts) {\n      returnDocs = opts.return_docs;\n    } else if ('returnDocs' in opts) {\n      // TODO: Remove 'returnDocs' in favor of 'return_docs' in a future release\n      returnDocs = opts.returnDocs;\n    } else {\n      returnDocs = true;\n    }\n    var results = [];\n    var numResults = 0;\n\n    function fetchChanges() {\n\n      var selectStmt =\n        DOC_STORE$1 + '.json AS metadata, ' +\n        DOC_STORE$1 + '.max_seq AS maxSeq, ' +\n        BY_SEQ_STORE$1 + '.json AS winningDoc, ' +\n        BY_SEQ_STORE$1 + '.rev AS winningRev ';\n\n      var from = DOC_STORE$1 + ' JOIN ' + BY_SEQ_STORE$1;\n\n      var joiner = DOC_STORE$1 + '.id=' + BY_SEQ_STORE$1 + '.doc_id' +\n        ' AND ' + DOC_STORE$1 + '.winningseq=' + BY_SEQ_STORE$1 + '.seq';\n\n      var criteria = ['maxSeq > ?'];\n      var sqlArgs = [opts.since];\n\n      if (opts.doc_ids) {\n        criteria.push(DOC_STORE$1 + '.id IN ' + qMarks(opts.doc_ids.length));\n        sqlArgs = sqlArgs.concat(opts.doc_ids);\n      }\n\n      var orderBy = 'maxSeq ' + (descending ? 'DESC' : 'ASC');\n\n      var sql = select(selectStmt, from, joiner, criteria, orderBy);\n\n      var filter = filterChange(opts);\n      if (!opts.view && !opts.filter) {\n        // we can just limit in the query\n        sql += ' LIMIT ' + limit;\n      }\n\n      var lastSeq = opts.since || 0;\n      db.readTransaction(function (tx) {\n        tx.executeSql(sql, sqlArgs, function (tx, result) {\n          function reportChange(change) {\n            return function () {\n              opts.onChange(change);\n            };\n          }\n          for (var i = 0, l = result.rows.length; i < l; i++) {\n            var item = result.rows.item(i);\n            var metadata = safeJsonParse(item.metadata);\n            lastSeq = item.maxSeq;\n\n            var doc = unstringifyDoc(item.winningDoc, metadata.id,\n              item.winningRev);\n            var change = opts.processChange(doc, metadata, opts);\n            change.seq = item.maxSeq;\n\n            var filtered = filter(change);\n            if (typeof filtered === 'object') {\n              return opts.complete(filtered);\n            }\n\n            if (filtered) {\n              numResults++;\n              if (returnDocs) {\n                results.push(change);\n              }\n              // process the attachment immediately\n              // for the benefit of live listeners\n              if (opts.attachments && opts.include_docs) {\n                fetchAttachmentsIfNecessary$1(doc, opts, api, tx,\n                  reportChange(change));\n              } else {\n                reportChange(change)();\n              }\n            }\n            if (numResults === limit) {\n              break;\n            }\n          }\n        });\n      }, websqlError(opts.complete), function () {\n        if (!opts.continuous) {\n          opts.complete(null, {\n            results: results,\n            last_seq: lastSeq\n          });\n        }\n      });\n    }\n\n    fetchChanges();\n  };\n\n  api._close = function (callback) {\n    //WebSQL databases do not need to be closed\n    callback();\n  };\n\n  api._getAttachment = function (docId, attachId, attachment, opts, callback) {\n    var res;\n    var tx = opts.ctx;\n    var digest = attachment.digest;\n    var type = attachment.content_type;\n    var sql = 'SELECT escaped, ' +\n      'CASE WHEN escaped = 1 THEN body ELSE HEX(body) END AS body FROM ' +\n      ATTACH_STORE$1 + ' WHERE digest=?';\n    tx.executeSql(sql, [digest], function (tx, result) {\n      // websql has a bug where \\u0000 causes early truncation in strings\n      // and blobs. to work around this, we used to use the hex() function,\n      // but that's not performant. after migration 6, we remove \\u0000\n      // and add it back in afterwards\n      var item = result.rows.item(0);\n      var data = item.escaped ? unescapeBlob(item.body) :\n        parseHexString(item.body, encoding);\n      if (opts.binary) {\n        res = binStringToBluffer(data, type);\n      } else {\n        res = thisBtoa(data);\n      }\n      callback(null, res);\n    });\n  };\n\n  api._getRevisionTree = function (docId, callback) {\n    db.readTransaction(function (tx) {\n      var sql = 'SELECT json AS metadata FROM ' + DOC_STORE$1 + ' WHERE id = ?';\n      tx.executeSql(sql, [docId], function (tx, result) {\n        if (!result.rows.length) {\n          callback(createError(MISSING_DOC));\n        } else {\n          var data = safeJsonParse(result.rows.item(0).metadata);\n          callback(null, data.rev_tree);\n        }\n      });\n    });\n  };\n\n  api._doCompaction = function (docId, revs, callback) {\n    if (!revs.length) {\n      return callback();\n    }\n    db.transaction(function (tx) {\n\n      // update doc store\n      var sql = 'SELECT json AS metadata FROM ' + DOC_STORE$1 + ' WHERE id = ?';\n      tx.executeSql(sql, [docId], function (tx, result) {\n        var metadata = safeJsonParse(result.rows.item(0).metadata);\n        traverseRevTree(metadata.rev_tree, function (isLeaf, pos,\n                                                           revHash, ctx, opts) {\n          var rev = pos + '-' + revHash;\n          if (revs.indexOf(rev) !== -1) {\n            opts.status = 'missing';\n          }\n        });\n\n        var sql = 'UPDATE ' + DOC_STORE$1 + ' SET json = ? WHERE id = ?';\n        tx.executeSql(sql, [safeJsonStringify(metadata), docId]);\n      });\n\n      compactRevs$1(revs, docId, tx);\n    }, websqlError(callback), function () {\n      callback();\n    });\n  };\n\n  api._getLocal = function (id, callback) {\n    db.readTransaction(function (tx) {\n      var sql = 'SELECT json, rev FROM ' + LOCAL_STORE$1 + ' WHERE id=?';\n      tx.executeSql(sql, [id], function (tx, res) {\n        if (res.rows.length) {\n          var item = res.rows.item(0);\n          var doc = unstringifyDoc(item.json, id, item.rev);\n          callback(null, doc);\n        } else {\n          callback(createError(MISSING_DOC));\n        }\n      });\n    });\n  };\n\n  api._putLocal = function (doc, opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    delete doc._revisions; // ignore this, trust the rev\n    var oldRev = doc._rev;\n    var id = doc._id;\n    var newRev;\n    if (!oldRev) {\n      newRev = doc._rev = '0-1';\n    } else {\n      newRev = doc._rev = '0-' + (parseInt(oldRev.split('-')[1], 10) + 1);\n    }\n    var json = stringifyDoc(doc);\n\n    var ret;\n    function putLocal(tx) {\n      var sql;\n      var values;\n      if (oldRev) {\n        sql = 'UPDATE ' + LOCAL_STORE$1 + ' SET rev=?, json=? ' +\n          'WHERE id=? AND rev=?';\n        values = [newRev, json, id, oldRev];\n      } else {\n        sql = 'INSERT INTO ' + LOCAL_STORE$1 + ' (id, rev, json) VALUES (?,?,?)';\n        values = [id, newRev, json];\n      }\n      tx.executeSql(sql, values, function (tx, res) {\n        if (res.rowsAffected) {\n          ret = {ok: true, id: id, rev: newRev};\n          if (opts.ctx) { // return immediately\n            callback(null, ret);\n          }\n        } else {\n          callback(createError(REV_CONFLICT));\n        }\n      }, function () {\n        callback(createError(REV_CONFLICT));\n        return false; // ack that we handled the error\n      });\n    }\n\n    if (opts.ctx) {\n      putLocal(opts.ctx);\n    } else {\n      db.transaction(putLocal, websqlError(callback), function () {\n        if (ret) {\n          callback(null, ret);\n        }\n      });\n    }\n  };\n\n  api._removeLocal = function (doc, opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    var ret;\n\n    function removeLocal(tx) {\n      var sql = 'DELETE FROM ' + LOCAL_STORE$1 + ' WHERE id=? AND rev=?';\n      var params = [doc._id, doc._rev];\n      tx.executeSql(sql, params, function (tx, res) {\n        if (!res.rowsAffected) {\n          return callback(createError(MISSING_DOC));\n        }\n        ret = {ok: true, id: doc._id, rev: '0-0'};\n        if (opts.ctx) { // return immediately\n          callback(null, ret);\n        }\n      });\n    }\n\n    if (opts.ctx) {\n      removeLocal(opts.ctx);\n    } else {\n      db.transaction(removeLocal, websqlError(callback), function () {\n        if (ret) {\n          callback(null, ret);\n        }\n      });\n    }\n  };\n\n  api._destroy = function (opts, callback) {\n    websqlChanges.removeAllListeners(api._name);\n    db.transaction(function (tx) {\n      var stores = [DOC_STORE$1, BY_SEQ_STORE$1, ATTACH_STORE$1, META_STORE$1,\n        LOCAL_STORE$1, ATTACH_AND_SEQ_STORE$1];\n      stores.forEach(function (store) {\n        tx.executeSql('DROP TABLE IF EXISTS ' + store, []);\n      });\n    }, websqlError(callback), function () {\n      if (hasLocalStorage()) {\n        delete window.localStorage['_pouch__websqldb_' + api._name];\n        delete window.localStorage[api._name];\n      }\n      callback(null, {'ok': true});\n    });\n  };\n}\n\nfunction canOpenTestDB() {\n  try {\n    openDatabase('_pouch_validate_websql', 1, '', 1);\n    return true;\n  } catch (err) {\n    return false;\n  }\n}\n\n// WKWebView had a bug where WebSQL would throw a DOM Exception 18\n// (see https://bugs.webkit.org/show_bug.cgi?id=137760 and\n// https://github.com/pouchdb/pouchdb/issues/5079)\n// This has been fixed in latest WebKit, so we try to detect it here.\nfunction isValidWebSQL() {\n  // WKWebView UA:\n  //   Mozilla/5.0 (iPhone; CPU iPhone OS 9_2 like Mac OS X)\n  //   AppleWebKit/601.1.46 (KHTML, like Gecko) Mobile/13C75\n  // Chrome for iOS UA:\n  //   Mozilla/5.0 (iPhone; U; CPU iPhone OS 5_1_1 like Mac OS X; en)\n  //   AppleWebKit/534.46.0 (KHTML, like Gecko) CriOS/19.0.1084.60\n  //   Mobile/9B206 Safari/7534.48.3\n  // Firefox for iOS UA:\n  //   Mozilla/5.0 (iPhone; CPU iPhone OS 8_3 like Mac OS X) AppleWebKit/600.1.4\n  //   (KHTML, like Gecko) FxiOS/1.0 Mobile/12F69 Safari/600.1.4\n\n  // indexedDB is null on some UIWebViews and undefined in others\n  // see: https://bugs.webkit.org/show_bug.cgi?id=137034\n  if (typeof indexedDB === 'undefined' || indexedDB === null ||\n      !/iP(hone|od|ad)/.test(navigator.userAgent)) {\n    // definitely not WKWebView, avoid creating an unnecessary database\n    return true;\n  }\n  // Cache the result in LocalStorage. Reason we do this is because if we\n  // call openDatabase() too many times, Safari craps out in SauceLabs and\n  // starts throwing DOM Exception 14s.\n  var hasLS = hasLocalStorage();\n  // Include user agent in the hash, so that if Safari is upgraded, we don't\n  // continually think it's broken.\n  var localStorageKey = '_pouch__websqldb_valid_' + navigator.userAgent;\n  if (hasLS && localStorage[localStorageKey]) {\n    return localStorage[localStorageKey] === '1';\n  }\n  var openedTestDB = canOpenTestDB();\n  if (hasLS) {\n    localStorage[localStorageKey] = openedTestDB ? '1' : '0';\n  }\n  return openedTestDB;\n}\n\nfunction valid() {\n  if (typeof openDatabase !== 'function') {\n    return false;\n  }\n  return isValidWebSQL();\n}\n\nfunction openDB(name, version, description, size) {\n  // Traditional WebSQL API\n  return openDatabase(name, version, description, size);\n}\n\nfunction WebSQLPouch(opts, callback) {\n  var _opts = assign$1({\n    websql: openDB\n  }, opts);\n\n  WebSqlPouch$1.call(this, _opts, callback);\n}\n\nWebSQLPouch.valid = valid;\n\nWebSQLPouch.use_prefix = true;\n\nvar WebSqlPouch = function (PouchDB) {\n  PouchDB.adapter('websql', WebSQLPouch, true);\n};\n\n/* global fetch */\n/* global Headers */\nfunction wrappedFetch() {\n  var wrappedPromise = {};\n\n  var promise = new PouchPromise$1(function (resolve, reject) {\n    wrappedPromise.resolve = resolve;\n    wrappedPromise.reject = reject;\n  });\n\n  var args = new Array(arguments.length);\n\n  for (var i = 0; i < args.length; i++) {\n    args[i] = arguments[i];\n  }\n\n  wrappedPromise.promise = promise;\n\n  PouchPromise$1.resolve().then(function () {\n    return fetch.apply(null, args);\n  }).then(function (response) {\n    wrappedPromise.resolve(response);\n  }).catch(function (error) {\n    wrappedPromise.reject(error);\n  });\n\n  return wrappedPromise;\n}\n\nfunction fetchRequest(options, callback) {\n  var wrappedPromise, timer, response;\n\n  var headers = new Headers();\n\n  var fetchOptions = {\n    method: options.method,\n    credentials: 'include',\n    headers: headers\n  };\n\n  if (options.json) {\n    headers.set('Accept', 'application/json');\n    headers.set('Content-Type', options.headers['Content-Type'] ||\n      'application/json');\n  }\n\n  if (options.body &&\n      options.processData &&\n      typeof options.body !== 'string') {\n    fetchOptions.body = JSON.stringify(options.body);\n  } else if ('body' in options) {\n    fetchOptions.body = options.body;\n  } else {\n    fetchOptions.body = null;\n  }\n\n  Object.keys(options.headers).forEach(function (key) {\n    if (options.headers.hasOwnProperty(key)) {\n      headers.set(key, options.headers[key]);\n    }\n  });\n\n  wrappedPromise = wrappedFetch(options.url, fetchOptions);\n\n  if (options.timeout > 0) {\n    timer = setTimeout(function () {\n      wrappedPromise.reject(new Error('Load timeout for resource: ' +\n        options.url));\n    }, options.timeout);\n  }\n\n  wrappedPromise.promise.then(function (fetchResponse) {\n    response = {\n      statusCode: fetchResponse.status\n    };\n\n    if (options.timeout > 0) {\n      clearTimeout(timer);\n    }\n\n    if (response.statusCode >= 200 && response.statusCode < 300) {\n      return options.binary ? fetchResponse.blob() : fetchResponse.text();\n    }\n\n    return fetchResponse.json();\n  }).then(function (result) {\n    if (response.statusCode >= 200 && response.statusCode < 300) {\n      callback(null, response, result);\n    } else {\n      result.status = response.statusCode;\n      callback(result);\n    }\n  }).catch(function (error) {\n    if (!error) {\n      // this happens when the listener is canceled\n      error = new Error('canceled');\n    }\n    callback(error);\n  });\n\n  return {abort: wrappedPromise.reject};\n}\n\nfunction xhRequest(options, callback) {\n\n  var xhr, timer;\n  var timedout = false;\n\n  var abortReq = function () {\n    xhr.abort();\n    cleanUp();\n  };\n\n  var timeoutReq = function () {\n    timedout = true;\n    xhr.abort();\n    cleanUp();\n  };\n\n  var ret = {abort: abortReq};\n\n  var cleanUp = function () {\n    clearTimeout(timer);\n    ret.abort = function () {};\n    if (xhr) {\n      xhr.onprogress = undefined;\n      if (xhr.upload) {\n        xhr.upload.onprogress = undefined;\n      }\n      xhr.onreadystatechange = undefined;\n      xhr = undefined;\n    }\n  };\n\n  if (options.xhr) {\n    xhr = new options.xhr();\n  } else {\n    xhr = new XMLHttpRequest();\n  }\n\n  try {\n    xhr.open(options.method, options.url);\n  } catch (exception) {\n    return callback(new Error(exception.name || 'Url is invalid'));\n  }\n\n  xhr.withCredentials = ('withCredentials' in options) ?\n    options.withCredentials : true;\n\n  if (options.method === 'GET') {\n    delete options.headers['Content-Type'];\n  } else if (options.json) {\n    options.headers.Accept = 'application/json';\n    options.headers['Content-Type'] = options.headers['Content-Type'] ||\n      'application/json';\n    if (options.body &&\n        options.processData &&\n        typeof options.body !== \"string\") {\n      options.body = JSON.stringify(options.body);\n    }\n  }\n\n  if (options.binary) {\n    xhr.responseType = 'arraybuffer';\n  }\n\n  if (!('body' in options)) {\n    options.body = null;\n  }\n\n  for (var key in options.headers) {\n    if (options.headers.hasOwnProperty(key)) {\n      xhr.setRequestHeader(key, options.headers[key]);\n    }\n  }\n\n  if (options.timeout > 0) {\n    timer = setTimeout(timeoutReq, options.timeout);\n    xhr.onprogress = function () {\n      clearTimeout(timer);\n      if(xhr.readyState !== 4) {\n        timer = setTimeout(timeoutReq, options.timeout);\n      }\n    };\n    if (typeof xhr.upload !== 'undefined') { // does not exist in ie9\n      xhr.upload.onprogress = xhr.onprogress;\n    }\n  }\n\n  xhr.onreadystatechange = function () {\n    if (xhr.readyState !== 4) {\n      return;\n    }\n\n    var response = {\n      statusCode: xhr.status\n    };\n\n    if (xhr.status >= 200 && xhr.status < 300) {\n      var data;\n      if (options.binary) {\n        data = createBlob([xhr.response || ''], {\n          type: xhr.getResponseHeader('Content-Type')\n        });\n      } else {\n        data = xhr.responseText;\n      }\n      callback(null, response, data);\n    } else {\n      var err = {};\n      if (timedout) {\n        err = new Error('ETIMEDOUT');\n        err.code = 'ETIMEDOUT';\n      } else if (typeof xhr.response === 'string') {\n        try {\n          err = JSON.parse(xhr.response);\n        } catch(e) {}\n      }\n      err.status = xhr.status;\n      callback(err);\n    }\n    cleanUp();\n  };\n\n  if (options.body && (options.body instanceof Blob)) {\n    readAsArrayBuffer(options.body, function (arrayBuffer) {\n      xhr.send(arrayBuffer);\n    });\n  } else {\n    xhr.send(options.body);\n  }\n\n  return ret;\n}\n\nfunction testXhr() {\n  try {\n    new XMLHttpRequest();\n    return true;\n  } catch (err) {\n    return false;\n  }\n}\n\nvar hasXhr = testXhr();\n\nfunction ajax$1(options, callback) {\n  if (!false && (hasXhr || options.xhr)) {\n    return xhRequest(options, callback);\n  } else {\n    return fetchRequest(options, callback);\n  }\n}\n\n// the blob already has a type; do nothing\nvar res$2 = function () {};\n\nfunction defaultBody() {\n  return '';\n}\n\nfunction ajaxCore$1(options, callback) {\n\n  options = clone(options);\n\n  var defaultOptions = {\n    method : \"GET\",\n    headers: {},\n    json: true,\n    processData: true,\n    timeout: 10000,\n    cache: false\n  };\n\n  options = assign$1(defaultOptions, options);\n\n  function onSuccess(obj, resp, cb) {\n    if (!options.binary && options.json && typeof obj === 'string') {\n      /* istanbul ignore next */\n      try {\n        obj = JSON.parse(obj);\n      } catch (e) {\n        // Probably a malformed JSON from server\n        return cb(e);\n      }\n    }\n    if (Array.isArray(obj)) {\n      obj = obj.map(function (v) {\n        if (v.error || v.missing) {\n          return generateErrorFromResponse(v);\n        } else {\n          return v;\n        }\n      });\n    }\n    if (options.binary) {\n      res$2(obj, resp);\n    }\n    cb(null, obj, resp);\n  }\n\n  if (options.json) {\n    if (!options.binary) {\n      options.headers.Accept = 'application/json';\n    }\n    options.headers['Content-Type'] = options.headers['Content-Type'] ||\n      'application/json';\n  }\n\n  if (options.binary) {\n    options.encoding = null;\n    options.json = false;\n  }\n\n  if (!options.processData) {\n    options.json = false;\n  }\n\n  return ajax$1(options, function (err, response, body) {\n\n    if (err) {\n      return callback(generateErrorFromResponse(err));\n    }\n\n    var error;\n    var content_type = response.headers && response.headers['content-type'];\n    var data = body || defaultBody();\n\n    // CouchDB doesn't always return the right content-type for JSON data, so\n    // we check for ^{ and }$ (ignoring leading/trailing whitespace)\n    if (!options.binary && (options.json || !options.processData) &&\n        typeof data !== 'object' &&\n        (/json/.test(content_type) ||\n         (/^[\\s]*\\{/.test(data) && /\\}[\\s]*$/.test(data)))) {\n      try {\n        data = JSON.parse(data.toString());\n      } catch (e) {}\n    }\n\n    if (response.statusCode >= 200 && response.statusCode < 300) {\n      onSuccess(data, response, callback);\n    } else {\n      error = generateErrorFromResponse(data);\n      error.status = response.statusCode;\n      callback(error);\n    }\n  });\n}\n\nfunction ajax(opts, callback) {\n\n  // cache-buster, specifically designed to work around IE's aggressive caching\n  // see http://www.dashbay.com/2011/05/internet-explorer-caches-ajax/\n  // Also Safari caches POSTs, so we need to cache-bust those too.\n  var ua = (navigator && navigator.userAgent) ?\n    navigator.userAgent.toLowerCase() : '';\n\n  var isSafari = ua.indexOf('safari') !== -1 && ua.indexOf('chrome') === -1;\n  var isIE = ua.indexOf('msie') !== -1;\n  var isEdge = ua.indexOf('edge') !== -1;\n\n  // it appears the new version of safari also caches GETs,\n  // see https://github.com/pouchdb/pouchdb/issues/5010\n  var shouldCacheBust = (isSafari ||\n    ((isIE || isEdge) && opts.method === 'GET'));\n\n  var cache = 'cache' in opts ? opts.cache : true;\n\n  var isBlobUrl = /^blob:/.test(opts.url); // don't append nonces for blob URLs\n\n  if (!isBlobUrl && (shouldCacheBust || !cache)) {\n    var hasArgs = opts.url.indexOf('?') !== -1;\n    opts.url += (hasArgs ? '&' : '?') + '_nonce=' + Date.now();\n  }\n\n  return ajaxCore$1(opts, callback);\n}\n\n// dead simple promise pool, inspired by https://github.com/timdp/es6-promise-pool\n// but much smaller in code size. limits the number of concurrent promises that are executed\n\nfunction pool(promiseFactories, limit) {\n  return new PouchPromise$1(function (resolve, reject) {\n    var running = 0;\n    var current = 0;\n    var done = 0;\n    var len = promiseFactories.length;\n    var err;\n\n    function runNext() {\n      running++;\n      promiseFactories[current++]().then(onSuccess, onError);\n    }\n\n    function doNext() {\n      if (++done === len) {\n        /* istanbul ignore if */\n        if (err) {\n          reject(err);\n        } else {\n          resolve();\n        }\n      } else {\n        runNextBatch();\n      }\n    }\n\n    function onSuccess() {\n      running--;\n      doNext();\n    }\n\n    /* istanbul ignore next */\n    function onError(thisErr) {\n      running--;\n      err = err || thisErr;\n      doNext();\n    }\n\n    function runNextBatch() {\n      while (running < limit && current < len) {\n        runNext();\n      }\n    }\n\n    runNextBatch();\n  });\n}\n\nvar CHANGES_BATCH_SIZE = 25;\nvar MAX_SIMULTANEOUS_REVS = 50;\n\nvar supportsBulkGetMap = {};\n\nvar log$1 = debug('pouchdb:http');\n\nfunction readAttachmentsAsBlobOrBuffer(row) {\n  var atts = row.doc && row.doc._attachments;\n  if (!atts) {\n    return;\n  }\n  Object.keys(atts).forEach(function (filename) {\n    var att = atts[filename];\n    att.data = b64ToBluffer(att.data, att.content_type);\n  });\n}\n\nfunction encodeDocId(id) {\n  if (/^_design/.test(id)) {\n    return '_design/' + encodeURIComponent(id.slice(8));\n  }\n  if (/^_local/.test(id)) {\n    return '_local/' + encodeURIComponent(id.slice(7));\n  }\n  return encodeURIComponent(id);\n}\n\nfunction preprocessAttachments$2(doc) {\n  if (!doc._attachments || !Object.keys(doc._attachments)) {\n    return PouchPromise$1.resolve();\n  }\n\n  return PouchPromise$1.all(Object.keys(doc._attachments).map(function (key) {\n    var attachment = doc._attachments[key];\n    if (attachment.data && typeof attachment.data !== 'string') {\n      return new PouchPromise$1(function (resolve) {\n        blobToBase64(attachment.data, resolve);\n      }).then(function (b64) {\n        attachment.data = b64;\n      });\n    }\n  }));\n}\n\nfunction hasUrlPrefix(opts) {\n  if (!opts.prefix) {\n    return false;\n  }\n\n  var protocol = parseUri(opts.prefix).protocol;\n\n  return protocol === 'http' || protocol === 'https';\n}\n\n// Get all the information you possibly can about the URI given by name and\n// return it as a suitable object.\nfunction getHost(name, opts) {\n\n  // encode db name if opts.prefix is a url (#5574)\n  if (hasUrlPrefix(opts)) {\n    var dbName = opts.name.substr(opts.prefix.length);\n    name = opts.prefix + encodeURIComponent(dbName);\n  }\n\n  // Prase the URI into all its little bits\n  var uri = parseUri(name);\n\n  // Store the user and password as a separate auth object\n  if (uri.user || uri.password) {\n    uri.auth = {username: uri.user, password: uri.password};\n  }\n\n  // Split the path part of the URI into parts using '/' as the delimiter\n  // after removing any leading '/' and any trailing '/'\n  var parts = uri.path.replace(/(^\\/|\\/$)/g, '').split('/');\n\n  // Store the first part as the database name and remove it from the parts\n  // array\n  uri.db = parts.pop();\n  // Prevent double encoding of URI component\n  if (uri.db.indexOf('%') === -1) {\n    uri.db = encodeURIComponent(uri.db);\n  }\n\n  // Restore the path by joining all the remaining parts (all the parts\n  // except for the database name) with '/'s\n  uri.path = parts.join('/');\n\n  return uri;\n}\n\n// Generate a URL with the host data given by opts and the given path\nfunction genDBUrl(opts, path) {\n  return genUrl(opts, opts.db + '/' + path);\n}\n\n// Generate a URL with the host data given by opts and the given path\nfunction genUrl(opts, path) {\n  // If the host already has a path, then we need to have a path delimiter\n  // Otherwise, the path delimiter is the empty string\n  var pathDel = !opts.path ? '' : '/';\n\n  // If the host already has a path, then we need to have a path delimiter\n  // Otherwise, the path delimiter is the empty string\n  return opts.protocol + '://' + opts.host +\n         (opts.port ? (':' + opts.port) : '') +\n         '/' + opts.path + pathDel + path;\n}\n\nfunction paramsToStr(params) {\n  return '?' + Object.keys(params).map(function (k) {\n    return k + '=' + encodeURIComponent(params[k]);\n  }).join('&');\n}\n\n// Implements the PouchDB API for dealing with CouchDB instances over HTTP\nfunction HttpPouch(opts, callback) {\n\n  // The functions that will be publicly available for HttpPouch\n  var api = this;\n\n  var host = getHost(opts.name, opts);\n  var dbUrl = genDBUrl(host, '');\n\n  opts = clone(opts);\n  var ajaxOpts = opts.ajax || {};\n\n  if (opts.auth || host.auth) {\n    var nAuth = opts.auth || host.auth;\n    var str = nAuth.username + ':' + nAuth.password;\n    var token = thisBtoa(unescape(encodeURIComponent(str)));\n    ajaxOpts.headers = ajaxOpts.headers || {};\n    ajaxOpts.headers.Authorization = 'Basic ' + token;\n  }\n\n  // Not strictly necessary, but we do this because numerous tests\n  // rely on swapping ajax in and out.\n  api._ajax = ajax;\n\n  function ajax$$1(userOpts, options, callback) {\n    var reqAjax = userOpts.ajax || {};\n    var reqOpts = assign$1(clone(ajaxOpts), reqAjax, options);\n    log$1(reqOpts.method + ' ' + reqOpts.url);\n    return api._ajax(reqOpts, callback);\n  }\n\n  function ajaxPromise(userOpts, opts) {\n    return new PouchPromise$1(function (resolve, reject) {\n      ajax$$1(userOpts, opts, function (err, res) {\n        /* istanbul ignore if */\n        if (err) {\n          return reject(err);\n        }\n        resolve(res);\n      });\n    });\n  }\n\n  function adapterFun$$1(name, fun) {\n    return adapterFun(name, getArguments(function (args) {\n      setup().then(function () {\n        return fun.apply(this, args);\n      }).catch(function (e) {\n        var callback = args.pop();\n        callback(e);\n      });\n    }));\n  }\n\n  var setupPromise;\n\n  function setup() {\n    // TODO: Remove `skipSetup` in favor of `skip_setup` in a future release\n    if (opts.skipSetup || opts.skip_setup) {\n      return PouchPromise$1.resolve();\n    }\n\n    // If there is a setup in process or previous successful setup\n    // done then we will use that\n    // If previous setups have been rejected we will try again\n    if (setupPromise) {\n      return setupPromise;\n    }\n\n    var checkExists = {method: 'GET', url: dbUrl};\n    setupPromise = ajaxPromise({}, checkExists).catch(function (err) {\n      if (err && err.status && err.status === 404) {\n        // Doesnt exist, create it\n        explainError(404, 'PouchDB is just detecting if the remote exists.');\n        return ajaxPromise({}, {method: 'PUT', url: dbUrl});\n      } else {\n        return PouchPromise$1.reject(err);\n      }\n    }).catch(function (err) {\n      // If we try to create a database that already exists, skipped in\n      // istanbul since its catching a race condition.\n      /* istanbul ignore if */\n      if (err && err.status && err.status === 412) {\n        return true;\n      }\n      return PouchPromise$1.reject(err);\n    });\n\n    setupPromise.catch(function () {\n      setupPromise = null;\n    });\n\n    return setupPromise;\n  }\n\n  nextTick(function () {\n    callback(null, api);\n  });\n\n  api.type = function () {\n    return 'http';\n  };\n\n  api.id = adapterFun$$1('id', function (callback) {\n    ajax$$1({}, {method: 'GET', url: genUrl(host, '')}, function (err, result) {\n      var uuid$$1 = (result && result.uuid) ?\n        (result.uuid + host.db) : genDBUrl(host, '');\n      callback(null, uuid$$1);\n    });\n  });\n\n  api.request = adapterFun$$1('request', function (options, callback) {\n    options.url = genDBUrl(host, options.url);\n    ajax$$1({}, options, callback);\n  });\n\n  // Sends a POST request to the host calling the couchdb _compact function\n  //    version: The version of CouchDB it is running\n  api.compact = adapterFun$$1('compact', function (opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    opts = clone(opts);\n    ajax$$1(opts, {\n      url: genDBUrl(host, '_compact'),\n      method: 'POST'\n    }, function () {\n      function ping() {\n        api.info(function (err, res) {\n          if (res && !res.compact_running) {\n            callback(null, {ok: true});\n          } else {\n            setTimeout(ping, opts.interval || 200);\n          }\n        });\n      }\n      // Ping the http if it's finished compaction\n      ping();\n    });\n  });\n\n  api.bulkGet = adapterFun('bulkGet', function (opts, callback) {\n    var self = this;\n\n    function doBulkGet(cb) {\n      var params = {};\n      if (opts.revs) {\n        params.revs = true;\n      }\n      if (opts.attachments) {\n        /* istanbul ignore next */\n        params.attachments = true;\n      }\n      if (opts.latest) {\n        params.latest = true;\n      }\n      ajax$$1(opts, {\n        url: genDBUrl(host, '_bulk_get' + paramsToStr(params)),\n        method: 'POST',\n        body: { docs: opts.docs}\n      }, cb);\n    }\n\n    function doBulkGetShim() {\n      // avoid \"url too long error\" by splitting up into multiple requests\n      var batchSize = MAX_SIMULTANEOUS_REVS;\n      var numBatches = Math.ceil(opts.docs.length / batchSize);\n      var numDone = 0;\n      var results = new Array(numBatches);\n\n      function onResult(batchNum) {\n        return function (err, res) {\n          // err is impossible because shim returns a list of errs in that case\n          results[batchNum] = res.results;\n          if (++numDone === numBatches) {\n            callback(null, {results: flatten(results)});\n          }\n        };\n      }\n\n      for (var i = 0; i < numBatches; i++) {\n        var subOpts = pick(opts, ['revs', 'attachments', 'latest']);\n        subOpts.ajax = ajaxOpts;\n        subOpts.docs = opts.docs.slice(i * batchSize,\n          Math.min(opts.docs.length, (i + 1) * batchSize));\n        bulkGet(self, subOpts, onResult(i));\n      }\n    }\n\n    // mark the whole database as either supporting or not supporting _bulk_get\n    var dbUrl = genUrl(host, '');\n    var supportsBulkGet = supportsBulkGetMap[dbUrl];\n\n    if (typeof supportsBulkGet !== 'boolean') {\n      // check if this database supports _bulk_get\n      doBulkGet(function (err, res) {\n        /* istanbul ignore else */\n        if (err) {\n          supportsBulkGetMap[dbUrl] = false;\n          explainError(\n            err.status,\n            'PouchDB is just detecting if the remote ' +\n            'supports the _bulk_get API.'\n          );\n          doBulkGetShim();\n        } else {\n          supportsBulkGetMap[dbUrl] = true;\n          callback(null, res);\n        }\n      });\n    } else if (supportsBulkGet) {\n      /* istanbul ignore next */\n      doBulkGet(callback);\n    } else {\n      doBulkGetShim();\n    }\n  });\n\n  // Calls GET on the host, which gets back a JSON string containing\n  //    couchdb: A welcome string\n  //    version: The version of CouchDB it is running\n  api._info = function (callback) {\n    setup().then(function () {\n      ajax$$1({}, {\n        method: 'GET',\n        url: genDBUrl(host, '')\n      }, function (err, res) {\n        /* istanbul ignore next */\n        if (err) {\n        return callback(err);\n        }\n        res.host = genDBUrl(host, '');\n        callback(null, res);\n      });\n    }).catch(callback);\n  };\n\n  // Get the document with the given id from the database given by host.\n  // The id could be solely the _id in the database, or it may be a\n  // _design/ID or _local/ID path\n  api.get = adapterFun$$1('get', function (id, opts, callback) {\n    // If no options were given, set the callback to the second parameter\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    opts = clone(opts);\n\n    // List of parameters to add to the GET request\n    var params = {};\n\n    if (opts.revs) {\n      params.revs = true;\n    }\n\n    if (opts.revs_info) {\n      params.revs_info = true;\n    }\n\n    if (opts.latest) {\n      params.latest = true;\n    }\n\n    if (opts.open_revs) {\n      if (opts.open_revs !== \"all\") {\n        opts.open_revs = JSON.stringify(opts.open_revs);\n      }\n      params.open_revs = opts.open_revs;\n    }\n\n    if (opts.rev) {\n      params.rev = opts.rev;\n    }\n\n    if (opts.conflicts) {\n      params.conflicts = opts.conflicts;\n    }\n\n    id = encodeDocId(id);\n\n    // Set the options for the ajax call\n    var options = {\n      method: 'GET',\n      url: genDBUrl(host, id + paramsToStr(params))\n    };\n\n    function fetchAttachments(doc) {\n      var atts = doc._attachments;\n      var filenames = atts && Object.keys(atts);\n      if (!atts || !filenames.length) {\n        return;\n      }\n      // we fetch these manually in separate XHRs, because\n      // Sync Gateway would normally send it back as multipart/mixed,\n      // which we cannot parse. Also, this is more efficient than\n      // receiving attachments as base64-encoded strings.\n      function fetch(filename) {\n        var att = atts[filename];\n        var path = encodeDocId(doc._id) + '/' + encodeAttachmentId(filename) +\n          '?rev=' + doc._rev;\n        return ajaxPromise(opts, {\n          method: 'GET',\n          url: genDBUrl(host, path),\n          binary: true\n        }).then(function (blob$$1) {\n          if (opts.binary) {\n            return blob$$1;\n          }\n          return new PouchPromise$1(function (resolve) {\n            blobToBase64(blob$$1, resolve);\n          });\n        }).then(function (data) {\n          delete att.stub;\n          delete att.length;\n          att.data = data;\n        });\n      }\n\n      var promiseFactories = filenames.map(function (filename) {\n        return function () {\n          return fetch(filename);\n        };\n      });\n\n      // This limits the number of parallel xhr requests to 5 any time\n      // to avoid issues with maximum browser request limits\n      return pool(promiseFactories, 5);\n    }\n\n    function fetchAllAttachments(docOrDocs) {\n      if (Array.isArray(docOrDocs)) {\n        return PouchPromise$1.all(docOrDocs.map(function (doc) {\n          if (doc.ok) {\n            return fetchAttachments(doc.ok);\n          }\n        }));\n      }\n      return fetchAttachments(docOrDocs);\n    }\n\n    ajaxPromise(opts, options).then(function (res) {\n      return PouchPromise$1.resolve().then(function () {\n        if (opts.attachments) {\n          return fetchAllAttachments(res);\n        }\n      }).then(function () {\n        callback(null, res);\n      });\n    }).catch(callback);\n  });\n\n  // Delete the document given by doc from the database given by host.\n  api.remove = adapterFun$$1('remove',\n      function (docOrId, optsOrRev, opts, callback) {\n    var doc;\n    if (typeof optsOrRev === 'string') {\n      // id, rev, opts, callback style\n      doc = {\n        _id: docOrId,\n        _rev: optsOrRev\n      };\n      if (typeof opts === 'function') {\n        callback = opts;\n        opts = {};\n      }\n    } else {\n      // doc, opts, callback style\n      doc = docOrId;\n      if (typeof optsOrRev === 'function') {\n        callback = optsOrRev;\n        opts = {};\n      } else {\n        callback = opts;\n        opts = optsOrRev;\n      }\n    }\n\n    var rev = (doc._rev || opts.rev);\n\n    // Delete the document\n    ajax$$1(opts, {\n      method: 'DELETE',\n      url: genDBUrl(host, encodeDocId(doc._id)) + '?rev=' + rev\n    }, callback);\n  });\n\n  function encodeAttachmentId(attachmentId) {\n    return attachmentId.split(\"/\").map(encodeURIComponent).join(\"/\");\n  }\n\n  // Get the attachment\n  api.getAttachment =\n    adapterFun$$1('getAttachment', function (docId, attachmentId, opts,\n                                                callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    var params = opts.rev ? ('?rev=' + opts.rev) : '';\n    var url = genDBUrl(host, encodeDocId(docId)) + '/' +\n      encodeAttachmentId(attachmentId) + params;\n    ajax$$1(opts, {\n      method: 'GET',\n      url: url,\n      binary: true\n    }, callback);\n  });\n\n  // Remove the attachment given by the id and rev\n  api.removeAttachment =\n    adapterFun$$1('removeAttachment', function (docId, attachmentId, rev,\n                                                   callback) {\n\n    var url = genDBUrl(host, encodeDocId(docId) + '/' +\n      encodeAttachmentId(attachmentId)) + '?rev=' + rev;\n\n    ajax$$1({}, {\n      method: 'DELETE',\n      url: url\n    }, callback);\n  });\n\n  // Add the attachment given by blob and its contentType property\n  // to the document with the given id, the revision given by rev, and\n  // add it to the database given by host.\n  api.putAttachment =\n    adapterFun$$1('putAttachment', function (docId, attachmentId, rev, blob$$1,\n                                                type, callback) {\n    if (typeof type === 'function') {\n      callback = type;\n      type = blob$$1;\n      blob$$1 = rev;\n      rev = null;\n    }\n    var id = encodeDocId(docId) + '/' + encodeAttachmentId(attachmentId);\n    var url = genDBUrl(host, id);\n    if (rev) {\n      url += '?rev=' + rev;\n    }\n\n    if (typeof blob$$1 === 'string') {\n      // input is assumed to be a base64 string\n      var binary;\n      try {\n        binary = thisAtob(blob$$1);\n      } catch (err) {\n        return callback(createError(BAD_ARG,\n                        'Attachment is not a valid base64 string'));\n      }\n      blob$$1 = binary ? binStringToBluffer(binary, type) : '';\n    }\n\n    var opts = {\n      headers: {'Content-Type': type},\n      method: 'PUT',\n      url: url,\n      processData: false,\n      body: blob$$1,\n      timeout: ajaxOpts.timeout || 60000\n    };\n    // Add the attachment\n    ajax$$1({}, opts, callback);\n  });\n\n  // Update/create multiple documents given by req in the database\n  // given by host.\n  api._bulkDocs = function (req, opts, callback) {\n    // If new_edits=false then it prevents the database from creating\n    // new revision numbers for the documents. Instead it just uses\n    // the old ones. This is used in database replication.\n    req.new_edits = opts.new_edits;\n\n    setup().then(function () {\n      return PouchPromise$1.all(req.docs.map(preprocessAttachments$2));\n    }).then(function () {\n      // Update/create the documents\n      ajax$$1(opts, {\n        method: 'POST',\n        url: genDBUrl(host, '_bulk_docs'),\n        timeout: opts.timeout,\n        body: req\n      }, function (err, results) {\n        if (err) {\n          return callback(err);\n        }\n        results.forEach(function (result) {\n          result.ok = true; // smooths out cloudant not adding this\n        });\n        callback(null, results);\n      });\n    }).catch(callback);\n  };\n\n\n  // Update/create document\n  api._put = function (doc, opts, callback) {\n    setup().then(function () {\n      return preprocessAttachments$2(doc);\n    }).then(function () {\n      // Update/create the document\n      ajax$$1(opts, {\n        method: 'PUT',\n        url: genDBUrl(host, encodeDocId(doc._id)),\n        body: doc\n      }, function (err, result) {\n        if (err) {\n          return callback(err);\n        }\n        callback(null, result);\n      });\n    }).catch(callback);\n  };\n\n\n  // Get a listing of the documents in the database given\n  // by host and ordered by increasing id.\n  api.allDocs = adapterFun$$1('allDocs', function (opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    opts = clone(opts);\n\n    // List of parameters to add to the GET request\n    var params = {};\n    var body;\n    var method = 'GET';\n\n    if (opts.conflicts) {\n      params.conflicts = true;\n    }\n\n    if (opts.descending) {\n      params.descending = true;\n    }\n\n    if (opts.include_docs) {\n      params.include_docs = true;\n    }\n\n    // added in CouchDB 1.6.0\n    if (opts.attachments) {\n      params.attachments = true;\n    }\n\n    if (opts.key) {\n      params.key = JSON.stringify(opts.key);\n    }\n\n    if (opts.start_key) {\n      opts.startkey = opts.start_key;\n    }\n\n    if (opts.startkey) {\n      params.startkey = JSON.stringify(opts.startkey);\n    }\n\n    if (opts.end_key) {\n      opts.endkey = opts.end_key;\n    }\n\n    if (opts.endkey) {\n      params.endkey = JSON.stringify(opts.endkey);\n    }\n\n    if (typeof opts.inclusive_end !== 'undefined') {\n      params.inclusive_end = !!opts.inclusive_end;\n    }\n\n    if (typeof opts.limit !== 'undefined') {\n      params.limit = opts.limit;\n    }\n\n    if (typeof opts.skip !== 'undefined') {\n      params.skip = opts.skip;\n    }\n\n    var paramStr = paramsToStr(params);\n\n    if (typeof opts.keys !== 'undefined') {\n      method = 'POST';\n      body = {keys: opts.keys};\n    }\n\n    // Get the document listing\n    ajaxPromise(opts, {\n      method: method,\n      url: genDBUrl(host, '_all_docs' + paramStr),\n      body: body\n    }).then(function (res) {\n      if (opts.include_docs && opts.attachments && opts.binary) {\n        res.rows.forEach(readAttachmentsAsBlobOrBuffer);\n      }\n      callback(null, res);\n    }).catch(callback);\n  });\n\n  // Get a list of changes made to documents in the database given by host.\n  // TODO According to the README, there should be two other methods here,\n  // api.changes.addListener and api.changes.removeListener.\n  api._changes = function (opts) {\n\n    // We internally page the results of a changes request, this means\n    // if there is a large set of changes to be returned we can start\n    // processing them quicker instead of waiting on the entire\n    // set of changes to return and attempting to process them at once\n    var batchSize = 'batch_size' in opts ? opts.batch_size : CHANGES_BATCH_SIZE;\n\n    opts = clone(opts);\n    opts.timeout = ('timeout' in opts) ? opts.timeout :\n      ('timeout' in ajaxOpts) ? ajaxOpts.timeout :\n      30 * 1000;\n\n    // We give a 5 second buffer for CouchDB changes to respond with\n    // an ok timeout (if a timeout it set)\n    var params = opts.timeout ? {timeout: opts.timeout - (5 * 1000)} : {};\n    var limit = (typeof opts.limit !== 'undefined') ? opts.limit : false;\n    var returnDocs;\n    if ('return_docs' in opts) {\n      returnDocs = opts.return_docs;\n    } else if ('returnDocs' in opts) {\n      // TODO: Remove 'returnDocs' in favor of 'return_docs' in a future release\n      returnDocs = opts.returnDocs;\n    } else {\n      returnDocs = true;\n    }\n    //\n    var leftToFetch = limit;\n\n    if (opts.style) {\n      params.style = opts.style;\n    }\n\n    if (opts.include_docs || opts.filter && typeof opts.filter === 'function') {\n      params.include_docs = true;\n    }\n\n    if (opts.attachments) {\n      params.attachments = true;\n    }\n\n    if (opts.continuous) {\n      params.feed = 'longpoll';\n    }\n\n    if (opts.conflicts) {\n      params.conflicts = true;\n    }\n\n    if (opts.descending) {\n      params.descending = true;\n    }\n\n    if ('heartbeat' in opts) {\n      // If the heartbeat value is false, it disables the default heartbeat\n      if (opts.heartbeat) {\n        params.heartbeat = opts.heartbeat;\n      }\n    } else if (opts.continuous) {\n      // Default heartbeat to 10 seconds\n      params.heartbeat = 10000;\n    }\n\n    if (opts.filter && typeof opts.filter === 'string') {\n      params.filter = opts.filter;\n    }\n\n    if (opts.view && typeof opts.view === 'string') {\n      params.filter = '_view';\n      params.view = opts.view;\n    }\n\n    // If opts.query_params exists, pass it through to the changes request.\n    // These parameters may be used by the filter on the source database.\n    if (opts.query_params && typeof opts.query_params === 'object') {\n      for (var param_name in opts.query_params) {\n        /* istanbul ignore else */\n        if (opts.query_params.hasOwnProperty(param_name)) {\n          params[param_name] = opts.query_params[param_name];\n        }\n      }\n    }\n\n    var method = 'GET';\n    var body;\n\n    if (opts.doc_ids) {\n      // set this automagically for the user; it's annoying that couchdb\n      // requires both a \"filter\" and a \"doc_ids\" param.\n      params.filter = '_doc_ids';\n      method = 'POST';\n      body = {doc_ids: opts.doc_ids };\n    }\n\n    var xhr;\n    var lastFetchedSeq;\n\n    // Get all the changes starting wtih the one immediately after the\n    // sequence number given by since.\n    var fetch = function (since, callback) {\n      if (opts.aborted) {\n        return;\n      }\n      params.since = since;\n      // \"since\" can be any kind of json object in Coudant/CouchDB 2.x\n      /* istanbul ignore next */\n      if (typeof params.since === \"object\") {\n        params.since = JSON.stringify(params.since);\n      }\n\n      if (opts.descending) {\n        if (limit) {\n          params.limit = leftToFetch;\n        }\n      } else {\n        params.limit = (!limit || leftToFetch > batchSize) ?\n          batchSize : leftToFetch;\n      }\n\n      // Set the options for the ajax call\n      var xhrOpts = {\n        method: method,\n        url: genDBUrl(host, '_changes' + paramsToStr(params)),\n        timeout: opts.timeout,\n        body: body\n      };\n      lastFetchedSeq = since;\n\n      /* istanbul ignore if */\n      if (opts.aborted) {\n        return;\n      }\n\n      // Get the changes\n      setup().then(function () {\n        xhr = ajax$$1(opts, xhrOpts, callback);\n      }).catch(callback);\n    };\n\n    // If opts.since exists, get all the changes from the sequence\n    // number given by opts.since. Otherwise, get all the changes\n    // from the sequence number 0.\n    var results = {results: []};\n\n    var fetched = function (err, res) {\n      if (opts.aborted) {\n        return;\n      }\n      var raw_results_length = 0;\n      // If the result of the ajax call (res) contains changes (res.results)\n      if (res && res.results) {\n        raw_results_length = res.results.length;\n        results.last_seq = res.last_seq;\n        // For each change\n        var req = {};\n        req.query = opts.query_params;\n        res.results = res.results.filter(function (c) {\n          leftToFetch--;\n          var ret = filterChange(opts)(c);\n          if (ret) {\n            if (opts.include_docs && opts.attachments && opts.binary) {\n              readAttachmentsAsBlobOrBuffer(c);\n            }\n            if (returnDocs) {\n              results.results.push(c);\n            }\n            opts.onChange(c);\n          }\n          return ret;\n        });\n      } else if (err) {\n        // In case of an error, stop listening for changes and call\n        // opts.complete\n        opts.aborted = true;\n        opts.complete(err);\n        return;\n      }\n\n      // The changes feed may have timed out with no results\n      // if so reuse last update sequence\n      if (res && res.last_seq) {\n        lastFetchedSeq = res.last_seq;\n      }\n\n      var finished = (limit && leftToFetch <= 0) ||\n        (res && raw_results_length < batchSize) ||\n        (opts.descending);\n\n      if ((opts.continuous && !(limit && leftToFetch <= 0)) || !finished) {\n        // Queue a call to fetch again with the newest sequence number\n        nextTick(function () { fetch(lastFetchedSeq, fetched); });\n      } else {\n        // We're done, call the callback\n        opts.complete(null, results);\n      }\n    };\n\n    fetch(opts.since || 0, fetched);\n\n    // Return a method to cancel this method from processing any more\n    return {\n      cancel: function () {\n        opts.aborted = true;\n        if (xhr) {\n          xhr.abort();\n        }\n      }\n    };\n  };\n\n  // Given a set of document/revision IDs (given by req), tets the subset of\n  // those that do NOT correspond to revisions stored in the database.\n  // See http://wiki.apache.org/couchdb/HttpPostRevsDiff\n  api.revsDiff = adapterFun$$1('revsDiff', function (req, opts, callback) {\n    // If no options were given, set the callback to be the second parameter\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n\n    // Get the missing document/revision IDs\n    ajax$$1(opts, {\n      method: 'POST',\n      url: genDBUrl(host, '_revs_diff'),\n      body: req\n    }, callback);\n  });\n\n  api._close = function (callback) {\n    callback();\n  };\n\n  api._destroy = function (options, callback) {\n    ajax$$1(options, {\n      url: genDBUrl(host, ''),\n      method: 'DELETE'\n    }, function (err, resp) {\n      if (err && err.status && err.status !== 404) {\n        return callback(err);\n      }\n      callback(null, resp);\n    });\n  };\n}\n\n// HttpPouch is a valid adapter.\nHttpPouch.valid = function () {\n  return true;\n};\n\nvar HttpPouch$1 = function (PouchDB) {\n  PouchDB.adapter('http', HttpPouch, false);\n  PouchDB.adapter('https', HttpPouch, false);\n};\n\nfunction pad(str, padWith, upToLength) {\n  var padding = '';\n  var targetLength = upToLength - str.length;\n  /* istanbul ignore next */\n  while (padding.length < targetLength) {\n    padding += padWith;\n  }\n  return padding;\n}\n\nfunction padLeft(str, padWith, upToLength) {\n  var padding = pad(str, padWith, upToLength);\n  return padding + str;\n}\n\nvar MIN_MAGNITUDE = -324; // verified by -Number.MIN_VALUE\nvar MAGNITUDE_DIGITS = 3; // ditto\nvar SEP = ''; // set to '_' for easier debugging \n\nfunction collate(a, b) {\n\n  if (a === b) {\n    return 0;\n  }\n\n  a = normalizeKey(a);\n  b = normalizeKey(b);\n\n  var ai = collationIndex(a);\n  var bi = collationIndex(b);\n  if ((ai - bi) !== 0) {\n    return ai - bi;\n  }\n  switch (typeof a) {\n    case 'number':\n      return a - b;\n    case 'boolean':\n      return a < b ? -1 : 1;\n    case 'string':\n      return stringCollate(a, b);\n  }\n  return Array.isArray(a) ? arrayCollate(a, b) : objectCollate(a, b);\n}\n\n// couch considers null/NaN/Infinity/-Infinity === undefined,\n// for the purposes of mapreduce indexes. also, dates get stringified.\nfunction normalizeKey(key) {\n  switch (typeof key) {\n    case 'undefined':\n      return null;\n    case 'number':\n      if (key === Infinity || key === -Infinity || isNaN(key)) {\n        return null;\n      }\n      return key;\n    case 'object':\n      var origKey = key;\n      if (Array.isArray(key)) {\n        var len = key.length;\n        key = new Array(len);\n        for (var i = 0; i < len; i++) {\n          key[i] = normalizeKey(origKey[i]);\n        }\n      /* istanbul ignore next */\n      } else if (key instanceof Date) {\n        return key.toJSON();\n      } else if (key !== null) { // generic object\n        key = {};\n        for (var k in origKey) {\n          if (origKey.hasOwnProperty(k)) {\n            var val = origKey[k];\n            if (typeof val !== 'undefined') {\n              key[k] = normalizeKey(val);\n            }\n          }\n        }\n      }\n  }\n  return key;\n}\n\nfunction indexify(key) {\n  if (key !== null) {\n    switch (typeof key) {\n      case 'boolean':\n        return key ? 1 : 0;\n      case 'number':\n        return numToIndexableString(key);\n      case 'string':\n        // We've to be sure that key does not contain \\u0000\n        // Do order-preserving replacements:\n        // 0 -> 1, 1\n        // 1 -> 1, 2\n        // 2 -> 2, 2\n        return key\n          .replace(/\\u0002/g, '\\u0002\\u0002')\n          .replace(/\\u0001/g, '\\u0001\\u0002')\n          .replace(/\\u0000/g, '\\u0001\\u0001');\n      case 'object':\n        var isArray = Array.isArray(key);\n        var arr = isArray ? key : Object.keys(key);\n        var i = -1;\n        var len = arr.length;\n        var result = '';\n        if (isArray) {\n          while (++i < len) {\n            result += toIndexableString(arr[i]);\n          }\n        } else {\n          while (++i < len) {\n            var objKey = arr[i];\n            result += toIndexableString(objKey) +\n                toIndexableString(key[objKey]);\n          }\n        }\n        return result;\n    }\n  }\n  return '';\n}\n\n// convert the given key to a string that would be appropriate\n// for lexical sorting, e.g. within a database, where the\n// sorting is the same given by the collate() function.\nfunction toIndexableString(key) {\n  var zero = '\\u0000';\n  key = normalizeKey(key);\n  return collationIndex(key) + SEP + indexify(key) + zero;\n}\n\nfunction parseNumber(str, i) {\n  var originalIdx = i;\n  var num;\n  var zero = str[i] === '1';\n  if (zero) {\n    num = 0;\n    i++;\n  } else {\n    var neg = str[i] === '0';\n    i++;\n    var numAsString = '';\n    var magAsString = str.substring(i, i + MAGNITUDE_DIGITS);\n    var magnitude = parseInt(magAsString, 10) + MIN_MAGNITUDE;\n    /* istanbul ignore next */\n    if (neg) {\n      magnitude = -magnitude;\n    }\n    i += MAGNITUDE_DIGITS;\n    while (true) {\n      var ch = str[i];\n      if (ch === '\\u0000') {\n        break;\n      } else {\n        numAsString += ch;\n      }\n      i++;\n    }\n    numAsString = numAsString.split('.');\n    if (numAsString.length === 1) {\n      num = parseInt(numAsString, 10);\n    } else {\n      /* istanbul ignore next */\n      num = parseFloat(numAsString[0] + '.' + numAsString[1]);\n    }\n    /* istanbul ignore next */\n    if (neg) {\n      num = num - 10;\n    }\n    /* istanbul ignore next */\n    if (magnitude !== 0) {\n      // parseFloat is more reliable than pow due to rounding errors\n      // e.g. Number.MAX_VALUE would return Infinity if we did\n      // num * Math.pow(10, magnitude);\n      num = parseFloat(num + 'e' + magnitude);\n    }\n  }\n  return {num: num, length : i - originalIdx};\n}\n\n// move up the stack while parsing\n// this function moved outside of parseIndexableString for performance\nfunction pop(stack, metaStack) {\n  var obj = stack.pop();\n\n  if (metaStack.length) {\n    var lastMetaElement = metaStack[metaStack.length - 1];\n    if (obj === lastMetaElement.element) {\n      // popping a meta-element, e.g. an object whose value is another object\n      metaStack.pop();\n      lastMetaElement = metaStack[metaStack.length - 1];\n    }\n    var element = lastMetaElement.element;\n    var lastElementIndex = lastMetaElement.index;\n    if (Array.isArray(element)) {\n      element.push(obj);\n    } else if (lastElementIndex === stack.length - 2) { // obj with key+value\n      var key = stack.pop();\n      element[key] = obj;\n    } else {\n      stack.push(obj); // obj with key only\n    }\n  }\n}\n\nfunction parseIndexableString(str) {\n  var stack = [];\n  var metaStack = []; // stack for arrays and objects\n  var i = 0;\n\n  /*eslint no-constant-condition: [\"error\", { \"checkLoops\": false }]*/\n  while (true) {\n    var collationIndex = str[i++];\n    if (collationIndex === '\\u0000') {\n      if (stack.length === 1) {\n        return stack.pop();\n      } else {\n        pop(stack, metaStack);\n        continue;\n      }\n    }\n    switch (collationIndex) {\n      case '1':\n        stack.push(null);\n        break;\n      case '2':\n        stack.push(str[i] === '1');\n        i++;\n        break;\n      case '3':\n        var parsedNum = parseNumber(str, i);\n        stack.push(parsedNum.num);\n        i += parsedNum.length;\n        break;\n      case '4':\n        var parsedStr = '';\n        /*eslint no-constant-condition: [\"error\", { \"checkLoops\": false }]*/\n        while (true) {\n          var ch = str[i];\n          if (ch === '\\u0000') {\n            break;\n          }\n          parsedStr += ch;\n          i++;\n        }\n        // perform the reverse of the order-preserving replacement\n        // algorithm (see above)\n        parsedStr = parsedStr.replace(/\\u0001\\u0001/g, '\\u0000')\n          .replace(/\\u0001\\u0002/g, '\\u0001')\n          .replace(/\\u0002\\u0002/g, '\\u0002');\n        stack.push(parsedStr);\n        break;\n      case '5':\n        var arrayElement = { element: [], index: stack.length };\n        stack.push(arrayElement.element);\n        metaStack.push(arrayElement);\n        break;\n      case '6':\n        var objElement = { element: {}, index: stack.length };\n        stack.push(objElement.element);\n        metaStack.push(objElement);\n        break;\n      /* istanbul ignore next */\n      default:\n        throw new Error(\n          'bad collationIndex or unexpectedly reached end of input: ' +\n            collationIndex);\n    }\n  }\n}\n\nfunction arrayCollate(a, b) {\n  var len = Math.min(a.length, b.length);\n  for (var i = 0; i < len; i++) {\n    var sort = collate(a[i], b[i]);\n    if (sort !== 0) {\n      return sort;\n    }\n  }\n  return (a.length === b.length) ? 0 :\n    (a.length > b.length) ? 1 : -1;\n}\nfunction stringCollate(a, b) {\n  // See: https://github.com/daleharvey/pouchdb/issues/40\n  // This is incompatible with the CouchDB implementation, but its the\n  // best we can do for now\n  return (a === b) ? 0 : ((a > b) ? 1 : -1);\n}\nfunction objectCollate(a, b) {\n  var ak = Object.keys(a), bk = Object.keys(b);\n  var len = Math.min(ak.length, bk.length);\n  for (var i = 0; i < len; i++) {\n    // First sort the keys\n    var sort = collate(ak[i], bk[i]);\n    if (sort !== 0) {\n      return sort;\n    }\n    // if the keys are equal sort the values\n    sort = collate(a[ak[i]], b[bk[i]]);\n    if (sort !== 0) {\n      return sort;\n    }\n\n  }\n  return (ak.length === bk.length) ? 0 :\n    (ak.length > bk.length) ? 1 : -1;\n}\n// The collation is defined by erlangs ordered terms\n// the atoms null, true, false come first, then numbers, strings,\n// arrays, then objects\n// null/undefined/NaN/Infinity/-Infinity are all considered null\nfunction collationIndex(x) {\n  var id = ['boolean', 'number', 'string', 'object'];\n  var idx = id.indexOf(typeof x);\n  //false if -1 otherwise true, but fast!!!!1\n  if (~idx) {\n    if (x === null) {\n      return 1;\n    }\n    if (Array.isArray(x)) {\n      return 5;\n    }\n    return idx < 3 ? (idx + 2) : (idx + 3);\n  }\n  /* istanbul ignore next */\n  if (Array.isArray(x)) {\n    return 5;\n  }\n}\n\n// conversion:\n// x yyy zz...zz\n// x = 0 for negative, 1 for 0, 2 for positive\n// y = exponent (for negative numbers negated) moved so that it's >= 0\n// z = mantisse\nfunction numToIndexableString(num) {\n\n  if (num === 0) {\n    return '1';\n  }\n\n  // convert number to exponential format for easier and\n  // more succinct string sorting\n  var expFormat = num.toExponential().split(/e\\+?/);\n  var magnitude = parseInt(expFormat[1], 10);\n\n  var neg = num < 0;\n\n  var result = neg ? '0' : '2';\n\n  // first sort by magnitude\n  // it's easier if all magnitudes are positive\n  var magForComparison = ((neg ? -magnitude : magnitude) - MIN_MAGNITUDE);\n  var magString = padLeft((magForComparison).toString(), '0', MAGNITUDE_DIGITS);\n\n  result += SEP + magString;\n\n  // then sort by the factor\n  var factor = Math.abs(parseFloat(expFormat[0])); // [1..10)\n  /* istanbul ignore next */\n  if (neg) { // for negative reverse ordering\n    factor = 10 - factor;\n  }\n\n  var factorStr = factor.toFixed(20);\n\n  // strip zeros from the end\n  factorStr = factorStr.replace(/\\.?0+$/, '');\n\n  result += SEP + factorStr;\n\n  return result;\n}\n\n/*\n * Simple task queue to sequentialize actions. Assumes\n * callbacks will eventually fire (once).\n */\n\nfunction TaskQueue$2() {\n  this.promise = new PouchPromise$1(function (fulfill) {fulfill(); });\n}\nTaskQueue$2.prototype.add = function (promiseFactory) {\n  this.promise = this.promise.catch(function () {\n    // just recover\n  }).then(function () {\n    return promiseFactory();\n  });\n  return this.promise;\n};\nTaskQueue$2.prototype.finish = function () {\n  return this.promise;\n};\n\nfunction createView(opts) {\n  var sourceDB = opts.db;\n  var viewName = opts.viewName;\n  var mapFun = opts.map;\n  var reduceFun = opts.reduce;\n  var temporary = opts.temporary;\n\n  // the \"undefined\" part is for backwards compatibility\n  var viewSignature = mapFun.toString() + (reduceFun && reduceFun.toString()) +\n    'undefined';\n\n  var cachedViews;\n  if (!temporary) {\n    // cache this to ensure we don't try to update the same view twice\n    cachedViews = sourceDB._cachedViews = sourceDB._cachedViews || {};\n    if (cachedViews[viewSignature]) {\n      return cachedViews[viewSignature];\n    }\n  }\n\n  var promiseForView = sourceDB.info().then(function (info) {\n\n    var depDbName = info.db_name + '-mrview-' +\n      (temporary ? 'temp' : stringMd5(viewSignature));\n\n    // save the view name in the source db so it can be cleaned up if necessary\n    // (e.g. when the _design doc is deleted, remove all associated view data)\n    function diffFunction(doc) {\n      doc.views = doc.views || {};\n      var fullViewName = viewName;\n      if (fullViewName.indexOf('/') === -1) {\n        fullViewName = viewName + '/' + viewName;\n      }\n      var depDbs = doc.views[fullViewName] = doc.views[fullViewName] || {};\n      /* istanbul ignore if */\n      if (depDbs[depDbName]) {\n        return; // no update necessary\n      }\n      depDbs[depDbName] = true;\n      return doc;\n    }\n    return upsert(sourceDB, '_local/mrviews', diffFunction).then(function () {\n      return sourceDB.registerDependentDatabase(depDbName).then(function (res) {\n        var db = res.db;\n        db.auto_compaction = true;\n        var view = {\n          name: depDbName,\n          db: db,\n          sourceDB: sourceDB,\n          adapter: sourceDB.adapter,\n          mapFun: mapFun,\n          reduceFun: reduceFun\n        };\n        return view.db.get('_local/lastSeq').catch(function (err) {\n          /* istanbul ignore if */\n          if (err.status !== 404) {\n            throw err;\n          }\n        }).then(function (lastSeqDoc) {\n          view.seq = lastSeqDoc ? lastSeqDoc.seq : 0;\n          if (cachedViews) {\n            view.db.once('destroyed', function () {\n              delete cachedViews[viewSignature];\n            });\n          }\n          return view;\n        });\n      });\n    });\n  });\n\n  if (cachedViews) {\n    cachedViews[viewSignature] = promiseForView;\n  }\n  return promiseForView;\n}\n\nfunction QueryParseError(message) {\n  this.status = 400;\n  this.name = 'query_parse_error';\n  this.message = message;\n  this.error = true;\n  try {\n    Error.captureStackTrace(this, QueryParseError);\n  } catch (e) {}\n}\n\ninherits(QueryParseError, Error);\n\nfunction NotFoundError(message) {\n  this.status = 404;\n  this.name = 'not_found';\n  this.message = message;\n  this.error = true;\n  try {\n    Error.captureStackTrace(this, NotFoundError);\n  } catch (e) {}\n}\n\ninherits(NotFoundError, Error);\n\nfunction BuiltInError(message) {\n  this.status = 500;\n  this.name = 'invalid_value';\n  this.message = message;\n  this.error = true;\n  try {\n    Error.captureStackTrace(this, BuiltInError);\n  } catch (e) {}\n}\n\ninherits(BuiltInError, Error);\n\nfunction createBuiltInError(name) {\n  var message = 'builtin ' + name +\n    ' function requires map values to be numbers' +\n    ' or number arrays';\n  return new BuiltInError(message);\n}\n\nfunction sum(values) {\n  var result = 0;\n  for (var i = 0, len = values.length; i < len; i++) {\n    var num = values[i];\n    if (typeof num !== 'number') {\n      if (Array.isArray(num)) {\n        // lists of numbers are also allowed, sum them separately\n        result = typeof result === 'number' ? [result] : result;\n        for (var j = 0, jLen = num.length; j < jLen; j++) {\n          var jNum = num[j];\n          if (typeof jNum !== 'number') {\n            throw createBuiltInError('_sum');\n          } else if (typeof result[j] === 'undefined') {\n            result.push(jNum);\n          } else {\n            result[j] += jNum;\n          }\n        }\n      } else { // not array/number\n        throw createBuiltInError('_sum');\n      }\n    } else if (typeof result === 'number') {\n      result += num;\n    } else { // add number to array\n      result[0] += num;\n    }\n  }\n  return result;\n}\n\nvar log$2 = guardedConsole.bind(null, 'log');\nvar isArray = Array.isArray;\nvar toJSON = JSON.parse;\n\nfunction evalFunctionWithEval(func, emit) {\n  return scopedEval(\n    \"return (\" + func.replace(/;\\s*$/, \"\") + \");\",\n    {\n      emit: emit,\n      sum: sum,\n      log: log$2,\n      isArray: isArray,\n      toJSON: toJSON\n    }\n  );\n}\n\nfunction promisedCallback(promise, callback) {\n  if (callback) {\n    promise.then(function (res) {\n      nextTick(function () {\n        callback(null, res);\n      });\n    }, function (reason) {\n      nextTick(function () {\n        callback(reason);\n      });\n    });\n  }\n  return promise;\n}\n\nfunction callbackify(fun) {\n  return getArguments(function (args) {\n    var cb = args.pop();\n    var promise = fun.apply(this, args);\n    if (typeof cb === 'function') {\n      promisedCallback(promise, cb);\n    }\n    return promise;\n  });\n}\n\n// Promise finally util similar to Q.finally\nfunction fin(promise, finalPromiseFactory) {\n  return promise.then(function (res) {\n    return finalPromiseFactory().then(function () {\n      return res;\n    });\n  }, function (reason) {\n    return finalPromiseFactory().then(function () {\n      throw reason;\n    });\n  });\n}\n\nfunction sequentialize(queue, promiseFactory) {\n  return function () {\n    var args = arguments;\n    var that = this;\n    return queue.add(function () {\n      return promiseFactory.apply(that, args);\n    });\n  };\n}\n\n// uniq an array of strings, order not guaranteed\n// similar to underscore/lodash _.uniq\nfunction uniq(arr) {\n  var theSet = new ExportedSet(arr);\n  var result = new Array(theSet.size);\n  var index = -1;\n  theSet.forEach(function (value) {\n    result[++index] = value;\n  });\n  return result;\n}\n\nfunction mapToKeysArray(map) {\n  var result = new Array(map.size);\n  var index = -1;\n  map.forEach(function (value, key) {\n    result[++index] = key;\n  });\n  return result;\n}\n\nvar persistentQueues = {};\nvar tempViewQueue = new TaskQueue$2();\nvar CHANGES_BATCH_SIZE$1 = 50;\n\nfunction parseViewName(name) {\n  // can be either 'ddocname/viewname' or just 'viewname'\n  // (where the ddoc name is the same)\n  return name.indexOf('/') === -1 ? [name, name] : name.split('/');\n}\n\nfunction isGenOne(changes) {\n  // only return true if the current change is 1-\n  // and there are no other leafs\n  return changes.length === 1 && /^1-/.test(changes[0].rev);\n}\n\nfunction emitError(db, e) {\n  try {\n    db.emit('error', e);\n  } catch (err) {\n    guardedConsole('error',\n      'The user\\'s map/reduce function threw an uncaught error.\\n' +\n      'You can debug this error by doing:\\n' +\n      'myDatabase.on(\\'error\\', function (err) { debugger; });\\n' +\n      'Please double-check your map/reduce function.');\n    guardedConsole('error', e);\n  }\n}\nfunction tryMap(db, fun, doc) {\n  // emit an event if there was an error thrown by a map function.\n  // putting try/catches in a single function also avoids deoptimizations.\n  try {\n    fun(doc);\n  } catch (e) {\n    emitError(db, e);\n  }\n}\n\nfunction tryReduce(db, fun, keys, values, rereduce) {\n  // same as above, but returning the result or an error. there are two separate\n  // functions to avoid extra memory allocations since the tryCode() case is used\n  // for custom map functions (common) vs this function, which is only used for\n  // custom reduce functions (rare)\n  try {\n    return {output : fun(keys, values, rereduce)};\n  } catch (e) {\n    emitError(db, e);\n    return {error: e};\n  }\n}\n\nfunction sortByKeyThenValue(x, y) {\n  var keyCompare = collate(x.key, y.key);\n  return keyCompare !== 0 ? keyCompare : collate(x.value, y.value);\n}\n\nfunction sliceResults(results, limit, skip) {\n  skip = skip || 0;\n  if (typeof limit === 'number') {\n    return results.slice(skip, limit + skip);\n  } else if (skip > 0) {\n    return results.slice(skip);\n  }\n  return results;\n}\n\nfunction rowToDocId(row) {\n  var val = row.value;\n  // Users can explicitly specify a joined doc _id, or it\n  // defaults to the doc _id that emitted the key/value.\n  var docId = (val && typeof val === 'object' && val._id) || row.id;\n  return docId;\n}\n\nfunction readAttachmentsAsBlobOrBuffer$1(res) {\n  res.rows.forEach(function (row) {\n    var atts = row.doc && row.doc._attachments;\n    if (!atts) {\n      return;\n    }\n    Object.keys(atts).forEach(function (filename) {\n      var att = atts[filename];\n      atts[filename].data = b64ToBluffer(att.data, att.content_type);\n    });\n  });\n}\n\nfunction postprocessAttachments(opts) {\n  return function (res) {\n    if (opts.include_docs && opts.attachments && opts.binary) {\n      readAttachmentsAsBlobOrBuffer$1(res);\n    }\n    return res;\n  };\n}\n\nvar builtInReduce = {\n  _sum: function (keys, values) {\n    return sum(values);\n  },\n\n  _count: function (keys, values) {\n    return values.length;\n  },\n\n  _stats: function (keys, values) {\n    // no need to implement rereduce=true, because Pouch\n    // will never call it\n    function sumsqr(values) {\n      var _sumsqr = 0;\n      for (var i = 0, len = values.length; i < len; i++) {\n        var num = values[i];\n        _sumsqr += (num * num);\n      }\n      return _sumsqr;\n    }\n    return {\n      sum     : sum(values),\n      min     : Math.min.apply(null, values),\n      max     : Math.max.apply(null, values),\n      count   : values.length,\n      sumsqr : sumsqr(values)\n    };\n  }\n};\n\nfunction addHttpParam(paramName, opts, params, asJson) {\n  // add an http param from opts to params, optionally json-encoded\n  var val = opts[paramName];\n  if (typeof val !== 'undefined') {\n    if (asJson) {\n      val = encodeURIComponent(JSON.stringify(val));\n    }\n    params.push(paramName + '=' + val);\n  }\n}\n\nfunction coerceInteger(integerCandidate) {\n  if (typeof integerCandidate !== 'undefined') {\n    var asNumber = Number(integerCandidate);\n    // prevents e.g. '1foo' or '1.1' being coerced to 1\n    if (!isNaN(asNumber) && asNumber === parseInt(integerCandidate, 10)) {\n      return asNumber;\n    } else {\n      return integerCandidate;\n    }\n  }\n}\n\nfunction coerceOptions(opts) {\n  opts.group_level = coerceInteger(opts.group_level);\n  opts.limit = coerceInteger(opts.limit);\n  opts.skip = coerceInteger(opts.skip);\n  return opts;\n}\n\nfunction checkPositiveInteger(number) {\n  if (number) {\n    if (typeof number !== 'number') {\n      return  new QueryParseError('Invalid value for integer: \"' +\n      number + '\"');\n    }\n    if (number < 0) {\n      return new QueryParseError('Invalid value for positive integer: ' +\n        '\"' + number + '\"');\n    }\n  }\n}\n\nfunction checkQueryParseError(options, fun) {\n  var startkeyName = options.descending ? 'endkey' : 'startkey';\n  var endkeyName = options.descending ? 'startkey' : 'endkey';\n\n  if (typeof options[startkeyName] !== 'undefined' &&\n    typeof options[endkeyName] !== 'undefined' &&\n    collate(options[startkeyName], options[endkeyName]) > 0) {\n    throw new QueryParseError('No rows can match your key range, ' +\n    'reverse your start_key and end_key or set {descending : true}');\n  } else if (fun.reduce && options.reduce !== false) {\n    if (options.include_docs) {\n      throw new QueryParseError('{include_docs:true} is invalid for reduce');\n    } else if (options.keys && options.keys.length > 1 &&\n        !options.group && !options.group_level) {\n      throw new QueryParseError('Multi-key fetches for reduce views must use ' +\n      '{group: true}');\n    }\n  }\n  ['group_level', 'limit', 'skip'].forEach(function (optionName) {\n    var error = checkPositiveInteger(options[optionName]);\n    if (error) {\n      throw error;\n    }\n  });\n}\n\nfunction httpQuery(db, fun, opts) {\n  // List of parameters to add to the PUT request\n  var params = [];\n  var body;\n  var method = 'GET';\n\n  // If opts.reduce exists and is defined, then add it to the list\n  // of parameters.\n  // If reduce=false then the results are that of only the map function\n  // not the final result of map and reduce.\n  addHttpParam('reduce', opts, params);\n  addHttpParam('include_docs', opts, params);\n  addHttpParam('attachments', opts, params);\n  addHttpParam('limit', opts, params);\n  addHttpParam('descending', opts, params);\n  addHttpParam('group', opts, params);\n  addHttpParam('group_level', opts, params);\n  addHttpParam('skip', opts, params);\n  addHttpParam('stale', opts, params);\n  addHttpParam('conflicts', opts, params);\n  addHttpParam('startkey', opts, params, true);\n  addHttpParam('start_key', opts, params, true);\n  addHttpParam('endkey', opts, params, true);\n  addHttpParam('end_key', opts, params, true);\n  addHttpParam('inclusive_end', opts, params);\n  addHttpParam('key', opts, params, true);\n\n  // Format the list of parameters into a valid URI query string\n  params = params.join('&');\n  params = params === '' ? '' : '?' + params;\n\n  // If keys are supplied, issue a POST to circumvent GET query string limits\n  // see http://wiki.apache.org/couchdb/HTTP_view_API#Querying_Options\n  if (typeof opts.keys !== 'undefined') {\n    var MAX_URL_LENGTH = 2000;\n    // according to http://stackoverflow.com/a/417184/680742,\n    // the de facto URL length limit is 2000 characters\n\n    var keysAsString =\n      'keys=' + encodeURIComponent(JSON.stringify(opts.keys));\n    if (keysAsString.length + params.length + 1 <= MAX_URL_LENGTH) {\n      // If the keys are short enough, do a GET. we do this to work around\n      // Safari not understanding 304s on POSTs (see pouchdb/pouchdb#1239)\n      params += (params[0] === '?' ? '&' : '?') + keysAsString;\n    } else {\n      method = 'POST';\n      if (typeof fun === 'string') {\n        body = {keys: opts.keys};\n      } else { // fun is {map : mapfun}, so append to this\n        fun.keys = opts.keys;\n      }\n    }\n  }\n\n  // We are referencing a query defined in the design doc\n  if (typeof fun === 'string') {\n    var parts = parseViewName(fun);\n    return db.request({\n      method: method,\n      url: '_design/' + parts[0] + '/_view/' + parts[1] + params,\n      body: body\n    }).then(postprocessAttachments(opts));\n  }\n\n  // We are using a temporary view, terrible for performance, good for testing\n  body = body || {};\n  Object.keys(fun).forEach(function (key) {\n    if (Array.isArray(fun[key])) {\n      body[key] = fun[key];\n    } else {\n      body[key] = fun[key].toString();\n    }\n  });\n  return db.request({\n    method: 'POST',\n    url: '_temp_view' + params,\n    body: body\n  }).then(postprocessAttachments(opts));\n}\n\n// custom adapters can define their own api._query\n// and override the default behavior\n/* istanbul ignore next */\nfunction customQuery(db, fun, opts) {\n  return new PouchPromise$1(function (resolve, reject) {\n    db._query(fun, opts, function (err, res) {\n      if (err) {\n        return reject(err);\n      }\n      resolve(res);\n    });\n  });\n}\n\n// custom adapters can define their own api._viewCleanup\n// and override the default behavior\n/* istanbul ignore next */\nfunction customViewCleanup(db) {\n  return new PouchPromise$1(function (resolve, reject) {\n    db._viewCleanup(function (err, res) {\n      if (err) {\n        return reject(err);\n      }\n      resolve(res);\n    });\n  });\n}\n\nfunction defaultsTo(value) {\n  return function (reason) {\n    /* istanbul ignore else */\n    if (reason.status === 404) {\n      return value;\n    } else {\n      throw reason;\n    }\n  };\n}\n\n// returns a promise for a list of docs to update, based on the input docId.\n// the order doesn't matter, because post-3.2.0, bulkDocs\n// is an atomic operation in all three adapters.\nfunction getDocsToPersist(docId, view, docIdsToChangesAndEmits) {\n  var metaDocId = '_local/doc_' + docId;\n  var defaultMetaDoc = {_id: metaDocId, keys: []};\n  var docData = docIdsToChangesAndEmits.get(docId);\n  var indexableKeysToKeyValues = docData[0];\n  var changes = docData[1];\n\n  function getMetaDoc() {\n    if (isGenOne(changes)) {\n      // generation 1, so we can safely assume initial state\n      // for performance reasons (avoids unnecessary GETs)\n      return PouchPromise$1.resolve(defaultMetaDoc);\n    }\n    return view.db.get(metaDocId).catch(defaultsTo(defaultMetaDoc));\n  }\n\n  function getKeyValueDocs(metaDoc) {\n    if (!metaDoc.keys.length) {\n      // no keys, no need for a lookup\n      return PouchPromise$1.resolve({rows: []});\n    }\n    return view.db.allDocs({\n      keys: metaDoc.keys,\n      include_docs: true\n    });\n  }\n\n  function processKeyValueDocs(metaDoc, kvDocsRes) {\n    var kvDocs = [];\n    var oldKeys = new ExportedSet();\n\n    for (var i = 0, len = kvDocsRes.rows.length; i < len; i++) {\n      var row = kvDocsRes.rows[i];\n      var doc = row.doc;\n      if (!doc) { // deleted\n        continue;\n      }\n      kvDocs.push(doc);\n      oldKeys.add(doc._id);\n      doc._deleted = !indexableKeysToKeyValues.has(doc._id);\n      if (!doc._deleted) {\n        var keyValue = indexableKeysToKeyValues.get(doc._id);\n        if ('value' in keyValue) {\n          doc.value = keyValue.value;\n        }\n      }\n    }\n    var newKeys = mapToKeysArray(indexableKeysToKeyValues);\n    newKeys.forEach(function (key) {\n      if (!oldKeys.has(key)) {\n        // new doc\n        var kvDoc = {\n          _id: key\n        };\n        var keyValue = indexableKeysToKeyValues.get(key);\n        if ('value' in keyValue) {\n          kvDoc.value = keyValue.value;\n        }\n        kvDocs.push(kvDoc);\n      }\n    });\n    metaDoc.keys = uniq(newKeys.concat(metaDoc.keys));\n    kvDocs.push(metaDoc);\n\n    return kvDocs;\n  }\n\n  return getMetaDoc().then(function (metaDoc) {\n    return getKeyValueDocs(metaDoc).then(function (kvDocsRes) {\n      return processKeyValueDocs(metaDoc, kvDocsRes);\n    });\n  });\n}\n\n// updates all emitted key/value docs and metaDocs in the mrview database\n// for the given batch of documents from the source database\nfunction saveKeyValues(view, docIdsToChangesAndEmits, seq) {\n  var seqDocId = '_local/lastSeq';\n  return view.db.get(seqDocId)\n  .catch(defaultsTo({_id: seqDocId, seq: 0}))\n  .then(function (lastSeqDoc) {\n    var docIds = mapToKeysArray(docIdsToChangesAndEmits);\n    return PouchPromise$1.all(docIds.map(function (docId) {\n      return getDocsToPersist(docId, view, docIdsToChangesAndEmits);\n    })).then(function (listOfDocsToPersist) {\n      var docsToPersist = flatten(listOfDocsToPersist);\n      lastSeqDoc.seq = seq;\n      docsToPersist.push(lastSeqDoc);\n      // write all docs in a single operation, update the seq once\n      return view.db.bulkDocs({docs : docsToPersist});\n    });\n  });\n}\n\nfunction getQueue(view) {\n  var viewName = typeof view === 'string' ? view : view.name;\n  var queue = persistentQueues[viewName];\n  if (!queue) {\n    queue = persistentQueues[viewName] = new TaskQueue$2();\n  }\n  return queue;\n}\n\nfunction updateView(view) {\n  return sequentialize(getQueue(view), function () {\n    return updateViewInQueue(view);\n  })();\n}\n\nfunction updateViewInQueue(view) {\n  // bind the emit function once\n  var mapResults;\n  var doc;\n\n  function emit(key, value) {\n    var output = {id: doc._id, key: normalizeKey(key)};\n    // Don't explicitly store the value unless it's defined and non-null.\n    // This saves on storage space, because often people don't use it.\n    if (typeof value !== 'undefined' && value !== null) {\n      output.value = normalizeKey(value);\n    }\n    mapResults.push(output);\n  }\n\n  var mapFun;\n  // for temp_views one can use emit(doc, emit), see #38\n  if (typeof view.mapFun === \"function\" && view.mapFun.length === 2) {\n    var origMap = view.mapFun;\n    mapFun = function (doc) {\n      return origMap(doc, emit);\n    };\n  } else {\n    mapFun = evalFunctionWithEval(view.mapFun.toString(), emit);\n  }\n\n  var currentSeq = view.seq || 0;\n\n  function processChange(docIdsToChangesAndEmits, seq) {\n    return function () {\n      return saveKeyValues(view, docIdsToChangesAndEmits, seq);\n    };\n  }\n\n  var queue = new TaskQueue$2();\n\n  function processNextBatch() {\n    return view.sourceDB.changes({\n      conflicts: true,\n      include_docs: true,\n      style: 'all_docs',\n      since: currentSeq,\n      limit: CHANGES_BATCH_SIZE$1\n    }).then(processBatch);\n  }\n\n  function processBatch(response) {\n    var results = response.results;\n    if (!results.length) {\n      return;\n    }\n    var docIdsToChangesAndEmits = createDocIdsToChangesAndEmits(results);\n    queue.add(processChange(docIdsToChangesAndEmits, currentSeq));\n    if (results.length < CHANGES_BATCH_SIZE$1) {\n      return;\n    }\n    return processNextBatch();\n  }\n\n  function createDocIdsToChangesAndEmits(results) {\n    var docIdsToChangesAndEmits = new ExportedMap();\n    for (var i = 0, len = results.length; i < len; i++) {\n      var change = results[i];\n      if (change.doc._id[0] !== '_') {\n        mapResults = [];\n        doc = change.doc;\n\n        if (!doc._deleted) {\n          tryMap(view.sourceDB, mapFun, doc);\n        }\n        mapResults.sort(sortByKeyThenValue);\n\n        var indexableKeysToKeyValues = createIndexableKeysToKeyValues(mapResults);\n        docIdsToChangesAndEmits.set(change.doc._id, [\n          indexableKeysToKeyValues,\n          change.changes\n        ]);\n      }\n      currentSeq = change.seq;\n    }\n    return docIdsToChangesAndEmits;\n  }\n\n  function createIndexableKeysToKeyValues(mapResults) {\n    var indexableKeysToKeyValues = new ExportedMap();\n    var lastKey;\n    for (var i = 0, len = mapResults.length; i < len; i++) {\n      var emittedKeyValue = mapResults[i];\n      var complexKey = [emittedKeyValue.key, emittedKeyValue.id];\n      if (i > 0 && collate(emittedKeyValue.key, lastKey) === 0) {\n        complexKey.push(i); // dup key+id, so make it unique\n      }\n      indexableKeysToKeyValues.set(toIndexableString(complexKey), emittedKeyValue);\n      lastKey = emittedKeyValue.key;\n    }\n    return indexableKeysToKeyValues;\n  }\n\n  return processNextBatch().then(function () {\n    return queue.finish();\n  }).then(function () {\n    view.seq = currentSeq;\n  });\n}\n\nfunction reduceView(view, results, options) {\n  if (options.group_level === 0) {\n    delete options.group_level;\n  }\n\n  var shouldGroup = options.group || options.group_level;\n\n  var reduceFun;\n  if (builtInReduce[view.reduceFun]) {\n    reduceFun = builtInReduce[view.reduceFun];\n  } else {\n    reduceFun = evalFunctionWithEval(view.reduceFun.toString());\n  }\n\n  var groups = [];\n  var lvl = isNaN(options.group_level) ? Number.POSITIVE_INFINITY :\n    options.group_level;\n  results.forEach(function (e) {\n    var last = groups[groups.length - 1];\n    var groupKey = shouldGroup ? e.key : null;\n\n    // only set group_level for array keys\n    if (shouldGroup && Array.isArray(groupKey)) {\n      groupKey = groupKey.slice(0, lvl);\n    }\n\n    if (last && collate(last.groupKey, groupKey) === 0) {\n      last.keys.push([e.key, e.id]);\n      last.values.push(e.value);\n      return;\n    }\n    groups.push({\n      keys: [[e.key, e.id]],\n      values: [e.value],\n      groupKey: groupKey\n    });\n  });\n  results = [];\n  for (var i = 0, len = groups.length; i < len; i++) {\n    var e = groups[i];\n    var reduceTry = tryReduce(view.sourceDB, reduceFun, e.keys, e.values, false);\n    if (reduceTry.error && reduceTry.error instanceof BuiltInError) {\n      // CouchDB returns an error if a built-in errors out\n      throw reduceTry.error;\n    }\n    results.push({\n      // CouchDB just sets the value to null if a non-built-in errors out\n      value: reduceTry.error ? null : reduceTry.output,\n      key: e.groupKey\n    });\n  }\n  // no total_rows/offset when reducing\n  return {rows: sliceResults(results, options.limit, options.skip)};\n}\n\nfunction queryView(view, opts) {\n  return sequentialize(getQueue(view), function () {\n    return queryViewInQueue(view, opts);\n  })();\n}\n\nfunction queryViewInQueue(view, opts) {\n  var totalRows;\n  var shouldReduce = view.reduceFun && opts.reduce !== false;\n  var skip = opts.skip || 0;\n  if (typeof opts.keys !== 'undefined' && !opts.keys.length) {\n    // equivalent query\n    opts.limit = 0;\n    delete opts.keys;\n  }\n\n  function fetchFromView(viewOpts) {\n    viewOpts.include_docs = true;\n    return view.db.allDocs(viewOpts).then(function (res) {\n      totalRows = res.total_rows;\n      return res.rows.map(function (result) {\n\n        // implicit migration - in older versions of PouchDB,\n        // we explicitly stored the doc as {id: ..., key: ..., value: ...}\n        // this is tested in a migration test\n        /* istanbul ignore next */\n        if ('value' in result.doc && typeof result.doc.value === 'object' &&\n            result.doc.value !== null) {\n          var keys = Object.keys(result.doc.value).sort();\n          // this detection method is not perfect, but it's unlikely the user\n          // emitted a value which was an object with these 3 exact keys\n          var expectedKeys = ['id', 'key', 'value'];\n          if (!(keys < expectedKeys || keys > expectedKeys)) {\n            return result.doc.value;\n          }\n        }\n\n        var parsedKeyAndDocId = parseIndexableString(result.doc._id);\n        return {\n          key: parsedKeyAndDocId[0],\n          id: parsedKeyAndDocId[1],\n          value: ('value' in result.doc ? result.doc.value : null)\n        };\n      });\n    });\n  }\n\n  function onMapResultsReady(rows) {\n    var finalResults;\n    if (shouldReduce) {\n      finalResults = reduceView(view, rows, opts);\n    } else {\n      finalResults = {\n        total_rows: totalRows,\n        offset: skip,\n        rows: rows\n      };\n    }\n    if (opts.include_docs) {\n      var docIds = uniq(rows.map(rowToDocId));\n\n      return view.sourceDB.allDocs({\n        keys: docIds,\n        include_docs: true,\n        conflicts: opts.conflicts,\n        attachments: opts.attachments,\n        binary: opts.binary\n      }).then(function (allDocsRes) {\n        var docIdsToDocs = new ExportedMap();\n        allDocsRes.rows.forEach(function (row) {\n          docIdsToDocs.set(row.id, row.doc);\n        });\n        rows.forEach(function (row) {\n          var docId = rowToDocId(row);\n          var doc = docIdsToDocs.get(docId);\n          if (doc) {\n            row.doc = doc;\n          }\n        });\n        return finalResults;\n      });\n    } else {\n      return finalResults;\n    }\n  }\n\n  if (typeof opts.keys !== 'undefined') {\n    var keys = opts.keys;\n    var fetchPromises = keys.map(function (key) {\n      var viewOpts = {\n        startkey : toIndexableString([key]),\n        endkey   : toIndexableString([key, {}])\n      };\n      return fetchFromView(viewOpts);\n    });\n    return PouchPromise$1.all(fetchPromises).then(flatten).then(onMapResultsReady);\n  } else { // normal query, no 'keys'\n    var viewOpts = {\n      descending : opts.descending\n    };\n    if (opts.start_key) {\n        opts.startkey = opts.start_key;\n    }\n    if (opts.end_key) {\n        opts.endkey = opts.end_key;\n    }\n    if (typeof opts.startkey !== 'undefined') {\n      viewOpts.startkey = opts.descending ?\n        toIndexableString([opts.startkey, {}]) :\n        toIndexableString([opts.startkey]);\n    }\n    if (typeof opts.endkey !== 'undefined') {\n      var inclusiveEnd = opts.inclusive_end !== false;\n      if (opts.descending) {\n        inclusiveEnd = !inclusiveEnd;\n      }\n\n      viewOpts.endkey = toIndexableString(\n        inclusiveEnd ? [opts.endkey, {}] : [opts.endkey]);\n    }\n    if (typeof opts.key !== 'undefined') {\n      var keyStart = toIndexableString([opts.key]);\n      var keyEnd = toIndexableString([opts.key, {}]);\n      if (viewOpts.descending) {\n        viewOpts.endkey = keyStart;\n        viewOpts.startkey = keyEnd;\n      } else {\n        viewOpts.startkey = keyStart;\n        viewOpts.endkey = keyEnd;\n      }\n    }\n    if (!shouldReduce) {\n      if (typeof opts.limit === 'number') {\n        viewOpts.limit = opts.limit;\n      }\n      viewOpts.skip = skip;\n    }\n    return fetchFromView(viewOpts).then(onMapResultsReady);\n  }\n}\n\nfunction httpViewCleanup(db) {\n  return db.request({\n    method: 'POST',\n    url: '_view_cleanup'\n  });\n}\n\nfunction localViewCleanup(db) {\n  return db.get('_local/mrviews').then(function (metaDoc) {\n    var docsToViews = new ExportedMap();\n    Object.keys(metaDoc.views).forEach(function (fullViewName) {\n      var parts = parseViewName(fullViewName);\n      var designDocName = '_design/' + parts[0];\n      var viewName = parts[1];\n      var views = docsToViews.get(designDocName);\n      if (!views) {\n        views = new ExportedSet();\n        docsToViews.set(designDocName, views);\n      }\n      views.add(viewName);\n    });\n    var opts = {\n      keys : mapToKeysArray(docsToViews),\n      include_docs : true\n    };\n    return db.allDocs(opts).then(function (res) {\n      var viewsToStatus = {};\n      res.rows.forEach(function (row) {\n        var ddocName = row.key.substring(8); // cuts off '_design/'\n        docsToViews.get(row.key).forEach(function (viewName) {\n          var fullViewName = ddocName + '/' + viewName;\n          /* istanbul ignore if */\n          if (!metaDoc.views[fullViewName]) {\n            // new format, without slashes, to support PouchDB 2.2.0\n            // migration test in pouchdb's browser.migration.js verifies this\n            fullViewName = viewName;\n          }\n          var viewDBNames = Object.keys(metaDoc.views[fullViewName]);\n          // design doc deleted, or view function nonexistent\n          var statusIsGood = row.doc && row.doc.views &&\n            row.doc.views[viewName];\n          viewDBNames.forEach(function (viewDBName) {\n            viewsToStatus[viewDBName] =\n              viewsToStatus[viewDBName] || statusIsGood;\n          });\n        });\n      });\n      var dbsToDelete = Object.keys(viewsToStatus).filter(\n        function (viewDBName) { return !viewsToStatus[viewDBName]; });\n      var destroyPromises = dbsToDelete.map(function (viewDBName) {\n        return sequentialize(getQueue(viewDBName), function () {\n          return new db.constructor(viewDBName, db.__opts).destroy();\n        })();\n      });\n      return PouchPromise$1.all(destroyPromises).then(function () {\n        return {ok: true};\n      });\n    });\n  }, defaultsTo({ok: true}));\n}\n\nvar viewCleanup = callbackify(function () {\n  var db = this;\n  if (db.type() === 'http') {\n    return httpViewCleanup(db);\n  }\n  /* istanbul ignore next */\n  if (typeof db._viewCleanup === 'function') {\n    return customViewCleanup(db);\n  }\n  return localViewCleanup(db);\n});\n\nfunction queryPromised(db, fun, opts) {\n  if (db.type() === 'http') {\n    return httpQuery(db, fun, opts);\n  }\n\n  /* istanbul ignore next */\n  if (typeof db._query === 'function') {\n    return customQuery(db, fun, opts);\n  }\n\n  if (typeof fun !== 'string') {\n    // temp_view\n    checkQueryParseError(opts, fun);\n\n    var createViewOpts = {\n      db : db,\n      viewName : 'temp_view/temp_view',\n      map : fun.map,\n      reduce : fun.reduce,\n      temporary : true\n    };\n    tempViewQueue.add(function () {\n      return createView(createViewOpts).then(function (view) {\n        function cleanup() {\n          return view.db.destroy();\n        }\n        return fin(updateView(view).then(function () {\n          return queryView(view, opts);\n        }), cleanup);\n      });\n    });\n    return tempViewQueue.finish();\n  } else {\n    // persistent view\n    var fullViewName = fun;\n    var parts = parseViewName(fullViewName);\n    var designDocName = parts[0];\n    var viewName = parts[1];\n    return db.get('_design/' + designDocName).then(function (doc) {\n      var fun = doc.views && doc.views[viewName];\n\n      if (!fun || typeof fun.map !== 'string') {\n        throw new NotFoundError('ddoc ' + designDocName +\n        ' has no view named ' + viewName);\n      }\n      checkQueryParseError(opts, fun);\n\n      var createViewOpts = {\n        db : db,\n        viewName : fullViewName,\n        map : fun.map,\n        reduce : fun.reduce\n      };\n      return createView(createViewOpts).then(function (view) {\n        if (opts.stale === 'ok' || opts.stale === 'update_after') {\n          if (opts.stale === 'update_after') {\n            nextTick(function () {\n              updateView(view);\n            });\n          }\n          return queryView(view, opts);\n        } else { // stale not ok\n          return updateView(view).then(function () {\n            return queryView(view, opts);\n          });\n        }\n      });\n    });\n  }\n}\n\nvar query = function (fun, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  opts = opts ? coerceOptions(opts) : {};\n\n  if (typeof fun === 'function') {\n    fun = {map : fun};\n  }\n\n  var db = this;\n  var promise = PouchPromise$1.resolve().then(function () {\n    return queryPromised(db, fun, opts);\n  });\n  promisedCallback(promise, callback);\n  return promise;\n};\n\n\nvar mapreduce = {\n  query: query,\n  viewCleanup: viewCleanup\n};\n\nfunction isGenOne$1(rev) {\n  return /^1-/.test(rev);\n}\n\nfunction fileHasChanged(localDoc, remoteDoc, filename) {\n  return !localDoc._attachments ||\n         !localDoc._attachments[filename] ||\n         localDoc._attachments[filename].digest !== remoteDoc._attachments[filename].digest;\n}\n\nfunction getDocAttachments(db, doc) {\n  var filenames = Object.keys(doc._attachments);\n  return PouchPromise$1.all(filenames.map(function (filename) {\n    return db.getAttachment(doc._id, filename, {rev: doc._rev});\n  }));\n}\n\nfunction getDocAttachmentsFromTargetOrSource(target, src, doc) {\n  var doCheckForLocalAttachments = src.type() === 'http' && target.type() !== 'http';\n  var filenames = Object.keys(doc._attachments);\n\n  if (!doCheckForLocalAttachments) {\n    return getDocAttachments(src, doc);\n  }\n\n  return target.get(doc._id).then(function (localDoc) {\n    return PouchPromise$1.all(filenames.map(function (filename) {\n      if (fileHasChanged(localDoc, doc, filename)) {\n        return src.getAttachment(doc._id, filename);\n      }\n\n      return target.getAttachment(localDoc._id, filename);\n    }));\n  }).catch(function (error) {\n    /* istanbul ignore if */\n    if (error.status !== 404) {\n      throw error;\n    }\n\n    return getDocAttachments(src, doc);\n  });\n}\n\nfunction createBulkGetOpts(diffs) {\n  var requests = [];\n  Object.keys(diffs).forEach(function (id) {\n    var missingRevs = diffs[id].missing;\n    missingRevs.forEach(function (missingRev) {\n      requests.push({\n        id: id,\n        rev: missingRev\n      });\n    });\n  });\n\n  return {\n    docs: requests,\n    revs: true,\n    latest: true\n  };\n}\n\n//\n// Fetch all the documents from the src as described in the \"diffs\",\n// which is a mapping of docs IDs to revisions. If the state ever\n// changes to \"cancelled\", then the returned promise will be rejected.\n// Else it will be resolved with a list of fetched documents.\n//\nfunction getDocs(src, target, diffs, state) {\n  diffs = clone(diffs); // we do not need to modify this\n\n  var resultDocs = [],\n      ok = true;\n\n  function getAllDocs() {\n\n    var bulkGetOpts = createBulkGetOpts(diffs);\n\n    if (!bulkGetOpts.docs.length) { // optimization: skip empty requests\n      return;\n    }\n\n    return src.bulkGet(bulkGetOpts).then(function (bulkGetResponse) {\n      /* istanbul ignore if */\n      if (state.cancelled) {\n        throw new Error('cancelled');\n      }\n      return PouchPromise$1.all(bulkGetResponse.results.map(function (bulkGetInfo) {\n        return PouchPromise$1.all(bulkGetInfo.docs.map(function (doc) {\n          var remoteDoc = doc.ok;\n\n          if (doc.error) {\n            // when AUTO_COMPACTION is set, docs can be returned which look\n            // like this: {\"missing\":\"1-7c3ac256b693c462af8442f992b83696\"}\n            ok = false;\n          }\n\n          if (!remoteDoc || !remoteDoc._attachments) {\n            return remoteDoc;\n          }\n\n          return getDocAttachmentsFromTargetOrSource(target, src, remoteDoc).then(function (attachments) {\n            var filenames = Object.keys(remoteDoc._attachments);\n            attachments.forEach(function (attachment, i) {\n              var att = remoteDoc._attachments[filenames[i]];\n              delete att.stub;\n              delete att.length;\n              att.data = attachment;\n            });\n\n            return remoteDoc;\n          });\n        }));\n      }))\n\n      .then(function (results) {\n        resultDocs = resultDocs.concat(flatten(results).filter(Boolean));\n      });\n    });\n  }\n\n  function hasAttachments(doc) {\n    return doc._attachments && Object.keys(doc._attachments).length > 0;\n  }\n\n  function hasConflicts(doc) {\n    return doc._conflicts && doc._conflicts.length > 0;\n  }\n\n  function fetchRevisionOneDocs(ids) {\n    // Optimization: fetch gen-1 docs and attachments in\n    // a single request using _all_docs\n    return src.allDocs({\n      keys: ids,\n      include_docs: true,\n      conflicts: true\n    }).then(function (res) {\n      if (state.cancelled) {\n        throw new Error('cancelled');\n      }\n      res.rows.forEach(function (row) {\n        if (row.deleted || !row.doc || !isGenOne$1(row.value.rev) ||\n            hasAttachments(row.doc) || hasConflicts(row.doc)) {\n          // if any of these conditions apply, we need to fetch using get()\n          return;\n        }\n\n        // strip _conflicts array to appease CSG (#5793)\n        /* istanbul ignore if */\n        if (row.doc._conflicts) {\n          delete row.doc._conflicts;\n        }\n\n        // the doc we got back from allDocs() is sufficient\n        resultDocs.push(row.doc);\n        delete diffs[row.id];\n      });\n    });\n  }\n\n  function getRevisionOneDocs() {\n    // filter out the generation 1 docs and get them\n    // leaving the non-generation one docs to be got otherwise\n    var ids = Object.keys(diffs).filter(function (id) {\n      var missing = diffs[id].missing;\n      return missing.length === 1 && isGenOne$1(missing[0]);\n    });\n    if (ids.length > 0) {\n      return fetchRevisionOneDocs(ids);\n    }\n  }\n\n  function returnResult() {\n    return { ok:ok, docs:resultDocs };\n  }\n\n  return PouchPromise$1.resolve()\n    .then(getRevisionOneDocs)\n    .then(getAllDocs)\n    .then(returnResult);\n}\n\nvar CHECKPOINT_VERSION = 1;\nvar REPLICATOR = \"pouchdb\";\n// This is an arbitrary number to limit the\n// amount of replication history we save in the checkpoint.\n// If we save too much, the checkpoing docs will become very big,\n// if we save fewer, we'll run a greater risk of having to\n// read all the changes from 0 when checkpoint PUTs fail\n// CouchDB 2.0 has a more involved history pruning,\n// but let's go for the simple version for now.\nvar CHECKPOINT_HISTORY_SIZE = 5;\nvar LOWEST_SEQ = 0;\n\nfunction updateCheckpoint(db, id, checkpoint, session, returnValue) {\n  return db.get(id).catch(function (err) {\n    if (err.status === 404) {\n      if (db.type() === 'http') {\n        explainError(\n          404, 'PouchDB is just checking if a remote checkpoint exists.'\n        );\n      }\n      return {\n        session_id: session,\n        _id: id,\n        history: [],\n        replicator: REPLICATOR,\n        version: CHECKPOINT_VERSION\n      };\n    }\n    throw err;\n  }).then(function (doc) {\n    if (returnValue.cancelled) {\n      return;\n    }\n\n    // if the checkpoint has not changed, do not update\n    if (doc.last_seq === checkpoint) {\n      return;\n    }\n\n    // Filter out current entry for this replication\n    doc.history = (doc.history || []).filter(function (item) {\n      return item.session_id !== session;\n    });\n\n    // Add the latest checkpoint to history\n    doc.history.unshift({\n      last_seq: checkpoint,\n      session_id: session\n    });\n\n    // Just take the last pieces in history, to\n    // avoid really big checkpoint docs.\n    // see comment on history size above\n    doc.history = doc.history.slice(0, CHECKPOINT_HISTORY_SIZE);\n\n    doc.version = CHECKPOINT_VERSION;\n    doc.replicator = REPLICATOR;\n\n    doc.session_id = session;\n    doc.last_seq = checkpoint;\n\n    return db.put(doc).catch(function (err) {\n      if (err.status === 409) {\n        // retry; someone is trying to write a checkpoint simultaneously\n        return updateCheckpoint(db, id, checkpoint, session, returnValue);\n      }\n      throw err;\n    });\n  });\n}\n\nfunction Checkpointer(src, target, id, returnValue) {\n  this.src = src;\n  this.target = target;\n  this.id = id;\n  this.returnValue = returnValue;\n}\n\nCheckpointer.prototype.writeCheckpoint = function (checkpoint, session) {\n  var self = this;\n  return this.updateTarget(checkpoint, session).then(function () {\n    return self.updateSource(checkpoint, session);\n  });\n};\n\nCheckpointer.prototype.updateTarget = function (checkpoint, session) {\n  return updateCheckpoint(this.target, this.id, checkpoint,\n    session, this.returnValue);\n};\n\nCheckpointer.prototype.updateSource = function (checkpoint, session) {\n  var self = this;\n  if (this.readOnlySource) {\n    return PouchPromise$1.resolve(true);\n  }\n  return updateCheckpoint(this.src, this.id, checkpoint,\n    session, this.returnValue)\n    .catch(function (err) {\n      if (isForbiddenError(err)) {\n        self.readOnlySource = true;\n        return true;\n      }\n      throw err;\n    });\n};\n\nvar comparisons = {\n  \"undefined\": function (targetDoc, sourceDoc) {\n    // This is the previous comparison function\n    if (collate(targetDoc.last_seq, sourceDoc.last_seq) === 0) {\n      return sourceDoc.last_seq;\n    }\n    /* istanbul ignore next */\n    return 0;\n  },\n  \"1\": function (targetDoc, sourceDoc) {\n    // This is the comparison function ported from CouchDB\n    return compareReplicationLogs(sourceDoc, targetDoc).last_seq;\n  }\n};\n\nCheckpointer.prototype.getCheckpoint = function () {\n  var self = this;\n  return self.target.get(self.id).then(function (targetDoc) {\n    if (self.readOnlySource) {\n      return PouchPromise$1.resolve(targetDoc.last_seq);\n    }\n\n    return self.src.get(self.id).then(function (sourceDoc) {\n      // Since we can't migrate an old version doc to a new one\n      // (no session id), we just go with the lowest seq in this case\n      /* istanbul ignore if */\n      if (targetDoc.version !== sourceDoc.version) {\n        return LOWEST_SEQ;\n      }\n\n      var version;\n      if (targetDoc.version) {\n        version = targetDoc.version.toString();\n      } else {\n        version = \"undefined\";\n      }\n\n      if (version in comparisons) {\n        return comparisons[version](targetDoc, sourceDoc);\n      }\n      /* istanbul ignore next */\n      return LOWEST_SEQ;\n    }, function (err) {\n      if (err.status === 404 && targetDoc.last_seq) {\n        return self.src.put({\n          _id: self.id,\n          last_seq: LOWEST_SEQ\n        }).then(function () {\n          return LOWEST_SEQ;\n        }, function (err) {\n          if (isForbiddenError(err)) {\n            self.readOnlySource = true;\n            return targetDoc.last_seq;\n          }\n          /* istanbul ignore next */\n          return LOWEST_SEQ;\n        });\n      }\n      throw err;\n    });\n  }).catch(function (err) {\n    if (err.status !== 404) {\n      throw err;\n    }\n    return LOWEST_SEQ;\n  });\n};\n// This checkpoint comparison is ported from CouchDBs source\n// they come from here:\n// https://github.com/apache/couchdb-couch-replicator/blob/master/src/couch_replicator.erl#L863-L906\n\nfunction compareReplicationLogs(srcDoc, tgtDoc) {\n  if (srcDoc.session_id === tgtDoc.session_id) {\n    return {\n      last_seq: srcDoc.last_seq,\n      history: srcDoc.history\n    };\n  }\n\n  return compareReplicationHistory(srcDoc.history, tgtDoc.history);\n}\n\nfunction compareReplicationHistory(sourceHistory, targetHistory) {\n  // the erlang loop via function arguments is not so easy to repeat in JS\n  // therefore, doing this as recursion\n  var S = sourceHistory[0];\n  var sourceRest = sourceHistory.slice(1);\n  var T = targetHistory[0];\n  var targetRest = targetHistory.slice(1);\n\n  if (!S || targetHistory.length === 0) {\n    return {\n      last_seq: LOWEST_SEQ,\n      history: []\n    };\n  }\n\n  var sourceId = S.session_id;\n  /* istanbul ignore if */\n  if (hasSessionId(sourceId, targetHistory)) {\n    return {\n      last_seq: S.last_seq,\n      history: sourceHistory\n    };\n  }\n\n  var targetId = T.session_id;\n  if (hasSessionId(targetId, sourceRest)) {\n    return {\n      last_seq: T.last_seq,\n      history: targetRest\n    };\n  }\n\n  return compareReplicationHistory(sourceRest, targetRest);\n}\n\nfunction hasSessionId(sessionId, history) {\n  var props = history[0];\n  var rest = history.slice(1);\n\n  if (!sessionId || history.length === 0) {\n    return false;\n  }\n\n  if (sessionId === props.session_id) {\n    return true;\n  }\n\n  return hasSessionId(sessionId, rest);\n}\n\nfunction isForbiddenError(err) {\n  return typeof err.status === 'number' && Math.floor(err.status / 100) === 4;\n}\n\nvar STARTING_BACK_OFF = 0;\n\nfunction backOff(opts, returnValue, error, callback) {\n  if (opts.retry === false) {\n    returnValue.emit('error', error);\n    returnValue.removeAllListeners();\n    return;\n  }\n  if (typeof opts.back_off_function !== 'function') {\n    opts.back_off_function = defaultBackOff;\n  }\n  returnValue.emit('requestError', error);\n  if (returnValue.state === 'active' || returnValue.state === 'pending') {\n    returnValue.emit('paused', error);\n    returnValue.state = 'stopped';\n    var backOffSet = function backoffTimeSet() {\n      opts.current_back_off = STARTING_BACK_OFF;\n    };\n    var removeBackOffSetter = function removeBackOffTimeSet() {\n      returnValue.removeListener('active', backOffSet);\n    };\n    returnValue.once('paused', removeBackOffSetter);\n    returnValue.once('active', backOffSet);\n  }\n\n  opts.current_back_off = opts.current_back_off || STARTING_BACK_OFF;\n  opts.current_back_off = opts.back_off_function(opts.current_back_off);\n  setTimeout(callback, opts.current_back_off);\n}\n\nfunction sortObjectPropertiesByKey(queryParams) {\n  return Object.keys(queryParams).sort(collate).reduce(function (result, key) {\n    result[key] = queryParams[key];\n    return result;\n  }, {});\n}\n\n// Generate a unique id particular to this replication.\n// Not guaranteed to align perfectly with CouchDB's rep ids.\nfunction generateReplicationId(src, target, opts) {\n  var docIds = opts.doc_ids ? opts.doc_ids.sort(collate) : '';\n  var filterFun = opts.filter ? opts.filter.toString() : '';\n  var queryParams = '';\n  var filterViewName =  '';\n\n  if (opts.filter && opts.query_params) {\n    queryParams = JSON.stringify(sortObjectPropertiesByKey(opts.query_params));\n  }\n\n  if (opts.filter && opts.filter === '_view') {\n    filterViewName = opts.view.toString();\n  }\n\n  return PouchPromise$1.all([src.id(), target.id()]).then(function (res) {\n    var queryData = res[0] + res[1] + filterFun + filterViewName +\n      queryParams + docIds;\n    return new PouchPromise$1(function (resolve) {\n      binaryMd5(queryData, resolve);\n    });\n  }).then(function (md5sum) {\n    // can't use straight-up md5 alphabet, because\n    // the char '/' is interpreted as being for attachments,\n    // and + is also not url-safe\n    md5sum = md5sum.replace(/\\//g, '.').replace(/\\+/g, '_');\n    return '_local/' + md5sum;\n  });\n}\n\nfunction replicate(src, target, opts, returnValue, result) {\n  var batches = [];               // list of batches to be processed\n  var currentBatch;               // the batch currently being processed\n  var pendingBatch = {\n    seq: 0,\n    changes: [],\n    docs: []\n  }; // next batch, not yet ready to be processed\n  var writingCheckpoint = false;  // true while checkpoint is being written\n  var changesCompleted = false;   // true when all changes received\n  var replicationCompleted = false; // true when replication has completed\n  var last_seq = 0;\n  var continuous = opts.continuous || opts.live || false;\n  var batch_size = opts.batch_size || 100;\n  var batches_limit = opts.batches_limit || 10;\n  var changesPending = false;     // true while src.changes is running\n  var doc_ids = opts.doc_ids;\n  var repId;\n  var checkpointer;\n  var changedDocs = [];\n  // Like couchdb, every replication gets a unique session id\n  var session = uuid();\n\n  result = result || {\n    ok: true,\n    start_time: new Date(),\n    docs_read: 0,\n    docs_written: 0,\n    doc_write_failures: 0,\n    errors: []\n  };\n\n  var changesOpts = {};\n  returnValue.ready(src, target);\n\n  function initCheckpointer() {\n    if (checkpointer) {\n      return PouchPromise$1.resolve();\n    }\n    return generateReplicationId(src, target, opts).then(function (res) {\n      repId = res;\n      checkpointer = new Checkpointer(src, target, repId, returnValue);\n    });\n  }\n\n  function writeDocs() {\n    changedDocs = [];\n\n    if (currentBatch.docs.length === 0) {\n      return;\n    }\n    var docs = currentBatch.docs;\n    var bulkOpts = {timeout: opts.timeout};\n    return target.bulkDocs({docs: docs, new_edits: false}, bulkOpts).then(function (res) {\n      /* istanbul ignore if */\n      if (returnValue.cancelled) {\n        completeReplication();\n        throw new Error('cancelled');\n      }\n\n      // `res` doesn't include full documents (which live in `docs`), so we create a map of \n      // (id -> error), and check for errors while iterating over `docs`\n      var errorsById = Object.create(null);\n      res.forEach(function (res) {\n        if (res.error) {\n          errorsById[res.id] = res;\n        }\n      });\n\n      var errorsNo = Object.keys(errorsById).length;\n      result.doc_write_failures += errorsNo;\n      result.docs_written += docs.length - errorsNo;\n\n      docs.forEach(function (doc) {\n        var error = errorsById[doc._id];\n        if (error) {\n          result.errors.push(error);\n          if (error.name === 'unauthorized' || error.name === 'forbidden') {\n            returnValue.emit('denied', clone(error));\n          } else {\n            throw error;\n          }\n        } else {\n          changedDocs.push(doc);\n        }\n      });\n\n    }, function (err) {\n      result.doc_write_failures += docs.length;\n      throw err;\n    });\n  }\n\n  function finishBatch() {\n    if (currentBatch.error) {\n      throw new Error('There was a problem getting docs.');\n    }\n    result.last_seq = last_seq = currentBatch.seq;\n    var outResult = clone(result);\n    if (changedDocs.length) {\n      outResult.docs = changedDocs;\n      returnValue.emit('change', outResult);\n    }\n    writingCheckpoint = true;\n    return checkpointer.writeCheckpoint(currentBatch.seq,\n        session).then(function () {\n      writingCheckpoint = false;\n      /* istanbul ignore if */\n      if (returnValue.cancelled) {\n        completeReplication();\n        throw new Error('cancelled');\n      }\n      currentBatch = undefined;\n      getChanges();\n    }).catch(function (err) {\n      onCheckpointError(err);\n      throw err;\n    });\n  }\n\n  function getDiffs() {\n    var diff = {};\n    currentBatch.changes.forEach(function (change) {\n      // Couchbase Sync Gateway emits these, but we can ignore them\n      /* istanbul ignore if */\n      if (change.id === \"_user/\") {\n        return;\n      }\n      diff[change.id] = change.changes.map(function (x) {\n        return x.rev;\n      });\n    });\n    return target.revsDiff(diff).then(function (diffs) {\n      /* istanbul ignore if */\n      if (returnValue.cancelled) {\n        completeReplication();\n        throw new Error('cancelled');\n      }\n      // currentBatch.diffs elements are deleted as the documents are written\n      currentBatch.diffs = diffs;\n    });\n  }\n\n  function getBatchDocs() {\n    return getDocs(src, target, currentBatch.diffs, returnValue).then(function (got) {\n      currentBatch.error = !got.ok;\n      got.docs.forEach(function (doc) {\n        delete currentBatch.diffs[doc._id];\n        result.docs_read++;\n        currentBatch.docs.push(doc);\n      });\n    });\n  }\n\n  function startNextBatch() {\n    if (returnValue.cancelled || currentBatch) {\n      return;\n    }\n    if (batches.length === 0) {\n      processPendingBatch(true);\n      return;\n    }\n    currentBatch = batches.shift();\n    getDiffs()\n      .then(getBatchDocs)\n      .then(writeDocs)\n      .then(finishBatch)\n      .then(startNextBatch)\n      .catch(function (err) {\n        abortReplication('batch processing terminated with error', err);\n      });\n  }\n\n\n  function processPendingBatch(immediate) {\n    if (pendingBatch.changes.length === 0) {\n      if (batches.length === 0 && !currentBatch) {\n        if ((continuous && changesOpts.live) || changesCompleted) {\n          returnValue.state = 'pending';\n          returnValue.emit('paused');\n        }\n        if (changesCompleted) {\n          completeReplication();\n        }\n      }\n      return;\n    }\n    if (\n      immediate ||\n      changesCompleted ||\n      pendingBatch.changes.length >= batch_size\n    ) {\n      batches.push(pendingBatch);\n      pendingBatch = {\n        seq: 0,\n        changes: [],\n        docs: []\n      };\n      if (returnValue.state === 'pending' || returnValue.state === 'stopped') {\n        returnValue.state = 'active';\n        returnValue.emit('active');\n      }\n      startNextBatch();\n    }\n  }\n\n\n  function abortReplication(reason, err) {\n    if (replicationCompleted) {\n      return;\n    }\n    if (!err.message) {\n      err.message = reason;\n    }\n    result.ok = false;\n    result.status = 'aborting';\n    batches = [];\n    pendingBatch = {\n      seq: 0,\n      changes: [],\n      docs: []\n    };\n    completeReplication(err);\n  }\n\n\n  function completeReplication(fatalError) {\n    if (replicationCompleted) {\n      return;\n    }\n    /* istanbul ignore if */\n    if (returnValue.cancelled) {\n      result.status = 'cancelled';\n      if (writingCheckpoint) {\n        return;\n      }\n    }\n    result.status = result.status || 'complete';\n    result.end_time = new Date();\n    result.last_seq = last_seq;\n    replicationCompleted = true;\n\n    if (fatalError) {\n      fatalError.result = result;\n\n      if (fatalError.name === 'unauthorized' || fatalError.name === 'forbidden') {\n        returnValue.emit('error', fatalError);\n        returnValue.removeAllListeners();\n      } else {\n        backOff(opts, returnValue, fatalError, function () {\n          replicate(src, target, opts, returnValue);\n        });\n      }\n    } else {\n      returnValue.emit('complete', result);\n      returnValue.removeAllListeners();\n    }\n  }\n\n\n  function onChange(change) {\n    /* istanbul ignore if */\n    if (returnValue.cancelled) {\n      return completeReplication();\n    }\n    var filter = filterChange(opts)(change);\n    if (!filter) {\n      return;\n    }\n    pendingBatch.seq = change.seq;\n    pendingBatch.changes.push(change);\n    processPendingBatch(batches.length === 0 && changesOpts.live);\n  }\n\n\n  function onChangesComplete(changes) {\n    changesPending = false;\n    /* istanbul ignore if */\n    if (returnValue.cancelled) {\n      return completeReplication();\n    }\n\n    // if no results were returned then we're done,\n    // else fetch more\n    if (changes.results.length > 0) {\n      changesOpts.since = changes.last_seq;\n      getChanges();\n      processPendingBatch(true);\n    } else {\n\n      var complete = function () {\n        if (continuous) {\n          changesOpts.live = true;\n          getChanges();\n        } else {\n          changesCompleted = true;\n        }\n        processPendingBatch(true);\n      };\n\n      // update the checkpoint so we start from the right seq next time\n      if (!currentBatch && changes.results.length === 0) {\n        writingCheckpoint = true;\n        checkpointer.writeCheckpoint(changes.last_seq,\n            session).then(function () {\n          writingCheckpoint = false;\n          result.last_seq = last_seq = changes.last_seq;\n          complete();\n        })\n        .catch(onCheckpointError);\n      } else {\n        complete();\n      }\n    }\n  }\n\n\n  function onChangesError(err) {\n    changesPending = false;\n    /* istanbul ignore if */\n    if (returnValue.cancelled) {\n      return completeReplication();\n    }\n    abortReplication('changes rejected', err);\n  }\n\n\n  function getChanges() {\n    if (!(\n      !changesPending &&\n      !changesCompleted &&\n      batches.length < batches_limit\n      )) {\n      return;\n    }\n    changesPending = true;\n    function abortChanges() {\n      changes.cancel();\n    }\n    function removeListener() {\n      returnValue.removeListener('cancel', abortChanges);\n    }\n\n    if (returnValue._changes) { // remove old changes() and listeners\n      returnValue.removeListener('cancel', returnValue._abortChanges);\n      returnValue._changes.cancel();\n    }\n    returnValue.once('cancel', abortChanges);\n\n    var changes = src.changes(changesOpts)\n      .on('change', onChange);\n    changes.then(removeListener, removeListener);\n    changes.then(onChangesComplete)\n      .catch(onChangesError);\n\n    if (opts.retry) {\n      // save for later so we can cancel if necessary\n      returnValue._changes = changes;\n      returnValue._abortChanges = abortChanges;\n    }\n  }\n\n\n  function startChanges() {\n    initCheckpointer().then(function () {\n      /* istanbul ignore if */\n      if (returnValue.cancelled) {\n        completeReplication();\n        return;\n      }\n      return checkpointer.getCheckpoint().then(function (checkpoint) {\n        last_seq = checkpoint;\n        changesOpts = {\n          since: last_seq,\n          limit: batch_size,\n          batch_size: batch_size,\n          style: 'all_docs',\n          doc_ids: doc_ids,\n          return_docs: true // required so we know when we're done\n        };\n        if (opts.filter) {\n          if (typeof opts.filter !== 'string') {\n            // required for the client-side filter in onChange\n            changesOpts.include_docs = true;\n          } else { // ddoc filter\n            changesOpts.filter = opts.filter;\n          }\n        }\n        if ('heartbeat' in opts) {\n          changesOpts.heartbeat = opts.heartbeat;\n        }\n        if ('timeout' in opts) {\n          changesOpts.timeout = opts.timeout;\n        }\n        if (opts.query_params) {\n          changesOpts.query_params = opts.query_params;\n        }\n        if (opts.view) {\n          changesOpts.view = opts.view;\n        }\n        getChanges();\n      });\n    }).catch(function (err) {\n      abortReplication('getCheckpoint rejected with ', err);\n    });\n  }\n\n  /* istanbul ignore next */\n  function onCheckpointError(err) {\n    writingCheckpoint = false;\n    abortReplication('writeCheckpoint completed with error', err);\n  }\n\n  /* istanbul ignore if */\n  if (returnValue.cancelled) { // cancelled immediately\n    completeReplication();\n    return;\n  }\n\n  if (!returnValue._addedListeners) {\n    returnValue.once('cancel', completeReplication);\n\n    if (typeof opts.complete === 'function') {\n      returnValue.once('error', opts.complete);\n      returnValue.once('complete', function (result) {\n        opts.complete(null, result);\n      });\n    }\n    returnValue._addedListeners = true;\n  }\n\n  if (typeof opts.since === 'undefined') {\n    startChanges();\n  } else {\n    initCheckpointer().then(function () {\n      writingCheckpoint = true;\n      return checkpointer.writeCheckpoint(opts.since, session);\n    }).then(function () {\n      writingCheckpoint = false;\n      /* istanbul ignore if */\n      if (returnValue.cancelled) {\n        completeReplication();\n        return;\n      }\n      last_seq = opts.since;\n      startChanges();\n    }).catch(onCheckpointError);\n  }\n}\n\n// We create a basic promise so the caller can cancel the replication possibly\n// before we have actually started listening to changes etc\ninherits(Replication, events.EventEmitter);\nfunction Replication() {\n  events.EventEmitter.call(this);\n  this.cancelled = false;\n  this.state = 'pending';\n  var self = this;\n  var promise = new PouchPromise$1(function (fulfill, reject) {\n    self.once('complete', fulfill);\n    self.once('error', reject);\n  });\n  self.then = function (resolve, reject) {\n    return promise.then(resolve, reject);\n  };\n  self.catch = function (reject) {\n    return promise.catch(reject);\n  };\n  // As we allow error handling via \"error\" event as well,\n  // put a stub in here so that rejecting never throws UnhandledError.\n  self.catch(function () {});\n}\n\nReplication.prototype.cancel = function () {\n  this.cancelled = true;\n  this.state = 'cancelled';\n  this.emit('cancel');\n};\n\nReplication.prototype.ready = function (src, target) {\n  var self = this;\n  if (self._readyCalled) {\n    return;\n  }\n  self._readyCalled = true;\n\n  function onDestroy() {\n    self.cancel();\n  }\n  src.once('destroyed', onDestroy);\n  target.once('destroyed', onDestroy);\n  function cleanup() {\n    src.removeListener('destroyed', onDestroy);\n    target.removeListener('destroyed', onDestroy);\n  }\n  self.once('complete', cleanup);\n};\n\nfunction toPouch(db, opts) {\n  var PouchConstructor = opts.PouchConstructor;\n  if (typeof db === 'string') {\n    return new PouchConstructor(db, opts);\n  } else {\n    return db;\n  }\n}\n\nfunction replicateWrapper(src, target, opts, callback) {\n\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  if (typeof opts === 'undefined') {\n    opts = {};\n  }\n\n  if (opts.doc_ids && !Array.isArray(opts.doc_ids)) {\n    throw createError(BAD_REQUEST,\n                       \"`doc_ids` filter parameter is not a list.\");\n  }\n\n  opts.complete = callback;\n  opts = clone(opts);\n  opts.continuous = opts.continuous || opts.live;\n  opts.retry = ('retry' in opts) ? opts.retry : false;\n  /*jshint validthis:true */\n  opts.PouchConstructor = opts.PouchConstructor || this;\n  var replicateRet = new Replication(opts);\n  var srcPouch = toPouch(src, opts);\n  var targetPouch = toPouch(target, opts);\n  replicate(srcPouch, targetPouch, opts, replicateRet);\n  return replicateRet;\n}\n\ninherits(Sync, events.EventEmitter);\nfunction sync$1(src, target, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  if (typeof opts === 'undefined') {\n    opts = {};\n  }\n  opts = clone(opts);\n  /*jshint validthis:true */\n  opts.PouchConstructor = opts.PouchConstructor || this;\n  src = toPouch(src, opts);\n  target = toPouch(target, opts);\n  return new Sync(src, target, opts, callback);\n}\n\nfunction Sync(src, target, opts, callback) {\n  var self = this;\n  this.canceled = false;\n\n  var optsPush = opts.push ? assign$1({}, opts, opts.push) : opts;\n  var optsPull = opts.pull ? assign$1({}, opts, opts.pull) : opts;\n\n  this.push = replicateWrapper(src, target, optsPush);\n  this.pull = replicateWrapper(target, src, optsPull);\n\n  this.pushPaused = true;\n  this.pullPaused = true;\n\n  function pullChange(change) {\n    self.emit('change', {\n      direction: 'pull',\n      change: change\n    });\n  }\n  function pushChange(change) {\n    self.emit('change', {\n      direction: 'push',\n      change: change\n    });\n  }\n  function pushDenied(doc) {\n    self.emit('denied', {\n      direction: 'push',\n      doc: doc\n    });\n  }\n  function pullDenied(doc) {\n    self.emit('denied', {\n      direction: 'pull',\n      doc: doc\n    });\n  }\n  function pushPaused() {\n    self.pushPaused = true;\n    /* istanbul ignore if */\n    if (self.pullPaused) {\n      self.emit('paused');\n    }\n  }\n  function pullPaused() {\n    self.pullPaused = true;\n    /* istanbul ignore if */\n    if (self.pushPaused) {\n      self.emit('paused');\n    }\n  }\n  function pushActive() {\n    self.pushPaused = false;\n    /* istanbul ignore if */\n    if (self.pullPaused) {\n      self.emit('active', {\n        direction: 'push'\n      });\n    }\n  }\n  function pullActive() {\n    self.pullPaused = false;\n    /* istanbul ignore if */\n    if (self.pushPaused) {\n      self.emit('active', {\n        direction: 'pull'\n      });\n    }\n  }\n\n  var removed = {};\n\n  function removeAll(type) { // type is 'push' or 'pull'\n    return function (event, func) {\n      var isChange = event === 'change' &&\n        (func === pullChange || func === pushChange);\n      var isDenied = event === 'denied' &&\n        (func === pullDenied || func === pushDenied);\n      var isPaused = event === 'paused' &&\n        (func === pullPaused || func === pushPaused);\n      var isActive = event === 'active' &&\n        (func === pullActive || func === pushActive);\n\n      if (isChange || isDenied || isPaused || isActive) {\n        if (!(event in removed)) {\n          removed[event] = {};\n        }\n        removed[event][type] = true;\n        if (Object.keys(removed[event]).length === 2) {\n          // both push and pull have asked to be removed\n          self.removeAllListeners(event);\n        }\n      }\n    };\n  }\n\n  if (opts.live) {\n    this.push.on('complete', self.pull.cancel.bind(self.pull));\n    this.pull.on('complete', self.push.cancel.bind(self.push));\n  }\n\n  function addOneListener(ee, event, listener) {\n    if (ee.listeners(event).indexOf(listener) == -1) {\n      ee.on(event, listener);\n    }\n  }\n\n  this.on('newListener', function (event) {\n    if (event === 'change') {\n      addOneListener(self.pull, 'change', pullChange);\n      addOneListener(self.push, 'change', pushChange);\n    } else if (event === 'denied') {\n      addOneListener(self.pull, 'denied', pullDenied);\n      addOneListener(self.push, 'denied', pushDenied);\n    } else if (event === 'active') {\n      addOneListener(self.pull, 'active', pullActive);\n      addOneListener(self.push, 'active', pushActive);\n    } else if (event === 'paused') {\n      addOneListener(self.pull, 'paused', pullPaused);\n      addOneListener(self.push, 'paused', pushPaused);\n    }\n  });\n\n  this.on('removeListener', function (event) {\n    if (event === 'change') {\n      self.pull.removeListener('change', pullChange);\n      self.push.removeListener('change', pushChange);\n    } else if (event === 'denied') {\n      self.pull.removeListener('denied', pullDenied);\n      self.push.removeListener('denied', pushDenied);\n    } else if (event === 'active') {\n      self.pull.removeListener('active', pullActive);\n      self.push.removeListener('active', pushActive);\n    } else if (event === 'paused') {\n      self.pull.removeListener('paused', pullPaused);\n      self.push.removeListener('paused', pushPaused);\n    }\n  });\n\n  this.pull.on('removeListener', removeAll('pull'));\n  this.push.on('removeListener', removeAll('push'));\n\n  var promise = PouchPromise$1.all([\n    this.push,\n    this.pull\n  ]).then(function (resp) {\n    var out = {\n      push: resp[0],\n      pull: resp[1]\n    };\n    self.emit('complete', out);\n    if (callback) {\n      callback(null, out);\n    }\n    self.removeAllListeners();\n    return out;\n  }, function (err) {\n    self.cancel();\n    if (callback) {\n      // if there's a callback, then the callback can receive\n      // the error event\n      callback(err);\n    } else {\n      // if there's no callback, then we're safe to emit an error\n      // event, which would otherwise throw an unhandled error\n      // due to 'error' being a special event in EventEmitters\n      self.emit('error', err);\n    }\n    self.removeAllListeners();\n    if (callback) {\n      // no sense throwing if we're already emitting an 'error' event\n      throw err;\n    }\n  });\n\n  this.then = function (success, err) {\n    return promise.then(success, err);\n  };\n\n  this.catch = function (err) {\n    return promise.catch(err);\n  };\n}\n\nSync.prototype.cancel = function () {\n  if (!this.canceled) {\n    this.canceled = true;\n    this.push.cancel();\n    this.pull.cancel();\n  }\n};\n\nfunction replication(PouchDB) {\n  PouchDB.replicate = replicateWrapper;\n  PouchDB.sync = sync$1;\n\n  Object.defineProperty(PouchDB.prototype, 'replicate', {\n    get: function () {\n      var self = this;\n      return {\n        from: function (other, opts, callback) {\n          return self.constructor.replicate(other, self, opts, callback);\n        },\n        to: function (other, opts, callback) {\n          return self.constructor.replicate(self, other, opts, callback);\n        }\n      };\n    }\n  });\n\n  PouchDB.prototype.sync = function (dbName, opts, callback) {\n    return this.constructor.sync(this, dbName, opts, callback);\n  };\n}\n\nPouchDB$3.plugin(IDBPouch)\n  .plugin(WebSqlPouch)\n  .plugin(HttpPouch$1)\n  .plugin(mapreduce)\n  .plugin(replication);\n\nmodule.exports = PouchDB$3;\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(0)))\n\n/***/ }),\n/* 5 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\nmodule.exports = argsArray;\n\nfunction argsArray(fun) {\n  return function () {\n    var len = arguments.length;\n    if (len) {\n      var args = [];\n      var i = -1;\n      while (++i < len) {\n        args[i] = arguments[i];\n      }\n      return fun.call(this, args);\n    } else {\n      return fun.call(this, []);\n    }\n  };\n}\n\n/***/ }),\n/* 6 */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(process) {/**\n * This is the web browser implementation of `debug()`.\n *\n * Expose `debug()` as the module.\n */\n\nexports = module.exports = __webpack_require__(7);\nexports.log = log;\nexports.formatArgs = formatArgs;\nexports.save = save;\nexports.load = load;\nexports.useColors = useColors;\nexports.storage = 'undefined' != typeof chrome\n               && 'undefined' != typeof chrome.storage\n                  ? chrome.storage.local\n                  : localstorage();\n\n/**\n * Colors.\n */\n\nexports.colors = [\n  'lightseagreen',\n  'forestgreen',\n  'goldenrod',\n  'dodgerblue',\n  'darkorchid',\n  'crimson'\n];\n\n/**\n * Currently only WebKit-based Web Inspectors, Firefox >= v31,\n * and the Firebug extension (any Firefox version) are known\n * to support \"%c\" CSS customizations.\n *\n * TODO: add a `localStorage` variable to explicitly enable/disable colors\n */\n\nfunction useColors() {\n  // NB: In an Electron preload script, document will be defined but not fully\n  // initialized. Since we know we're in Chrome, we'll just detect this case\n  // explicitly\n  if (typeof window !== 'undefined' && window && typeof window.process !== 'undefined' && window.process.type === 'renderer') {\n    return true;\n  }\n\n  // is webkit? http://stackoverflow.com/a/16459606/376773\n  // document is undefined in react-native: https://github.com/facebook/react-native/pull/1632\n  return (typeof document !== 'undefined' && document && 'WebkitAppearance' in document.documentElement.style) ||\n    // is firebug? http://stackoverflow.com/a/398120/376773\n    (typeof window !== 'undefined' && window && window.console && (console.firebug || (console.exception && console.table))) ||\n    // is firefox >= v31?\n    // https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages\n    (typeof navigator !== 'undefined' && navigator && navigator.userAgent && navigator.userAgent.toLowerCase().match(/firefox\\/(\\d+)/) && parseInt(RegExp.$1, 10) >= 31) ||\n    // double check webkit in userAgent just in case we are in a worker\n    (typeof navigator !== 'undefined' && navigator && navigator.userAgent && navigator.userAgent.toLowerCase().match(/applewebkit\\/(\\d+)/));\n}\n\n/**\n * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.\n */\n\nexports.formatters.j = function(v) {\n  try {\n    return JSON.stringify(v);\n  } catch (err) {\n    return '[UnexpectedJSONParseError]: ' + err.message;\n  }\n};\n\n\n/**\n * Colorize log arguments if enabled.\n *\n * @api public\n */\n\nfunction formatArgs(args) {\n  var useColors = this.useColors;\n\n  args[0] = (useColors ? '%c' : '')\n    + this.namespace\n    + (useColors ? ' %c' : ' ')\n    + args[0]\n    + (useColors ? '%c ' : ' ')\n    + '+' + exports.humanize(this.diff);\n\n  if (!useColors) return;\n\n  var c = 'color: ' + this.color;\n  args.splice(1, 0, c, 'color: inherit')\n\n  // the final \"%c\" is somewhat tricky, because there could be other\n  // arguments passed either before or after the %c, so we need to\n  // figure out the correct index to insert the CSS into\n  var index = 0;\n  var lastC = 0;\n  args[0].replace(/%[a-zA-Z%]/g, function(match) {\n    if ('%%' === match) return;\n    index++;\n    if ('%c' === match) {\n      // we only are interested in the *last* %c\n      // (the user may have provided their own)\n      lastC = index;\n    }\n  });\n\n  args.splice(lastC, 0, c);\n}\n\n/**\n * Invokes `console.log()` when available.\n * No-op when `console.log` is not a \"function\".\n *\n * @api public\n */\n\nfunction log() {\n  // this hackery is required for IE8/9, where\n  // the `console.log` function doesn't have 'apply'\n  return 'object' === typeof console\n    && console.log\n    && Function.prototype.apply.call(console.log, console, arguments);\n}\n\n/**\n * Save `namespaces`.\n *\n * @param {String} namespaces\n * @api private\n */\n\nfunction save(namespaces) {\n  try {\n    if (null == namespaces) {\n      exports.storage.removeItem('debug');\n    } else {\n      exports.storage.debug = namespaces;\n    }\n  } catch(e) {}\n}\n\n/**\n * Load `namespaces`.\n *\n * @return {String} returns the previously persisted debug modes\n * @api private\n */\n\nfunction load() {\n  try {\n    return exports.storage.debug;\n  } catch(e) {}\n\n  // If debug isn't set in LS, and we're in Electron, try to load $DEBUG\n  if (typeof process !== 'undefined' && 'env' in process) {\n    return {\"NODE_ENV\":\"production\"}.DEBUG;\n  }\n}\n\n/**\n * Enable namespaces listed in `localStorage.debug` initially.\n */\n\nexports.enable(load());\n\n/**\n * Localstorage attempts to return the localstorage.\n *\n * This is necessary because safari throws\n * when a user disables cookies/localstorage\n * and you attempt to access it.\n *\n * @return {LocalStorage}\n * @api private\n */\n\nfunction localstorage() {\n  try {\n    return window.localStorage;\n  } catch (e) {}\n}\n\n/* WEBPACK VAR INJECTION */}.call(exports, __webpack_require__(12)))\n\n/***/ }),\n/* 7 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\n/**\n * This is the common logic for both the Node.js and web browser\n * implementations of `debug()`.\n *\n * Expose `debug()` as the module.\n */\n\nexports = module.exports = createDebug.debug = createDebug.default = createDebug;\nexports.coerce = coerce;\nexports.disable = disable;\nexports.enable = enable;\nexports.enabled = enabled;\nexports.humanize = __webpack_require__(11);\n\n/**\n * The currently active debug mode names, and names to skip.\n */\n\nexports.names = [];\nexports.skips = [];\n\n/**\n * Map of special \"%n\" handling functions, for the debug \"format\" argument.\n *\n * Valid key names are a single, lower or upper-case letter, i.e. \"n\" and \"N\".\n */\n\nexports.formatters = {};\n\n/**\n * Previous log timestamp.\n */\n\nvar prevTime;\n\n/**\n * Select a color.\n * @param {String} namespace\n * @return {Number}\n * @api private\n */\n\nfunction selectColor(namespace) {\n  var hash = 0, i;\n\n  for (i in namespace) {\n    hash  = ((hash << 5) - hash) + namespace.charCodeAt(i);\n    hash |= 0; // Convert to 32bit integer\n  }\n\n  return exports.colors[Math.abs(hash) % exports.colors.length];\n}\n\n/**\n * Create a debugger with the given `namespace`.\n *\n * @param {String} namespace\n * @return {Function}\n * @api public\n */\n\nfunction createDebug(namespace) {\n\n  function debug() {\n    // disabled?\n    if (!debug.enabled) return;\n\n    var self = debug;\n\n    // set `diff` timestamp\n    var curr = +new Date();\n    var ms = curr - (prevTime || curr);\n    self.diff = ms;\n    self.prev = prevTime;\n    self.curr = curr;\n    prevTime = curr;\n\n    // turn the `arguments` into a proper Array\n    var args = new Array(arguments.length);\n    for (var i = 0; i < args.length; i++) {\n      args[i] = arguments[i];\n    }\n\n    args[0] = exports.coerce(args[0]);\n\n    if ('string' !== typeof args[0]) {\n      // anything else let's inspect with %O\n      args.unshift('%O');\n    }\n\n    // apply any `formatters` transformations\n    var index = 0;\n    args[0] = args[0].replace(/%([a-zA-Z%])/g, function(match, format) {\n      // if we encounter an escaped % then don't increase the array index\n      if (match === '%%') return match;\n      index++;\n      var formatter = exports.formatters[format];\n      if ('function' === typeof formatter) {\n        var val = args[index];\n        match = formatter.call(self, val);\n\n        // now we need to remove `args[index]` since it's inlined in the `format`\n        args.splice(index, 1);\n        index--;\n      }\n      return match;\n    });\n\n    // apply env-specific formatting (colors, etc.)\n    exports.formatArgs.call(self, args);\n\n    var logFn = debug.log || exports.log || console.log.bind(console);\n    logFn.apply(self, args);\n  }\n\n  debug.namespace = namespace;\n  debug.enabled = exports.enabled(namespace);\n  debug.useColors = exports.useColors();\n  debug.color = selectColor(namespace);\n\n  // env-specific initialization logic for debug instances\n  if ('function' === typeof exports.init) {\n    exports.init(debug);\n  }\n\n  return debug;\n}\n\n/**\n * Enables a debug mode by namespaces. This can include modes\n * separated by a colon and wildcards.\n *\n * @param {String} namespaces\n * @api public\n */\n\nfunction enable(namespaces) {\n  exports.save(namespaces);\n\n  var split = (namespaces || '').split(/[\\s,]+/);\n  var len = split.length;\n\n  for (var i = 0; i < len; i++) {\n    if (!split[i]) continue; // ignore empty strings\n    namespaces = split[i].replace(/\\*/g, '.*?');\n    if (namespaces[0] === '-') {\n      exports.skips.push(new RegExp('^' + namespaces.substr(1) + '$'));\n    } else {\n      exports.names.push(new RegExp('^' + namespaces + '$'));\n    }\n  }\n}\n\n/**\n * Disable debug output.\n *\n * @api public\n */\n\nfunction disable() {\n  exports.enable('');\n}\n\n/**\n * Returns true if the given mode name is enabled, false otherwise.\n *\n * @param {String} name\n * @return {Boolean}\n * @api public\n */\n\nfunction enabled(name) {\n  var i, len;\n  for (i = 0, len = exports.skips.length; i < len; i++) {\n    if (exports.skips[i].test(name)) {\n      return false;\n    }\n  }\n  for (i = 0, len = exports.names.length; i < len; i++) {\n    if (exports.names[i].test(name)) {\n      return true;\n    }\n  }\n  return false;\n}\n\n/**\n * Coerce `val`.\n *\n * @param {Mixed} val\n * @return {Mixed}\n * @api private\n */\n\nfunction coerce(val) {\n  if (val instanceof Error) return val.stack || val.message;\n  return val;\n}\n\n\n/***/ }),\n/* 8 */\n/***/ (function(module, exports) {\n\n// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nfunction EventEmitter() {\n  this._events = this._events || {};\n  this._maxListeners = this._maxListeners || undefined;\n}\nmodule.exports = EventEmitter;\n\n// Backwards-compat with node 0.10.x\nEventEmitter.EventEmitter = EventEmitter;\n\nEventEmitter.prototype._events = undefined;\nEventEmitter.prototype._maxListeners = undefined;\n\n// By default EventEmitters will print a warning if more than 10 listeners are\n// added to it. This is a useful default which helps finding memory leaks.\nEventEmitter.defaultMaxListeners = 10;\n\n// Obviously not all Emitters should be limited to 10. This function allows\n// that to be increased. Set to zero for unlimited.\nEventEmitter.prototype.setMaxListeners = function(n) {\n  if (!isNumber(n) || n < 0 || isNaN(n))\n    throw TypeError('n must be a positive number');\n  this._maxListeners = n;\n  return this;\n};\n\nEventEmitter.prototype.emit = function(type) {\n  var er, handler, len, args, i, listeners;\n\n  if (!this._events)\n    this._events = {};\n\n  // If there is no 'error' event listener then throw.\n  if (type === 'error') {\n    if (!this._events.error ||\n        (isObject(this._events.error) && !this._events.error.length)) {\n      er = arguments[1];\n      if (er instanceof Error) {\n        throw er; // Unhandled 'error' event\n      } else {\n        // At least give some kind of context to the user\n        var err = new Error('Uncaught, unspecified \"error\" event. (' + er + ')');\n        err.context = er;\n        throw err;\n      }\n    }\n  }\n\n  handler = this._events[type];\n\n  if (isUndefined(handler))\n    return false;\n\n  if (isFunction(handler)) {\n    switch (arguments.length) {\n      // fast cases\n      case 1:\n        handler.call(this);\n        break;\n      case 2:\n        handler.call(this, arguments[1]);\n        break;\n      case 3:\n        handler.call(this, arguments[1], arguments[2]);\n        break;\n      // slower\n      default:\n        args = Array.prototype.slice.call(arguments, 1);\n        handler.apply(this, args);\n    }\n  } else if (isObject(handler)) {\n    args = Array.prototype.slice.call(arguments, 1);\n    listeners = handler.slice();\n    len = listeners.length;\n    for (i = 0; i < len; i++)\n      listeners[i].apply(this, args);\n  }\n\n  return true;\n};\n\nEventEmitter.prototype.addListener = function(type, listener) {\n  var m;\n\n  if (!isFunction(listener))\n    throw TypeError('listener must be a function');\n\n  if (!this._events)\n    this._events = {};\n\n  // To avoid recursion in the case that type === \"newListener\"! Before\n  // adding it to the listeners, first emit \"newListener\".\n  if (this._events.newListener)\n    this.emit('newListener', type,\n              isFunction(listener.listener) ?\n              listener.listener : listener);\n\n  if (!this._events[type])\n    // Optimize the case of one listener. Don't need the extra array object.\n    this._events[type] = listener;\n  else if (isObject(this._events[type]))\n    // If we've already got an array, just append.\n    this._events[type].push(listener);\n  else\n    // Adding the second element, need to change to array.\n    this._events[type] = [this._events[type], listener];\n\n  // Check for listener leak\n  if (isObject(this._events[type]) && !this._events[type].warned) {\n    if (!isUndefined(this._maxListeners)) {\n      m = this._maxListeners;\n    } else {\n      m = EventEmitter.defaultMaxListeners;\n    }\n\n    if (m && m > 0 && this._events[type].length > m) {\n      this._events[type].warned = true;\n      console.error('(node) warning: possible EventEmitter memory ' +\n                    'leak detected. %d listeners added. ' +\n                    'Use emitter.setMaxListeners() to increase limit.',\n                    this._events[type].length);\n      if (typeof console.trace === 'function') {\n        // not supported in IE 10\n        console.trace();\n      }\n    }\n  }\n\n  return this;\n};\n\nEventEmitter.prototype.on = EventEmitter.prototype.addListener;\n\nEventEmitter.prototype.once = function(type, listener) {\n  if (!isFunction(listener))\n    throw TypeError('listener must be a function');\n\n  var fired = false;\n\n  function g() {\n    this.removeListener(type, g);\n\n    if (!fired) {\n      fired = true;\n      listener.apply(this, arguments);\n    }\n  }\n\n  g.listener = listener;\n  this.on(type, g);\n\n  return this;\n};\n\n// emits a 'removeListener' event iff the listener was removed\nEventEmitter.prototype.removeListener = function(type, listener) {\n  var list, position, length, i;\n\n  if (!isFunction(listener))\n    throw TypeError('listener must be a function');\n\n  if (!this._events || !this._events[type])\n    return this;\n\n  list = this._events[type];\n  length = list.length;\n  position = -1;\n\n  if (list === listener ||\n      (isFunction(list.listener) && list.listener === listener)) {\n    delete this._events[type];\n    if (this._events.removeListener)\n      this.emit('removeListener', type, listener);\n\n  } else if (isObject(list)) {\n    for (i = length; i-- > 0;) {\n      if (list[i] === listener ||\n          (list[i].listener && list[i].listener === listener)) {\n        position = i;\n        break;\n      }\n    }\n\n    if (position < 0)\n      return this;\n\n    if (list.length === 1) {\n      list.length = 0;\n      delete this._events[type];\n    } else {\n      list.splice(position, 1);\n    }\n\n    if (this._events.removeListener)\n      this.emit('removeListener', type, listener);\n  }\n\n  return this;\n};\n\nEventEmitter.prototype.removeAllListeners = function(type) {\n  var key, listeners;\n\n  if (!this._events)\n    return this;\n\n  // not listening for removeListener, no need to emit\n  if (!this._events.removeListener) {\n    if (arguments.length === 0)\n      this._events = {};\n    else if (this._events[type])\n      delete this._events[type];\n    return this;\n  }\n\n  // emit removeListener for all listeners on all events\n  if (arguments.length === 0) {\n    for (key in this._events) {\n      if (key === 'removeListener') continue;\n      this.removeAllListeners(key);\n    }\n    this.removeAllListeners('removeListener');\n    this._events = {};\n    return this;\n  }\n\n  listeners = this._events[type];\n\n  if (isFunction(listeners)) {\n    this.removeListener(type, listeners);\n  } else if (listeners) {\n    // LIFO order\n    while (listeners.length)\n      this.removeListener(type, listeners[listeners.length - 1]);\n  }\n  delete this._events[type];\n\n  return this;\n};\n\nEventEmitter.prototype.listeners = function(type) {\n  var ret;\n  if (!this._events || !this._events[type])\n    ret = [];\n  else if (isFunction(this._events[type]))\n    ret = [this._events[type]];\n  else\n    ret = this._events[type].slice();\n  return ret;\n};\n\nEventEmitter.prototype.listenerCount = function(type) {\n  if (this._events) {\n    var evlistener = this._events[type];\n\n    if (isFunction(evlistener))\n      return 1;\n    else if (evlistener)\n      return evlistener.length;\n  }\n  return 0;\n};\n\nEventEmitter.listenerCount = function(emitter, type) {\n  return emitter.listenerCount(type);\n};\n\nfunction isFunction(arg) {\n  return typeof arg === 'function';\n}\n\nfunction isNumber(arg) {\n  return typeof arg === 'number';\n}\n\nfunction isObject(arg) {\n  return typeof arg === 'object' && arg !== null;\n}\n\nfunction isUndefined(arg) {\n  return arg === void 0;\n}\n\n\n/***/ }),\n/* 9 */\n/***/ (function(module, exports) {\n\nif (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    ctor.prototype = Object.create(superCtor.prototype, {\n      constructor: {\n        value: ctor,\n        enumerable: false,\n        writable: true,\n        configurable: true\n      }\n    });\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    var TempCtor = function () {}\n    TempCtor.prototype = superCtor.prototype\n    ctor.prototype = new TempCtor()\n    ctor.prototype.constructor = ctor\n  }\n}\n\n\n/***/ }),\n/* 10 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\nvar immediate = __webpack_require__(2);\n\n/* istanbul ignore next */\nfunction INTERNAL() {}\n\nvar handlers = {};\n\nvar REJECTED = ['REJECTED'];\nvar FULFILLED = ['FULFILLED'];\nvar PENDING = ['PENDING'];\n\nmodule.exports = Promise;\n\nfunction Promise(resolver) {\n  if (typeof resolver !== 'function') {\n    throw new TypeError('resolver must be a function');\n  }\n  this.state = PENDING;\n  this.queue = [];\n  this.outcome = void 0;\n  if (resolver !== INTERNAL) {\n    safelyResolveThenable(this, resolver);\n  }\n}\n\nPromise.prototype[\"catch\"] = function (onRejected) {\n  return this.then(null, onRejected);\n};\nPromise.prototype.then = function (onFulfilled, onRejected) {\n  if (typeof onFulfilled !== 'function' && this.state === FULFILLED ||\n    typeof onRejected !== 'function' && this.state === REJECTED) {\n    return this;\n  }\n  var promise = new this.constructor(INTERNAL);\n  if (this.state !== PENDING) {\n    var resolver = this.state === FULFILLED ? onFulfilled : onRejected;\n    unwrap(promise, resolver, this.outcome);\n  } else {\n    this.queue.push(new QueueItem(promise, onFulfilled, onRejected));\n  }\n\n  return promise;\n};\nfunction QueueItem(promise, onFulfilled, onRejected) {\n  this.promise = promise;\n  if (typeof onFulfilled === 'function') {\n    this.onFulfilled = onFulfilled;\n    this.callFulfilled = this.otherCallFulfilled;\n  }\n  if (typeof onRejected === 'function') {\n    this.onRejected = onRejected;\n    this.callRejected = this.otherCallRejected;\n  }\n}\nQueueItem.prototype.callFulfilled = function (value) {\n  handlers.resolve(this.promise, value);\n};\nQueueItem.prototype.otherCallFulfilled = function (value) {\n  unwrap(this.promise, this.onFulfilled, value);\n};\nQueueItem.prototype.callRejected = function (value) {\n  handlers.reject(this.promise, value);\n};\nQueueItem.prototype.otherCallRejected = function (value) {\n  unwrap(this.promise, this.onRejected, value);\n};\n\nfunction unwrap(promise, func, value) {\n  immediate(function () {\n    var returnValue;\n    try {\n      returnValue = func(value);\n    } catch (e) {\n      return handlers.reject(promise, e);\n    }\n    if (returnValue === promise) {\n      handlers.reject(promise, new TypeError('Cannot resolve promise with itself'));\n    } else {\n      handlers.resolve(promise, returnValue);\n    }\n  });\n}\n\nhandlers.resolve = function (self, value) {\n  var result = tryCatch(getThen, value);\n  if (result.status === 'error') {\n    return handlers.reject(self, result.value);\n  }\n  var thenable = result.value;\n\n  if (thenable) {\n    safelyResolveThenable(self, thenable);\n  } else {\n    self.state = FULFILLED;\n    self.outcome = value;\n    var i = -1;\n    var len = self.queue.length;\n    while (++i < len) {\n      self.queue[i].callFulfilled(value);\n    }\n  }\n  return self;\n};\nhandlers.reject = function (self, error) {\n  self.state = REJECTED;\n  self.outcome = error;\n  var i = -1;\n  var len = self.queue.length;\n  while (++i < len) {\n    self.queue[i].callRejected(error);\n  }\n  return self;\n};\n\nfunction getThen(obj) {\n  // Make sure we only access the accessor once as required by the spec\n  var then = obj && obj.then;\n  if (obj && typeof obj === 'object' && typeof then === 'function') {\n    return function appyThen() {\n      then.apply(obj, arguments);\n    };\n  }\n}\n\nfunction safelyResolveThenable(self, thenable) {\n  // Either fulfill, reject or reject with error\n  var called = false;\n  function onError(value) {\n    if (called) {\n      return;\n    }\n    called = true;\n    handlers.reject(self, value);\n  }\n\n  function onSuccess(value) {\n    if (called) {\n      return;\n    }\n    called = true;\n    handlers.resolve(self, value);\n  }\n\n  function tryToUnwrap() {\n    thenable(onSuccess, onError);\n  }\n\n  var result = tryCatch(tryToUnwrap);\n  if (result.status === 'error') {\n    onError(result.value);\n  }\n}\n\nfunction tryCatch(func, value) {\n  var out = {};\n  try {\n    out.value = func(value);\n    out.status = 'success';\n  } catch (e) {\n    out.status = 'error';\n    out.value = e;\n  }\n  return out;\n}\n\nPromise.resolve = resolve;\nfunction resolve(value) {\n  if (value instanceof this) {\n    return value;\n  }\n  return handlers.resolve(new this(INTERNAL), value);\n}\n\nPromise.reject = reject;\nfunction reject(reason) {\n  var promise = new this(INTERNAL);\n  return handlers.reject(promise, reason);\n}\n\nPromise.all = all;\nfunction all(iterable) {\n  var self = this;\n  if (Object.prototype.toString.call(iterable) !== '[object Array]') {\n    return this.reject(new TypeError('must be an array'));\n  }\n\n  var len = iterable.length;\n  var called = false;\n  if (!len) {\n    return this.resolve([]);\n  }\n\n  var values = new Array(len);\n  var resolved = 0;\n  var i = -1;\n  var promise = new this(INTERNAL);\n\n  while (++i < len) {\n    allResolver(iterable[i], i);\n  }\n  return promise;\n  function allResolver(value, i) {\n    self.resolve(value).then(resolveFromAll, function (error) {\n      if (!called) {\n        called = true;\n        handlers.reject(promise, error);\n      }\n    });\n    function resolveFromAll(outValue) {\n      values[i] = outValue;\n      if (++resolved === len && !called) {\n        called = true;\n        handlers.resolve(promise, values);\n      }\n    }\n  }\n}\n\nPromise.race = race;\nfunction race(iterable) {\n  var self = this;\n  if (Object.prototype.toString.call(iterable) !== '[object Array]') {\n    return this.reject(new TypeError('must be an array'));\n  }\n\n  var len = iterable.length;\n  var called = false;\n  if (!len) {\n    return this.resolve([]);\n  }\n\n  var i = -1;\n  var promise = new this(INTERNAL);\n\n  while (++i < len) {\n    resolver(iterable[i]);\n  }\n  return promise;\n  function resolver(value) {\n    self.resolve(value).then(function (response) {\n      if (!called) {\n        called = true;\n        handlers.resolve(promise, response);\n      }\n    }, function (error) {\n      if (!called) {\n        called = true;\n        handlers.reject(promise, error);\n      }\n    });\n  }\n}\n\n\n/***/ }),\n/* 11 */\n/***/ (function(module, exports) {\n\n/**\n * Helpers.\n */\n\nvar s = 1000\nvar m = s * 60\nvar h = m * 60\nvar d = h * 24\nvar y = d * 365.25\n\n/**\n * Parse or format the given `val`.\n *\n * Options:\n *\n *  - `long` verbose formatting [false]\n *\n * @param {String|Number} val\n * @param {Object} options\n * @throws {Error} throw an error if val is not a non-empty string or a number\n * @return {String|Number}\n * @api public\n */\n\nmodule.exports = function (val, options) {\n  options = options || {}\n  var type = typeof val\n  if (type === 'string' && val.length > 0) {\n    return parse(val)\n  } else if (type === 'number' && isNaN(val) === false) {\n    return options.long ?\n\t\t\tfmtLong(val) :\n\t\t\tfmtShort(val)\n  }\n  throw new Error('val is not a non-empty string or a valid number. val=' + JSON.stringify(val))\n}\n\n/**\n * Parse the given `str` and return milliseconds.\n *\n * @param {String} str\n * @return {Number}\n * @api private\n */\n\nfunction parse(str) {\n  str = String(str)\n  if (str.length > 10000) {\n    return\n  }\n  var match = /^((?:\\d+)?\\.?\\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|years?|yrs?|y)?$/i.exec(str)\n  if (!match) {\n    return\n  }\n  var n = parseFloat(match[1])\n  var type = (match[2] || 'ms').toLowerCase()\n  switch (type) {\n    case 'years':\n    case 'year':\n    case 'yrs':\n    case 'yr':\n    case 'y':\n      return n * y\n    case 'days':\n    case 'day':\n    case 'd':\n      return n * d\n    case 'hours':\n    case 'hour':\n    case 'hrs':\n    case 'hr':\n    case 'h':\n      return n * h\n    case 'minutes':\n    case 'minute':\n    case 'mins':\n    case 'min':\n    case 'm':\n      return n * m\n    case 'seconds':\n    case 'second':\n    case 'secs':\n    case 'sec':\n    case 's':\n      return n * s\n    case 'milliseconds':\n    case 'millisecond':\n    case 'msecs':\n    case 'msec':\n    case 'ms':\n      return n\n    default:\n      return undefined\n  }\n}\n\n/**\n * Short format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtShort(ms) {\n  if (ms >= d) {\n    return Math.round(ms / d) + 'd'\n  }\n  if (ms >= h) {\n    return Math.round(ms / h) + 'h'\n  }\n  if (ms >= m) {\n    return Math.round(ms / m) + 'm'\n  }\n  if (ms >= s) {\n    return Math.round(ms / s) + 's'\n  }\n  return ms + 'ms'\n}\n\n/**\n * Long format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtLong(ms) {\n  return plural(ms, d, 'day') ||\n    plural(ms, h, 'hour') ||\n    plural(ms, m, 'minute') ||\n    plural(ms, s, 'second') ||\n    ms + ' ms'\n}\n\n/**\n * Pluralization helper.\n */\n\nfunction plural(ms, n, name) {\n  if (ms < n) {\n    return\n  }\n  if (ms < n * 1.5) {\n    return Math.floor(ms / n) + ' ' + name\n  }\n  return Math.ceil(ms / n) + ' ' + name + 's'\n}\n\n\n/***/ }),\n/* 12 */\n/***/ (function(module, exports) {\n\n// shim for using process in browser\nvar process = module.exports = {};\n\n// cached from whatever global is present so that test runners that stub it\n// don't break things.  But we need to wrap it in a try catch in case it is\n// wrapped in strict mode code which doesn't define any globals.  It's inside a\n// function because try/catches deoptimize in certain engines.\n\nvar cachedSetTimeout;\nvar cachedClearTimeout;\n\nfunction defaultSetTimout() {\n    throw new Error('setTimeout has not been defined');\n}\nfunction defaultClearTimeout () {\n    throw new Error('clearTimeout has not been defined');\n}\n(function () {\n    try {\n        if (typeof setTimeout === 'function') {\n            cachedSetTimeout = setTimeout;\n        } else {\n            cachedSetTimeout = defaultSetTimout;\n        }\n    } catch (e) {\n        cachedSetTimeout = defaultSetTimout;\n    }\n    try {\n        if (typeof clearTimeout === 'function') {\n            cachedClearTimeout = clearTimeout;\n        } else {\n            cachedClearTimeout = defaultClearTimeout;\n        }\n    } catch (e) {\n        cachedClearTimeout = defaultClearTimeout;\n    }\n} ())\nfunction runTimeout(fun) {\n    if (cachedSetTimeout === setTimeout) {\n        //normal enviroments in sane situations\n        return setTimeout(fun, 0);\n    }\n    // if setTimeout wasn't available but was latter defined\n    if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {\n        cachedSetTimeout = setTimeout;\n        return setTimeout(fun, 0);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedSetTimeout(fun, 0);\n    } catch(e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally\n            return cachedSetTimeout.call(null, fun, 0);\n        } catch(e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error\n            return cachedSetTimeout.call(this, fun, 0);\n        }\n    }\n\n\n}\nfunction runClearTimeout(marker) {\n    if (cachedClearTimeout === clearTimeout) {\n        //normal enviroments in sane situations\n        return clearTimeout(marker);\n    }\n    // if clearTimeout wasn't available but was latter defined\n    if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {\n        cachedClearTimeout = clearTimeout;\n        return clearTimeout(marker);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedClearTimeout(marker);\n    } catch (e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally\n            return cachedClearTimeout.call(null, marker);\n        } catch (e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.\n            // Some versions of I.E. have different rules for clearTimeout vs setTimeout\n            return cachedClearTimeout.call(this, marker);\n        }\n    }\n\n\n\n}\nvar queue = [];\nvar draining = false;\nvar currentQueue;\nvar queueIndex = -1;\n\nfunction cleanUpNextTick() {\n    if (!draining || !currentQueue) {\n        return;\n    }\n    draining = false;\n    if (currentQueue.length) {\n        queue = currentQueue.concat(queue);\n    } else {\n        queueIndex = -1;\n    }\n    if (queue.length) {\n        drainQueue();\n    }\n}\n\nfunction drainQueue() {\n    if (draining) {\n        return;\n    }\n    var timeout = runTimeout(cleanUpNextTick);\n    draining = true;\n\n    var len = queue.length;\n    while(len) {\n        currentQueue = queue;\n        queue = [];\n        while (++queueIndex < len) {\n            if (currentQueue) {\n                currentQueue[queueIndex].run();\n            }\n        }\n        queueIndex = -1;\n        len = queue.length;\n    }\n    currentQueue = null;\n    draining = false;\n    runClearTimeout(timeout);\n}\n\nprocess.nextTick = function (fun) {\n    var args = new Array(arguments.length - 1);\n    if (arguments.length > 1) {\n        for (var i = 1; i < arguments.length; i++) {\n            args[i - 1] = arguments[i];\n        }\n    }\n    queue.push(new Item(fun, args));\n    if (queue.length === 1 && !draining) {\n        runTimeout(drainQueue);\n    }\n};\n\n// v8 likes predictible objects\nfunction Item(fun, array) {\n    this.fun = fun;\n    this.array = array;\n}\nItem.prototype.run = function () {\n    this.fun.apply(null, this.array);\n};\nprocess.title = 'browser';\nprocess.browser = true;\nprocess.env = {};\nprocess.argv = [];\nprocess.version = ''; // empty string to avoid regexp issues\nprocess.versions = {};\n\nfunction noop() {}\n\nprocess.on = noop;\nprocess.addListener = noop;\nprocess.once = noop;\nprocess.off = noop;\nprocess.removeListener = noop;\nprocess.removeAllListeners = noop;\nprocess.emit = noop;\n\nprocess.binding = function (name) {\n    throw new Error('process.binding is not supported');\n};\n\nprocess.cwd = function () { return '/' };\nprocess.chdir = function (dir) {\n    throw new Error('process.chdir is not supported');\n};\nprocess.umask = function() { return 0; };\n\n\n/***/ }),\n/* 13 */\n/***/ (function(module, exports) {\n\n// Generated by CoffeeScript 1.9.2\n(function() {\n  var hasProp = {}.hasOwnProperty,\n    slice = [].slice;\n\n  module.exports = function(source, scope) {\n    var key, keys, value, values;\n    keys = [];\n    values = [];\n    for (key in scope) {\n      if (!hasProp.call(scope, key)) continue;\n      value = scope[key];\n      if (key === 'this') {\n        continue;\n      }\n      keys.push(key);\n      values.push(value);\n    }\n    return Function.apply(null, slice.call(keys).concat([source])).apply(scope[\"this\"], values);\n  };\n\n}).call(this);\n\n\n/***/ }),\n/* 14 */\n/***/ (function(module, exports) {\n\n/*\n * Sift 3.x\n *\n * Copryright 2015, Craig Condon\n * Licensed under MIT\n *\n * Filter JavaScript objects with mongodb queries\n */\n\n(function() {\n\n  'use strict';\n\n  /**\n   */\n\n  function isFunction(value) {\n    return typeof value === 'function';\n  }\n\n  /**\n   */\n\n  function isArray(value) {\n    return Object.prototype.toString.call(value) === '[object Array]';\n  }\n\n  /**\n   */\n\n  function comparable(value) {\n    if (value instanceof Date) {\n      return value.getTime();\n    } else if (value instanceof Array) {\n      return value.map(comparable);\n    } else {\n      return value;\n    }\n  }\n\n  function get(obj, key) {\n    if (obj.get) return obj.get(key);\n    return obj[key];\n  }\n\n  /**\n   */\n\n  function or(validator) {\n    return function(a, b) {\n      if (!isArray(b) || !b.length) return validator(a, b);\n      for (var i = 0, n = b.length; i < n; i++) if (validator(a, get(b,i))) return true;\n      return false;\n    }\n  }\n\n  /**\n   */\n\n  function and(validator) {\n    return function(a, b) {\n      if (!isArray(b) || !b.length) return validator(a, b);\n      for (var i = 0, n = b.length; i < n; i++) if (!validator(a, get(b, i))) return false;\n      return true;\n    };\n  }\n\n  function validate(validator, b) {\n    return validator.v(validator.a, b);\n  }\n\n  var operator = {\n\n    /**\n     */\n\n    $eq: or(function(a, b) {\n      return a(b);\n    }),\n\n    /**\n     */\n\n    $ne: and(function(a, b) {\n      return !a(b);\n    }),\n\n    /**\n     */\n\n    $or: function(a, b) {\n      for (var i = 0, n = a.length; i < n; i++) if (validate(get(a, i), b)) return true;\n      return false;\n    },\n\n    /**\n     */\n\n    $gt: or(function(a, b) {\n      return sift.compare(comparable(b), a) > 0;\n    }),\n\n    /**\n     */\n\n    $gte: or(function(a, b) {\n      return sift.compare(comparable(b), a) >= 0;\n    }),\n\n    /**\n     */\n\n    $lt: or(function(a, b) {\n      return sift.compare(comparable(b), a) < 0;\n    }),\n\n    /**\n     */\n\n    $lte: or(function(a, b) {\n      return sift.compare(comparable(b), a) <= 0;\n    }),\n\n    /**\n     */\n\n    $mod: or(function(a, b) {\n      return b % a[0] == a[1];\n    }),\n\n    /**\n     */\n\n    $in: function(a, b) {\n\n      if (b instanceof Array) {\n        for (var i = b.length; i--;) {\n          if (~a.indexOf(comparable(get(b, i)))) return true;\n        }\n      } else {\n        return !!~a.indexOf(comparable(b));\n      }\n\n      return false;\n    },\n\n    /**\n     */\n\n    $nin: function(a, b) {\n      return !operator.$in(a, b);\n    },\n\n    /**\n     */\n\n    $not: function(a, b) {\n      return !validate(a, b);\n    },\n\n    /**\n     */\n\n    $type: function(a, b) {\n      return b != void 0 ? b instanceof a || b.constructor == a : false;\n     },\n\n    /**\n     */\n\n    $all: function(a, b) {\n      return operator.$and(a, b);\n    },\n\n    /**\n     */\n\n    $size: function(a, b) {\n      return b ? a === b.length : false;\n    },\n\n    /**\n     */\n\n    $nor: function(a, b) {\n      // todo - this suffice? return !operator.$in(a)\n      for (var i = 0, n = a.length; i < n; i++) if (validate(get(a, i), b)) return false;\n      return true;\n    },\n\n    /**\n     */\n\n    $and: function(a, b) {\n      if (!b) b = [];\n      for (var i = 0, n = a.length; i < n; i++) if (!validate(get(a, i), b)) return false;\n      return true;\n    },\n\n    /**\n     */\n\n    $regex: or(function(a, b) {\n      return typeof b === 'string' && a.test(b);\n    }),\n\n    /**\n     */\n\n    $where: function(a, b) {\n      return a.call(b, b);\n    },\n\n    /**\n     */\n\n    $elemMatch: function(a, b) {\n      if (isArray(b)) return !!~search(b, a);\n      return validate(a, b);\n    },\n\n    /**\n     */\n\n    $exists: function(a, b) {\n      return (b != void 0) === a;\n    }\n  };\n\n  /**\n   */\n\n  var prepare = {\n\n    /**\n     */\n\n    $eq: function(a) {\n\n      if (a instanceof RegExp) {\n        return function(b) {\n          return typeof b === 'string' && a.test(b);\n        };\n      } else if (a instanceof Function) {\n        return a;\n      } else if (isArray(a) && !a.length) {\n        // Special case of a == []\n        return function(b) {\n          return (isArray(b) && !b.length);\n        };\n      } else if (a === null){\n        return function(b){\n          //will match both null and undefined\n          return b == null;\n        }\n      }\n\n      return function(b) {\n        return sift.compare(comparable(b), a) === 0;\n      };\n    },\n\n    /**\n     */\n\n    $ne: function(a) {\n      return prepare.$eq(a);\n    },\n\n    /**\n     */\n\n    $and: function(a) {\n      return a.map(parse);\n    },\n\n    /**\n     */\n\n    $all: function(a) {\n      return prepare.$and(a);\n    },\n\n    /**\n     */\n\n    $or: function(a) {\n      return a.map(parse);\n    },\n\n    /**\n     */\n\n    $nor: function(a) {\n      return a.map(parse);\n    },\n\n    /**\n     */\n\n    $not: function(a) {\n      return parse(a);\n    },\n\n    /**\n     */\n\n    $regex: function(a, query) {\n      return new RegExp(a, query.$options);\n    },\n\n    /**\n     */\n\n    $where: function(a) {\n      return typeof a === 'string' ? new Function('obj', 'return ' + a) : a;\n    },\n\n    /**\n     */\n\n    $elemMatch: function(a) {\n      return parse(a);\n    },\n\n    /**\n     */\n\n    $exists: function(a) {\n      return !!a;\n    }\n  };\n\n  /**\n   */\n\n  function search(array, validator) {\n\n    for (var i = 0; i < array.length; i++) {\n      if (validate(validator, get(array, i))) {\n        return i;\n      }\n    }\n\n    return -1;\n  }\n\n  /**\n   */\n\n  function createValidator(a, validate) {\n    return { a: a, v: validate };\n  }\n\n  /**\n   */\n\n  function nestedValidator(a, b) {\n    var values  = [];\n    findValues(b, a.k, 0, values);\n\n    if (values.length === 1) {\n      return validate(a.nv, values[0]);\n    }\n\n    return !!~search(values, a.nv);\n  }\n\n  /**\n   */\n\n  function findValues(current, keypath, index, values) {\n\n    if (index === keypath.length || current == void 0) {\n      values.push(current);\n      return;\n    }\n\n    var k = get(keypath, index);\n\n    // ensure that if current is an array, that the current key\n    // is NOT an array index. This sort of thing needs to work:\n    // sift({'foo.0':42}, [{foo: [42]}]);\n    if (isArray(current) && isNaN(Number(k))) {\n      for (var i = 0, n = current.length; i < n; i++) {\n        findValues(get(current, i), keypath, index, values);\n      }\n    } else {\n      findValues(get(current, k), keypath, index + 1, values);\n    }\n  }\n\n  /**\n   */\n\n  function createNestedValidator(keypath, a) {\n    return { a: { k: keypath, nv: a }, v: nestedValidator };\n  }\n\n  /**\n   * flatten the query\n   */\n\n  function parse(query) {\n    query = comparable(query);\n\n    if (!query || (query.constructor.toString() !== 'Object' &&\n        query.constructor.toString().replace(/\\n/g,'').replace(/ /g, '') !== 'functionObject(){[nativecode]}')) { // cross browser support\n      query = { $eq: query };\n    }\n\n    var validators = [];\n\n    for (var key in query) {\n      var a = query[key];\n\n      if (key === '$options') continue;\n\n      if (operator[key]) {\n        if (prepare[key]) a = prepare[key](a, query);\n        validators.push(createValidator(comparable(a), operator[key]));\n      } else {\n\n        if (key.charCodeAt(0) === 36) {\n          throw new Error('Unknown operation ' + key);\n        }\n\n        validators.push(createNestedValidator(key.split('.'), parse(a)));\n      }\n    }\n\n    return validators.length === 1 ? validators[0] : createValidator(validators, operator.$and);\n  }\n\n  /**\n   */\n\n  function createRootValidator(query, getter) {\n    var validator = parse(query);\n    if (getter) {\n      validator = {\n        a: validator,\n        v: function(a, b) {\n          return validate(a, getter(b));\n        }\n      };\n    }\n    return validator;\n  }\n\n  /**\n   */\n\n  function sift(query, array, getter) {\n\n    if (isFunction(array)) {\n      getter = array;\n      array  = void 0;\n    }\n\n    var validator = createRootValidator(query, getter);\n\n    function filter(b) {\n      return validate(validator, b);\n    }\n\n    if (array) {\n      return array.filter(filter);\n    }\n\n    return filter;\n  }\n\n  /**\n   */\n\n  sift.use = function(plugin) {\n    if (isFunction(plugin)) return plugin(sift);\n    for (var key in plugin) {\n      if (key.charCodeAt(0) === 36) operator[key] = plugin[key];\n    }\n  };\n\n  /**\n   */\n\n  sift.indexOf = function(query, array, getter) {\n    return search(array, createRootValidator(query, getter));\n  };\n\n  /**\n   */\n\n  sift.compare = function(a, b) {\n    if(a===b) return 0;\n    if(typeof a === typeof b) {\n      if (a > b) return 1;\n      if (a < b) return -1;\n    }\n  };\n\n  /* istanbul ignore next */\n  if (typeof module !== 'undefined' && typeof module.exports !== 'undefined') {\n    module.exports = sift;\n  }\n\n  if (typeof window !== 'undefined') {\n    window.sift = sift;\n  }\n})();\n\n\n/***/ }),\n/* 15 */\n/***/ (function(module, exports, __webpack_require__) {\n\n(function (factory) {\n    if (true) {\n        // Node/CommonJS\n        module.exports = factory();\n    } else if (typeof define === 'function' && define.amd) {\n        // AMD\n        define(factory);\n    } else {\n        // Browser globals (with support for web workers)\n        var glob;\n\n        try {\n            glob = window;\n        } catch (e) {\n            glob = self;\n        }\n\n        glob.SparkMD5 = factory();\n    }\n}(function (undefined) {\n\n    'use strict';\n\n    /*\n     * Fastest md5 implementation around (JKM md5).\n     * Credits: Joseph Myers\n     *\n     * @see http://www.myersdaily.org/joseph/javascript/md5-text.html\n     * @see http://jsperf.com/md5-shootout/7\n     */\n\n    /* this function is much faster,\n      so if possible we use it. Some IEs\n      are the only ones I know of that\n      need the idiotic second function,\n      generated by an if clause.  */\n    var add32 = function (a, b) {\n        return (a + b) & 0xFFFFFFFF;\n    },\n        hex_chr = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f'];\n\n\n    function cmn(q, a, b, x, s, t) {\n        a = add32(add32(a, q), add32(x, t));\n        return add32((a << s) | (a >>> (32 - s)), b);\n    }\n\n    function md5cycle(x, k) {\n        var a = x[0],\n            b = x[1],\n            c = x[2],\n            d = x[3];\n\n        a += (b & c | ~b & d) + k[0] - 680876936 | 0;\n        a  = (a << 7 | a >>> 25) + b | 0;\n        d += (a & b | ~a & c) + k[1] - 389564586 | 0;\n        d  = (d << 12 | d >>> 20) + a | 0;\n        c += (d & a | ~d & b) + k[2] + 606105819 | 0;\n        c  = (c << 17 | c >>> 15) + d | 0;\n        b += (c & d | ~c & a) + k[3] - 1044525330 | 0;\n        b  = (b << 22 | b >>> 10) + c | 0;\n        a += (b & c | ~b & d) + k[4] - 176418897 | 0;\n        a  = (a << 7 | a >>> 25) + b | 0;\n        d += (a & b | ~a & c) + k[5] + 1200080426 | 0;\n        d  = (d << 12 | d >>> 20) + a | 0;\n        c += (d & a | ~d & b) + k[6] - 1473231341 | 0;\n        c  = (c << 17 | c >>> 15) + d | 0;\n        b += (c & d | ~c & a) + k[7] - 45705983 | 0;\n        b  = (b << 22 | b >>> 10) + c | 0;\n        a += (b & c | ~b & d) + k[8] + 1770035416 | 0;\n        a  = (a << 7 | a >>> 25) + b | 0;\n        d += (a & b | ~a & c) + k[9] - 1958414417 | 0;\n        d  = (d << 12 | d >>> 20) + a | 0;\n        c += (d & a | ~d & b) + k[10] - 42063 | 0;\n        c  = (c << 17 | c >>> 15) + d | 0;\n        b += (c & d | ~c & a) + k[11] - 1990404162 | 0;\n        b  = (b << 22 | b >>> 10) + c | 0;\n        a += (b & c | ~b & d) + k[12] + 1804603682 | 0;\n        a  = (a << 7 | a >>> 25) + b | 0;\n        d += (a & b | ~a & c) + k[13] - 40341101 | 0;\n        d  = (d << 12 | d >>> 20) + a | 0;\n        c += (d & a | ~d & b) + k[14] - 1502002290 | 0;\n        c  = (c << 17 | c >>> 15) + d | 0;\n        b += (c & d | ~c & a) + k[15] + 1236535329 | 0;\n        b  = (b << 22 | b >>> 10) + c | 0;\n\n        a += (b & d | c & ~d) + k[1] - 165796510 | 0;\n        a  = (a << 5 | a >>> 27) + b | 0;\n        d += (a & c | b & ~c) + k[6] - 1069501632 | 0;\n        d  = (d << 9 | d >>> 23) + a | 0;\n        c += (d & b | a & ~b) + k[11] + 643717713 | 0;\n        c  = (c << 14 | c >>> 18) + d | 0;\n        b += (c & a | d & ~a) + k[0] - 373897302 | 0;\n        b  = (b << 20 | b >>> 12) + c | 0;\n        a += (b & d | c & ~d) + k[5] - 701558691 | 0;\n        a  = (a << 5 | a >>> 27) + b | 0;\n        d += (a & c | b & ~c) + k[10] + 38016083 | 0;\n        d  = (d << 9 | d >>> 23) + a | 0;\n        c += (d & b | a & ~b) + k[15] - 660478335 | 0;\n        c  = (c << 14 | c >>> 18) + d | 0;\n        b += (c & a | d & ~a) + k[4] - 405537848 | 0;\n        b  = (b << 20 | b >>> 12) + c | 0;\n        a += (b & d | c & ~d) + k[9] + 568446438 | 0;\n        a  = (a << 5 | a >>> 27) + b | 0;\n        d += (a & c | b & ~c) + k[14] - 1019803690 | 0;\n        d  = (d << 9 | d >>> 23) + a | 0;\n        c += (d & b | a & ~b) + k[3] - 187363961 | 0;\n        c  = (c << 14 | c >>> 18) + d | 0;\n        b += (c & a | d & ~a) + k[8] + 1163531501 | 0;\n        b  = (b << 20 | b >>> 12) + c | 0;\n        a += (b & d | c & ~d) + k[13] - 1444681467 | 0;\n        a  = (a << 5 | a >>> 27) + b | 0;\n        d += (a & c | b & ~c) + k[2] - 51403784 | 0;\n        d  = (d << 9 | d >>> 23) + a | 0;\n        c += (d & b | a & ~b) + k[7] + 1735328473 | 0;\n        c  = (c << 14 | c >>> 18) + d | 0;\n        b += (c & a | d & ~a) + k[12] - 1926607734 | 0;\n        b  = (b << 20 | b >>> 12) + c | 0;\n\n        a += (b ^ c ^ d) + k[5] - 378558 | 0;\n        a  = (a << 4 | a >>> 28) + b | 0;\n        d += (a ^ b ^ c) + k[8] - 2022574463 | 0;\n        d  = (d << 11 | d >>> 21) + a | 0;\n        c += (d ^ a ^ b) + k[11] + 1839030562 | 0;\n        c  = (c << 16 | c >>> 16) + d | 0;\n        b += (c ^ d ^ a) + k[14] - 35309556 | 0;\n        b  = (b << 23 | b >>> 9) + c | 0;\n        a += (b ^ c ^ d) + k[1] - 1530992060 | 0;\n        a  = (a << 4 | a >>> 28) + b | 0;\n        d += (a ^ b ^ c) + k[4] + 1272893353 | 0;\n        d  = (d << 11 | d >>> 21) + a | 0;\n        c += (d ^ a ^ b) + k[7] - 155497632 | 0;\n        c  = (c << 16 | c >>> 16) + d | 0;\n        b += (c ^ d ^ a) + k[10] - 1094730640 | 0;\n        b  = (b << 23 | b >>> 9) + c | 0;\n        a += (b ^ c ^ d) + k[13] + 681279174 | 0;\n        a  = (a << 4 | a >>> 28) + b | 0;\n        d += (a ^ b ^ c) + k[0] - 358537222 | 0;\n        d  = (d << 11 | d >>> 21) + a | 0;\n        c += (d ^ a ^ b) + k[3] - 722521979 | 0;\n        c  = (c << 16 | c >>> 16) + d | 0;\n        b += (c ^ d ^ a) + k[6] + 76029189 | 0;\n        b  = (b << 23 | b >>> 9) + c | 0;\n        a += (b ^ c ^ d) + k[9] - 640364487 | 0;\n        a  = (a << 4 | a >>> 28) + b | 0;\n        d += (a ^ b ^ c) + k[12] - 421815835 | 0;\n        d  = (d << 11 | d >>> 21) + a | 0;\n        c += (d ^ a ^ b) + k[15] + 530742520 | 0;\n        c  = (c << 16 | c >>> 16) + d | 0;\n        b += (c ^ d ^ a) + k[2] - 995338651 | 0;\n        b  = (b << 23 | b >>> 9) + c | 0;\n\n        a += (c ^ (b | ~d)) + k[0] - 198630844 | 0;\n        a  = (a << 6 | a >>> 26) + b | 0;\n        d += (b ^ (a | ~c)) + k[7] + 1126891415 | 0;\n        d  = (d << 10 | d >>> 22) + a | 0;\n        c += (a ^ (d | ~b)) + k[14] - 1416354905 | 0;\n        c  = (c << 15 | c >>> 17) + d | 0;\n        b += (d ^ (c | ~a)) + k[5] - 57434055 | 0;\n        b  = (b << 21 |b >>> 11) + c | 0;\n        a += (c ^ (b | ~d)) + k[12] + 1700485571 | 0;\n        a  = (a << 6 | a >>> 26) + b | 0;\n        d += (b ^ (a | ~c)) + k[3] - 1894986606 | 0;\n        d  = (d << 10 | d >>> 22) + a | 0;\n        c += (a ^ (d | ~b)) + k[10] - 1051523 | 0;\n        c  = (c << 15 | c >>> 17) + d | 0;\n        b += (d ^ (c | ~a)) + k[1] - 2054922799 | 0;\n        b  = (b << 21 |b >>> 11) + c | 0;\n        a += (c ^ (b | ~d)) + k[8] + 1873313359 | 0;\n        a  = (a << 6 | a >>> 26) + b | 0;\n        d += (b ^ (a | ~c)) + k[15] - 30611744 | 0;\n        d  = (d << 10 | d >>> 22) + a | 0;\n        c += (a ^ (d | ~b)) + k[6] - 1560198380 | 0;\n        c  = (c << 15 | c >>> 17) + d | 0;\n        b += (d ^ (c | ~a)) + k[13] + 1309151649 | 0;\n        b  = (b << 21 |b >>> 11) + c | 0;\n        a += (c ^ (b | ~d)) + k[4] - 145523070 | 0;\n        a  = (a << 6 | a >>> 26) + b | 0;\n        d += (b ^ (a | ~c)) + k[11] - 1120210379 | 0;\n        d  = (d << 10 | d >>> 22) + a | 0;\n        c += (a ^ (d | ~b)) + k[2] + 718787259 | 0;\n        c  = (c << 15 | c >>> 17) + d | 0;\n        b += (d ^ (c | ~a)) + k[9] - 343485551 | 0;\n        b  = (b << 21 | b >>> 11) + c | 0;\n\n        x[0] = a + x[0] | 0;\n        x[1] = b + x[1] | 0;\n        x[2] = c + x[2] | 0;\n        x[3] = d + x[3] | 0;\n    }\n\n    function md5blk(s) {\n        var md5blks = [],\n            i; /* Andy King said do it this way. */\n\n        for (i = 0; i < 64; i += 4) {\n            md5blks[i >> 2] = s.charCodeAt(i) + (s.charCodeAt(i + 1) << 8) + (s.charCodeAt(i + 2) << 16) + (s.charCodeAt(i + 3) << 24);\n        }\n        return md5blks;\n    }\n\n    function md5blk_array(a) {\n        var md5blks = [],\n            i; /* Andy King said do it this way. */\n\n        for (i = 0; i < 64; i += 4) {\n            md5blks[i >> 2] = a[i] + (a[i + 1] << 8) + (a[i + 2] << 16) + (a[i + 3] << 24);\n        }\n        return md5blks;\n    }\n\n    function md51(s) {\n        var n = s.length,\n            state = [1732584193, -271733879, -1732584194, 271733878],\n            i,\n            length,\n            tail,\n            tmp,\n            lo,\n            hi;\n\n        for (i = 64; i <= n; i += 64) {\n            md5cycle(state, md5blk(s.substring(i - 64, i)));\n        }\n        s = s.substring(i - 64);\n        length = s.length;\n        tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];\n        for (i = 0; i < length; i += 1) {\n            tail[i >> 2] |= s.charCodeAt(i) << ((i % 4) << 3);\n        }\n        tail[i >> 2] |= 0x80 << ((i % 4) << 3);\n        if (i > 55) {\n            md5cycle(state, tail);\n            for (i = 0; i < 16; i += 1) {\n                tail[i] = 0;\n            }\n        }\n\n        // Beware that the final length might not fit in 32 bits so we take care of that\n        tmp = n * 8;\n        tmp = tmp.toString(16).match(/(.*?)(.{0,8})$/);\n        lo = parseInt(tmp[2], 16);\n        hi = parseInt(tmp[1], 16) || 0;\n\n        tail[14] = lo;\n        tail[15] = hi;\n\n        md5cycle(state, tail);\n        return state;\n    }\n\n    function md51_array(a) {\n        var n = a.length,\n            state = [1732584193, -271733879, -1732584194, 271733878],\n            i,\n            length,\n            tail,\n            tmp,\n            lo,\n            hi;\n\n        for (i = 64; i <= n; i += 64) {\n            md5cycle(state, md5blk_array(a.subarray(i - 64, i)));\n        }\n\n        // Not sure if it is a bug, however IE10 will always produce a sub array of length 1\n        // containing the last element of the parent array if the sub array specified starts\n        // beyond the length of the parent array - weird.\n        // https://connect.microsoft.com/IE/feedback/details/771452/typed-array-subarray-issue\n        a = (i - 64) < n ? a.subarray(i - 64) : new Uint8Array(0);\n\n        length = a.length;\n        tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];\n        for (i = 0; i < length; i += 1) {\n            tail[i >> 2] |= a[i] << ((i % 4) << 3);\n        }\n\n        tail[i >> 2] |= 0x80 << ((i % 4) << 3);\n        if (i > 55) {\n            md5cycle(state, tail);\n            for (i = 0; i < 16; i += 1) {\n                tail[i] = 0;\n            }\n        }\n\n        // Beware that the final length might not fit in 32 bits so we take care of that\n        tmp = n * 8;\n        tmp = tmp.toString(16).match(/(.*?)(.{0,8})$/);\n        lo = parseInt(tmp[2], 16);\n        hi = parseInt(tmp[1], 16) || 0;\n\n        tail[14] = lo;\n        tail[15] = hi;\n\n        md5cycle(state, tail);\n\n        return state;\n    }\n\n    function rhex(n) {\n        var s = '',\n            j;\n        for (j = 0; j < 4; j += 1) {\n            s += hex_chr[(n >> (j * 8 + 4)) & 0x0F] + hex_chr[(n >> (j * 8)) & 0x0F];\n        }\n        return s;\n    }\n\n    function hex(x) {\n        var i;\n        for (i = 0; i < x.length; i += 1) {\n            x[i] = rhex(x[i]);\n        }\n        return x.join('');\n    }\n\n    // In some cases the fast add32 function cannot be used..\n    if (hex(md51('hello')) !== '5d41402abc4b2a76b9719d911017c592') {\n        add32 = function (x, y) {\n            var lsw = (x & 0xFFFF) + (y & 0xFFFF),\n                msw = (x >> 16) + (y >> 16) + (lsw >> 16);\n            return (msw << 16) | (lsw & 0xFFFF);\n        };\n    }\n\n    // ---------------------------------------------------\n\n    /**\n     * ArrayBuffer slice polyfill.\n     *\n     * @see https://github.com/ttaubert/node-arraybuffer-slice\n     */\n\n    if (typeof ArrayBuffer !== 'undefined' && !ArrayBuffer.prototype.slice) {\n        (function () {\n            function clamp(val, length) {\n                val = (val | 0) || 0;\n\n                if (val < 0) {\n                    return Math.max(val + length, 0);\n                }\n\n                return Math.min(val, length);\n            }\n\n            ArrayBuffer.prototype.slice = function (from, to) {\n                var length = this.byteLength,\n                    begin = clamp(from, length),\n                    end = length,\n                    num,\n                    target,\n                    targetArray,\n                    sourceArray;\n\n                if (to !== undefined) {\n                    end = clamp(to, length);\n                }\n\n                if (begin > end) {\n                    return new ArrayBuffer(0);\n                }\n\n                num = end - begin;\n                target = new ArrayBuffer(num);\n                targetArray = new Uint8Array(target);\n\n                sourceArray = new Uint8Array(this, begin, num);\n                targetArray.set(sourceArray);\n\n                return target;\n            };\n        })();\n    }\n\n    // ---------------------------------------------------\n\n    /**\n     * Helpers.\n     */\n\n    function toUtf8(str) {\n        if (/[\\u0080-\\uFFFF]/.test(str)) {\n            str = unescape(encodeURIComponent(str));\n        }\n\n        return str;\n    }\n\n    function utf8Str2ArrayBuffer(str, returnUInt8Array) {\n        var length = str.length,\n           buff = new ArrayBuffer(length),\n           arr = new Uint8Array(buff),\n           i;\n\n        for (i = 0; i < length; i += 1) {\n            arr[i] = str.charCodeAt(i);\n        }\n\n        return returnUInt8Array ? arr : buff;\n    }\n\n    function arrayBuffer2Utf8Str(buff) {\n        return String.fromCharCode.apply(null, new Uint8Array(buff));\n    }\n\n    function concatenateArrayBuffers(first, second, returnUInt8Array) {\n        var result = new Uint8Array(first.byteLength + second.byteLength);\n\n        result.set(new Uint8Array(first));\n        result.set(new Uint8Array(second), first.byteLength);\n\n        return returnUInt8Array ? result : result.buffer;\n    }\n\n    function hexToBinaryString(hex) {\n        var bytes = [],\n            length = hex.length,\n            x;\n\n        for (x = 0; x < length - 1; x += 2) {\n            bytes.push(parseInt(hex.substr(x, 2), 16));\n        }\n\n        return String.fromCharCode.apply(String, bytes);\n    }\n\n    // ---------------------------------------------------\n\n    /**\n     * SparkMD5 OOP implementation.\n     *\n     * Use this class to perform an incremental md5, otherwise use the\n     * static methods instead.\n     */\n\n    function SparkMD5() {\n        // call reset to init the instance\n        this.reset();\n    }\n\n    /**\n     * Appends a string.\n     * A conversion will be applied if an utf8 string is detected.\n     *\n     * @param {String} str The string to be appended\n     *\n     * @return {SparkMD5} The instance itself\n     */\n    SparkMD5.prototype.append = function (str) {\n        // Converts the string to utf8 bytes if necessary\n        // Then append as binary\n        this.appendBinary(toUtf8(str));\n\n        return this;\n    };\n\n    /**\n     * Appends a binary string.\n     *\n     * @param {String} contents The binary string to be appended\n     *\n     * @return {SparkMD5} The instance itself\n     */\n    SparkMD5.prototype.appendBinary = function (contents) {\n        this._buff += contents;\n        this._length += contents.length;\n\n        var length = this._buff.length,\n            i;\n\n        for (i = 64; i <= length; i += 64) {\n            md5cycle(this._hash, md5blk(this._buff.substring(i - 64, i)));\n        }\n\n        this._buff = this._buff.substring(i - 64);\n\n        return this;\n    };\n\n    /**\n     * Finishes the incremental computation, reseting the internal state and\n     * returning the result.\n     *\n     * @param {Boolean} raw True to get the raw string, false to get the hex string\n     *\n     * @return {String} The result\n     */\n    SparkMD5.prototype.end = function (raw) {\n        var buff = this._buff,\n            length = buff.length,\n            i,\n            tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            ret;\n\n        for (i = 0; i < length; i += 1) {\n            tail[i >> 2] |= buff.charCodeAt(i) << ((i % 4) << 3);\n        }\n\n        this._finish(tail, length);\n        ret = hex(this._hash);\n\n        if (raw) {\n            ret = hexToBinaryString(ret);\n        }\n\n        this.reset();\n\n        return ret;\n    };\n\n    /**\n     * Resets the internal state of the computation.\n     *\n     * @return {SparkMD5} The instance itself\n     */\n    SparkMD5.prototype.reset = function () {\n        this._buff = '';\n        this._length = 0;\n        this._hash = [1732584193, -271733879, -1732584194, 271733878];\n\n        return this;\n    };\n\n    /**\n     * Gets the internal state of the computation.\n     *\n     * @return {Object} The state\n     */\n    SparkMD5.prototype.getState = function () {\n        return {\n            buff: this._buff,\n            length: this._length,\n            hash: this._hash\n        };\n    };\n\n    /**\n     * Gets the internal state of the computation.\n     *\n     * @param {Object} state The state\n     *\n     * @return {SparkMD5} The instance itself\n     */\n    SparkMD5.prototype.setState = function (state) {\n        this._buff = state.buff;\n        this._length = state.length;\n        this._hash = state.hash;\n\n        return this;\n    };\n\n    /**\n     * Releases memory used by the incremental buffer and other additional\n     * resources. If you plan to use the instance again, use reset instead.\n     */\n    SparkMD5.prototype.destroy = function () {\n        delete this._hash;\n        delete this._buff;\n        delete this._length;\n    };\n\n    /**\n     * Finish the final calculation based on the tail.\n     *\n     * @param {Array}  tail   The tail (will be modified)\n     * @param {Number} length The length of the remaining buffer\n     */\n    SparkMD5.prototype._finish = function (tail, length) {\n        var i = length,\n            tmp,\n            lo,\n            hi;\n\n        tail[i >> 2] |= 0x80 << ((i % 4) << 3);\n        if (i > 55) {\n            md5cycle(this._hash, tail);\n            for (i = 0; i < 16; i += 1) {\n                tail[i] = 0;\n            }\n        }\n\n        // Do the final computation based on the tail and length\n        // Beware that the final length may not fit in 32 bits so we take care of that\n        tmp = this._length * 8;\n        tmp = tmp.toString(16).match(/(.*?)(.{0,8})$/);\n        lo = parseInt(tmp[2], 16);\n        hi = parseInt(tmp[1], 16) || 0;\n\n        tail[14] = lo;\n        tail[15] = hi;\n        md5cycle(this._hash, tail);\n    };\n\n    /**\n     * Performs the md5 hash on a string.\n     * A conversion will be applied if utf8 string is detected.\n     *\n     * @param {String}  str The string\n     * @param {Boolean} raw True to get the raw string, false to get the hex string\n     *\n     * @return {String} The result\n     */\n    SparkMD5.hash = function (str, raw) {\n        // Converts the string to utf8 bytes if necessary\n        // Then compute it using the binary function\n        return SparkMD5.hashBinary(toUtf8(str), raw);\n    };\n\n    /**\n     * Performs the md5 hash on a binary string.\n     *\n     * @param {String}  content The binary string\n     * @param {Boolean} raw     True to get the raw string, false to get the hex string\n     *\n     * @return {String} The result\n     */\n    SparkMD5.hashBinary = function (content, raw) {\n        var hash = md51(content),\n            ret = hex(hash);\n\n        return raw ? hexToBinaryString(ret) : ret;\n    };\n\n    // ---------------------------------------------------\n\n    /**\n     * SparkMD5 OOP implementation for array buffers.\n     *\n     * Use this class to perform an incremental md5 ONLY for array buffers.\n     */\n    SparkMD5.ArrayBuffer = function () {\n        // call reset to init the instance\n        this.reset();\n    };\n\n    /**\n     * Appends an array buffer.\n     *\n     * @param {ArrayBuffer} arr The array to be appended\n     *\n     * @return {SparkMD5.ArrayBuffer} The instance itself\n     */\n    SparkMD5.ArrayBuffer.prototype.append = function (arr) {\n        var buff = concatenateArrayBuffers(this._buff.buffer, arr, true),\n            length = buff.length,\n            i;\n\n        this._length += arr.byteLength;\n\n        for (i = 64; i <= length; i += 64) {\n            md5cycle(this._hash, md5blk_array(buff.subarray(i - 64, i)));\n        }\n\n        this._buff = (i - 64) < length ? new Uint8Array(buff.buffer.slice(i - 64)) : new Uint8Array(0);\n\n        return this;\n    };\n\n    /**\n     * Finishes the incremental computation, reseting the internal state and\n     * returning the result.\n     *\n     * @param {Boolean} raw True to get the raw string, false to get the hex string\n     *\n     * @return {String} The result\n     */\n    SparkMD5.ArrayBuffer.prototype.end = function (raw) {\n        var buff = this._buff,\n            length = buff.length,\n            tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            i,\n            ret;\n\n        for (i = 0; i < length; i += 1) {\n            tail[i >> 2] |= buff[i] << ((i % 4) << 3);\n        }\n\n        this._finish(tail, length);\n        ret = hex(this._hash);\n\n        if (raw) {\n            ret = hexToBinaryString(ret);\n        }\n\n        this.reset();\n\n        return ret;\n    };\n\n    /**\n     * Resets the internal state of the computation.\n     *\n     * @return {SparkMD5.ArrayBuffer} The instance itself\n     */\n    SparkMD5.ArrayBuffer.prototype.reset = function () {\n        this._buff = new Uint8Array(0);\n        this._length = 0;\n        this._hash = [1732584193, -271733879, -1732584194, 271733878];\n\n        return this;\n    };\n\n    /**\n     * Gets the internal state of the computation.\n     *\n     * @return {Object} The state\n     */\n    SparkMD5.ArrayBuffer.prototype.getState = function () {\n        var state = SparkMD5.prototype.getState.call(this);\n\n        // Convert buffer to a string\n        state.buff = arrayBuffer2Utf8Str(state.buff);\n\n        return state;\n    };\n\n    /**\n     * Gets the internal state of the computation.\n     *\n     * @param {Object} state The state\n     *\n     * @return {SparkMD5.ArrayBuffer} The instance itself\n     */\n    SparkMD5.ArrayBuffer.prototype.setState = function (state) {\n        // Convert string to buffer\n        state.buff = utf8Str2ArrayBuffer(state.buff, true);\n\n        return SparkMD5.prototype.setState.call(this, state);\n    };\n\n    SparkMD5.ArrayBuffer.prototype.destroy = SparkMD5.prototype.destroy;\n\n    SparkMD5.ArrayBuffer.prototype._finish = SparkMD5.prototype._finish;\n\n    /**\n     * Performs the md5 hash on an array buffer.\n     *\n     * @param {ArrayBuffer} arr The array buffer\n     * @param {Boolean}     raw True to get the raw string, false to get the hex one\n     *\n     * @return {String} The result\n     */\n    SparkMD5.ArrayBuffer.hash = function (arr, raw) {\n        var hash = md51_array(new Uint8Array(arr)),\n            ret = hex(hash);\n\n        return raw ? hexToBinaryString(ret) : ret;\n    };\n\n    return SparkMD5;\n}));\n\n\n/***/ }),\n/* 16 */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\n/**\n * Stringify/parse functions that don't operate\n * recursively, so they avoid call stack exceeded\n * errors.\n */\nexports.stringify = function stringify(input) {\n  var queue = [];\n  queue.push({obj: input});\n\n  var res = '';\n  var next, obj, prefix, val, i, arrayPrefix, keys, k, key, value, objPrefix;\n  while ((next = queue.pop())) {\n    obj = next.obj;\n    prefix = next.prefix || '';\n    val = next.val || '';\n    res += prefix;\n    if (val) {\n      res += val;\n    } else if (typeof obj !== 'object') {\n      res += typeof obj === 'undefined' ? null : JSON.stringify(obj);\n    } else if (obj === null) {\n      res += 'null';\n    } else if (Array.isArray(obj)) {\n      queue.push({val: ']'});\n      for (i = obj.length - 1; i >= 0; i--) {\n        arrayPrefix = i === 0 ? '' : ',';\n        queue.push({obj: obj[i], prefix: arrayPrefix});\n      }\n      queue.push({val: '['});\n    } else { // object\n      keys = [];\n      for (k in obj) {\n        if (obj.hasOwnProperty(k)) {\n          keys.push(k);\n        }\n      }\n      queue.push({val: '}'});\n      for (i = keys.length - 1; i >= 0; i--) {\n        key = keys[i];\n        value = obj[key];\n        objPrefix = (i > 0 ? ',' : '');\n        objPrefix += JSON.stringify(key) + ':';\n        queue.push({obj: value, prefix: objPrefix});\n      }\n      queue.push({val: '{'});\n    }\n  }\n  return res;\n};\n\n// Convenience function for the parse function.\n// This pop function is basically copied from\n// pouchCollate.parseIndexableString\nfunction pop(obj, stack, metaStack) {\n  var lastMetaElement = metaStack[metaStack.length - 1];\n  if (obj === lastMetaElement.element) {\n    // popping a meta-element, e.g. an object whose value is another object\n    metaStack.pop();\n    lastMetaElement = metaStack[metaStack.length - 1];\n  }\n  var element = lastMetaElement.element;\n  var lastElementIndex = lastMetaElement.index;\n  if (Array.isArray(element)) {\n    element.push(obj);\n  } else if (lastElementIndex === stack.length - 2) { // obj with key+value\n    var key = stack.pop();\n    element[key] = obj;\n  } else {\n    stack.push(obj); // obj with key only\n  }\n}\n\nexports.parse = function (str) {\n  var stack = [];\n  var metaStack = []; // stack for arrays and objects\n  var i = 0;\n  var collationIndex,parsedNum,numChar;\n  var parsedString,lastCh,numConsecutiveSlashes,ch;\n  var arrayElement, objElement;\n  while (true) {\n    collationIndex = str[i++];\n    if (collationIndex === '}' ||\n        collationIndex === ']' ||\n        typeof collationIndex === 'undefined') {\n      if (stack.length === 1) {\n        return stack.pop();\n      } else {\n        pop(stack.pop(), stack, metaStack);\n        continue;\n      }\n    }\n    switch (collationIndex) {\n      case ' ':\n      case '\\t':\n      case '\\n':\n      case ':':\n      case ',':\n        break;\n      case 'n':\n        i += 3; // 'ull'\n        pop(null, stack, metaStack);\n        break;\n      case 't':\n        i += 3; // 'rue'\n        pop(true, stack, metaStack);\n        break;\n      case 'f':\n        i += 4; // 'alse'\n        pop(false, stack, metaStack);\n        break;\n      case '0':\n      case '1':\n      case '2':\n      case '3':\n      case '4':\n      case '5':\n      case '6':\n      case '7':\n      case '8':\n      case '9':\n      case '-':\n        parsedNum = '';\n        i--;\n        while (true) {\n          numChar = str[i++];\n          if (/[\\d\\.\\-e\\+]/.test(numChar)) {\n            parsedNum += numChar;\n          } else {\n            i--;\n            break;\n          }\n        }\n        pop(parseFloat(parsedNum), stack, metaStack);\n        break;\n      case '\"':\n        parsedString = '';\n        lastCh = void 0;\n        numConsecutiveSlashes = 0;\n        while (true) {\n          ch = str[i++];\n          if (ch !== '\"' || (lastCh === '\\\\' &&\n              numConsecutiveSlashes % 2 === 1)) {\n            parsedString += ch;\n            lastCh = ch;\n            if (lastCh === '\\\\') {\n              numConsecutiveSlashes++;\n            } else {\n              numConsecutiveSlashes = 0;\n            }\n          } else {\n            break;\n          }\n        }\n        pop(JSON.parse('\"' + parsedString + '\"'), stack, metaStack);\n        break;\n      case '[':\n        arrayElement = { element: [], index: stack.length };\n        stack.push(arrayElement.element);\n        metaStack.push(arrayElement);\n        break;\n      case '{':\n        objElement = { element: {}, index: stack.length };\n        stack.push(objElement.element);\n        metaStack.push(objElement);\n        break;\n      default:\n        throw new Error(\n          'unexpectedly reached end of input: ' + collationIndex);\n    }\n  }\n};\n\n\n/***/ }),\n/* 17 */\n/***/ (function(module, exports) {\n\nmodule.exports = function(module) {\r\n\tif(!module.webpackPolyfill) {\r\n\t\tmodule.deprecate = function() {};\r\n\t\tmodule.paths = [];\r\n\t\t// module.parent = undefined by default\r\n\t\tif(!module.children) module.children = [];\r\n\t\tObject.defineProperty(module, \"loaded\", {\r\n\t\t\tenumerable: true,\r\n\t\t\tget: function() {\r\n\t\t\t\treturn module.l;\r\n\t\t\t}\r\n\t\t});\r\n\t\tObject.defineProperty(module, \"id\", {\r\n\t\t\tenumerable: true,\r\n\t\t\tget: function() {\r\n\t\t\t\treturn module.i;\r\n\t\t\t}\r\n\t\t});\r\n\t\tmodule.webpackPolyfill = 1;\r\n\t}\r\n\treturn module;\r\n};\r\n\n\n/***/ }),\n/* 18 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\nObject.defineProperty(__webpack_exports__, \"__esModule\", { value: true });\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_pouchdb_browser__ = __webpack_require__(4);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_0_pouchdb_browser___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_0_pouchdb_browser__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_1_lodash_merge__ = __webpack_require__(1);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_1_lodash_merge___default = __webpack_require__.n(__WEBPACK_IMPORTED_MODULE_1_lodash_merge__);\n/* harmony import */ var __WEBPACK_IMPORTED_MODULE_2__utils__ = __webpack_require__(3);\n/* harmony reexport (binding) */ __webpack_require__.d(__webpack_exports__, \"mapQueries\", function() { return __WEBPACK_IMPORTED_MODULE_2__utils__[\"c\"]; });\nvar _createClass = function () { function defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } } return function (Constructor, protoProps, staticProps) { if (protoProps) defineProperties(Constructor.prototype, protoProps); if (staticProps) defineProperties(Constructor, staticProps); return Constructor; }; }();\n\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\n/**\n * Importing\n */\n\n\n/**\n * Utilities\n */\n\n\n\n/**\n * Internal Global Vue reference\n */\nvar Vue = void 0;\n\n/**\n * Bucket Class\n */\n\nvar Bucket = function () {\n\n  /**\n   * Creating internal state for Bucket\n   * @param schema\n   */\n  function Bucket() {\n    var _this = this;\n\n    var schema = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n\n    _classCallCheck(this, Bucket);\n\n    // Ignore Schema Keys\n    var ignoredKeys = ['config', 'plugins', 'actions'];\n\n    // Internal Config reference\n    this._config = schema.config;\n\n    // Internal State\n    this._dbs = {};\n    this._watch = {};\n    this._state = {};\n\n    // Throw Error if Global Config not defined\n    if (!schema.config) {\n      throw new Error('[VuePouch]: Global Config is not declared in the upper level!');\n    }\n\n    // Referencing Actions to the $bucket\n    if (schema.actions) {\n      __WEBPACK_IMPORTED_MODULE_1_lodash_merge___default()(this, schema.actions);\n    }\n\n    // Init PouchDB plugins\n    if (schema.plugins.constructor === Array && schema.plugins.length > 0) {\n      for (var i = 0; i < schema.plugins.length; i += 1) {\n        __WEBPACK_IMPORTED_MODULE_0_pouchdb_browser___default.a.plugin(schema.plugins[i]);\n      }\n    }\n\n    // Initializing DBs that are declared in the schema{}\n    Object.keys(schema).forEach(function (dbname) {\n      // If is ignored Key, skip!\n      if (ignoredKeys.indexOf(dbname) !== -1) return null;\n\n      // Initialize the DB\n      return _this._initDB(dbname, __WEBPACK_IMPORTED_MODULE_1_lodash_merge___default()({}, schema.config, schema[dbname]));\n    });\n  }\n\n  // Delete Object from _state\n\n\n  _createClass(Bucket, [{\n    key: '_deleted',\n    value: function _deleted(dbname, docID) {\n      var index = __webpack_require__.i(__WEBPACK_IMPORTED_MODULE_2__utils__[\"a\" /* binarySearch */])(this._state[dbname], docID);\n      var doc = this._state[dbname][index];\n\n      // Delete\n      if (doc && doc._id === docID) {\n        this._state[dbname].splice(index, 1);\n      }\n    }\n\n    // Update or insert state in object\n\n  }, {\n    key: '_upsert',\n    value: function _upsert(dbname, newDoc) {\n      var index = __webpack_require__.i(__WEBPACK_IMPORTED_MODULE_2__utils__[\"a\" /* binarySearch */])(this._state[dbname], newDoc._id);\n      var doc = this._state[dbname][index];\n\n      // Update\n      if (doc && doc._id === newDoc._id) {\n        // Make Reactive\n        Vue.set(this._state[dbname], index, newDoc);\n      } else {\n        // Insert an Empty object to reserve the index\n        this._state[dbname].splice(index, 0, {});\n        // Set the reactive data\n        Vue.set(this._state[dbname], index, newDoc);\n      }\n    }\n\n    /**\n     * Relax, and send the request to CouchDB\n     * @param options\n     * @private\n     */\n\n  }, {\n    key: '_relax',\n    value: function _relax(options) {\n      return fetch(this._config.remote + '/' + options.url, __WEBPACK_IMPORTED_MODULE_1_lodash_merge___default()({\n        credentials: 'include',\n        headers: { 'Content-Type': 'application/json' }\n      }, options, { body: JSON.stringify(options.body) })).then(function (response) {\n        return response.json();\n      });\n    }\n\n    /**\n     * Init Database\n     * @param dbname\n     * @param config\n     * @returns {*}\n     * @private\n     */\n\n  }, {\n    key: '_initDB',\n    value: function _initDB(dbname) {\n      var _this2 = this;\n\n      var config = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n\n      // If DB Exists return it\n      if (this._dbs[dbname]) {\n        return this._dbs[dbname];\n      }\n\n      // Init only remote\n      if (config.remoteOnly) {\n        this._dbs[dbname] = new __WEBPACK_IMPORTED_MODULE_0_pouchdb_browser___default.a(config.remote + '/' + dbname, config.options);\n        return this._dbs[dbname];\n      }\n\n      // Init DB\n      this._dbs[dbname] = new __WEBPACK_IMPORTED_MODULE_0_pouchdb_browser___default.a(dbname, config.options);\n\n      // Populate state with data\n      this._dbs[dbname].allDocs(config.allDocs).then(function (data) {\n        return Vue.set(_this2._state, dbname, data.rows.map(function (row) {\n          return row.doc;\n        }));\n      });\n\n      // Sync DB\n      __WEBPACK_IMPORTED_MODULE_0_pouchdb_browser___default.a.sync(dbname, config.remote + '/' + dbname, config.sync);\n\n      // Start detecting changes\n      this._initChanges(dbname, config);\n\n      // Return instance\n      return this._dbs[dbname];\n    }\n  }, {\n    key: '_initChanges',\n    value: function _initChanges(dbname, config) {\n      var _this3 = this;\n\n      // Detect Changes and update the _state tree\n      var dbChanges = this._dbs[dbname].changes(config.changes).on('change', function (change) {\n        if (change.deleted) {\n          _this3._deleted(dbname, change.id);\n        } else {\n          _this3._upsert(dbname, change.doc);\n        }\n        return config.onChanges && config.onChanges(change);\n      }).on('complete', function (complete) {\n        if (complete.results) {\n          complete.results.forEach(function (change) {\n            if (change.deleted) {\n              _this3._deleted(dbname, change.id);\n            } else {\n              _this3._upsert(dbname, change.doc);\n            }\n          });\n        }\n        return config.onComplete || config.onComplete(complete);\n      }).on('error', config.onError || __WEBPACK_IMPORTED_MODULE_2__utils__[\"b\" /* noop */]).on('paused', config.onPaused || __WEBPACK_IMPORTED_MODULE_2__utils__[\"b\" /* noop */]).on('active', config.onActive || __WEBPACK_IMPORTED_MODULE_2__utils__[\"b\" /* noop */]).on('denied', config.onDenied || __WEBPACK_IMPORTED_MODULE_2__utils__[\"b\" /* noop */]);\n\n      // Calling the Cancel function\n      config.cancel && config.cancel(dbChanges.cancel);\n\n      // Reference all Subscriptions\n      this._watch[dbname] = dbChanges;\n\n      // Returing the Watch\n      return this._watch[dbname];\n    }\n\n    /**\n     * Reference internal state\n     */\n\n  }, {\n    key: 'db',\n\n\n    /**\n     * DB Accessor\n     * @param dbname\n     * @param config\n     * @returns {*}\n     */\n    value: function db(dbname) {\n      var config = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n\n      return this._initDB(dbname, __WEBPACK_IMPORTED_MODULE_1_lodash_merge___default()({}, this._config, config));\n    }\n\n    /**\n     * Closing the DB and removing all the change watchers and state.\n     * @param dbname\n     * @returns {Promise}\n     */\n\n  }, {\n    key: 'closedb',\n    value: function closedb(dbname) {\n      var _this4 = this;\n\n      // If db does not exist, skip.\n      if (!this._dbs[dbname]) return null;\n      // If the DB is already closed, simply skip.\n      if (this._dbs[dbname]._closed) return null;\n      // Close the DB and return Promise\n      return new Promise(function (resolve, reject) {\n        // Closing the DB\n        _this4._dbs[dbname].close().then(function (response) {\n          // Canceling the Change Event\n          _this4._watch[dbname].cancel();\n          // Deleting internal db reference\n          delete _this4._dbs[dbname];\n          // Removing the State of the DB\n          Vue.delete(_this4._state, dbname);\n          // Deleting internal watch reference\n          delete _this4._watch[dbname];\n          // Resolving Promise\n          return resolve(response);\n        }).catch(reject);\n      });\n    }\n  }, {\n    key: 'state',\n    get: function get() {\n      return this._state;\n    }\n\n    /**\n     * Don't let the state be overwritten from outside\n     */\n    ,\n    set: function set(value) {\n      console.error('[VuePouch]: Do not replace the entire state! \\n       VuePouch takes care of the updates internally, \\n       change the DB instead!');\n      // Return Undefined\n      return undefined;\n    }\n  }]);\n\n  return Bucket;\n}();\n\n/**\n * Exporting public utility functions\n */\n\n\n\n\n/**\n * Exporting\n **/\n/* harmony default export */ __webpack_exports__[\"default\"] = {\n  // Bucket Class\n  Bucket: Bucket,\n\n  // Install Plugin\n  install: function install($Vue) {\n\n    // Checking if Vue is Installed\n    if (Vue) {\n      throw new Error('[VuePouch] already installed. Vue.use(VuePouch) should be called only once.');\n    }\n\n    // Making Vue globally available\n    Vue = $Vue;\n\n    // Get Util Functions\n    var defineReactive = Vue.util.defineReactive;\n\n    // Check Version Number\n\n    var version = Number(Vue.version.split('.')[0]);\n\n    /**\n     * Setup the internal $dbsetup object\n     * @param dbsetup\n     */\n    function $dbsetup() {\n      var _this5 = this;\n\n      // If dbsetup does not exist, terminate!\n      if (!this.$options.dbsetup) return null;\n      // Getting DB Setup\n      var dbsetup = this.$options.dbsetup;\n      // Compile the Object and assign it to the instance\n\n      return __WEBPACK_IMPORTED_MODULE_1_lodash_merge___default()(this, {\n        $dbsetup: Object.keys(dbsetup).reduce(function (db, prop) {\n          return __WEBPACK_IMPORTED_MODULE_1_lodash_merge___default()(db, _defineProperty({}, prop, __webpack_require__.i(__WEBPACK_IMPORTED_MODULE_2__utils__[\"d\" /* expand */])(dbsetup[prop] || {}, _this5)));\n        }, {})\n      });\n    }\n\n    /**\n     * Vuex init hook, injected into each instances init hooks list.\n     */\n    function bucketInit() {\n      // Getting Options\n      var options = this.$options;\n      // Bucket injection\n      if (options.bucket) {\n        // Getting the core $bucket\n        this.$bucket = options.bucket;\n        // Define Reactive state\n        defineReactive(this.$bucket, '_state', options.bucket._state);\n      } else if (options.parent && options.parent.$bucket) {\n        // Getting parent bucket\n        this.$bucket = options.parent.$bucket;\n      }\n    }\n\n    /**\n     * Based on dbsetup object, configure the Database\n     */\n    function dbCreated() {\n      // Compiling this.$options.dbsetup to have local component variables\n      $dbsetup.call(this);\n      // If dbsetup does not exist, terminate!\n      if (!this.$dbsetup) return null;\n      // Setting up the database\n      return this.$bucket.db(this.$dbsetup.name, this.$dbsetup.options);\n    }\n\n    /**\n     * Close DB connections when component gets Destroyed\n     */\n    function dbDestroy() {\n      // If dbsetup does not exist, terminate!\n      if (!this.$dbsetup) return null;\n      // Closing the DB Connection on component destroy\n      return this.$bucket.closedb(this.$dbsetup.name);\n    }\n\n    // Check Version\n    if (version >= 2) {\n      var usesInit = Vue.config._lifecycleHooks.indexOf('init') > -1;\n      Vue.mixin(usesInit ? {\n        init: bucketInit,\n        created: dbCreated,\n        beforeDestroy: dbDestroy\n      } : {\n        beforeCreate: bucketInit,\n        created: dbCreated,\n        activated: dbCreated,\n        deactivated: dbDestroy,\n        beforeDestroy: dbDestroy\n      });\n    } else {\n      (function () {\n        // override init and inject VuePouch init procedure\n        // for 1.x backwards compatibility.\n        var _init = Vue.prototype._init;\n        // Initializing the bucket\n        Vue.prototype._init = function VueInit() {\n          var options = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};\n\n          options.init = options.init ? [bucketInit].concat(options.init) : bucketInit;\n          _init.call(this, options);\n        };\n      })();\n    }\n  }\n};\n\n/**\n * Making PouchDB Available for Debugging\n */\nif (false) {\n  window.PouchDB = PouchDB;\n}\n\n/***/ })\n/******/ ]);\n});\n\n\n// WEBPACK FOOTER //\n// build.js"," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId])\n \t\t\treturn installedModules[moduleId].exports;\n\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// identity function for calling harmony imports with the correct context\n \t__webpack_require__.i = function(value) { return value; };\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, {\n \t\t\t\tconfigurable: false,\n \t\t\t\tenumerable: true,\n \t\t\t\tget: getter\n \t\t\t});\n \t\t}\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 18);\n\n\n\n// WEBPACK FOOTER //\n// webpack/bootstrap 6ca1a8b5d6575cb0f2d0","var g;\r\n\r\n// This works in non-strict mode\r\ng = (function() {\r\n\treturn this;\r\n})();\r\n\r\ntry {\r\n\t// This works if eval is allowed (see CSP)\r\n\tg = g || Function(\"return this\")() || (1,eval)(\"this\");\r\n} catch(e) {\r\n\t// This works if the window reference is available\r\n\tif(typeof window === \"object\")\r\n\t\tg = window;\r\n}\r\n\r\n// g can still be undefined, but nothing to do about it...\r\n// We return undefined, instead of nothing here, so it's\r\n// easier to handle this case. if(!global) { ...}\r\n\r\nmodule.exports = g;\r\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// (webpack)/buildin/global.js\n// module id = 0\n// module chunks = 0","/**\n * lodash (Custom Build) <https://lodash.com/>\n * Build: `lodash modularize exports=\"npm\" -o ./`\n * Copyright jQuery Foundation and other contributors <https://jquery.org/>\n * Released under MIT license <https://lodash.com/license>\n * Based on Underscore.js 1.8.3 <http://underscorejs.org/LICENSE>\n * Copyright Jeremy Ashkenas, DocumentCloud and Investigative Reporters & Editors\n */\n\n/** Used as the size to enable large array optimizations. */\nvar LARGE_ARRAY_SIZE = 200;\n\n/** Used to stand-in for `undefined` hash values. */\nvar HASH_UNDEFINED = '__lodash_hash_undefined__';\n\n/** Used as references for various `Number` constants. */\nvar MAX_SAFE_INTEGER = 9007199254740991;\n\n/** `Object#toString` result references. */\nvar argsTag = '[object Arguments]',\n    arrayTag = '[object Array]',\n    boolTag = '[object Boolean]',\n    dateTag = '[object Date]',\n    errorTag = '[object Error]',\n    funcTag = '[object Function]',\n    genTag = '[object GeneratorFunction]',\n    mapTag = '[object Map]',\n    numberTag = '[object Number]',\n    objectTag = '[object Object]',\n    promiseTag = '[object Promise]',\n    regexpTag = '[object RegExp]',\n    setTag = '[object Set]',\n    stringTag = '[object String]',\n    symbolTag = '[object Symbol]',\n    weakMapTag = '[object WeakMap]';\n\nvar arrayBufferTag = '[object ArrayBuffer]',\n    dataViewTag = '[object DataView]',\n    float32Tag = '[object Float32Array]',\n    float64Tag = '[object Float64Array]',\n    int8Tag = '[object Int8Array]',\n    int16Tag = '[object Int16Array]',\n    int32Tag = '[object Int32Array]',\n    uint8Tag = '[object Uint8Array]',\n    uint8ClampedTag = '[object Uint8ClampedArray]',\n    uint16Tag = '[object Uint16Array]',\n    uint32Tag = '[object Uint32Array]';\n\n/**\n * Used to match `RegExp`\n * [syntax characters](http://ecma-international.org/ecma-262/7.0/#sec-patterns).\n */\nvar reRegExpChar = /[\\\\^$.*+?()[\\]{}|]/g;\n\n/** Used to match `RegExp` flags from their coerced string values. */\nvar reFlags = /\\w*$/;\n\n/** Used to detect host constructors (Safari). */\nvar reIsHostCtor = /^\\[object .+?Constructor\\]$/;\n\n/** Used to detect unsigned integer values. */\nvar reIsUint = /^(?:0|[1-9]\\d*)$/;\n\n/** Used to identify `toStringTag` values of typed arrays. */\nvar typedArrayTags = {};\ntypedArrayTags[float32Tag] = typedArrayTags[float64Tag] =\ntypedArrayTags[int8Tag] = typedArrayTags[int16Tag] =\ntypedArrayTags[int32Tag] = typedArrayTags[uint8Tag] =\ntypedArrayTags[uint8ClampedTag] = typedArrayTags[uint16Tag] =\ntypedArrayTags[uint32Tag] = true;\ntypedArrayTags[argsTag] = typedArrayTags[arrayTag] =\ntypedArrayTags[arrayBufferTag] = typedArrayTags[boolTag] =\ntypedArrayTags[dataViewTag] = typedArrayTags[dateTag] =\ntypedArrayTags[errorTag] = typedArrayTags[funcTag] =\ntypedArrayTags[mapTag] = typedArrayTags[numberTag] =\ntypedArrayTags[objectTag] = typedArrayTags[regexpTag] =\ntypedArrayTags[setTag] = typedArrayTags[stringTag] =\ntypedArrayTags[weakMapTag] = false;\n\n/** Used to identify `toStringTag` values supported by `_.clone`. */\nvar cloneableTags = {};\ncloneableTags[argsTag] = cloneableTags[arrayTag] =\ncloneableTags[arrayBufferTag] = cloneableTags[dataViewTag] =\ncloneableTags[boolTag] = cloneableTags[dateTag] =\ncloneableTags[float32Tag] = cloneableTags[float64Tag] =\ncloneableTags[int8Tag] = cloneableTags[int16Tag] =\ncloneableTags[int32Tag] = cloneableTags[mapTag] =\ncloneableTags[numberTag] = cloneableTags[objectTag] =\ncloneableTags[regexpTag] = cloneableTags[setTag] =\ncloneableTags[stringTag] = cloneableTags[symbolTag] =\ncloneableTags[uint8Tag] = cloneableTags[uint8ClampedTag] =\ncloneableTags[uint16Tag] = cloneableTags[uint32Tag] = true;\ncloneableTags[errorTag] = cloneableTags[funcTag] =\ncloneableTags[weakMapTag] = false;\n\n/** Detect free variable `global` from Node.js. */\nvar freeGlobal = typeof global == 'object' && global && global.Object === Object && global;\n\n/** Detect free variable `self`. */\nvar freeSelf = typeof self == 'object' && self && self.Object === Object && self;\n\n/** Used as a reference to the global object. */\nvar root = freeGlobal || freeSelf || Function('return this')();\n\n/** Detect free variable `exports`. */\nvar freeExports = typeof exports == 'object' && exports && !exports.nodeType && exports;\n\n/** Detect free variable `module`. */\nvar freeModule = freeExports && typeof module == 'object' && module && !module.nodeType && module;\n\n/** Detect the popular CommonJS extension `module.exports`. */\nvar moduleExports = freeModule && freeModule.exports === freeExports;\n\n/** Detect free variable `process` from Node.js. */\nvar freeProcess = moduleExports && freeGlobal.process;\n\n/** Used to access faster Node.js helpers. */\nvar nodeUtil = (function() {\n  try {\n    return freeProcess && freeProcess.binding('util');\n  } catch (e) {}\n}());\n\n/* Node.js helper references. */\nvar nodeIsTypedArray = nodeUtil && nodeUtil.isTypedArray;\n\n/**\n * Adds the key-value `pair` to `map`.\n *\n * @private\n * @param {Object} map The map to modify.\n * @param {Array} pair The key-value pair to add.\n * @returns {Object} Returns `map`.\n */\nfunction addMapEntry(map, pair) {\n  // Don't return `map.set` because it's not chainable in IE 11.\n  map.set(pair[0], pair[1]);\n  return map;\n}\n\n/**\n * Adds `value` to `set`.\n *\n * @private\n * @param {Object} set The set to modify.\n * @param {*} value The value to add.\n * @returns {Object} Returns `set`.\n */\nfunction addSetEntry(set, value) {\n  // Don't return `set.add` because it's not chainable in IE 11.\n  set.add(value);\n  return set;\n}\n\n/**\n * A faster alternative to `Function#apply`, this function invokes `func`\n * with the `this` binding of `thisArg` and the arguments of `args`.\n *\n * @private\n * @param {Function} func The function to invoke.\n * @param {*} thisArg The `this` binding of `func`.\n * @param {Array} args The arguments to invoke `func` with.\n * @returns {*} Returns the result of `func`.\n */\nfunction apply(func, thisArg, args) {\n  switch (args.length) {\n    case 0: return func.call(thisArg);\n    case 1: return func.call(thisArg, args[0]);\n    case 2: return func.call(thisArg, args[0], args[1]);\n    case 3: return func.call(thisArg, args[0], args[1], args[2]);\n  }\n  return func.apply(thisArg, args);\n}\n\n/**\n * A specialized version of `_.forEach` for arrays without support for\n * iteratee shorthands.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} iteratee The function invoked per iteration.\n * @returns {Array} Returns `array`.\n */\nfunction arrayEach(array, iteratee) {\n  var index = -1,\n      length = array ? array.length : 0;\n\n  while (++index < length) {\n    if (iteratee(array[index], index, array) === false) {\n      break;\n    }\n  }\n  return array;\n}\n\n/**\n * Appends the elements of `values` to `array`.\n *\n * @private\n * @param {Array} array The array to modify.\n * @param {Array} values The values to append.\n * @returns {Array} Returns `array`.\n */\nfunction arrayPush(array, values) {\n  var index = -1,\n      length = values.length,\n      offset = array.length;\n\n  while (++index < length) {\n    array[offset + index] = values[index];\n  }\n  return array;\n}\n\n/**\n * A specialized version of `_.reduce` for arrays without support for\n * iteratee shorthands.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} iteratee The function invoked per iteration.\n * @param {*} [accumulator] The initial value.\n * @param {boolean} [initAccum] Specify using the first element of `array` as\n *  the initial value.\n * @returns {*} Returns the accumulated value.\n */\nfunction arrayReduce(array, iteratee, accumulator, initAccum) {\n  var index = -1,\n      length = array ? array.length : 0;\n\n  if (initAccum && length) {\n    accumulator = array[++index];\n  }\n  while (++index < length) {\n    accumulator = iteratee(accumulator, array[index], index, array);\n  }\n  return accumulator;\n}\n\n/**\n * The base implementation of `_.times` without support for iteratee shorthands\n * or max array length checks.\n *\n * @private\n * @param {number} n The number of times to invoke `iteratee`.\n * @param {Function} iteratee The function invoked per iteration.\n * @returns {Array} Returns the array of results.\n */\nfunction baseTimes(n, iteratee) {\n  var index = -1,\n      result = Array(n);\n\n  while (++index < n) {\n    result[index] = iteratee(index);\n  }\n  return result;\n}\n\n/**\n * The base implementation of `_.unary` without support for storing metadata.\n *\n * @private\n * @param {Function} func The function to cap arguments for.\n * @returns {Function} Returns the new capped function.\n */\nfunction baseUnary(func) {\n  return function(value) {\n    return func(value);\n  };\n}\n\n/**\n * Gets the value at `key` of `object`.\n *\n * @private\n * @param {Object} [object] The object to query.\n * @param {string} key The key of the property to get.\n * @returns {*} Returns the property value.\n */\nfunction getValue(object, key) {\n  return object == null ? undefined : object[key];\n}\n\n/**\n * Checks if `value` is a host object in IE < 9.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a host object, else `false`.\n */\nfunction isHostObject(value) {\n  // Many host objects are `Object` objects that can coerce to strings\n  // despite having improperly defined `toString` methods.\n  var result = false;\n  if (value != null && typeof value.toString != 'function') {\n    try {\n      result = !!(value + '');\n    } catch (e) {}\n  }\n  return result;\n}\n\n/**\n * Converts `map` to its key-value pairs.\n *\n * @private\n * @param {Object} map The map to convert.\n * @returns {Array} Returns the key-value pairs.\n */\nfunction mapToArray(map) {\n  var index = -1,\n      result = Array(map.size);\n\n  map.forEach(function(value, key) {\n    result[++index] = [key, value];\n  });\n  return result;\n}\n\n/**\n * Creates a unary function that invokes `func` with its argument transformed.\n *\n * @private\n * @param {Function} func The function to wrap.\n * @param {Function} transform The argument transform.\n * @returns {Function} Returns the new function.\n */\nfunction overArg(func, transform) {\n  return function(arg) {\n    return func(transform(arg));\n  };\n}\n\n/**\n * Converts `set` to an array of its values.\n *\n * @private\n * @param {Object} set The set to convert.\n * @returns {Array} Returns the values.\n */\nfunction setToArray(set) {\n  var index = -1,\n      result = Array(set.size);\n\n  set.forEach(function(value) {\n    result[++index] = value;\n  });\n  return result;\n}\n\n/** Used for built-in method references. */\nvar arrayProto = Array.prototype,\n    funcProto = Function.prototype,\n    objectProto = Object.prototype;\n\n/** Used to detect overreaching core-js shims. */\nvar coreJsData = root['__core-js_shared__'];\n\n/** Used to detect methods masquerading as native. */\nvar maskSrcKey = (function() {\n  var uid = /[^.]+$/.exec(coreJsData && coreJsData.keys && coreJsData.keys.IE_PROTO || '');\n  return uid ? ('Symbol(src)_1.' + uid) : '';\n}());\n\n/** Used to resolve the decompiled source of functions. */\nvar funcToString = funcProto.toString;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/** Used to infer the `Object` constructor. */\nvar objectCtorString = funcToString.call(Object);\n\n/**\n * Used to resolve the\n * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)\n * of values.\n */\nvar objectToString = objectProto.toString;\n\n/** Used to detect if a method is native. */\nvar reIsNative = RegExp('^' +\n  funcToString.call(hasOwnProperty).replace(reRegExpChar, '\\\\$&')\n  .replace(/hasOwnProperty|(function).*?(?=\\\\\\()| for .+?(?=\\\\\\])/g, '$1.*?') + '$'\n);\n\n/** Built-in value references. */\nvar Buffer = moduleExports ? root.Buffer : undefined,\n    Symbol = root.Symbol,\n    Uint8Array = root.Uint8Array,\n    getPrototype = overArg(Object.getPrototypeOf, Object),\n    objectCreate = Object.create,\n    propertyIsEnumerable = objectProto.propertyIsEnumerable,\n    splice = arrayProto.splice;\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeGetSymbols = Object.getOwnPropertySymbols,\n    nativeIsBuffer = Buffer ? Buffer.isBuffer : undefined,\n    nativeKeys = overArg(Object.keys, Object),\n    nativeMax = Math.max;\n\n/* Built-in method references that are verified to be native. */\nvar DataView = getNative(root, 'DataView'),\n    Map = getNative(root, 'Map'),\n    Promise = getNative(root, 'Promise'),\n    Set = getNative(root, 'Set'),\n    WeakMap = getNative(root, 'WeakMap'),\n    nativeCreate = getNative(Object, 'create');\n\n/** Used to detect maps, sets, and weakmaps. */\nvar dataViewCtorString = toSource(DataView),\n    mapCtorString = toSource(Map),\n    promiseCtorString = toSource(Promise),\n    setCtorString = toSource(Set),\n    weakMapCtorString = toSource(WeakMap);\n\n/** Used to convert symbols to primitives and strings. */\nvar symbolProto = Symbol ? Symbol.prototype : undefined,\n    symbolValueOf = symbolProto ? symbolProto.valueOf : undefined;\n\n/**\n * Creates a hash object.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction Hash(entries) {\n  var index = -1,\n      length = entries ? entries.length : 0;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n/**\n * Removes all key-value entries from the hash.\n *\n * @private\n * @name clear\n * @memberOf Hash\n */\nfunction hashClear() {\n  this.__data__ = nativeCreate ? nativeCreate(null) : {};\n}\n\n/**\n * Removes `key` and its value from the hash.\n *\n * @private\n * @name delete\n * @memberOf Hash\n * @param {Object} hash The hash to modify.\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction hashDelete(key) {\n  return this.has(key) && delete this.__data__[key];\n}\n\n/**\n * Gets the hash value for `key`.\n *\n * @private\n * @name get\n * @memberOf Hash\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction hashGet(key) {\n  var data = this.__data__;\n  if (nativeCreate) {\n    var result = data[key];\n    return result === HASH_UNDEFINED ? undefined : result;\n  }\n  return hasOwnProperty.call(data, key) ? data[key] : undefined;\n}\n\n/**\n * Checks if a hash value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf Hash\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction hashHas(key) {\n  var data = this.__data__;\n  return nativeCreate ? data[key] !== undefined : hasOwnProperty.call(data, key);\n}\n\n/**\n * Sets the hash `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf Hash\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the hash instance.\n */\nfunction hashSet(key, value) {\n  var data = this.__data__;\n  data[key] = (nativeCreate && value === undefined) ? HASH_UNDEFINED : value;\n  return this;\n}\n\n// Add methods to `Hash`.\nHash.prototype.clear = hashClear;\nHash.prototype['delete'] = hashDelete;\nHash.prototype.get = hashGet;\nHash.prototype.has = hashHas;\nHash.prototype.set = hashSet;\n\n/**\n * Creates an list cache object.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction ListCache(entries) {\n  var index = -1,\n      length = entries ? entries.length : 0;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n/**\n * Removes all key-value entries from the list cache.\n *\n * @private\n * @name clear\n * @memberOf ListCache\n */\nfunction listCacheClear() {\n  this.__data__ = [];\n}\n\n/**\n * Removes `key` and its value from the list cache.\n *\n * @private\n * @name delete\n * @memberOf ListCache\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction listCacheDelete(key) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  if (index < 0) {\n    return false;\n  }\n  var lastIndex = data.length - 1;\n  if (index == lastIndex) {\n    data.pop();\n  } else {\n    splice.call(data, index, 1);\n  }\n  return true;\n}\n\n/**\n * Gets the list cache value for `key`.\n *\n * @private\n * @name get\n * @memberOf ListCache\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction listCacheGet(key) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  return index < 0 ? undefined : data[index][1];\n}\n\n/**\n * Checks if a list cache value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf ListCache\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction listCacheHas(key) {\n  return assocIndexOf(this.__data__, key) > -1;\n}\n\n/**\n * Sets the list cache `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf ListCache\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the list cache instance.\n */\nfunction listCacheSet(key, value) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  if (index < 0) {\n    data.push([key, value]);\n  } else {\n    data[index][1] = value;\n  }\n  return this;\n}\n\n// Add methods to `ListCache`.\nListCache.prototype.clear = listCacheClear;\nListCache.prototype['delete'] = listCacheDelete;\nListCache.prototype.get = listCacheGet;\nListCache.prototype.has = listCacheHas;\nListCache.prototype.set = listCacheSet;\n\n/**\n * Creates a map cache object to store key-value pairs.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction MapCache(entries) {\n  var index = -1,\n      length = entries ? entries.length : 0;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n/**\n * Removes all key-value entries from the map.\n *\n * @private\n * @name clear\n * @memberOf MapCache\n */\nfunction mapCacheClear() {\n  this.__data__ = {\n    'hash': new Hash,\n    'map': new (Map || ListCache),\n    'string': new Hash\n  };\n}\n\n/**\n * Removes `key` and its value from the map.\n *\n * @private\n * @name delete\n * @memberOf MapCache\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction mapCacheDelete(key) {\n  return getMapData(this, key)['delete'](key);\n}\n\n/**\n * Gets the map value for `key`.\n *\n * @private\n * @name get\n * @memberOf MapCache\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction mapCacheGet(key) {\n  return getMapData(this, key).get(key);\n}\n\n/**\n * Checks if a map value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf MapCache\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction mapCacheHas(key) {\n  return getMapData(this, key).has(key);\n}\n\n/**\n * Sets the map `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf MapCache\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the map cache instance.\n */\nfunction mapCacheSet(key, value) {\n  getMapData(this, key).set(key, value);\n  return this;\n}\n\n// Add methods to `MapCache`.\nMapCache.prototype.clear = mapCacheClear;\nMapCache.prototype['delete'] = mapCacheDelete;\nMapCache.prototype.get = mapCacheGet;\nMapCache.prototype.has = mapCacheHas;\nMapCache.prototype.set = mapCacheSet;\n\n/**\n * Creates a stack cache object to store key-value pairs.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction Stack(entries) {\n  this.__data__ = new ListCache(entries);\n}\n\n/**\n * Removes all key-value entries from the stack.\n *\n * @private\n * @name clear\n * @memberOf Stack\n */\nfunction stackClear() {\n  this.__data__ = new ListCache;\n}\n\n/**\n * Removes `key` and its value from the stack.\n *\n * @private\n * @name delete\n * @memberOf Stack\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction stackDelete(key) {\n  return this.__data__['delete'](key);\n}\n\n/**\n * Gets the stack value for `key`.\n *\n * @private\n * @name get\n * @memberOf Stack\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction stackGet(key) {\n  return this.__data__.get(key);\n}\n\n/**\n * Checks if a stack value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf Stack\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction stackHas(key) {\n  return this.__data__.has(key);\n}\n\n/**\n * Sets the stack `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf Stack\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the stack cache instance.\n */\nfunction stackSet(key, value) {\n  var cache = this.__data__;\n  if (cache instanceof ListCache) {\n    var pairs = cache.__data__;\n    if (!Map || (pairs.length < LARGE_ARRAY_SIZE - 1)) {\n      pairs.push([key, value]);\n      return this;\n    }\n    cache = this.__data__ = new MapCache(pairs);\n  }\n  cache.set(key, value);\n  return this;\n}\n\n// Add methods to `Stack`.\nStack.prototype.clear = stackClear;\nStack.prototype['delete'] = stackDelete;\nStack.prototype.get = stackGet;\nStack.prototype.has = stackHas;\nStack.prototype.set = stackSet;\n\n/**\n * Creates an array of the enumerable property names of the array-like `value`.\n *\n * @private\n * @param {*} value The value to query.\n * @param {boolean} inherited Specify returning inherited property names.\n * @returns {Array} Returns the array of property names.\n */\nfunction arrayLikeKeys(value, inherited) {\n  // Safari 8.1 makes `arguments.callee` enumerable in strict mode.\n  // Safari 9 makes `arguments.length` enumerable in strict mode.\n  var result = (isArray(value) || isArguments(value))\n    ? baseTimes(value.length, String)\n    : [];\n\n  var length = result.length,\n      skipIndexes = !!length;\n\n  for (var key in value) {\n    if ((inherited || hasOwnProperty.call(value, key)) &&\n        !(skipIndexes && (key == 'length' || isIndex(key, length)))) {\n      result.push(key);\n    }\n  }\n  return result;\n}\n\n/**\n * This function is like `assignValue` except that it doesn't assign\n * `undefined` values.\n *\n * @private\n * @param {Object} object The object to modify.\n * @param {string} key The key of the property to assign.\n * @param {*} value The value to assign.\n */\nfunction assignMergeValue(object, key, value) {\n  if ((value !== undefined && !eq(object[key], value)) ||\n      (typeof key == 'number' && value === undefined && !(key in object))) {\n    object[key] = value;\n  }\n}\n\n/**\n * Assigns `value` to `key` of `object` if the existing value is not equivalent\n * using [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons.\n *\n * @private\n * @param {Object} object The object to modify.\n * @param {string} key The key of the property to assign.\n * @param {*} value The value to assign.\n */\nfunction assignValue(object, key, value) {\n  var objValue = object[key];\n  if (!(hasOwnProperty.call(object, key) && eq(objValue, value)) ||\n      (value === undefined && !(key in object))) {\n    object[key] = value;\n  }\n}\n\n/**\n * Gets the index at which the `key` is found in `array` of key-value pairs.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {*} key The key to search for.\n * @returns {number} Returns the index of the matched value, else `-1`.\n */\nfunction assocIndexOf(array, key) {\n  var length = array.length;\n  while (length--) {\n    if (eq(array[length][0], key)) {\n      return length;\n    }\n  }\n  return -1;\n}\n\n/**\n * The base implementation of `_.assign` without support for multiple sources\n * or `customizer` functions.\n *\n * @private\n * @param {Object} object The destination object.\n * @param {Object} source The source object.\n * @returns {Object} Returns `object`.\n */\nfunction baseAssign(object, source) {\n  return object && copyObject(source, keys(source), object);\n}\n\n/**\n * The base implementation of `_.clone` and `_.cloneDeep` which tracks\n * traversed objects.\n *\n * @private\n * @param {*} value The value to clone.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @param {boolean} [isFull] Specify a clone including symbols.\n * @param {Function} [customizer] The function to customize cloning.\n * @param {string} [key] The key of `value`.\n * @param {Object} [object] The parent object of `value`.\n * @param {Object} [stack] Tracks traversed objects and their clone counterparts.\n * @returns {*} Returns the cloned value.\n */\nfunction baseClone(value, isDeep, isFull, customizer, key, object, stack) {\n  var result;\n  if (customizer) {\n    result = object ? customizer(value, key, object, stack) : customizer(value);\n  }\n  if (result !== undefined) {\n    return result;\n  }\n  if (!isObject(value)) {\n    return value;\n  }\n  var isArr = isArray(value);\n  if (isArr) {\n    result = initCloneArray(value);\n    if (!isDeep) {\n      return copyArray(value, result);\n    }\n  } else {\n    var tag = getTag(value),\n        isFunc = tag == funcTag || tag == genTag;\n\n    if (isBuffer(value)) {\n      return cloneBuffer(value, isDeep);\n    }\n    if (tag == objectTag || tag == argsTag || (isFunc && !object)) {\n      if (isHostObject(value)) {\n        return object ? value : {};\n      }\n      result = initCloneObject(isFunc ? {} : value);\n      if (!isDeep) {\n        return copySymbols(value, baseAssign(result, value));\n      }\n    } else {\n      if (!cloneableTags[tag]) {\n        return object ? value : {};\n      }\n      result = initCloneByTag(value, tag, baseClone, isDeep);\n    }\n  }\n  // Check for circular references and return its corresponding clone.\n  stack || (stack = new Stack);\n  var stacked = stack.get(value);\n  if (stacked) {\n    return stacked;\n  }\n  stack.set(value, result);\n\n  if (!isArr) {\n    var props = isFull ? getAllKeys(value) : keys(value);\n  }\n  arrayEach(props || value, function(subValue, key) {\n    if (props) {\n      key = subValue;\n      subValue = value[key];\n    }\n    // Recursively populate clone (susceptible to call stack limits).\n    assignValue(result, key, baseClone(subValue, isDeep, isFull, customizer, key, value, stack));\n  });\n  return result;\n}\n\n/**\n * The base implementation of `_.create` without support for assigning\n * properties to the created object.\n *\n * @private\n * @param {Object} prototype The object to inherit from.\n * @returns {Object} Returns the new object.\n */\nfunction baseCreate(proto) {\n  return isObject(proto) ? objectCreate(proto) : {};\n}\n\n/**\n * The base implementation of `getAllKeys` and `getAllKeysIn` which uses\n * `keysFunc` and `symbolsFunc` to get the enumerable property names and\n * symbols of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @param {Function} keysFunc The function to get the keys of `object`.\n * @param {Function} symbolsFunc The function to get the symbols of `object`.\n * @returns {Array} Returns the array of property names and symbols.\n */\nfunction baseGetAllKeys(object, keysFunc, symbolsFunc) {\n  var result = keysFunc(object);\n  return isArray(object) ? result : arrayPush(result, symbolsFunc(object));\n}\n\n/**\n * The base implementation of `getTag`.\n *\n * @private\n * @param {*} value The value to query.\n * @returns {string} Returns the `toStringTag`.\n */\nfunction baseGetTag(value) {\n  return objectToString.call(value);\n}\n\n/**\n * The base implementation of `_.isNative` without bad shim checks.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a native function,\n *  else `false`.\n */\nfunction baseIsNative(value) {\n  if (!isObject(value) || isMasked(value)) {\n    return false;\n  }\n  var pattern = (isFunction(value) || isHostObject(value)) ? reIsNative : reIsHostCtor;\n  return pattern.test(toSource(value));\n}\n\n/**\n * The base implementation of `_.isTypedArray` without Node.js optimizations.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a typed array, else `false`.\n */\nfunction baseIsTypedArray(value) {\n  return isObjectLike(value) &&\n    isLength(value.length) && !!typedArrayTags[objectToString.call(value)];\n}\n\n/**\n * The base implementation of `_.keys` which doesn't treat sparse arrays as dense.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n */\nfunction baseKeys(object) {\n  if (!isPrototype(object)) {\n    return nativeKeys(object);\n  }\n  var result = [];\n  for (var key in Object(object)) {\n    if (hasOwnProperty.call(object, key) && key != 'constructor') {\n      result.push(key);\n    }\n  }\n  return result;\n}\n\n/**\n * The base implementation of `_.keysIn` which doesn't treat sparse arrays as dense.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n */\nfunction baseKeysIn(object) {\n  if (!isObject(object)) {\n    return nativeKeysIn(object);\n  }\n  var isProto = isPrototype(object),\n      result = [];\n\n  for (var key in object) {\n    if (!(key == 'constructor' && (isProto || !hasOwnProperty.call(object, key)))) {\n      result.push(key);\n    }\n  }\n  return result;\n}\n\n/**\n * The base implementation of `_.merge` without support for multiple sources.\n *\n * @private\n * @param {Object} object The destination object.\n * @param {Object} source The source object.\n * @param {number} srcIndex The index of `source`.\n * @param {Function} [customizer] The function to customize merged values.\n * @param {Object} [stack] Tracks traversed source values and their merged\n *  counterparts.\n */\nfunction baseMerge(object, source, srcIndex, customizer, stack) {\n  if (object === source) {\n    return;\n  }\n  if (!(isArray(source) || isTypedArray(source))) {\n    var props = baseKeysIn(source);\n  }\n  arrayEach(props || source, function(srcValue, key) {\n    if (props) {\n      key = srcValue;\n      srcValue = source[key];\n    }\n    if (isObject(srcValue)) {\n      stack || (stack = new Stack);\n      baseMergeDeep(object, source, key, srcIndex, baseMerge, customizer, stack);\n    }\n    else {\n      var newValue = customizer\n        ? customizer(object[key], srcValue, (key + ''), object, source, stack)\n        : undefined;\n\n      if (newValue === undefined) {\n        newValue = srcValue;\n      }\n      assignMergeValue(object, key, newValue);\n    }\n  });\n}\n\n/**\n * A specialized version of `baseMerge` for arrays and objects which performs\n * deep merges and tracks traversed objects enabling objects with circular\n * references to be merged.\n *\n * @private\n * @param {Object} object The destination object.\n * @param {Object} source The source object.\n * @param {string} key The key of the value to merge.\n * @param {number} srcIndex The index of `source`.\n * @param {Function} mergeFunc The function to merge values.\n * @param {Function} [customizer] The function to customize assigned values.\n * @param {Object} [stack] Tracks traversed source values and their merged\n *  counterparts.\n */\nfunction baseMergeDeep(object, source, key, srcIndex, mergeFunc, customizer, stack) {\n  var objValue = object[key],\n      srcValue = source[key],\n      stacked = stack.get(srcValue);\n\n  if (stacked) {\n    assignMergeValue(object, key, stacked);\n    return;\n  }\n  var newValue = customizer\n    ? customizer(objValue, srcValue, (key + ''), object, source, stack)\n    : undefined;\n\n  var isCommon = newValue === undefined;\n\n  if (isCommon) {\n    newValue = srcValue;\n    if (isArray(srcValue) || isTypedArray(srcValue)) {\n      if (isArray(objValue)) {\n        newValue = objValue;\n      }\n      else if (isArrayLikeObject(objValue)) {\n        newValue = copyArray(objValue);\n      }\n      else {\n        isCommon = false;\n        newValue = baseClone(srcValue, true);\n      }\n    }\n    else if (isPlainObject(srcValue) || isArguments(srcValue)) {\n      if (isArguments(objValue)) {\n        newValue = toPlainObject(objValue);\n      }\n      else if (!isObject(objValue) || (srcIndex && isFunction(objValue))) {\n        isCommon = false;\n        newValue = baseClone(srcValue, true);\n      }\n      else {\n        newValue = objValue;\n      }\n    }\n    else {\n      isCommon = false;\n    }\n  }\n  if (isCommon) {\n    // Recursively merge objects and arrays (susceptible to call stack limits).\n    stack.set(srcValue, newValue);\n    mergeFunc(newValue, srcValue, srcIndex, customizer, stack);\n    stack['delete'](srcValue);\n  }\n  assignMergeValue(object, key, newValue);\n}\n\n/**\n * The base implementation of `_.rest` which doesn't validate or coerce arguments.\n *\n * @private\n * @param {Function} func The function to apply a rest parameter to.\n * @param {number} [start=func.length-1] The start position of the rest parameter.\n * @returns {Function} Returns the new function.\n */\nfunction baseRest(func, start) {\n  start = nativeMax(start === undefined ? (func.length - 1) : start, 0);\n  return function() {\n    var args = arguments,\n        index = -1,\n        length = nativeMax(args.length - start, 0),\n        array = Array(length);\n\n    while (++index < length) {\n      array[index] = args[start + index];\n    }\n    index = -1;\n    var otherArgs = Array(start + 1);\n    while (++index < start) {\n      otherArgs[index] = args[index];\n    }\n    otherArgs[start] = array;\n    return apply(func, this, otherArgs);\n  };\n}\n\n/**\n * Creates a clone of  `buffer`.\n *\n * @private\n * @param {Buffer} buffer The buffer to clone.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Buffer} Returns the cloned buffer.\n */\nfunction cloneBuffer(buffer, isDeep) {\n  if (isDeep) {\n    return buffer.slice();\n  }\n  var result = new buffer.constructor(buffer.length);\n  buffer.copy(result);\n  return result;\n}\n\n/**\n * Creates a clone of `arrayBuffer`.\n *\n * @private\n * @param {ArrayBuffer} arrayBuffer The array buffer to clone.\n * @returns {ArrayBuffer} Returns the cloned array buffer.\n */\nfunction cloneArrayBuffer(arrayBuffer) {\n  var result = new arrayBuffer.constructor(arrayBuffer.byteLength);\n  new Uint8Array(result).set(new Uint8Array(arrayBuffer));\n  return result;\n}\n\n/**\n * Creates a clone of `dataView`.\n *\n * @private\n * @param {Object} dataView The data view to clone.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Object} Returns the cloned data view.\n */\nfunction cloneDataView(dataView, isDeep) {\n  var buffer = isDeep ? cloneArrayBuffer(dataView.buffer) : dataView.buffer;\n  return new dataView.constructor(buffer, dataView.byteOffset, dataView.byteLength);\n}\n\n/**\n * Creates a clone of `map`.\n *\n * @private\n * @param {Object} map The map to clone.\n * @param {Function} cloneFunc The function to clone values.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Object} Returns the cloned map.\n */\nfunction cloneMap(map, isDeep, cloneFunc) {\n  var array = isDeep ? cloneFunc(mapToArray(map), true) : mapToArray(map);\n  return arrayReduce(array, addMapEntry, new map.constructor);\n}\n\n/**\n * Creates a clone of `regexp`.\n *\n * @private\n * @param {Object} regexp The regexp to clone.\n * @returns {Object} Returns the cloned regexp.\n */\nfunction cloneRegExp(regexp) {\n  var result = new regexp.constructor(regexp.source, reFlags.exec(regexp));\n  result.lastIndex = regexp.lastIndex;\n  return result;\n}\n\n/**\n * Creates a clone of `set`.\n *\n * @private\n * @param {Object} set The set to clone.\n * @param {Function} cloneFunc The function to clone values.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Object} Returns the cloned set.\n */\nfunction cloneSet(set, isDeep, cloneFunc) {\n  var array = isDeep ? cloneFunc(setToArray(set), true) : setToArray(set);\n  return arrayReduce(array, addSetEntry, new set.constructor);\n}\n\n/**\n * Creates a clone of the `symbol` object.\n *\n * @private\n * @param {Object} symbol The symbol object to clone.\n * @returns {Object} Returns the cloned symbol object.\n */\nfunction cloneSymbol(symbol) {\n  return symbolValueOf ? Object(symbolValueOf.call(symbol)) : {};\n}\n\n/**\n * Creates a clone of `typedArray`.\n *\n * @private\n * @param {Object} typedArray The typed array to clone.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Object} Returns the cloned typed array.\n */\nfunction cloneTypedArray(typedArray, isDeep) {\n  var buffer = isDeep ? cloneArrayBuffer(typedArray.buffer) : typedArray.buffer;\n  return new typedArray.constructor(buffer, typedArray.byteOffset, typedArray.length);\n}\n\n/**\n * Copies the values of `source` to `array`.\n *\n * @private\n * @param {Array} source The array to copy values from.\n * @param {Array} [array=[]] The array to copy values to.\n * @returns {Array} Returns `array`.\n */\nfunction copyArray(source, array) {\n  var index = -1,\n      length = source.length;\n\n  array || (array = Array(length));\n  while (++index < length) {\n    array[index] = source[index];\n  }\n  return array;\n}\n\n/**\n * Copies properties of `source` to `object`.\n *\n * @private\n * @param {Object} source The object to copy properties from.\n * @param {Array} props The property identifiers to copy.\n * @param {Object} [object={}] The object to copy properties to.\n * @param {Function} [customizer] The function to customize copied values.\n * @returns {Object} Returns `object`.\n */\nfunction copyObject(source, props, object, customizer) {\n  object || (object = {});\n\n  var index = -1,\n      length = props.length;\n\n  while (++index < length) {\n    var key = props[index];\n\n    var newValue = customizer\n      ? customizer(object[key], source[key], key, object, source)\n      : undefined;\n\n    assignValue(object, key, newValue === undefined ? source[key] : newValue);\n  }\n  return object;\n}\n\n/**\n * Copies own symbol properties of `source` to `object`.\n *\n * @private\n * @param {Object} source The object to copy symbols from.\n * @param {Object} [object={}] The object to copy symbols to.\n * @returns {Object} Returns `object`.\n */\nfunction copySymbols(source, object) {\n  return copyObject(source, getSymbols(source), object);\n}\n\n/**\n * Creates a function like `_.assign`.\n *\n * @private\n * @param {Function} assigner The function to assign values.\n * @returns {Function} Returns the new assigner function.\n */\nfunction createAssigner(assigner) {\n  return baseRest(function(object, sources) {\n    var index = -1,\n        length = sources.length,\n        customizer = length > 1 ? sources[length - 1] : undefined,\n        guard = length > 2 ? sources[2] : undefined;\n\n    customizer = (assigner.length > 3 && typeof customizer == 'function')\n      ? (length--, customizer)\n      : undefined;\n\n    if (guard && isIterateeCall(sources[0], sources[1], guard)) {\n      customizer = length < 3 ? undefined : customizer;\n      length = 1;\n    }\n    object = Object(object);\n    while (++index < length) {\n      var source = sources[index];\n      if (source) {\n        assigner(object, source, index, customizer);\n      }\n    }\n    return object;\n  });\n}\n\n/**\n * Creates an array of own enumerable property names and symbols of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names and symbols.\n */\nfunction getAllKeys(object) {\n  return baseGetAllKeys(object, keys, getSymbols);\n}\n\n/**\n * Gets the data for `map`.\n *\n * @private\n * @param {Object} map The map to query.\n * @param {string} key The reference key.\n * @returns {*} Returns the map data.\n */\nfunction getMapData(map, key) {\n  var data = map.__data__;\n  return isKeyable(key)\n    ? data[typeof key == 'string' ? 'string' : 'hash']\n    : data.map;\n}\n\n/**\n * Gets the native function at `key` of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @param {string} key The key of the method to get.\n * @returns {*} Returns the function if it's native, else `undefined`.\n */\nfunction getNative(object, key) {\n  var value = getValue(object, key);\n  return baseIsNative(value) ? value : undefined;\n}\n\n/**\n * Creates an array of the own enumerable symbol properties of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of symbols.\n */\nvar getSymbols = nativeGetSymbols ? overArg(nativeGetSymbols, Object) : stubArray;\n\n/**\n * Gets the `toStringTag` of `value`.\n *\n * @private\n * @param {*} value The value to query.\n * @returns {string} Returns the `toStringTag`.\n */\nvar getTag = baseGetTag;\n\n// Fallback for data views, maps, sets, and weak maps in IE 11,\n// for data views in Edge < 14, and promises in Node.js.\nif ((DataView && getTag(new DataView(new ArrayBuffer(1))) != dataViewTag) ||\n    (Map && getTag(new Map) != mapTag) ||\n    (Promise && getTag(Promise.resolve()) != promiseTag) ||\n    (Set && getTag(new Set) != setTag) ||\n    (WeakMap && getTag(new WeakMap) != weakMapTag)) {\n  getTag = function(value) {\n    var result = objectToString.call(value),\n        Ctor = result == objectTag ? value.constructor : undefined,\n        ctorString = Ctor ? toSource(Ctor) : undefined;\n\n    if (ctorString) {\n      switch (ctorString) {\n        case dataViewCtorString: return dataViewTag;\n        case mapCtorString: return mapTag;\n        case promiseCtorString: return promiseTag;\n        case setCtorString: return setTag;\n        case weakMapCtorString: return weakMapTag;\n      }\n    }\n    return result;\n  };\n}\n\n/**\n * Initializes an array clone.\n *\n * @private\n * @param {Array} array The array to clone.\n * @returns {Array} Returns the initialized clone.\n */\nfunction initCloneArray(array) {\n  var length = array.length,\n      result = array.constructor(length);\n\n  // Add properties assigned by `RegExp#exec`.\n  if (length && typeof array[0] == 'string' && hasOwnProperty.call(array, 'index')) {\n    result.index = array.index;\n    result.input = array.input;\n  }\n  return result;\n}\n\n/**\n * Initializes an object clone.\n *\n * @private\n * @param {Object} object The object to clone.\n * @returns {Object} Returns the initialized clone.\n */\nfunction initCloneObject(object) {\n  return (typeof object.constructor == 'function' && !isPrototype(object))\n    ? baseCreate(getPrototype(object))\n    : {};\n}\n\n/**\n * Initializes an object clone based on its `toStringTag`.\n *\n * **Note:** This function only supports cloning values with tags of\n * `Boolean`, `Date`, `Error`, `Number`, `RegExp`, or `String`.\n *\n * @private\n * @param {Object} object The object to clone.\n * @param {string} tag The `toStringTag` of the object to clone.\n * @param {Function} cloneFunc The function to clone values.\n * @param {boolean} [isDeep] Specify a deep clone.\n * @returns {Object} Returns the initialized clone.\n */\nfunction initCloneByTag(object, tag, cloneFunc, isDeep) {\n  var Ctor = object.constructor;\n  switch (tag) {\n    case arrayBufferTag:\n      return cloneArrayBuffer(object);\n\n    case boolTag:\n    case dateTag:\n      return new Ctor(+object);\n\n    case dataViewTag:\n      return cloneDataView(object, isDeep);\n\n    case float32Tag: case float64Tag:\n    case int8Tag: case int16Tag: case int32Tag:\n    case uint8Tag: case uint8ClampedTag: case uint16Tag: case uint32Tag:\n      return cloneTypedArray(object, isDeep);\n\n    case mapTag:\n      return cloneMap(object, isDeep, cloneFunc);\n\n    case numberTag:\n    case stringTag:\n      return new Ctor(object);\n\n    case regexpTag:\n      return cloneRegExp(object);\n\n    case setTag:\n      return cloneSet(object, isDeep, cloneFunc);\n\n    case symbolTag:\n      return cloneSymbol(object);\n  }\n}\n\n/**\n * Checks if `value` is a valid array-like index.\n *\n * @private\n * @param {*} value The value to check.\n * @param {number} [length=MAX_SAFE_INTEGER] The upper bounds of a valid index.\n * @returns {boolean} Returns `true` if `value` is a valid index, else `false`.\n */\nfunction isIndex(value, length) {\n  length = length == null ? MAX_SAFE_INTEGER : length;\n  return !!length &&\n    (typeof value == 'number' || reIsUint.test(value)) &&\n    (value > -1 && value % 1 == 0 && value < length);\n}\n\n/**\n * Checks if the given arguments are from an iteratee call.\n *\n * @private\n * @param {*} value The potential iteratee value argument.\n * @param {*} index The potential iteratee index or key argument.\n * @param {*} object The potential iteratee object argument.\n * @returns {boolean} Returns `true` if the arguments are from an iteratee call,\n *  else `false`.\n */\nfunction isIterateeCall(value, index, object) {\n  if (!isObject(object)) {\n    return false;\n  }\n  var type = typeof index;\n  if (type == 'number'\n        ? (isArrayLike(object) && isIndex(index, object.length))\n        : (type == 'string' && index in object)\n      ) {\n    return eq(object[index], value);\n  }\n  return false;\n}\n\n/**\n * Checks if `value` is suitable for use as unique object key.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is suitable, else `false`.\n */\nfunction isKeyable(value) {\n  var type = typeof value;\n  return (type == 'string' || type == 'number' || type == 'symbol' || type == 'boolean')\n    ? (value !== '__proto__')\n    : (value === null);\n}\n\n/**\n * Checks if `func` has its source masked.\n *\n * @private\n * @param {Function} func The function to check.\n * @returns {boolean} Returns `true` if `func` is masked, else `false`.\n */\nfunction isMasked(func) {\n  return !!maskSrcKey && (maskSrcKey in func);\n}\n\n/**\n * Checks if `value` is likely a prototype object.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a prototype, else `false`.\n */\nfunction isPrototype(value) {\n  var Ctor = value && value.constructor,\n      proto = (typeof Ctor == 'function' && Ctor.prototype) || objectProto;\n\n  return value === proto;\n}\n\n/**\n * This function is like\n * [`Object.keys`](http://ecma-international.org/ecma-262/7.0/#sec-object.keys)\n * except that it includes inherited enumerable properties.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n */\nfunction nativeKeysIn(object) {\n  var result = [];\n  if (object != null) {\n    for (var key in Object(object)) {\n      result.push(key);\n    }\n  }\n  return result;\n}\n\n/**\n * Converts `func` to its source code.\n *\n * @private\n * @param {Function} func The function to process.\n * @returns {string} Returns the source code.\n */\nfunction toSource(func) {\n  if (func != null) {\n    try {\n      return funcToString.call(func);\n    } catch (e) {}\n    try {\n      return (func + '');\n    } catch (e) {}\n  }\n  return '';\n}\n\n/**\n * Performs a\n * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * comparison between two values to determine if they are equivalent.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to compare.\n * @param {*} other The other value to compare.\n * @returns {boolean} Returns `true` if the values are equivalent, else `false`.\n * @example\n *\n * var object = { 'a': 1 };\n * var other = { 'a': 1 };\n *\n * _.eq(object, object);\n * // => true\n *\n * _.eq(object, other);\n * // => false\n *\n * _.eq('a', 'a');\n * // => true\n *\n * _.eq('a', Object('a'));\n * // => false\n *\n * _.eq(NaN, NaN);\n * // => true\n */\nfunction eq(value, other) {\n  return value === other || (value !== value && other !== other);\n}\n\n/**\n * Checks if `value` is likely an `arguments` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an `arguments` object,\n *  else `false`.\n * @example\n *\n * _.isArguments(function() { return arguments; }());\n * // => true\n *\n * _.isArguments([1, 2, 3]);\n * // => false\n */\nfunction isArguments(value) {\n  // Safari 8.1 makes `arguments.callee` enumerable in strict mode.\n  return isArrayLikeObject(value) && hasOwnProperty.call(value, 'callee') &&\n    (!propertyIsEnumerable.call(value, 'callee') || objectToString.call(value) == argsTag);\n}\n\n/**\n * Checks if `value` is classified as an `Array` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an array, else `false`.\n * @example\n *\n * _.isArray([1, 2, 3]);\n * // => true\n *\n * _.isArray(document.body.children);\n * // => false\n *\n * _.isArray('abc');\n * // => false\n *\n * _.isArray(_.noop);\n * // => false\n */\nvar isArray = Array.isArray;\n\n/**\n * Checks if `value` is array-like. A value is considered array-like if it's\n * not a function and has a `value.length` that's an integer greater than or\n * equal to `0` and less than or equal to `Number.MAX_SAFE_INTEGER`.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is array-like, else `false`.\n * @example\n *\n * _.isArrayLike([1, 2, 3]);\n * // => true\n *\n * _.isArrayLike(document.body.children);\n * // => true\n *\n * _.isArrayLike('abc');\n * // => true\n *\n * _.isArrayLike(_.noop);\n * // => false\n */\nfunction isArrayLike(value) {\n  return value != null && isLength(value.length) && !isFunction(value);\n}\n\n/**\n * This method is like `_.isArrayLike` except that it also checks if `value`\n * is an object.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an array-like object,\n *  else `false`.\n * @example\n *\n * _.isArrayLikeObject([1, 2, 3]);\n * // => true\n *\n * _.isArrayLikeObject(document.body.children);\n * // => true\n *\n * _.isArrayLikeObject('abc');\n * // => false\n *\n * _.isArrayLikeObject(_.noop);\n * // => false\n */\nfunction isArrayLikeObject(value) {\n  return isObjectLike(value) && isArrayLike(value);\n}\n\n/**\n * Checks if `value` is a buffer.\n *\n * @static\n * @memberOf _\n * @since 4.3.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a buffer, else `false`.\n * @example\n *\n * _.isBuffer(new Buffer(2));\n * // => true\n *\n * _.isBuffer(new Uint8Array(2));\n * // => false\n */\nvar isBuffer = nativeIsBuffer || stubFalse;\n\n/**\n * Checks if `value` is classified as a `Function` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a function, else `false`.\n * @example\n *\n * _.isFunction(_);\n * // => true\n *\n * _.isFunction(/abc/);\n * // => false\n */\nfunction isFunction(value) {\n  // The use of `Object#toString` avoids issues with the `typeof` operator\n  // in Safari 8-9 which returns 'object' for typed array and other constructors.\n  var tag = isObject(value) ? objectToString.call(value) : '';\n  return tag == funcTag || tag == genTag;\n}\n\n/**\n * Checks if `value` is a valid array-like length.\n *\n * **Note:** This method is loosely based on\n * [`ToLength`](http://ecma-international.org/ecma-262/7.0/#sec-tolength).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a valid length, else `false`.\n * @example\n *\n * _.isLength(3);\n * // => true\n *\n * _.isLength(Number.MIN_VALUE);\n * // => false\n *\n * _.isLength(Infinity);\n * // => false\n *\n * _.isLength('3');\n * // => false\n */\nfunction isLength(value) {\n  return typeof value == 'number' &&\n    value > -1 && value % 1 == 0 && value <= MAX_SAFE_INTEGER;\n}\n\n/**\n * Checks if `value` is the\n * [language type](http://www.ecma-international.org/ecma-262/7.0/#sec-ecmascript-language-types)\n * of `Object`. (e.g. arrays, functions, objects, regexes, `new Number(0)`, and `new String('')`)\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an object, else `false`.\n * @example\n *\n * _.isObject({});\n * // => true\n *\n * _.isObject([1, 2, 3]);\n * // => true\n *\n * _.isObject(_.noop);\n * // => true\n *\n * _.isObject(null);\n * // => false\n */\nfunction isObject(value) {\n  var type = typeof value;\n  return !!value && (type == 'object' || type == 'function');\n}\n\n/**\n * Checks if `value` is object-like. A value is object-like if it's not `null`\n * and has a `typeof` result of \"object\".\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is object-like, else `false`.\n * @example\n *\n * _.isObjectLike({});\n * // => true\n *\n * _.isObjectLike([1, 2, 3]);\n * // => true\n *\n * _.isObjectLike(_.noop);\n * // => false\n *\n * _.isObjectLike(null);\n * // => false\n */\nfunction isObjectLike(value) {\n  return !!value && typeof value == 'object';\n}\n\n/**\n * Checks if `value` is a plain object, that is, an object created by the\n * `Object` constructor or one with a `[[Prototype]]` of `null`.\n *\n * @static\n * @memberOf _\n * @since 0.8.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a plain object, else `false`.\n * @example\n *\n * function Foo() {\n *   this.a = 1;\n * }\n *\n * _.isPlainObject(new Foo);\n * // => false\n *\n * _.isPlainObject([1, 2, 3]);\n * // => false\n *\n * _.isPlainObject({ 'x': 0, 'y': 0 });\n * // => true\n *\n * _.isPlainObject(Object.create(null));\n * // => true\n */\nfunction isPlainObject(value) {\n  if (!isObjectLike(value) ||\n      objectToString.call(value) != objectTag || isHostObject(value)) {\n    return false;\n  }\n  var proto = getPrototype(value);\n  if (proto === null) {\n    return true;\n  }\n  var Ctor = hasOwnProperty.call(proto, 'constructor') && proto.constructor;\n  return (typeof Ctor == 'function' &&\n    Ctor instanceof Ctor && funcToString.call(Ctor) == objectCtorString);\n}\n\n/**\n * Checks if `value` is classified as a typed array.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a typed array, else `false`.\n * @example\n *\n * _.isTypedArray(new Uint8Array);\n * // => true\n *\n * _.isTypedArray([]);\n * // => false\n */\nvar isTypedArray = nodeIsTypedArray ? baseUnary(nodeIsTypedArray) : baseIsTypedArray;\n\n/**\n * Converts `value` to a plain object flattening inherited enumerable string\n * keyed properties of `value` to own properties of the plain object.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category Lang\n * @param {*} value The value to convert.\n * @returns {Object} Returns the converted plain object.\n * @example\n *\n * function Foo() {\n *   this.b = 2;\n * }\n *\n * Foo.prototype.c = 3;\n *\n * _.assign({ 'a': 1 }, new Foo);\n * // => { 'a': 1, 'b': 2 }\n *\n * _.assign({ 'a': 1 }, _.toPlainObject(new Foo));\n * // => { 'a': 1, 'b': 2, 'c': 3 }\n */\nfunction toPlainObject(value) {\n  return copyObject(value, keysIn(value));\n}\n\n/**\n * Creates an array of the own enumerable property names of `object`.\n *\n * **Note:** Non-object values are coerced to objects. See the\n * [ES spec](http://ecma-international.org/ecma-262/7.0/#sec-object.keys)\n * for more details.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Object\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n * @example\n *\n * function Foo() {\n *   this.a = 1;\n *   this.b = 2;\n * }\n *\n * Foo.prototype.c = 3;\n *\n * _.keys(new Foo);\n * // => ['a', 'b'] (iteration order is not guaranteed)\n *\n * _.keys('hi');\n * // => ['0', '1']\n */\nfunction keys(object) {\n  return isArrayLike(object) ? arrayLikeKeys(object) : baseKeys(object);\n}\n\n/**\n * Creates an array of the own and inherited enumerable property names of `object`.\n *\n * **Note:** Non-object values are coerced to objects.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category Object\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n * @example\n *\n * function Foo() {\n *   this.a = 1;\n *   this.b = 2;\n * }\n *\n * Foo.prototype.c = 3;\n *\n * _.keysIn(new Foo);\n * // => ['a', 'b', 'c'] (iteration order is not guaranteed)\n */\nfunction keysIn(object) {\n  return isArrayLike(object) ? arrayLikeKeys(object, true) : baseKeysIn(object);\n}\n\n/**\n * This method is like `_.assign` except that it recursively merges own and\n * inherited enumerable string keyed properties of source objects into the\n * destination object. Source properties that resolve to `undefined` are\n * skipped if a destination value exists. Array and plain object properties\n * are merged recursively. Other objects and value types are overridden by\n * assignment. Source objects are applied from left to right. Subsequent\n * sources overwrite property assignments of previous sources.\n *\n * **Note:** This method mutates `object`.\n *\n * @static\n * @memberOf _\n * @since 0.5.0\n * @category Object\n * @param {Object} object The destination object.\n * @param {...Object} [sources] The source objects.\n * @returns {Object} Returns `object`.\n * @example\n *\n * var object = {\n *   'a': [{ 'b': 2 }, { 'd': 4 }]\n * };\n *\n * var other = {\n *   'a': [{ 'c': 3 }, { 'e': 5 }]\n * };\n *\n * _.merge(object, other);\n * // => { 'a': [{ 'b': 2, 'c': 3 }, { 'd': 4, 'e': 5 }] }\n */\nvar merge = createAssigner(function(object, source, srcIndex) {\n  baseMerge(object, source, srcIndex);\n});\n\n/**\n * This method returns a new empty array.\n *\n * @static\n * @memberOf _\n * @since 4.13.0\n * @category Util\n * @returns {Array} Returns the new empty array.\n * @example\n *\n * var arrays = _.times(2, _.stubArray);\n *\n * console.log(arrays);\n * // => [[], []]\n *\n * console.log(arrays[0] === arrays[1]);\n * // => false\n */\nfunction stubArray() {\n  return [];\n}\n\n/**\n * This method returns `false`.\n *\n * @static\n * @memberOf _\n * @since 4.13.0\n * @category Util\n * @returns {boolean} Returns `false`.\n * @example\n *\n * _.times(2, _.stubFalse);\n * // => [false, false]\n */\nfunction stubFalse() {\n  return false;\n}\n\nmodule.exports = merge;\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/lodash.merge/index.js\n// module id = 1\n// module chunks = 0","'use strict';\nvar Mutation = global.MutationObserver || global.WebKitMutationObserver;\n\nvar scheduleDrain;\n\n{\n  if (Mutation) {\n    var called = 0;\n    var observer = new Mutation(nextTick);\n    var element = global.document.createTextNode('');\n    observer.observe(element, {\n      characterData: true\n    });\n    scheduleDrain = function () {\n      element.data = (called = ++called % 2);\n    };\n  } else if (!global.setImmediate && typeof global.MessageChannel !== 'undefined') {\n    var channel = new global.MessageChannel();\n    channel.port1.onmessage = nextTick;\n    scheduleDrain = function () {\n      channel.port2.postMessage(0);\n    };\n  } else if ('document' in global && 'onreadystatechange' in global.document.createElement('script')) {\n    scheduleDrain = function () {\n\n      // Create a <script> element; its readystatechange event will be fired asynchronously once it is inserted\n      // into the document. Do so, thus queuing up the task. Remember to clean up once it's been called.\n      var scriptEl = global.document.createElement('script');\n      scriptEl.onreadystatechange = function () {\n        nextTick();\n\n        scriptEl.onreadystatechange = null;\n        scriptEl.parentNode.removeChild(scriptEl);\n        scriptEl = null;\n      };\n      global.document.documentElement.appendChild(scriptEl);\n    };\n  } else {\n    scheduleDrain = function () {\n      setTimeout(nextTick, 0);\n    };\n  }\n}\n\nvar draining;\nvar queue = [];\n//named nextTick for less confusing stack traces\nfunction nextTick() {\n  draining = true;\n  var i, oldQueue;\n  var len = queue.length;\n  while (len) {\n    oldQueue = queue;\n    queue = [];\n    i = -1;\n    while (++i < len) {\n      oldQueue[i]();\n    }\n    len = queue.length;\n  }\n  draining = false;\n}\n\nmodule.exports = immediate;\nfunction immediate(task) {\n  if (queue.push(task) === 1 && !draining) {\n    scheduleDrain();\n  }\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/immediate/lib/browser.js\n// module id = 2\n// module chunks = 0","/**\n * Importing\n */\nimport sift  from 'sift';\nimport merge from 'lodash.merge';\n\n/**\n * Noop Function\n */\nexport const noop = () => {};\n\n/**\n * Executes a function based on context, and returns the value\n */\nexport const expand = (fn, context = null) => {\n  return typeof fn === 'function' ? fn.call(context) : fn;\n};\n\n/**\n * Maps Databases to an Object list\n * @param queries\n * @returns {*}\n */\nexport const mapQueries = function mapQueries(queries) {\n  return Object.keys(queries).reduce((db, name) => {\n    return merge(db, {\n      [name]: function computedQueries() {\n        // If dbsetup does not exist, throw Error!\n        if (!this.$dbsetup) throw new Error('[VuePouch] dbsetup{} does not exist!');\n        // Setting up the Queries\n        return (this.$bucket.state[expand(this.$dbsetup.name, this)] || []).filter(\n          sift(expand(queries[name], this) || {})\n        );\n      }\n    });\n  }, {});\n};\n\n/**\n * Binary Search for Arrays\n */\nexport const binarySearch = (arr, docId) => {\n  let low = 0;\n  let high = arr.length;\n  let mid;\n  // traverse\n  while (low < high) {\n    mid = (low + high) >>> 1;\n    arr[mid]._id < docId ? low = mid + 1 : high = mid;\n  }\n  return low;\n};\n\n\n\n// WEBPACK FOOTER //\n// ./src/utils/index.js","'use strict';\n\nfunction _interopDefault (ex) { return (ex && (typeof ex === 'object') && 'default' in ex) ? ex['default'] : ex; }\n\nvar lie = _interopDefault(require('lie'));\nvar getArguments = _interopDefault(require('argsarray'));\nvar debug = _interopDefault(require('debug'));\nvar events = require('events');\nvar inherits = _interopDefault(require('inherits'));\nvar nextTick = _interopDefault(require('immediate'));\nvar scopedEval = _interopDefault(require('scope-eval'));\nvar Md5 = _interopDefault(require('spark-md5'));\nvar vuvuzela = _interopDefault(require('vuvuzela'));\n\n/* istanbul ignore next */\nvar PouchPromise$1 = typeof Promise === 'function' ? Promise : lie;\n\nfunction isBinaryObject(object) {\n  return (typeof ArrayBuffer !== 'undefined' && object instanceof ArrayBuffer) ||\n    (typeof Blob !== 'undefined' && object instanceof Blob);\n}\n\nfunction cloneArrayBuffer(buff) {\n  if (typeof buff.slice === 'function') {\n    return buff.slice(0);\n  }\n  // IE10-11 slice() polyfill\n  var target = new ArrayBuffer(buff.byteLength);\n  var targetArray = new Uint8Array(target);\n  var sourceArray = new Uint8Array(buff);\n  targetArray.set(sourceArray);\n  return target;\n}\n\nfunction cloneBinaryObject(object) {\n  if (object instanceof ArrayBuffer) {\n    return cloneArrayBuffer(object);\n  }\n  var size = object.size;\n  var type = object.type;\n  // Blob\n  if (typeof object.slice === 'function') {\n    return object.slice(0, size, type);\n  }\n  // PhantomJS slice() replacement\n  return object.webkitSlice(0, size, type);\n}\n\n// most of this is borrowed from lodash.isPlainObject:\n// https://github.com/fis-components/lodash.isplainobject/\n// blob/29c358140a74f252aeb08c9eb28bef86f2217d4a/index.js\n\nvar funcToString = Function.prototype.toString;\nvar objectCtorString = funcToString.call(Object);\n\nfunction isPlainObject(value) {\n  var proto = Object.getPrototypeOf(value);\n  /* istanbul ignore if */\n  if (proto === null) { // not sure when this happens, but I guess it can\n    return true;\n  }\n  var Ctor = proto.constructor;\n  return (typeof Ctor == 'function' &&\n    Ctor instanceof Ctor && funcToString.call(Ctor) == objectCtorString);\n}\n\nfunction clone(object) {\n  var newObject;\n  var i;\n  var len;\n\n  if (!object || typeof object !== 'object') {\n    return object;\n  }\n\n  if (Array.isArray(object)) {\n    newObject = [];\n    for (i = 0, len = object.length; i < len; i++) {\n      newObject[i] = clone(object[i]);\n    }\n    return newObject;\n  }\n\n  // special case: to avoid inconsistencies between IndexedDB\n  // and other backends, we automatically stringify Dates\n  if (object instanceof Date) {\n    return object.toISOString();\n  }\n\n  if (isBinaryObject(object)) {\n    return cloneBinaryObject(object);\n  }\n\n  if (!isPlainObject(object)) {\n    return object; // don't clone objects like Workers\n  }\n\n  newObject = {};\n  for (i in object) {\n    /* istanbul ignore else */\n    if (Object.prototype.hasOwnProperty.call(object, i)) {\n      var value = clone(object[i]);\n      if (typeof value !== 'undefined') {\n        newObject[i] = value;\n      }\n    }\n  }\n  return newObject;\n}\n\nfunction once(fun) {\n  var called = false;\n  return getArguments(function (args) {\n    /* istanbul ignore if */\n    if (called) {\n      // this is a smoke test and should never actually happen\n      throw new Error('once called more than once');\n    } else {\n      called = true;\n      fun.apply(this, args);\n    }\n  });\n}\n\nfunction toPromise(func) {\n  //create the function we will be returning\n  return getArguments(function (args) {\n    // Clone arguments\n    args = clone(args);\n    var self = this;\n    // if the last argument is a function, assume its a callback\n    var usedCB = (typeof args[args.length - 1] === 'function') ? args.pop() : false;\n    var promise = new PouchPromise$1(function (fulfill, reject) {\n      var resp;\n      try {\n        var callback = once(function (err, mesg) {\n          if (err) {\n            reject(err);\n          } else {\n            fulfill(mesg);\n          }\n        });\n        // create a callback for this invocation\n        // apply the function in the orig context\n        args.push(callback);\n        resp = func.apply(self, args);\n        if (resp && typeof resp.then === 'function') {\n          fulfill(resp);\n        }\n      } catch (e) {\n        reject(e);\n      }\n    });\n    // if there is a callback, call it back\n    if (usedCB) {\n      promise.then(function (result) {\n        usedCB(null, result);\n      }, usedCB);\n    }\n    return promise;\n  });\n}\n\nvar log = debug('pouchdb:api');\n\nfunction adapterFun(name, callback) {\n  function logApiCall(self, name, args) {\n    /* istanbul ignore if */\n    if (log.enabled) {\n      var logArgs = [self.name, name];\n      for (var i = 0; i < args.length - 1; i++) {\n        logArgs.push(args[i]);\n      }\n      log.apply(null, logArgs);\n\n      // override the callback itself to log the response\n      var origCallback = args[args.length - 1];\n      args[args.length - 1] = function (err, res) {\n        var responseArgs = [self.name, name];\n        responseArgs = responseArgs.concat(\n          err ? ['error', err] : ['success', res]\n        );\n        log.apply(null, responseArgs);\n        origCallback(err, res);\n      };\n    }\n  }\n\n  return toPromise(getArguments(function (args) {\n    if (this._closed) {\n      return PouchPromise$1.reject(new Error('database is closed'));\n    }\n    if (this._destroyed) {\n      return PouchPromise$1.reject(new Error('database is destroyed'));\n    }\n    var self = this;\n    logApiCall(self, name, args);\n    if (!this.taskqueue.isReady) {\n      return new PouchPromise$1(function (fulfill, reject) {\n        self.taskqueue.addTask(function (failed) {\n          if (failed) {\n            reject(failed);\n          } else {\n            fulfill(self[name].apply(self, args));\n          }\n        });\n      });\n    }\n    return callback.apply(this, args);\n  }));\n}\n\n// like underscore/lodash _.pick()\nfunction pick(obj, arr) {\n  var res = {};\n  for (var i = 0, len = arr.length; i < len; i++) {\n    var prop = arr[i];\n    if (prop in obj) {\n      res[prop] = obj[prop];\n    }\n  }\n  return res;\n}\n\nfunction mangle(key) {\n  return '$' + key;\n}\nfunction unmangle(key) {\n  return key.substring(1);\n}\nfunction Map$1() {\n  this._store = {};\n}\nMap$1.prototype.get = function (key) {\n  var mangled = mangle(key);\n  return this._store[mangled];\n};\nMap$1.prototype.set = function (key, value) {\n  var mangled = mangle(key);\n  this._store[mangled] = value;\n  return true;\n};\nMap$1.prototype.has = function (key) {\n  var mangled = mangle(key);\n  return mangled in this._store;\n};\nMap$1.prototype.delete = function (key) {\n  var mangled = mangle(key);\n  var res = mangled in this._store;\n  delete this._store[mangled];\n  return res;\n};\nMap$1.prototype.forEach = function (cb) {\n  var keys = Object.keys(this._store);\n  for (var i = 0, len = keys.length; i < len; i++) {\n    var key = keys[i];\n    var value = this._store[key];\n    key = unmangle(key);\n    cb(value, key);\n  }\n};\nObject.defineProperty(Map$1.prototype, 'size', {\n  get: function () {\n    return Object.keys(this._store).length;\n  }\n});\n\nfunction Set$1(array) {\n  this._store = new Map$1();\n\n  // init with an array\n  if (array && Array.isArray(array)) {\n    for (var i = 0, len = array.length; i < len; i++) {\n      this.add(array[i]);\n    }\n  }\n}\nSet$1.prototype.add = function (key) {\n  return this._store.set(key, true);\n};\nSet$1.prototype.has = function (key) {\n  return this._store.has(key);\n};\nSet$1.prototype.forEach = function (cb) {\n  this._store.forEach(function (value, key) {\n    cb(key);\n  });\n};\nObject.defineProperty(Set$1.prototype, 'size', {\n  get: function () {\n    return this._store.size;\n  }\n});\n\n/* global Map,Set,Symbol */\n// Based on https://kangax.github.io/compat-table/es6/ we can sniff out\n// incomplete Map/Set implementations which would otherwise cause our tests to fail.\n// Notably they fail in IE11 and iOS 8.4, which this prevents.\nfunction supportsMapAndSet() {\n  if (typeof Symbol === 'undefined' || typeof Map === 'undefined' || typeof Set === 'undefined') {\n    return false;\n  }\n  var prop = Object.getOwnPropertyDescriptor(Map, Symbol.species);\n  return prop && 'get' in prop && Map[Symbol.species] === Map;\n}\n\n// based on https://github.com/montagejs/collections\n/* global Map,Set */\n\nvar ExportedSet;\nvar ExportedMap;\n\n{\n  if (supportsMapAndSet()) { // prefer built-in Map/Set\n    ExportedSet = Set;\n    ExportedMap = Map;\n  } else { // fall back to our polyfill\n    ExportedSet = Set$1;\n    ExportedMap = Map$1;\n  }\n}\n\n// Most browsers throttle concurrent requests at 6, so it's silly\n// to shim _bulk_get by trying to launch potentially hundreds of requests\n// and then letting the majority time out. We can handle this ourselves.\nvar MAX_NUM_CONCURRENT_REQUESTS = 6;\n\nfunction identityFunction(x) {\n  return x;\n}\n\nfunction formatResultForOpenRevsGet(result) {\n  return [{\n    ok: result\n  }];\n}\n\n// shim for P/CouchDB adapters that don't directly implement _bulk_get\nfunction bulkGet(db, opts, callback) {\n  var requests = opts.docs;\n\n  // consolidate into one request per doc if possible\n  var requestsById = new ExportedMap();\n  requests.forEach(function (request) {\n    if (requestsById.has(request.id)) {\n      requestsById.get(request.id).push(request);\n    } else {\n      requestsById.set(request.id, [request]);\n    }\n  });\n\n  var numDocs = requestsById.size;\n  var numDone = 0;\n  var perDocResults = new Array(numDocs);\n\n  function collapseResultsAndFinish() {\n    var results = [];\n    perDocResults.forEach(function (res) {\n      res.docs.forEach(function (info) {\n        results.push({\n          id: res.id,\n          docs: [info]\n        });\n      });\n    });\n    callback(null, {results: results});\n  }\n\n  function checkDone() {\n    if (++numDone === numDocs) {\n      collapseResultsAndFinish();\n    }\n  }\n\n  function gotResult(docIndex, id, docs) {\n    perDocResults[docIndex] = {id: id, docs: docs};\n    checkDone();\n  }\n\n  var allRequests = [];\n  requestsById.forEach(function (value, key) {\n    allRequests.push(key);\n  });\n\n  var i = 0;\n\n  function nextBatch() {\n\n    if (i >= allRequests.length) {\n      return;\n    }\n\n    var upTo = Math.min(i + MAX_NUM_CONCURRENT_REQUESTS, allRequests.length);\n    var batch = allRequests.slice(i, upTo);\n    processBatch(batch, i);\n    i += batch.length;\n  }\n\n  function processBatch(batch, offset) {\n    batch.forEach(function (docId, j) {\n      var docIdx = offset + j;\n      var docRequests = requestsById.get(docId);\n\n      // just use the first request as the \"template\"\n      // TODO: The _bulk_get API allows for more subtle use cases than this,\n      // but for now it is unlikely that there will be a mix of different\n      // \"atts_since\" or \"attachments\" in the same request, since it's just\n      // replicate.js that is using this for the moment.\n      // Also, atts_since is aspirational, since we don't support it yet.\n      var docOpts = pick(docRequests[0], ['atts_since', 'attachments']);\n      docOpts.open_revs = docRequests.map(function (request) {\n        // rev is optional, open_revs disallowed\n        return request.rev;\n      });\n\n      // remove falsey / undefined revisions\n      docOpts.open_revs = docOpts.open_revs.filter(identityFunction);\n\n      var formatResult = identityFunction;\n\n      if (docOpts.open_revs.length === 0) {\n        delete docOpts.open_revs;\n\n        // when fetching only the \"winning\" leaf,\n        // transform the result so it looks like an open_revs\n        // request\n        formatResult = formatResultForOpenRevsGet;\n      }\n\n      // globally-supplied options\n      ['revs', 'attachments', 'binary', 'ajax', 'latest'].forEach(function (param) {\n        if (param in opts) {\n          docOpts[param] = opts[param];\n        }\n      });\n      db.get(docId, docOpts, function (err, res) {\n        var result;\n        /* istanbul ignore if */\n        if (err) {\n          result = [{error: err}];\n        } else {\n          result = formatResult(res);\n        }\n        gotResult(docIdx, docId, result);\n        nextBatch();\n      });\n    });\n  }\n\n  nextBatch();\n\n}\n\nfunction isChromeApp() {\n  return (typeof chrome !== \"undefined\" &&\n    typeof chrome.storage !== \"undefined\" &&\n    typeof chrome.storage.local !== \"undefined\");\n}\n\nvar hasLocal;\n\nif (isChromeApp()) {\n  hasLocal = false;\n} else {\n  try {\n    localStorage.setItem('_pouch_check_localstorage', 1);\n    hasLocal = !!localStorage.getItem('_pouch_check_localstorage');\n  } catch (e) {\n    hasLocal = false;\n  }\n}\n\nfunction hasLocalStorage() {\n  return hasLocal;\n}\n\ninherits(Changes, events.EventEmitter);\n\n/* istanbul ignore next */\nfunction attachBrowserEvents(self) {\n  if (isChromeApp()) {\n    chrome.storage.onChanged.addListener(function (e) {\n      // make sure it's event addressed to us\n      if (e.db_name != null) {\n        //object only has oldValue, newValue members\n        self.emit(e.dbName.newValue);\n      }\n    });\n  } else if (hasLocalStorage()) {\n    if (typeof addEventListener !== 'undefined') {\n      addEventListener(\"storage\", function (e) {\n        self.emit(e.key);\n      });\n    } else { // old IE\n      window.attachEvent(\"storage\", function (e) {\n        self.emit(e.key);\n      });\n    }\n  }\n}\n\nfunction Changes() {\n  events.EventEmitter.call(this);\n  this._listeners = {};\n\n  attachBrowserEvents(this);\n}\nChanges.prototype.addListener = function (dbName, id, db, opts) {\n  /* istanbul ignore if */\n  if (this._listeners[id]) {\n    return;\n  }\n  var self = this;\n  var inprogress = false;\n  function eventFunction() {\n    /* istanbul ignore if */\n    if (!self._listeners[id]) {\n      return;\n    }\n    if (inprogress) {\n      inprogress = 'waiting';\n      return;\n    }\n    inprogress = true;\n    var changesOpts = pick(opts, [\n      'style', 'include_docs', 'attachments', 'conflicts', 'filter',\n      'doc_ids', 'view', 'since', 'query_params', 'binary'\n    ]);\n\n    /* istanbul ignore next */\n    function onError() {\n      inprogress = false;\n    }\n\n    db.changes(changesOpts).on('change', function (c) {\n      if (c.seq > opts.since && !opts.cancelled) {\n        opts.since = c.seq;\n        opts.onChange(c);\n      }\n    }).on('complete', function () {\n      if (inprogress === 'waiting') {\n        nextTick(eventFunction);\n      }\n      inprogress = false;\n    }).on('error', onError);\n  }\n  this._listeners[id] = eventFunction;\n  this.on(dbName, eventFunction);\n};\n\nChanges.prototype.removeListener = function (dbName, id) {\n  /* istanbul ignore if */\n  if (!(id in this._listeners)) {\n    return;\n  }\n  events.EventEmitter.prototype.removeListener.call(this, dbName,\n    this._listeners[id]);\n  delete this._listeners[id];\n};\n\n\n/* istanbul ignore next */\nChanges.prototype.notifyLocalWindows = function (dbName) {\n  //do a useless change on a storage thing\n  //in order to get other windows's listeners to activate\n  if (isChromeApp()) {\n    chrome.storage.local.set({dbName: dbName});\n  } else if (hasLocalStorage()) {\n    localStorage[dbName] = (localStorage[dbName] === \"a\") ? \"b\" : \"a\";\n  }\n};\n\nChanges.prototype.notify = function (dbName) {\n  this.emit(dbName);\n  this.notifyLocalWindows(dbName);\n};\n\nfunction guardedConsole(method) {\n  /* istanbul ignore else */\n  if (console !== 'undefined' && method in console) {\n    var args = Array.prototype.slice.call(arguments, 1);\n    console[method].apply(console, args);\n  }\n}\n\nfunction randomNumber(min, max) {\n  var maxTimeout = 600000; // Hard-coded default of 10 minutes\n  min = parseInt(min, 10) || 0;\n  max = parseInt(max, 10);\n  if (max !== max || max <= min) {\n    max = (min || 1) << 1; //doubling\n  } else {\n    max = max + 1;\n  }\n  // In order to not exceed maxTimeout, pick a random value between half of maxTimeout and maxTimeout\n  if(max > maxTimeout) {\n    min = maxTimeout >> 1; // divide by two\n    max = maxTimeout;\n  }\n  var ratio = Math.random();\n  var range = max - min;\n\n  return ~~(range * ratio + min); // ~~ coerces to an int, but fast.\n}\n\nfunction defaultBackOff(min) {\n  var max = 0;\n  if (!min) {\n    max = 2000;\n  }\n  return randomNumber(min, max);\n}\n\n// designed to give info to browser users, who are disturbed\n// when they see http errors in the console\nfunction explainError(status, str) {\n  guardedConsole('info', 'The above ' + status + ' is totally normal. ' + str);\n}\n\nvar assign;\n{\n  if (typeof Object.assign === 'function') {\n    assign = Object.assign;\n  } else {\n    // lite Object.assign polyfill based on\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/assign\n    assign = function (target) {\n      var to = Object(target);\n\n      for (var index = 1; index < arguments.length; index++) {\n        var nextSource = arguments[index];\n\n        if (nextSource != null) { // Skip over if undefined or null\n          for (var nextKey in nextSource) {\n            // Avoid bugs when hasOwnProperty is shadowed\n            if (Object.prototype.hasOwnProperty.call(nextSource, nextKey)) {\n              to[nextKey] = nextSource[nextKey];\n            }\n          }\n        }\n      }\n      return to;\n    };\n  }\n}\n\nvar assign$1 = assign;\n\ninherits(PouchError, Error);\n\nfunction PouchError(status, error, reason) {\n  Error.call(this, reason);\n  this.status = status;\n  this.name = error;\n  this.message = reason;\n  this.error = true;\n}\n\nPouchError.prototype.toString = function () {\n  return JSON.stringify({\n    status: this.status,\n    name: this.name,\n    message: this.message,\n    reason: this.reason\n  });\n};\n\nvar UNAUTHORIZED = new PouchError(401, 'unauthorized', \"Name or password is incorrect.\");\nvar MISSING_BULK_DOCS = new PouchError(400, 'bad_request', \"Missing JSON list of 'docs'\");\nvar MISSING_DOC = new PouchError(404, 'not_found', 'missing');\nvar REV_CONFLICT = new PouchError(409, 'conflict', 'Document update conflict');\nvar INVALID_ID = new PouchError(400, 'bad_request', '_id field must contain a string');\nvar MISSING_ID = new PouchError(412, 'missing_id', '_id is required for puts');\nvar RESERVED_ID = new PouchError(400, 'bad_request', 'Only reserved document ids may start with underscore.');\nvar NOT_OPEN = new PouchError(412, 'precondition_failed', 'Database not open');\nvar UNKNOWN_ERROR = new PouchError(500, 'unknown_error', 'Database encountered an unknown error');\nvar BAD_ARG = new PouchError(500, 'badarg', 'Some query argument is invalid');\nvar INVALID_REQUEST = new PouchError(400, 'invalid_request', 'Request was invalid');\nvar QUERY_PARSE_ERROR = new PouchError(400, 'query_parse_error', 'Some query parameter is invalid');\nvar DOC_VALIDATION = new PouchError(500, 'doc_validation', 'Bad special document member');\nvar BAD_REQUEST = new PouchError(400, 'bad_request', 'Something wrong with the request');\nvar NOT_AN_OBJECT = new PouchError(400, 'bad_request', 'Document must be a JSON object');\nvar DB_MISSING = new PouchError(404, 'not_found', 'Database not found');\nvar IDB_ERROR = new PouchError(500, 'indexed_db_went_bad', 'unknown');\nvar WSQ_ERROR = new PouchError(500, 'web_sql_went_bad', 'unknown');\nvar LDB_ERROR = new PouchError(500, 'levelDB_went_went_bad', 'unknown');\nvar FORBIDDEN = new PouchError(403, 'forbidden', 'Forbidden by design doc validate_doc_update function');\nvar INVALID_REV = new PouchError(400, 'bad_request', 'Invalid rev format');\nvar FILE_EXISTS = new PouchError(412, 'file_exists', 'The database could not be created, the file already exists.');\nvar MISSING_STUB = new PouchError(412, 'missing_stub', 'A pre-existing attachment stub wasn\\'t found');\nvar INVALID_URL = new PouchError(413, 'invalid_url', 'Provided URL is invalid');\n\nfunction createError(error, reason) {\n  function CustomPouchError(reason) {\n    // inherit error properties from our parent error manually\n    // so as to allow proper JSON parsing.\n    /* jshint ignore:start */\n    for (var p in error) {\n      if (typeof error[p] !== 'function') {\n        this[p] = error[p];\n      }\n    }\n    /* jshint ignore:end */\n    if (reason !== undefined) {\n      this.reason = reason;\n    }\n  }\n  CustomPouchError.prototype = PouchError.prototype;\n  return new CustomPouchError(reason);\n}\n\nfunction generateErrorFromResponse(err) {\n\n  if (typeof err !== 'object') {\n    var data = err;\n    err = UNKNOWN_ERROR;\n    err.data = data;\n  }\n\n  if ('error' in err && err.error === 'conflict') {\n    err.name = 'conflict';\n    err.status = 409;\n  }\n\n  if (!('name' in err)) {\n    err.name = err.error || 'unknown';\n  }\n\n  if (!('status' in err)) {\n    err.status = 500;\n  }\n\n  if (!('message' in err)) {\n    err.message = err.message || err.reason;\n  }\n\n  return err;\n}\n\nfunction tryFilter(filter, doc, req) {\n  try {\n    return !filter(doc, req);\n  } catch (err) {\n    var msg = 'Filter function threw: ' + err.toString();\n    return createError(BAD_REQUEST, msg);\n  }\n}\n\nfunction filterChange(opts) {\n  var req = {};\n  var hasFilter = opts.filter && typeof opts.filter === 'function';\n  req.query = opts.query_params;\n\n  return function filter(change) {\n    if (!change.doc) {\n      // CSG sends events on the changes feed that don't have documents,\n      // this hack makes a whole lot of existing code robust.\n      change.doc = {};\n    }\n\n    var filterReturn = hasFilter && tryFilter(opts.filter, change.doc, req);\n\n    if (typeof filterReturn === 'object') {\n      return filterReturn;\n    }\n\n    if (filterReturn) {\n      return false;\n    }\n\n    if (!opts.include_docs) {\n      delete change.doc;\n    } else if (!opts.attachments) {\n      for (var att in change.doc._attachments) {\n        /* istanbul ignore else */\n        if (change.doc._attachments.hasOwnProperty(att)) {\n          change.doc._attachments[att].stub = true;\n        }\n      }\n    }\n    return true;\n  };\n}\n\nfunction flatten(arrs) {\n  var res = [];\n  for (var i = 0, len = arrs.length; i < len; i++) {\n    res = res.concat(arrs[i]);\n  }\n  return res;\n}\n\n// shim for Function.prototype.name,\n// for browsers that don't support it like IE\n\n/* istanbul ignore next */\nfunction f() {}\n\nvar hasName = f.name;\nvar res;\n\n// We dont run coverage in IE\n/* istanbul ignore else */\nif (hasName) {\n  res = function (fun) {\n    return fun.name;\n  };\n} else {\n  res = function (fun) {\n    return fun.toString().match(/^\\s*function\\s*(\\S*)\\s*\\(/)[1];\n  };\n}\n\n// Determine id an ID is valid\n//   - invalid IDs begin with an underescore that does not begin '_design' or\n//     '_local'\n//   - any other string value is a valid id\n// Returns the specific error object for each case\nfunction invalidIdError(id) {\n  var err;\n  if (!id) {\n    err = createError(MISSING_ID);\n  } else if (typeof id !== 'string') {\n    err = createError(INVALID_ID);\n  } else if (/^_/.test(id) && !(/^_(design|local)/).test(id)) {\n    err = createError(RESERVED_ID);\n  }\n  if (err) {\n    throw err;\n  }\n}\n\nfunction listenerCount(ee, type) {\n  return 'listenerCount' in ee ? ee.listenerCount(type) :\n                                 events.EventEmitter.listenerCount(ee, type);\n}\n\n// Custom nextTick() shim for browsers. In node, this will just be process.nextTick(). We\n// avoid using process.nextTick() directly because the polyfill is very large and we don't\n// need all of it (see: https://github.com/defunctzombie/node-process).\n// \"immediate\" 3.0.8 is used by lie, and it's a smaller version of the latest \"immediate\"\n// package, so it's the one we use.\n// When we use nextTick() in our codebase, we only care about not releasing Zalgo\n// (see: http://blog.izs.me/post/59142742143/designing-apis-for-asynchrony).\n// Microtask vs macrotask doesn't matter to us. So we're free to use the fastest\n// (least latency) option, which is \"immediate\" due to use of microtasks.\n// All of our nextTicks are isolated to this one function so we can easily swap out one\n// implementation for another.\n\nfunction parseDesignDocFunctionName(s) {\n  if (!s) {\n    return null;\n  }\n  var parts = s.split('/');\n  if (parts.length === 2) {\n    return parts;\n  }\n  if (parts.length === 1) {\n    return [s, s];\n  }\n  return null;\n}\n\nfunction normalizeDesignDocFunctionName(s) {\n  var normalized = parseDesignDocFunctionName(s);\n  return normalized ? normalized.join('/') : null;\n}\n\n// originally parseUri 1.2.2, now patched by us\n// (c) Steven Levithan <stevenlevithan.com>\n// MIT License\nvar keys = [\"source\", \"protocol\", \"authority\", \"userInfo\", \"user\", \"password\",\n    \"host\", \"port\", \"relative\", \"path\", \"directory\", \"file\", \"query\", \"anchor\"];\nvar qName =\"queryKey\";\nvar qParser = /(?:^|&)([^&=]*)=?([^&]*)/g;\n\n// use the \"loose\" parser\n/* jshint maxlen: false */\nvar parser = /^(?:(?![^:@]+:[^:@\\/]*@)([^:\\/?#.]+):)?(?:\\/\\/)?((?:(([^:@]*)(?::([^:@]*))?)?@)?([^:\\/?#]*)(?::(\\d*))?)(((\\/(?:[^?#](?![^?#\\/]*\\.[^?#\\/.]+(?:[?#]|$)))*\\/?)?([^?#\\/]*))(?:\\?([^#]*))?(?:#(.*))?)/;\n\nfunction parseUri(str) {\n  var m = parser.exec(str);\n  var uri = {};\n  var i = 14;\n\n  while (i--) {\n    var key = keys[i];\n    var value = m[i] || \"\";\n    var encoded = ['user', 'password'].indexOf(key) !== -1;\n    uri[key] = encoded ? decodeURIComponent(value) : value;\n  }\n\n  uri[qName] = {};\n  uri[keys[12]].replace(qParser, function ($0, $1, $2) {\n    if ($1) {\n      uri[qName][$1] = $2;\n    }\n  });\n\n  return uri;\n}\n\n// this is essentially the \"update sugar\" function from daleharvey/pouchdb#1388\n// the diffFun tells us what delta to apply to the doc.  it either returns\n// the doc, or false if it doesn't need to do an update after all\nfunction upsert(db, docId, diffFun) {\n  return new PouchPromise$1(function (fulfill, reject) {\n    db.get(docId, function (err, doc) {\n      if (err) {\n        /* istanbul ignore next */\n        if (err.status !== 404) {\n          return reject(err);\n        }\n        doc = {};\n      }\n\n      // the user might change the _rev, so save it for posterity\n      var docRev = doc._rev;\n      var newDoc = diffFun(doc);\n\n      if (!newDoc) {\n        // if the diffFun returns falsy, we short-circuit as\n        // an optimization\n        return fulfill({updated: false, rev: docRev});\n      }\n\n      // users aren't allowed to modify these values,\n      // so reset them here\n      newDoc._id = docId;\n      newDoc._rev = docRev;\n      fulfill(tryAndPut(db, newDoc, diffFun));\n    });\n  });\n}\n\nfunction tryAndPut(db, doc, diffFun) {\n  return db.put(doc).then(function (res) {\n    return {\n      updated: true,\n      rev: res.rev\n    };\n  }, function (err) {\n    /* istanbul ignore next */\n    if (err.status !== 409) {\n      throw err;\n    }\n    return upsert(db, doc._id, diffFun);\n  });\n}\n\n// BEGIN Math.uuid.js\n\n/*!\nMath.uuid.js (v1.4)\nhttp://www.broofa.com\nmailto:robert@broofa.com\n\nCopyright (c) 2010 Robert Kieffer\nDual licensed under the MIT and GPL licenses.\n*/\n\n/*\n * Generate a random uuid.\n *\n * USAGE: Math.uuid(length, radix)\n *   length - the desired number of characters\n *   radix  - the number of allowable values for each character.\n *\n * EXAMPLES:\n *   // No arguments  - returns RFC4122, version 4 ID\n *   >>> Math.uuid()\n *   \"92329D39-6F5C-4520-ABFC-AAB64544E172\"\n *\n *   // One argument - returns ID of the specified length\n *   >>> Math.uuid(15)     // 15 character ID (default base=62)\n *   \"VcydxgltxrVZSTV\"\n *\n *   // Two arguments - returns ID of the specified length, and radix. \n *   // (Radix must be <= 62)\n *   >>> Math.uuid(8, 2)  // 8 character ID (base=2)\n *   \"01001010\"\n *   >>> Math.uuid(8, 10) // 8 character ID (base=10)\n *   \"47473046\"\n *   >>> Math.uuid(8, 16) // 8 character ID (base=16)\n *   \"098F4D35\"\n */\nvar chars = (\n  '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ' +\n  'abcdefghijklmnopqrstuvwxyz'\n).split('');\nfunction getValue(radix) {\n  return 0 | Math.random() * radix;\n}\nfunction uuid(len, radix) {\n  radix = radix || chars.length;\n  var out = '';\n  var i = -1;\n\n  if (len) {\n    // Compact form\n    while (++i < len) {\n      out += chars[getValue(radix)];\n    }\n    return out;\n  }\n    // rfc4122, version 4 form\n    // Fill in random data.  At i==19 set the high bits of clock sequence as\n    // per rfc4122, sec. 4.1.5\n  while (++i < 36) {\n    switch (i) {\n      case 8:\n      case 13:\n      case 18:\n      case 23:\n        out += '-';\n        break;\n      case 19:\n        out += chars[(getValue(16) & 0x3) | 0x8];\n        break;\n      default:\n        out += chars[getValue(16)];\n    }\n  }\n\n  return out;\n}\n\n// We fetch all leafs of the revision tree, and sort them based on tree length\n// and whether they were deleted, undeleted documents with the longest revision\n// tree (most edits) win\n// The final sort algorithm is slightly documented in a sidebar here:\n// http://guide.couchdb.org/draft/conflicts.html\nfunction winningRev(metadata) {\n  var winningId;\n  var winningPos;\n  var winningDeleted;\n  var toVisit = metadata.rev_tree.slice();\n  var node;\n  while ((node = toVisit.pop())) {\n    var tree = node.ids;\n    var branches = tree[2];\n    var pos = node.pos;\n    if (branches.length) { // non-leaf\n      for (var i = 0, len = branches.length; i < len; i++) {\n        toVisit.push({pos: pos + 1, ids: branches[i]});\n      }\n      continue;\n    }\n    var deleted = !!tree[1].deleted;\n    var id = tree[0];\n    // sort by deleted, then pos, then id\n    if (!winningId || (winningDeleted !== deleted ? winningDeleted :\n        winningPos !== pos ? winningPos < pos : winningId < id)) {\n      winningId = id;\n      winningPos = pos;\n      winningDeleted = deleted;\n    }\n  }\n\n  return winningPos + '-' + winningId;\n}\n\n// Pretty much all below can be combined into a higher order function to\n// traverse revisions\n// The return value from the callback will be passed as context to all\n// children of that node\nfunction traverseRevTree(revs, callback) {\n  var toVisit = revs.slice();\n\n  var node;\n  while ((node = toVisit.pop())) {\n    var pos = node.pos;\n    var tree = node.ids;\n    var branches = tree[2];\n    var newCtx =\n      callback(branches.length === 0, pos, tree[0], node.ctx, tree[1]);\n    for (var i = 0, len = branches.length; i < len; i++) {\n      toVisit.push({pos: pos + 1, ids: branches[i], ctx: newCtx});\n    }\n  }\n}\n\nfunction sortByPos(a, b) {\n  return a.pos - b.pos;\n}\n\nfunction collectLeaves(revs) {\n  var leaves = [];\n  traverseRevTree(revs, function (isLeaf, pos, id, acc, opts) {\n    if (isLeaf) {\n      leaves.push({rev: pos + \"-\" + id, pos: pos, opts: opts});\n    }\n  });\n  leaves.sort(sortByPos).reverse();\n  for (var i = 0, len = leaves.length; i < len; i++) {\n    delete leaves[i].pos;\n  }\n  return leaves;\n}\n\n// returns revs of all conflicts that is leaves such that\n// 1. are not deleted and\n// 2. are different than winning revision\nfunction collectConflicts(metadata) {\n  var win = winningRev(metadata);\n  var leaves = collectLeaves(metadata.rev_tree);\n  var conflicts = [];\n  for (var i = 0, len = leaves.length; i < len; i++) {\n    var leaf = leaves[i];\n    if (leaf.rev !== win && !leaf.opts.deleted) {\n      conflicts.push(leaf.rev);\n    }\n  }\n  return conflicts;\n}\n\n// compact a tree by marking its non-leafs as missing,\n// and return a list of revs to delete\nfunction compactTree(metadata) {\n  var revs = [];\n  traverseRevTree(metadata.rev_tree, function (isLeaf, pos,\n                                               revHash, ctx, opts) {\n    if (opts.status === 'available' && !isLeaf) {\n      revs.push(pos + '-' + revHash);\n      opts.status = 'missing';\n    }\n  });\n  return revs;\n}\n\n// build up a list of all the paths to the leafs in this revision tree\nfunction rootToLeaf(revs) {\n  var paths = [];\n  var toVisit = revs.slice();\n  var node;\n  while ((node = toVisit.pop())) {\n    var pos = node.pos;\n    var tree = node.ids;\n    var id = tree[0];\n    var opts = tree[1];\n    var branches = tree[2];\n    var isLeaf = branches.length === 0;\n\n    var history = node.history ? node.history.slice() : [];\n    history.push({id: id, opts: opts});\n    if (isLeaf) {\n      paths.push({pos: (pos + 1 - history.length), ids: history});\n    }\n    for (var i = 0, len = branches.length; i < len; i++) {\n      toVisit.push({pos: pos + 1, ids: branches[i], history: history});\n    }\n  }\n  return paths.reverse();\n}\n\n// for a better overview of what this is doing, read:\n// https://github.com/apache/couchdb-couch/blob/master/src/couch_key_tree.erl\n//\n// But for a quick intro, CouchDB uses a revision tree to store a documents\n// history, A -> B -> C, when a document has conflicts, that is a branch in the\n// tree, A -> (B1 | B2 -> C), We store these as a nested array in the format\n//\n// KeyTree = [Path ... ]\n// Path = {pos: position_from_root, ids: Tree}\n// Tree = [Key, Opts, [Tree, ...]], in particular single node: [Key, []]\n\nfunction sortByPos$1(a, b) {\n  return a.pos - b.pos;\n}\n\n// classic binary search\nfunction binarySearch(arr, item, comparator) {\n  var low = 0;\n  var high = arr.length;\n  var mid;\n  while (low < high) {\n    mid = (low + high) >>> 1;\n    if (comparator(arr[mid], item) < 0) {\n      low = mid + 1;\n    } else {\n      high = mid;\n    }\n  }\n  return low;\n}\n\n// assuming the arr is sorted, insert the item in the proper place\nfunction insertSorted(arr, item, comparator) {\n  var idx = binarySearch(arr, item, comparator);\n  arr.splice(idx, 0, item);\n}\n\n// Turn a path as a flat array into a tree with a single branch.\n// If any should be stemmed from the beginning of the array, that's passed\n// in as the second argument\nfunction pathToTree(path, numStemmed) {\n  var root;\n  var leaf;\n  for (var i = numStemmed, len = path.length; i < len; i++) {\n    var node = path[i];\n    var currentLeaf = [node.id, node.opts, []];\n    if (leaf) {\n      leaf[2].push(currentLeaf);\n      leaf = currentLeaf;\n    } else {\n      root = leaf = currentLeaf;\n    }\n  }\n  return root;\n}\n\n// compare the IDs of two trees\nfunction compareTree(a, b) {\n  return a[0] < b[0] ? -1 : 1;\n}\n\n// Merge two trees together\n// The roots of tree1 and tree2 must be the same revision\nfunction mergeTree(in_tree1, in_tree2) {\n  var queue = [{tree1: in_tree1, tree2: in_tree2}];\n  var conflicts = false;\n  while (queue.length > 0) {\n    var item = queue.pop();\n    var tree1 = item.tree1;\n    var tree2 = item.tree2;\n\n    if (tree1[1].status || tree2[1].status) {\n      tree1[1].status =\n        (tree1[1].status ===  'available' ||\n        tree2[1].status === 'available') ? 'available' : 'missing';\n    }\n\n    for (var i = 0; i < tree2[2].length; i++) {\n      if (!tree1[2][0]) {\n        conflicts = 'new_leaf';\n        tree1[2][0] = tree2[2][i];\n        continue;\n      }\n\n      var merged = false;\n      for (var j = 0; j < tree1[2].length; j++) {\n        if (tree1[2][j][0] === tree2[2][i][0]) {\n          queue.push({tree1: tree1[2][j], tree2: tree2[2][i]});\n          merged = true;\n        }\n      }\n      if (!merged) {\n        conflicts = 'new_branch';\n        insertSorted(tree1[2], tree2[2][i], compareTree);\n      }\n    }\n  }\n  return {conflicts: conflicts, tree: in_tree1};\n}\n\nfunction doMerge(tree, path, dontExpand) {\n  var restree = [];\n  var conflicts = false;\n  var merged = false;\n  var res;\n\n  if (!tree.length) {\n    return {tree: [path], conflicts: 'new_leaf'};\n  }\n\n  for (var i = 0, len = tree.length; i < len; i++) {\n    var branch = tree[i];\n    if (branch.pos === path.pos && branch.ids[0] === path.ids[0]) {\n      // Paths start at the same position and have the same root, so they need\n      // merged\n      res = mergeTree(branch.ids, path.ids);\n      restree.push({pos: branch.pos, ids: res.tree});\n      conflicts = conflicts || res.conflicts;\n      merged = true;\n    } else if (dontExpand !== true) {\n      // The paths start at a different position, take the earliest path and\n      // traverse up until it as at the same point from root as the path we\n      // want to merge.  If the keys match we return the longer path with the\n      // other merged After stemming we dont want to expand the trees\n\n      var t1 = branch.pos < path.pos ? branch : path;\n      var t2 = branch.pos < path.pos ? path : branch;\n      var diff = t2.pos - t1.pos;\n\n      var candidateParents = [];\n\n      var trees = [];\n      trees.push({ids: t1.ids, diff: diff, parent: null, parentIdx: null});\n      while (trees.length > 0) {\n        var item = trees.pop();\n        if (item.diff === 0) {\n          if (item.ids[0] === t2.ids[0]) {\n            candidateParents.push(item);\n          }\n          continue;\n        }\n        var elements = item.ids[2];\n        for (var j = 0, elementsLen = elements.length; j < elementsLen; j++) {\n          trees.push({\n            ids: elements[j],\n            diff: item.diff - 1,\n            parent: item.ids,\n            parentIdx: j\n          });\n        }\n      }\n\n      var el = candidateParents[0];\n\n      if (!el) {\n        restree.push(branch);\n      } else {\n        res = mergeTree(el.ids, t2.ids);\n        el.parent[2][el.parentIdx] = res.tree;\n        restree.push({pos: t1.pos, ids: t1.ids});\n        conflicts = conflicts || res.conflicts;\n        merged = true;\n      }\n    } else {\n      restree.push(branch);\n    }\n  }\n\n  // We didnt find\n  if (!merged) {\n    restree.push(path);\n  }\n\n  restree.sort(sortByPos$1);\n\n  return {\n    tree: restree,\n    conflicts: conflicts || 'internal_node'\n  };\n}\n\n// To ensure we dont grow the revision tree infinitely, we stem old revisions\nfunction stem(tree, depth) {\n  // First we break out the tree into a complete list of root to leaf paths\n  var paths = rootToLeaf(tree);\n  var maybeStem = {};\n\n  var result;\n  for (var i = 0, len = paths.length; i < len; i++) {\n    // Then for each path, we cut off the start of the path based on the\n    // `depth` to stem to, and generate a new set of flat trees\n    var path = paths[i];\n    var stemmed = path.ids;\n    var numStemmed = Math.max(0, stemmed.length - depth);\n    var stemmedNode = {\n      pos: path.pos + numStemmed,\n      ids: pathToTree(stemmed, numStemmed)\n    };\n\n    for (var s = 0; s < numStemmed; s++) {\n      var rev = (path.pos + s) + '-' + stemmed[s].id;\n      maybeStem[rev] = true;\n    }\n\n    // Then we remerge all those flat trees together, ensuring that we dont\n    // connect trees that would go beyond the depth limit\n    if (result) {\n      result = doMerge(result, stemmedNode, true).tree;\n    } else {\n      result = [stemmedNode];\n    }\n  }\n\n  traverseRevTree(result, function (isLeaf, pos, revHash) {\n    // some revisions may have been removed in a branch but not in another\n    delete maybeStem[pos + '-' + revHash];\n  });\n\n  return {\n    tree: result,\n    revs: Object.keys(maybeStem)\n  };\n}\n\nfunction merge(tree, path, depth) {\n  var newTree = doMerge(tree, path);\n  var stemmed = stem(newTree.tree, depth);\n  return {\n    tree: stemmed.tree,\n    stemmedRevs: stemmed.revs,\n    conflicts: newTree.conflicts\n  };\n}\n\n// return true if a rev exists in the rev tree, false otherwise\nfunction revExists(revs, rev) {\n  var toVisit = revs.slice();\n  var splitRev = rev.split('-');\n  var targetPos = parseInt(splitRev[0], 10);\n  var targetId = splitRev[1];\n\n  var node;\n  while ((node = toVisit.pop())) {\n    if (node.pos === targetPos && node.ids[0] === targetId) {\n      return true;\n    }\n    var branches = node.ids[2];\n    for (var i = 0, len = branches.length; i < len; i++) {\n      toVisit.push({pos: node.pos + 1, ids: branches[i]});\n    }\n  }\n  return false;\n}\n\nfunction getTrees(node) {\n  return node.ids;\n}\n\n// check if a specific revision of a doc has been deleted\n//  - metadata: the metadata object from the doc store\n//  - rev: (optional) the revision to check. defaults to winning revision\nfunction isDeleted(metadata, rev) {\n  if (!rev) {\n    rev = winningRev(metadata);\n  }\n  var id = rev.substring(rev.indexOf('-') + 1);\n  var toVisit = metadata.rev_tree.map(getTrees);\n\n  var tree;\n  while ((tree = toVisit.pop())) {\n    if (tree[0] === id) {\n      return !!tree[1].deleted;\n    }\n    toVisit = toVisit.concat(tree[2]);\n  }\n}\n\nfunction isLocalId(id) {\n  return (/^_local/).test(id);\n}\n\n// returns the current leaf node for a given revision\nfunction latest(rev, metadata) {\n  var toVisit = metadata.rev_tree.slice();\n  var node;\n  while ((node = toVisit.pop())) {\n    var pos = node.pos;\n    var tree = node.ids;\n    var id = tree[0];\n    var opts = tree[1];\n    var branches = tree[2];\n    var isLeaf = branches.length === 0;\n\n    var history = node.history ? node.history.slice() : [];\n    history.push({id: id, pos: pos, opts: opts});\n\n    if (isLeaf) {\n      for (var i = 0, len = history.length; i < len; i++) {\n        var historyNode = history[i];\n        var historyRev = historyNode.pos + '-' + historyNode.id;\n\n        if (historyRev === rev) {\n          // return the rev of this leaf\n          return pos + '-' + id;\n        }\n      }\n    }\n\n    for (var j = 0, l = branches.length; j < l; j++) {\n      toVisit.push({pos: pos + 1, ids: branches[j], history: history});\n    }\n  }\n\n  /* istanbul ignore next */\n  throw new Error('Unable to resolve latest revision for id ' + metadata.id + ', rev ' + rev);\n}\n\nfunction evalFilter(input) {\n  return scopedEval('\"use strict\";\\nreturn ' + input + ';', {});\n}\n\nfunction evalView(input) {\n  var code = [\n    'return function(doc) {',\n    '  \"use strict\";',\n    '  var emitted = false;',\n    '  var emit = function (a, b) {',\n    '    emitted = true;',\n    '  };',\n    '  var view = ' + input + ';',\n    '  view(doc);',\n    '  if (emitted) {',\n    '    return true;',\n    '  }',\n    '};'\n  ].join('\\n');\n\n  return scopedEval(code, {});\n}\n\ninherits(Changes$2, events.EventEmitter);\n\nfunction tryCatchInChangeListener(self, change) {\n  // isolate try/catches to avoid V8 deoptimizations\n  try {\n    self.emit('change', change);\n  } catch (e) {\n    guardedConsole('error', 'Error in .on(\"change\", function):', e);\n  }\n}\n\nfunction Changes$2(db, opts, callback) {\n  events.EventEmitter.call(this);\n  var self = this;\n  this.db = db;\n  opts = opts ? clone(opts) : {};\n  var complete = opts.complete = once(function (err, resp) {\n    if (err) {\n      if (listenerCount(self, 'error') > 0) {\n        self.emit('error', err);\n      }\n    } else {\n      self.emit('complete', resp);\n    }\n    self.removeAllListeners();\n    db.removeListener('destroyed', onDestroy);\n  });\n  if (callback) {\n    self.on('complete', function (resp) {\n      callback(null, resp);\n    });\n    self.on('error', callback);\n  }\n  function onDestroy() {\n    self.cancel();\n  }\n  db.once('destroyed', onDestroy);\n\n  opts.onChange = function (change) {\n    /* istanbul ignore if */\n    if (self.isCancelled) {\n      return;\n    }\n    tryCatchInChangeListener(self, change);\n  };\n\n  var promise = new PouchPromise$1(function (fulfill, reject) {\n    opts.complete = function (err, res) {\n      if (err) {\n        reject(err);\n      } else {\n        fulfill(res);\n      }\n    };\n  });\n  self.once('cancel', function () {\n    db.removeListener('destroyed', onDestroy);\n    opts.complete(null, {status: 'cancelled'});\n  });\n  this.then = promise.then.bind(promise);\n  this['catch'] = promise['catch'].bind(promise);\n  this.then(function (result) {\n    complete(null, result);\n  }, complete);\n\n\n\n  if (!db.taskqueue.isReady) {\n    db.taskqueue.addTask(function (failed) {\n      if (failed) {\n        opts.complete(failed);\n      } else if (self.isCancelled) {\n        self.emit('cancel');\n      } else {\n        self.doChanges(opts);\n      }\n    });\n  } else {\n    self.doChanges(opts);\n  }\n}\nChanges$2.prototype.cancel = function () {\n  this.isCancelled = true;\n  if (this.db.taskqueue.isReady) {\n    this.emit('cancel');\n  }\n};\nfunction processChange(doc, metadata, opts) {\n  var changeList = [{rev: doc._rev}];\n  if (opts.style === 'all_docs') {\n    changeList = collectLeaves(metadata.rev_tree)\n    .map(function (x) { return {rev: x.rev}; });\n  }\n  var change = {\n    id: metadata.id,\n    changes: changeList,\n    doc: doc\n  };\n\n  if (isDeleted(metadata, doc._rev)) {\n    change.deleted = true;\n  }\n  if (opts.conflicts) {\n    change.doc._conflicts = collectConflicts(metadata);\n    if (!change.doc._conflicts.length) {\n      delete change.doc._conflicts;\n    }\n  }\n  return change;\n}\n\nChanges$2.prototype.doChanges = function (opts) {\n  var self = this;\n  var callback = opts.complete;\n\n  opts = clone(opts);\n  if ('live' in opts && !('continuous' in opts)) {\n    opts.continuous = opts.live;\n  }\n  opts.processChange = processChange;\n\n  if (opts.since === 'latest') {\n    opts.since = 'now';\n  }\n  if (!opts.since) {\n    opts.since = 0;\n  }\n  if (opts.since === 'now') {\n    this.db.info().then(function (info) {\n      /* istanbul ignore if */\n      if (self.isCancelled) {\n        callback(null, {status: 'cancelled'});\n        return;\n      }\n      opts.since = info.update_seq;\n      self.doChanges(opts);\n    }, callback);\n    return;\n  }\n\n\n  if (opts.view && !opts.filter) {\n    opts.filter = '_view';\n  }\n\n  if (opts.filter && typeof opts.filter === 'string') {\n    if (opts.filter === '_view') {\n      opts.view = normalizeDesignDocFunctionName(opts.view);\n    } else {\n      opts.filter = normalizeDesignDocFunctionName(opts.filter);\n    }\n\n    if (this.db.type() !== 'http' && !opts.doc_ids) {\n      return this.filterChanges(opts);\n    }\n  }\n\n  if (!('descending' in opts)) {\n    opts.descending = false;\n  }\n\n  // 0 and 1 should return 1 document\n  opts.limit = opts.limit === 0 ? 1 : opts.limit;\n  opts.complete = callback;\n  var newPromise = this.db._changes(opts);\n  /* istanbul ignore else */\n  if (newPromise && typeof newPromise.cancel === 'function') {\n    var cancel = self.cancel;\n    self.cancel = getArguments(function (args) {\n      newPromise.cancel();\n      cancel.apply(this, args);\n    });\n  }\n};\n\nChanges$2.prototype.filterChanges = function (opts) {\n  var self = this;\n  var callback = opts.complete;\n  if (opts.filter === '_view') {\n    if (!opts.view || typeof opts.view !== 'string') {\n      var err = createError(BAD_REQUEST,\n        '`view` filter parameter not found or invalid.');\n      return callback(err);\n    }\n    // fetch a view from a design doc, make it behave like a filter\n    var viewName = parseDesignDocFunctionName(opts.view);\n    this.db.get('_design/' + viewName[0], function (err, ddoc) {\n      /* istanbul ignore if */\n      if (self.isCancelled) {\n        return callback(null, {status: 'cancelled'});\n      }\n      /* istanbul ignore next */\n      if (err) {\n        return callback(generateErrorFromResponse(err));\n      }\n      var mapFun = ddoc && ddoc.views && ddoc.views[viewName[1]] &&\n        ddoc.views[viewName[1]].map;\n      if (!mapFun) {\n        return callback(createError(MISSING_DOC,\n          (ddoc.views ? 'missing json key: ' + viewName[1] :\n            'missing json key: views')));\n      }\n      opts.filter = evalView(mapFun);\n      self.doChanges(opts);\n    });\n  } else {\n    // fetch a filter from a design doc\n    var filterName = parseDesignDocFunctionName(opts.filter);\n    if (!filterName) {\n      return self.doChanges(opts);\n    }\n    this.db.get('_design/' + filterName[0], function (err, ddoc) {\n      /* istanbul ignore if */\n      if (self.isCancelled) {\n        return callback(null, {status: 'cancelled'});\n      }\n      /* istanbul ignore next */\n      if (err) {\n        return callback(generateErrorFromResponse(err));\n      }\n      var filterFun = ddoc && ddoc.filters && ddoc.filters[filterName[1]];\n      if (!filterFun) {\n        return callback(createError(MISSING_DOC,\n          ((ddoc && ddoc.filters) ? 'missing json key: ' + filterName[1]\n            : 'missing json key: filters')));\n      }\n      opts.filter = evalFilter(filterFun);\n      self.doChanges(opts);\n    });\n  }\n};\n\n/*\n * A generic pouch adapter\n */\n\nfunction compare(left, right) {\n  return left < right ? -1 : left > right ? 1 : 0;\n}\n\n// Wrapper for functions that call the bulkdocs api with a single doc,\n// if the first result is an error, return an error\nfunction yankError(callback) {\n  return function (err, results) {\n    if (err || (results[0] && results[0].error)) {\n      callback(err || results[0]);\n    } else {\n      callback(null, results.length ? results[0]  : results);\n    }\n  };\n}\n\n// clean docs given to us by the user\nfunction cleanDocs(docs) {\n  for (var i = 0; i < docs.length; i++) {\n    var doc = docs[i];\n    if (doc._deleted) {\n      delete doc._attachments; // ignore atts for deleted docs\n    } else if (doc._attachments) {\n      // filter out extraneous keys from _attachments\n      var atts = Object.keys(doc._attachments);\n      for (var j = 0; j < atts.length; j++) {\n        var att = atts[j];\n        doc._attachments[att] = pick(doc._attachments[att],\n          ['data', 'digest', 'content_type', 'length', 'revpos', 'stub']);\n      }\n    }\n  }\n}\n\n// compare two docs, first by _id then by _rev\nfunction compareByIdThenRev(a, b) {\n  var idCompare = compare(a._id, b._id);\n  if (idCompare !== 0) {\n    return idCompare;\n  }\n  var aStart = a._revisions ? a._revisions.start : 0;\n  var bStart = b._revisions ? b._revisions.start : 0;\n  return compare(aStart, bStart);\n}\n\n// for every node in a revision tree computes its distance from the closest\n// leaf\nfunction computeHeight(revs) {\n  var height = {};\n  var edges = [];\n  traverseRevTree(revs, function (isLeaf, pos, id, prnt) {\n    var rev = pos + \"-\" + id;\n    if (isLeaf) {\n      height[rev] = 0;\n    }\n    if (prnt !== undefined) {\n      edges.push({from: prnt, to: rev});\n    }\n    return rev;\n  });\n\n  edges.reverse();\n  edges.forEach(function (edge) {\n    if (height[edge.from] === undefined) {\n      height[edge.from] = 1 + height[edge.to];\n    } else {\n      height[edge.from] = Math.min(height[edge.from], 1 + height[edge.to]);\n    }\n  });\n  return height;\n}\n\nfunction allDocsKeysQuery(api, opts, callback) {\n  var keys =  ('limit' in opts) ?\n      opts.keys.slice(opts.skip, opts.limit + opts.skip) :\n      (opts.skip > 0) ? opts.keys.slice(opts.skip) : opts.keys;\n  if (opts.descending) {\n    keys.reverse();\n  }\n  if (!keys.length) {\n    return api._allDocs({limit: 0}, callback);\n  }\n  var finalResults = {\n    offset: opts.skip\n  };\n  return PouchPromise$1.all(keys.map(function (key) {\n    var subOpts = assign$1({key: key, deleted: 'ok'}, opts);\n    ['limit', 'skip', 'keys'].forEach(function (optKey) {\n      delete subOpts[optKey];\n    });\n    return new PouchPromise$1(function (resolve, reject) {\n      api._allDocs(subOpts, function (err, res) {\n        /* istanbul ignore if */\n        if (err) {\n          return reject(err);\n        }\n        finalResults.total_rows = res.total_rows;\n        resolve(res.rows[0] || {key: key, error: 'not_found'});\n      });\n    });\n  })).then(function (results) {\n    finalResults.rows = results;\n    return finalResults;\n  });\n}\n\n// all compaction is done in a queue, to avoid attaching\n// too many listeners at once\nfunction doNextCompaction(self) {\n  var task = self._compactionQueue[0];\n  var opts = task.opts;\n  var callback = task.callback;\n  self.get('_local/compaction').catch(function () {\n    return false;\n  }).then(function (doc) {\n    if (doc && doc.last_seq) {\n      opts.last_seq = doc.last_seq;\n    }\n    self._compact(opts, function (err, res) {\n      /* istanbul ignore if */\n      if (err) {\n        callback(err);\n      } else {\n        callback(null, res);\n      }\n      nextTick(function () {\n        self._compactionQueue.shift();\n        if (self._compactionQueue.length) {\n          doNextCompaction(self);\n        }\n      });\n    });\n  });\n}\n\nfunction attachmentNameError(name) {\n  if (name.charAt(0) === '_') {\n    return name + 'is not a valid attachment name, attachment ' +\n      'names cannot start with \\'_\\'';\n  }\n  return false;\n}\n\ninherits(AbstractPouchDB, events.EventEmitter);\n\nfunction AbstractPouchDB() {\n  events.EventEmitter.call(this);\n}\n\nAbstractPouchDB.prototype.post =\n  adapterFun('post', function (doc, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  if (typeof doc !== 'object' || Array.isArray(doc)) {\n    return callback(createError(NOT_AN_OBJECT));\n  }\n  this.bulkDocs({docs: [doc]}, opts, yankError(callback));\n});\n\nAbstractPouchDB.prototype.put = adapterFun('put', function (doc, opts, cb) {\n  if (typeof opts === 'function') {\n    cb = opts;\n    opts = {};\n  }\n  if (typeof doc !== 'object' || Array.isArray(doc)) {\n    return cb(createError(NOT_AN_OBJECT));\n  }\n  invalidIdError(doc._id);\n  if (isLocalId(doc._id) && typeof this._putLocal === 'function') {\n    if (doc._deleted) {\n      return this._removeLocal(doc, cb);\n    } else {\n      return this._putLocal(doc, cb);\n    }\n  }\n  if (typeof this._put === 'function' && opts.new_edits !== false) {\n    this._put(doc, opts, cb);\n  } else {\n    this.bulkDocs({docs: [doc]}, opts, yankError(cb));\n  }\n});\n\nAbstractPouchDB.prototype.putAttachment =\n  adapterFun('putAttachment', function (docId, attachmentId, rev,\n                                              blob, type) {\n  var api = this;\n  if (typeof type === 'function') {\n    type = blob;\n    blob = rev;\n    rev = null;\n  }\n  // Lets fix in https://github.com/pouchdb/pouchdb/issues/3267\n  /* istanbul ignore if */\n  if (typeof type === 'undefined') {\n    type = blob;\n    blob = rev;\n    rev = null;\n  }\n  if (!type) {\n    guardedConsole('warn', 'Attachment', attachmentId, 'on document', docId, 'is missing content_type');\n  }\n\n  function createAttachment(doc) {\n    var prevrevpos = '_rev' in doc ? parseInt(doc._rev, 10) : 0;\n    doc._attachments = doc._attachments || {};\n    doc._attachments[attachmentId] = {\n      content_type: type,\n      data: blob,\n      revpos: ++prevrevpos\n    };\n    return api.put(doc);\n  }\n\n  return api.get(docId).then(function (doc) {\n    if (doc._rev !== rev) {\n      throw createError(REV_CONFLICT);\n    }\n\n    return createAttachment(doc);\n  }, function (err) {\n     // create new doc\n    /* istanbul ignore else */\n    if (err.reason === MISSING_DOC.message) {\n      return createAttachment({_id: docId});\n    } else {\n      throw err;\n    }\n  });\n});\n\nAbstractPouchDB.prototype.removeAttachment =\n  adapterFun('removeAttachment', function (docId, attachmentId, rev,\n                                                 callback) {\n  var self = this;\n  self.get(docId, function (err, obj) {\n    /* istanbul ignore if */\n    if (err) {\n      callback(err);\n      return;\n    }\n    if (obj._rev !== rev) {\n      callback(createError(REV_CONFLICT));\n      return;\n    }\n    /* istanbul ignore if */\n    if (!obj._attachments) {\n      return callback();\n    }\n    delete obj._attachments[attachmentId];\n    if (Object.keys(obj._attachments).length === 0) {\n      delete obj._attachments;\n    }\n    self.put(obj, callback);\n  });\n});\n\nAbstractPouchDB.prototype.remove =\n  adapterFun('remove', function (docOrId, optsOrRev, opts, callback) {\n  var doc;\n  if (typeof optsOrRev === 'string') {\n    // id, rev, opts, callback style\n    doc = {\n      _id: docOrId,\n      _rev: optsOrRev\n    };\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n  } else {\n    // doc, opts, callback style\n    doc = docOrId;\n    if (typeof optsOrRev === 'function') {\n      callback = optsOrRev;\n      opts = {};\n    } else {\n      callback = opts;\n      opts = optsOrRev;\n    }\n  }\n  opts = opts || {};\n  opts.was_delete = true;\n  var newDoc = {_id: doc._id, _rev: (doc._rev || opts.rev)};\n  newDoc._deleted = true;\n  if (isLocalId(newDoc._id) && typeof this._removeLocal === 'function') {\n    return this._removeLocal(doc, callback);\n  }\n  this.bulkDocs({docs: [newDoc]}, opts, yankError(callback));\n});\n\nAbstractPouchDB.prototype.revsDiff =\n  adapterFun('revsDiff', function (req, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  var ids = Object.keys(req);\n\n  if (!ids.length) {\n    return callback(null, {});\n  }\n\n  var count = 0;\n  var missing = new ExportedMap();\n\n  function addToMissing(id, revId) {\n    if (!missing.has(id)) {\n      missing.set(id, {missing: []});\n    }\n    missing.get(id).missing.push(revId);\n  }\n\n  function processDoc(id, rev_tree) {\n    // Is this fast enough? Maybe we should switch to a set simulated by a map\n    var missingForId = req[id].slice(0);\n    traverseRevTree(rev_tree, function (isLeaf, pos, revHash, ctx,\n      opts) {\n        var rev = pos + '-' + revHash;\n        var idx = missingForId.indexOf(rev);\n        if (idx === -1) {\n          return;\n        }\n\n        missingForId.splice(idx, 1);\n        /* istanbul ignore if */\n        if (opts.status !== 'available') {\n          addToMissing(id, rev);\n        }\n      });\n\n    // Traversing the tree is synchronous, so now `missingForId` contains\n    // revisions that were not found in the tree\n    missingForId.forEach(function (rev) {\n      addToMissing(id, rev);\n    });\n  }\n\n  ids.map(function (id) {\n    this._getRevisionTree(id, function (err, rev_tree) {\n      if (err && err.status === 404 && err.message === 'missing') {\n        missing.set(id, {missing: req[id]});\n      } else if (err) {\n        /* istanbul ignore next */\n        return callback(err);\n      } else {\n        processDoc(id, rev_tree);\n      }\n\n      if (++count === ids.length) {\n        // convert LazyMap to object\n        var missingObj = {};\n        missing.forEach(function (value, key) {\n          missingObj[key] = value;\n        });\n        return callback(null, missingObj);\n      }\n    });\n  }, this);\n});\n\n// _bulk_get API for faster replication, as described in\n// https://github.com/apache/couchdb-chttpd/pull/33\n// At the \"abstract\" level, it will just run multiple get()s in\n// parallel, because this isn't much of a performance cost\n// for local databases (except the cost of multiple transactions, which is\n// small). The http adapter overrides this in order\n// to do a more efficient single HTTP request.\nAbstractPouchDB.prototype.bulkGet =\n  adapterFun('bulkGet', function (opts, callback) {\n  bulkGet(this, opts, callback);\n});\n\n// compact one document and fire callback\n// by compacting we mean removing all revisions which\n// are further from the leaf in revision tree than max_height\nAbstractPouchDB.prototype.compactDocument =\n  adapterFun('compactDocument', function (docId, maxHeight, callback) {\n  var self = this;\n  this._getRevisionTree(docId, function (err, revTree) {\n    /* istanbul ignore if */\n    if (err) {\n      return callback(err);\n    }\n    var height = computeHeight(revTree);\n    var candidates = [];\n    var revs = [];\n    Object.keys(height).forEach(function (rev) {\n      if (height[rev] > maxHeight) {\n        candidates.push(rev);\n      }\n    });\n\n    traverseRevTree(revTree, function (isLeaf, pos, revHash, ctx, opts) {\n      var rev = pos + '-' + revHash;\n      if (opts.status === 'available' && candidates.indexOf(rev) !== -1) {\n        revs.push(rev);\n      }\n    });\n    self._doCompaction(docId, revs, callback);\n  });\n});\n\n// compact the whole database using single document\n// compaction\nAbstractPouchDB.prototype.compact =\n  adapterFun('compact', function (opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n\n  var self = this;\n  opts = opts || {};\n\n  self._compactionQueue = self._compactionQueue || [];\n  self._compactionQueue.push({opts: opts, callback: callback});\n  if (self._compactionQueue.length === 1) {\n    doNextCompaction(self);\n  }\n});\nAbstractPouchDB.prototype._compact = function (opts, callback) {\n  var self = this;\n  var changesOpts = {\n    return_docs: false,\n    last_seq: opts.last_seq || 0\n  };\n  var promises = [];\n\n  function onChange(row) {\n    promises.push(self.compactDocument(row.id, 0));\n  }\n  function onComplete(resp) {\n    var lastSeq = resp.last_seq;\n    PouchPromise$1.all(promises).then(function () {\n      return upsert(self, '_local/compaction', function deltaFunc(doc) {\n        if (!doc.last_seq || doc.last_seq < lastSeq) {\n          doc.last_seq = lastSeq;\n          return doc;\n        }\n        return false; // somebody else got here first, don't update\n      });\n    }).then(function () {\n      callback(null, {ok: true});\n    }).catch(callback);\n  }\n  self.changes(changesOpts)\n    .on('change', onChange)\n    .on('complete', onComplete)\n    .on('error', callback);\n};\n\n/* Begin api wrappers. Specific functionality to storage belongs in the\n   _[method] */\nAbstractPouchDB.prototype.get = adapterFun('get', function (id, opts, cb) {\n  if (typeof opts === 'function') {\n    cb = opts;\n    opts = {};\n  }\n  if (typeof id !== 'string') {\n    return cb(createError(INVALID_ID));\n  }\n  if (isLocalId(id) && typeof this._getLocal === 'function') {\n    return this._getLocal(id, cb);\n  }\n  var leaves = [], self = this;\n\n  function finishOpenRevs() {\n    var result = [];\n    var count = leaves.length;\n    /* istanbul ignore if */\n    if (!count) {\n      return cb(null, result);\n    }\n\n    // order with open_revs is unspecified\n    leaves.forEach(function (leaf) {\n      self.get(id, {\n        rev: leaf,\n        revs: opts.revs,\n        latest: opts.latest,\n        attachments: opts.attachments\n      }, function (err, doc) {\n        if (!err) {\n          // using latest=true can produce duplicates\n          var existing;\n          for (var i = 0, l = result.length; i < l; i++) {\n            if (result[i].ok && result[i].ok._rev === doc._rev) {\n              existing = true;\n              break;\n            }\n          }\n          if (!existing) {\n            result.push({ok: doc});\n          }\n        } else {\n          result.push({missing: leaf});\n        }\n        count--;\n        if (!count) {\n          cb(null, result);\n        }\n      });\n    });\n  }\n\n  if (opts.open_revs) {\n    if (opts.open_revs === \"all\") {\n      this._getRevisionTree(id, function (err, rev_tree) {\n        if (err) {\n          return cb(err);\n        }\n        leaves = collectLeaves(rev_tree).map(function (leaf) {\n          return leaf.rev;\n        });\n        finishOpenRevs();\n      });\n    } else {\n      if (Array.isArray(opts.open_revs)) {\n        leaves = opts.open_revs;\n        for (var i = 0; i < leaves.length; i++) {\n          var l = leaves[i];\n          // looks like it's the only thing couchdb checks\n          if (!(typeof (l) === \"string\" && /^\\d+-/.test(l))) {\n            return cb(createError(INVALID_REV));\n          }\n        }\n        finishOpenRevs();\n      } else {\n        return cb(createError(UNKNOWN_ERROR, 'function_clause'));\n      }\n    }\n    return; // open_revs does not like other options\n  }\n\n  return this._get(id, opts, function (err, result) {\n    if (err) {\n      return cb(err);\n    }\n\n    var doc = result.doc;\n    var metadata = result.metadata;\n    var ctx = result.ctx;\n\n    if (opts.conflicts) {\n      var conflicts = collectConflicts(metadata);\n      if (conflicts.length) {\n        doc._conflicts = conflicts;\n      }\n    }\n\n    if (isDeleted(metadata, doc._rev)) {\n      doc._deleted = true;\n    }\n\n    if (opts.revs || opts.revs_info) {\n      var splittedRev = doc._rev.split('-');\n      var revNo       = parseInt(splittedRev[0], 10);\n      var revHash     = splittedRev[1];\n\n      var paths = rootToLeaf(metadata.rev_tree);\n      var path = null;\n\n      for (var i = 0; i < paths.length; i++) {\n        var currentPath = paths[i];\n        var hashIndex = currentPath.ids.map(function (x) { return x.id; })\n          .indexOf(revHash);\n        var hashFoundAtRevPos = hashIndex === (revNo - 1);\n\n        if (hashFoundAtRevPos || (!path && hashIndex !== -1)) {\n          path = currentPath;\n        }\n      }\n\n      var indexOfRev = path.ids.map(function (x) { return x.id; })\n        .indexOf(doc._rev.split('-')[1]) + 1;\n      var howMany = path.ids.length - indexOfRev;\n      path.ids.splice(indexOfRev, howMany);\n      path.ids.reverse();\n\n      if (opts.revs) {\n        doc._revisions = {\n          start: (path.pos + path.ids.length) - 1,\n          ids: path.ids.map(function (rev) {\n            return rev.id;\n          })\n        };\n      }\n      if (opts.revs_info) {\n        var pos =  path.pos + path.ids.length;\n        doc._revs_info = path.ids.map(function (rev) {\n          pos--;\n          return {\n            rev: pos + '-' + rev.id,\n            status: rev.opts.status\n          };\n        });\n      }\n    }\n\n    if (opts.attachments && doc._attachments) {\n      var attachments = doc._attachments;\n      var count = Object.keys(attachments).length;\n      if (count === 0) {\n        return cb(null, doc);\n      }\n      Object.keys(attachments).forEach(function (key) {\n        this._getAttachment(doc._id, key, attachments[key], {\n          // Previously the revision handling was done in adapter.js\n          // getAttachment, however since idb-next doesnt we need to\n          // pass the rev through\n          rev: doc._rev,\n          binary: opts.binary,\n          ctx: ctx\n        }, function (err, data) {\n          var att = doc._attachments[key];\n          att.data = data;\n          delete att.stub;\n          delete att.length;\n          if (!--count) {\n            cb(null, doc);\n          }\n        });\n      }, self);\n    } else {\n      if (doc._attachments) {\n        for (var key in doc._attachments) {\n          /* istanbul ignore else */\n          if (doc._attachments.hasOwnProperty(key)) {\n            doc._attachments[key].stub = true;\n          }\n        }\n      }\n      cb(null, doc);\n    }\n  });\n});\n\n// TODO: I dont like this, it forces an extra read for every\n// attachment read and enforces a confusing api between\n// adapter.js and the adapter implementation\nAbstractPouchDB.prototype.getAttachment =\n  adapterFun('getAttachment', function (docId, attachmentId, opts, callback) {\n  var self = this;\n  if (opts instanceof Function) {\n    callback = opts;\n    opts = {};\n  }\n  this._get(docId, opts, function (err, res) {\n    if (err) {\n      return callback(err);\n    }\n    if (res.doc._attachments && res.doc._attachments[attachmentId]) {\n      opts.ctx = res.ctx;\n      opts.binary = true;\n      self._getAttachment(docId, attachmentId,\n                          res.doc._attachments[attachmentId], opts, callback);\n    } else {\n      return callback(createError(MISSING_DOC));\n    }\n  });\n});\n\nAbstractPouchDB.prototype.allDocs =\n  adapterFun('allDocs', function (opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  opts.skip = typeof opts.skip !== 'undefined' ? opts.skip : 0;\n  if (opts.start_key) {\n    opts.startkey = opts.start_key;\n  }\n  if (opts.end_key) {\n    opts.endkey = opts.end_key;\n  }\n  if ('keys' in opts) {\n    if (!Array.isArray(opts.keys)) {\n      return callback(new TypeError('options.keys must be an array'));\n    }\n    var incompatibleOpt =\n      ['startkey', 'endkey', 'key'].filter(function (incompatibleOpt) {\n      return incompatibleOpt in opts;\n    })[0];\n    if (incompatibleOpt) {\n      callback(createError(QUERY_PARSE_ERROR,\n        'Query parameter `' + incompatibleOpt +\n        '` is not compatible with multi-get'\n      ));\n      return;\n    }\n    if (this.type() !== 'http') {\n      return allDocsKeysQuery(this, opts, callback);\n    }\n  }\n\n  return this._allDocs(opts, callback);\n});\n\nAbstractPouchDB.prototype.changes = function (opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  return new Changes$2(this, opts, callback);\n};\n\nAbstractPouchDB.prototype.close = adapterFun('close', function (callback) {\n  this._closed = true;\n  this.emit('closed');\n  return this._close(callback);\n});\n\nAbstractPouchDB.prototype.info = adapterFun('info', function (callback) {\n  var self = this;\n  this._info(function (err, info) {\n    if (err) {\n      return callback(err);\n    }\n    // assume we know better than the adapter, unless it informs us\n    info.db_name = info.db_name || self.name;\n    info.auto_compaction = !!(self.auto_compaction && self.type() !== 'http');\n    info.adapter = self.type();\n    callback(null, info);\n  });\n});\n\nAbstractPouchDB.prototype.id = adapterFun('id', function (callback) {\n  return this._id(callback);\n});\n\n/* istanbul ignore next */\nAbstractPouchDB.prototype.type = function () {\n  return (typeof this._type === 'function') ? this._type() : this.adapter;\n};\n\nAbstractPouchDB.prototype.bulkDocs =\n  adapterFun('bulkDocs', function (req, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n\n  opts = opts || {};\n\n  if (Array.isArray(req)) {\n    req = {\n      docs: req\n    };\n  }\n\n  if (!req || !req.docs || !Array.isArray(req.docs)) {\n    return callback(createError(MISSING_BULK_DOCS));\n  }\n\n  for (var i = 0; i < req.docs.length; ++i) {\n    if (typeof req.docs[i] !== 'object' || Array.isArray(req.docs[i])) {\n      return callback(createError(NOT_AN_OBJECT));\n    }\n  }\n\n  var attachmentError;\n  req.docs.forEach(function (doc) {\n    if (doc._attachments) {\n      Object.keys(doc._attachments).forEach(function (name) {\n        attachmentError = attachmentError || attachmentNameError(name);\n        if (!doc._attachments[name].content_type) {\n          guardedConsole('warn', 'Attachment', name, 'on document', doc._id, 'is missing content_type');\n        }\n      });\n    }\n  });\n\n  if (attachmentError) {\n    return callback(createError(BAD_REQUEST, attachmentError));\n  }\n\n  if (!('new_edits' in opts)) {\n    if ('new_edits' in req) {\n      opts.new_edits = req.new_edits;\n    } else {\n      opts.new_edits = true;\n    }\n  }\n\n  var adapter = this;\n  if (!opts.new_edits && adapter.type() !== 'http') {\n    // ensure revisions of the same doc are sorted, so that\n    // the local adapter processes them correctly (#2935)\n    req.docs.sort(compareByIdThenRev);\n  }\n\n  cleanDocs(req.docs);\n\n  // in the case of conflicts, we want to return the _ids to the user\n  // however, the underlying adapter may destroy the docs array, so\n  // create a copy here\n  var ids = req.docs.map(function (doc) {\n    return doc._id;\n  });\n\n  return this._bulkDocs(req, opts, function (err, res) {\n    if (err) {\n      return callback(err);\n    }\n    if (!opts.new_edits) {\n      // this is what couch does when new_edits is false\n      res = res.filter(function (x) {\n        return x.error;\n      });\n    }\n    // add ids for error/conflict responses (not required for CouchDB)\n    if (adapter.type() !== 'http') {\n      for (var i = 0, l = res.length; i < l; i++) {\n        res[i].id = res[i].id || ids[i];\n      }\n    }\n\n    callback(null, res);\n  });\n});\n\nAbstractPouchDB.prototype.registerDependentDatabase =\n  adapterFun('registerDependentDatabase', function (dependentDb,\n                                                          callback) {\n  var depDB = new this.constructor(dependentDb, this.__opts);\n\n  function diffFun(doc) {\n    doc.dependentDbs = doc.dependentDbs || {};\n    if (doc.dependentDbs[dependentDb]) {\n      return false; // no update required\n    }\n    doc.dependentDbs[dependentDb] = true;\n    return doc;\n  }\n  upsert(this, '_local/_pouch_dependentDbs', diffFun)\n    .then(function () {\n      callback(null, {db: depDB});\n    }).catch(callback);\n});\n\nAbstractPouchDB.prototype.destroy =\n  adapterFun('destroy', function (opts, callback) {\n\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n\n  var self = this;\n  var usePrefix = 'use_prefix' in self ? self.use_prefix : true;\n\n  function destroyDb() {\n    // call destroy method of the particular adaptor\n    self._destroy(opts, function (err, resp) {\n      if (err) {\n        return callback(err);\n      }\n      self._destroyed = true;\n      self.emit('destroyed');\n      callback(null, resp || { 'ok': true });\n    });\n  }\n\n  if (self.type() === 'http') {\n    // no need to check for dependent DBs if it's a remote DB\n    return destroyDb();\n  }\n\n  self.get('_local/_pouch_dependentDbs', function (err, localDoc) {\n    if (err) {\n      /* istanbul ignore if */\n      if (err.status !== 404) {\n        return callback(err);\n      } else { // no dependencies\n        return destroyDb();\n      }\n    }\n    var dependentDbs = localDoc.dependentDbs;\n    var PouchDB = self.constructor;\n    var deletedMap = Object.keys(dependentDbs).map(function (name) {\n      // use_prefix is only false in the browser\n      /* istanbul ignore next */\n      var trueName = usePrefix ?\n        name.replace(new RegExp('^' + PouchDB.prefix), '') : name;\n      return new PouchDB(trueName, self.__opts).destroy();\n    });\n    PouchPromise$1.all(deletedMap).then(destroyDb, callback);\n  });\n});\n\nfunction TaskQueue$1() {\n  this.isReady = false;\n  this.failed = false;\n  this.queue = [];\n}\n\nTaskQueue$1.prototype.execute = function () {\n  var fun;\n  if (this.failed) {\n    while ((fun = this.queue.shift())) {\n      fun(this.failed);\n    }\n  } else {\n    while ((fun = this.queue.shift())) {\n      fun();\n    }\n  }\n};\n\nTaskQueue$1.prototype.fail = function (err) {\n  this.failed = err;\n  this.execute();\n};\n\nTaskQueue$1.prototype.ready = function (db) {\n  this.isReady = true;\n  this.db = db;\n  this.execute();\n};\n\nTaskQueue$1.prototype.addTask = function (fun) {\n  this.queue.push(fun);\n  if (this.failed) {\n    this.execute();\n  }\n};\n\nfunction parseAdapter(name, opts) {\n  var match = name.match(/([a-z\\-]*):\\/\\/(.*)/);\n  if (match) {\n    // the http adapter expects the fully qualified name\n    return {\n      name: /https?/.test(match[1]) ? match[1] + '://' + match[2] : match[2],\n      adapter: match[1]\n    };\n  }\n\n  var adapters = PouchDB$3.adapters;\n  var preferredAdapters = PouchDB$3.preferredAdapters;\n  var prefix = PouchDB$3.prefix;\n  var adapterName = opts.adapter;\n\n  if (!adapterName) { // automatically determine adapter\n    for (var i = 0; i < preferredAdapters.length; ++i) {\n      adapterName = preferredAdapters[i];\n      // check for browsers that have been upgraded from websql-only to websql+idb\n      /* istanbul ignore if */\n      if (adapterName === 'idb' && 'websql' in adapters &&\n          hasLocalStorage() && localStorage['_pouch__websqldb_' + prefix + name]) {\n        // log it, because this can be confusing during development\n        guardedConsole('log', 'PouchDB is downgrading \"' + name + '\" to WebSQL to' +\n          ' avoid data loss, because it was already opened with WebSQL.');\n        continue; // keep using websql to avoid user data loss\n      }\n      break;\n    }\n  }\n\n  var adapter = adapters[adapterName];\n\n  // if adapter is invalid, then an error will be thrown later\n  var usePrefix = (adapter && 'use_prefix' in adapter) ?\n    adapter.use_prefix : true;\n\n  return {\n    name: usePrefix ? (prefix + name) : name,\n    adapter: adapterName\n  };\n}\n\n// OK, so here's the deal. Consider this code:\n//     var db1 = new PouchDB('foo');\n//     var db2 = new PouchDB('foo');\n//     db1.destroy();\n// ^ these two both need to emit 'destroyed' events,\n// as well as the PouchDB constructor itself.\n// So we have one db object (whichever one got destroy() called on it)\n// responsible for emitting the initial event, which then gets emitted\n// by the constructor, which then broadcasts it to any other dbs\n// that may have been created with the same name.\nfunction prepareForDestruction(self) {\n\n  var destructionListeners = self.constructor._destructionListeners;\n\n  function onDestroyed() {\n    self.removeListener('closed', onClosed);\n    self.constructor.emit('destroyed', self.name);\n  }\n\n  function onConstructorDestroyed() {\n    self.removeListener('destroyed', onDestroyed);\n    self.removeListener('closed', onClosed);\n    self.emit('destroyed');\n  }\n\n  function onClosed() {\n    self.removeListener('destroyed', onDestroyed);\n    destructionListeners.delete(self.name);\n  }\n\n  self.once('destroyed', onDestroyed);\n  self.once('closed', onClosed);\n\n  // in setup.js, the constructor is primed to listen for destroy events\n  if (!destructionListeners.has(self.name)) {\n    destructionListeners.set(self.name, []);\n  }\n  destructionListeners.get(self.name).push(onConstructorDestroyed);\n}\n\ninherits(PouchDB$3, AbstractPouchDB);\nfunction PouchDB$3(name, opts) {\n  // In Node our test suite only tests this for PouchAlt unfortunately\n  /* istanbul ignore if */\n  if (!(this instanceof PouchDB$3)) {\n    return new PouchDB$3(name, opts);\n  }\n\n  var self = this;\n  opts = opts || {};\n\n  if (name && typeof name === 'object') {\n    opts = name;\n    name = opts.name;\n    delete opts.name;\n  }\n\n  this.__opts = opts = clone(opts);\n\n  self.auto_compaction = opts.auto_compaction;\n  self.prefix = PouchDB$3.prefix;\n\n  if (typeof name !== 'string') {\n    throw new Error('Missing/invalid DB name');\n  }\n\n  var prefixedName = (opts.prefix || '') + name;\n  var backend = parseAdapter(prefixedName, opts);\n\n  opts.name = backend.name;\n  opts.adapter = opts.adapter || backend.adapter;\n\n  self.name = name;\n  self._adapter = opts.adapter;\n  debug('pouchdb:adapter')('Picked adapter: ' + opts.adapter);\n\n  if (!PouchDB$3.adapters[opts.adapter] ||\n      !PouchDB$3.adapters[opts.adapter].valid()) {\n    throw new Error('Invalid Adapter: ' + opts.adapter);\n  }\n\n  AbstractPouchDB.call(self);\n  self.taskqueue = new TaskQueue$1();\n\n  self.adapter = opts.adapter;\n\n  PouchDB$3.adapters[opts.adapter].call(self, opts, function (err) {\n    if (err) {\n      return self.taskqueue.fail(err);\n    }\n    prepareForDestruction(self);\n\n    self.emit('created', self);\n    PouchDB$3.emit('created', self.name);\n    self.taskqueue.ready(self);\n  });\n\n}\n\nPouchDB$3.debug = debug;\n\nPouchDB$3.adapters = {};\nPouchDB$3.preferredAdapters = [];\n\nPouchDB$3.prefix = '_pouch_';\n\nvar eventEmitter = new events.EventEmitter();\n\nfunction setUpEventEmitter(Pouch) {\n  Object.keys(events.EventEmitter.prototype).forEach(function (key) {\n    if (typeof events.EventEmitter.prototype[key] === 'function') {\n      Pouch[key] = eventEmitter[key].bind(eventEmitter);\n    }\n  });\n\n  // these are created in constructor.js, and allow us to notify each DB with\n  // the same name that it was destroyed, via the constructor object\n  var destructListeners = Pouch._destructionListeners = new ExportedMap();\n  Pouch.on('destroyed', function onConstructorDestroyed(name) {\n    destructListeners.get(name).forEach(function (callback) {\n      callback();\n    });\n    destructListeners.delete(name);\n  });\n}\n\nsetUpEventEmitter(PouchDB$3);\n\nPouchDB$3.adapter = function (id, obj, addToPreferredAdapters) {\n  /* istanbul ignore else */\n  if (obj.valid()) {\n    PouchDB$3.adapters[id] = obj;\n    if (addToPreferredAdapters) {\n      PouchDB$3.preferredAdapters.push(id);\n    }\n  }\n};\n\nPouchDB$3.plugin = function (obj) {\n  if (typeof obj === 'function') { // function style for plugins\n    obj(PouchDB$3);\n  } else if (typeof obj !== 'object' || Object.keys(obj).length === 0){\n    throw new Error('Invalid plugin: got \\\"' + obj + '\\\", expected an object or a function');\n  } else {\n    Object.keys(obj).forEach(function (id) { // object style for plugins\n      PouchDB$3.prototype[id] = obj[id];\n    });\n  }\n  return PouchDB$3;\n};\n\nPouchDB$3.defaults = function (defaultOpts) {\n  function PouchAlt(name, opts) {\n    if (!(this instanceof PouchAlt)) {\n      return new PouchAlt(name, opts);\n    }\n\n    opts = opts || {};\n\n    if (name && typeof name === 'object') {\n      opts = name;\n      name = opts.name;\n      delete opts.name;\n    }\n\n    opts = assign$1({}, PouchAlt.__defaults, opts);\n    PouchDB$3.call(this, name, opts);\n  }\n\n  inherits(PouchAlt, PouchDB$3);\n\n  PouchAlt.preferredAdapters = PouchDB$3.preferredAdapters.slice();\n  Object.keys(PouchDB$3).forEach(function (key) {\n    if (!(key in PouchAlt)) {\n      PouchAlt[key] = PouchDB$3[key];\n    }\n  });\n\n  // make default options transitive\n  // https://github.com/pouchdb/pouchdb/issues/5922\n  PouchAlt.__defaults = assign$1({}, this.__defaults, defaultOpts);\n\n  return PouchAlt;\n};\n\n// managed automatically by set-version.js\nvar version = \"6.1.1\";\n\nPouchDB$3.version = version;\n\nfunction toObject(array) {\n  return array.reduce(function (obj, item) {\n    obj[item] = true;\n    return obj;\n  }, {});\n}\n// List of top level reserved words for doc\nvar reservedWords = toObject([\n  '_id',\n  '_rev',\n  '_attachments',\n  '_deleted',\n  '_revisions',\n  '_revs_info',\n  '_conflicts',\n  '_deleted_conflicts',\n  '_local_seq',\n  '_rev_tree',\n  //replication documents\n  '_replication_id',\n  '_replication_state',\n  '_replication_state_time',\n  '_replication_state_reason',\n  '_replication_stats',\n  // Specific to Couchbase Sync Gateway\n  '_removed'\n]);\n\n// List of reserved words that should end up the document\nvar dataWords = toObject([\n  '_attachments',\n  //replication documents\n  '_replication_id',\n  '_replication_state',\n  '_replication_state_time',\n  '_replication_state_reason',\n  '_replication_stats'\n]);\n\nfunction parseRevisionInfo(rev) {\n  if (!/^\\d+\\-./.test(rev)) {\n    return createError(INVALID_REV);\n  }\n  var idx = rev.indexOf('-');\n  var left = rev.substring(0, idx);\n  var right = rev.substring(idx + 1);\n  return {\n    prefix: parseInt(left, 10),\n    id: right\n  };\n}\n\nfunction makeRevTreeFromRevisions(revisions, opts) {\n  var pos = revisions.start - revisions.ids.length + 1;\n\n  var revisionIds = revisions.ids;\n  var ids = [revisionIds[0], opts, []];\n\n  for (var i = 1, len = revisionIds.length; i < len; i++) {\n    ids = [revisionIds[i], {status: 'missing'}, [ids]];\n  }\n\n  return [{\n    pos: pos,\n    ids: ids\n  }];\n}\n\n// Preprocess documents, parse their revisions, assign an id and a\n// revision for new writes that are missing them, etc\nfunction parseDoc(doc, newEdits) {\n\n  var nRevNum;\n  var newRevId;\n  var revInfo;\n  var opts = {status: 'available'};\n  if (doc._deleted) {\n    opts.deleted = true;\n  }\n\n  if (newEdits) {\n    if (!doc._id) {\n      doc._id = uuid();\n    }\n    newRevId = uuid(32, 16).toLowerCase();\n    if (doc._rev) {\n      revInfo = parseRevisionInfo(doc._rev);\n      if (revInfo.error) {\n        return revInfo;\n      }\n      doc._rev_tree = [{\n        pos: revInfo.prefix,\n        ids: [revInfo.id, {status: 'missing'}, [[newRevId, opts, []]]]\n      }];\n      nRevNum = revInfo.prefix + 1;\n    } else {\n      doc._rev_tree = [{\n        pos: 1,\n        ids : [newRevId, opts, []]\n      }];\n      nRevNum = 1;\n    }\n  } else {\n    if (doc._revisions) {\n      doc._rev_tree = makeRevTreeFromRevisions(doc._revisions, opts);\n      nRevNum = doc._revisions.start;\n      newRevId = doc._revisions.ids[0];\n    }\n    if (!doc._rev_tree) {\n      revInfo = parseRevisionInfo(doc._rev);\n      if (revInfo.error) {\n        return revInfo;\n      }\n      nRevNum = revInfo.prefix;\n      newRevId = revInfo.id;\n      doc._rev_tree = [{\n        pos: nRevNum,\n        ids: [newRevId, opts, []]\n      }];\n    }\n  }\n\n  invalidIdError(doc._id);\n\n  doc._rev = nRevNum + '-' + newRevId;\n\n  var result = {metadata : {}, data : {}};\n  for (var key in doc) {\n    /* istanbul ignore else */\n    if (Object.prototype.hasOwnProperty.call(doc, key)) {\n      var specialKey = key[0] === '_';\n      if (specialKey && !reservedWords[key]) {\n        var error = createError(DOC_VALIDATION, key);\n        error.message = DOC_VALIDATION.message + ': ' + key;\n        throw error;\n      } else if (specialKey && !dataWords[key]) {\n        result.metadata[key.slice(1)] = doc[key];\n      } else {\n        result.data[key] = doc[key];\n      }\n    }\n  }\n  return result;\n}\n\nvar thisAtob = function (str) {\n  return atob(str);\n};\n\nvar thisBtoa = function (str) {\n  return btoa(str);\n};\n\n// Abstracts constructing a Blob object, so it also works in older\n// browsers that don't support the native Blob constructor (e.g.\n// old QtWebKit versions, Android < 4.4).\nfunction createBlob(parts, properties) {\n  /* global BlobBuilder,MSBlobBuilder,MozBlobBuilder,WebKitBlobBuilder */\n  parts = parts || [];\n  properties = properties || {};\n  try {\n    return new Blob(parts, properties);\n  } catch (e) {\n    if (e.name !== \"TypeError\") {\n      throw e;\n    }\n    var Builder = typeof BlobBuilder !== 'undefined' ? BlobBuilder :\n                  typeof MSBlobBuilder !== 'undefined' ? MSBlobBuilder :\n                  typeof MozBlobBuilder !== 'undefined' ? MozBlobBuilder :\n                  WebKitBlobBuilder;\n    var builder = new Builder();\n    for (var i = 0; i < parts.length; i += 1) {\n      builder.append(parts[i]);\n    }\n    return builder.getBlob(properties.type);\n  }\n}\n\n// From http://stackoverflow.com/questions/14967647/ (continues on next line)\n// encode-decode-image-with-base64-breaks-image (2013-04-21)\nfunction binaryStringToArrayBuffer(bin) {\n  var length = bin.length;\n  var buf = new ArrayBuffer(length);\n  var arr = new Uint8Array(buf);\n  for (var i = 0; i < length; i++) {\n    arr[i] = bin.charCodeAt(i);\n  }\n  return buf;\n}\n\nfunction binStringToBluffer(binString, type) {\n  return createBlob([binaryStringToArrayBuffer(binString)], {type: type});\n}\n\nfunction b64ToBluffer(b64, type) {\n  return binStringToBluffer(thisAtob(b64), type);\n}\n\n//Can't find original post, but this is close\n//http://stackoverflow.com/questions/6965107/ (continues on next line)\n//converting-between-strings-and-arraybuffers\nfunction arrayBufferToBinaryString(buffer) {\n  var binary = '';\n  var bytes = new Uint8Array(buffer);\n  var length = bytes.byteLength;\n  for (var i = 0; i < length; i++) {\n    binary += String.fromCharCode(bytes[i]);\n  }\n  return binary;\n}\n\n// shim for browsers that don't support it\nfunction readAsBinaryString(blob, callback) {\n  if (typeof FileReader === 'undefined') {\n    // fix for Firefox in a web worker\n    // https://bugzilla.mozilla.org/show_bug.cgi?id=901097\n    return callback(arrayBufferToBinaryString(\n      new FileReaderSync().readAsArrayBuffer(blob)));\n  }\n\n  var reader = new FileReader();\n  var hasBinaryString = typeof reader.readAsBinaryString === 'function';\n  reader.onloadend = function (e) {\n    var result = e.target.result || '';\n    if (hasBinaryString) {\n      return callback(result);\n    }\n    callback(arrayBufferToBinaryString(result));\n  };\n  if (hasBinaryString) {\n    reader.readAsBinaryString(blob);\n  } else {\n    reader.readAsArrayBuffer(blob);\n  }\n}\n\nfunction blobToBinaryString(blobOrBuffer, callback) {\n  readAsBinaryString(blobOrBuffer, function (bin) {\n    callback(bin);\n  });\n}\n\nfunction blobToBase64(blobOrBuffer, callback) {\n  blobToBinaryString(blobOrBuffer, function (base64) {\n    callback(thisBtoa(base64));\n  });\n}\n\n// simplified API. universal browser support is assumed\nfunction readAsArrayBuffer(blob, callback) {\n  if (typeof FileReader === 'undefined') {\n    // fix for Firefox in a web worker:\n    // https://bugzilla.mozilla.org/show_bug.cgi?id=901097\n    return callback(new FileReaderSync().readAsArrayBuffer(blob));\n  }\n\n  var reader = new FileReader();\n  reader.onloadend = function (e) {\n    var result = e.target.result || new ArrayBuffer(0);\n    callback(result);\n  };\n  reader.readAsArrayBuffer(blob);\n}\n\n// this is not used in the browser\n\nvar setImmediateShim = global.setImmediate || global.setTimeout;\nvar MD5_CHUNK_SIZE = 32768;\n\nfunction rawToBase64(raw) {\n  return thisBtoa(raw);\n}\n\nfunction sliceBlob(blob$$1, start, end) {\n  if (blob$$1.webkitSlice) {\n    return blob$$1.webkitSlice(start, end);\n  }\n  return blob$$1.slice(start, end);\n}\n\nfunction appendBlob(buffer, blob$$1, start, end, callback) {\n  if (start > 0 || end < blob$$1.size) {\n    // only slice blob if we really need to\n    blob$$1 = sliceBlob(blob$$1, start, end);\n  }\n  readAsArrayBuffer(blob$$1, function (arrayBuffer) {\n    buffer.append(arrayBuffer);\n    callback();\n  });\n}\n\nfunction appendString(buffer, string, start, end, callback) {\n  if (start > 0 || end < string.length) {\n    // only create a substring if we really need to\n    string = string.substring(start, end);\n  }\n  buffer.appendBinary(string);\n  callback();\n}\n\nfunction binaryMd5(data, callback) {\n  var inputIsString = typeof data === 'string';\n  var len = inputIsString ? data.length : data.size;\n  var chunkSize = Math.min(MD5_CHUNK_SIZE, len);\n  var chunks = Math.ceil(len / chunkSize);\n  var currentChunk = 0;\n  var buffer = inputIsString ? new Md5() : new Md5.ArrayBuffer();\n\n  var append = inputIsString ? appendString : appendBlob;\n\n  function next() {\n    setImmediateShim(loadNextChunk);\n  }\n\n  function done() {\n    var raw = buffer.end(true);\n    var base64 = rawToBase64(raw);\n    callback(base64);\n    buffer.destroy();\n  }\n\n  function loadNextChunk() {\n    var start = currentChunk * chunkSize;\n    var end = start + chunkSize;\n    currentChunk++;\n    if (currentChunk < chunks) {\n      append(buffer, data, start, end, next);\n    } else {\n      append(buffer, data, start, end, done);\n    }\n  }\n  loadNextChunk();\n}\n\nfunction stringMd5(string) {\n  return Md5.hash(string);\n}\n\nfunction parseBase64(data) {\n  try {\n    return thisAtob(data);\n  } catch (e) {\n    var err = createError(BAD_ARG,\n      'Attachment is not a valid base64 string');\n    return {error: err};\n  }\n}\n\nfunction preprocessString(att, blobType, callback) {\n  var asBinary = parseBase64(att.data);\n  if (asBinary.error) {\n    return callback(asBinary.error);\n  }\n\n  att.length = asBinary.length;\n  if (blobType === 'blob') {\n    att.data = binStringToBluffer(asBinary, att.content_type);\n  } else if (blobType === 'base64') {\n    att.data = thisBtoa(asBinary);\n  } else { // binary\n    att.data = asBinary;\n  }\n  binaryMd5(asBinary, function (result) {\n    att.digest = 'md5-' + result;\n    callback();\n  });\n}\n\nfunction preprocessBlob(att, blobType, callback) {\n  binaryMd5(att.data, function (md5) {\n    att.digest = 'md5-' + md5;\n    // size is for blobs (browser), length is for buffers (node)\n    att.length = att.data.size || att.data.length || 0;\n    if (blobType === 'binary') {\n      blobToBinaryString(att.data, function (binString) {\n        att.data = binString;\n        callback();\n      });\n    } else if (blobType === 'base64') {\n      blobToBase64(att.data, function (b64) {\n        att.data = b64;\n        callback();\n      });\n    } else {\n      callback();\n    }\n  });\n}\n\nfunction preprocessAttachment(att, blobType, callback) {\n  if (att.stub) {\n    return callback();\n  }\n  if (typeof att.data === 'string') { // input is a base64 string\n    preprocessString(att, blobType, callback);\n  } else { // input is a blob\n    preprocessBlob(att, blobType, callback);\n  }\n}\n\nfunction preprocessAttachments(docInfos, blobType, callback) {\n\n  if (!docInfos.length) {\n    return callback();\n  }\n\n  var docv = 0;\n  var overallErr;\n\n  docInfos.forEach(function (docInfo) {\n    var attachments = docInfo.data && docInfo.data._attachments ?\n      Object.keys(docInfo.data._attachments) : [];\n    var recv = 0;\n\n    if (!attachments.length) {\n      return done();\n    }\n\n    function processedAttachment(err) {\n      overallErr = err;\n      recv++;\n      if (recv === attachments.length) {\n        done();\n      }\n    }\n\n    for (var key in docInfo.data._attachments) {\n      if (docInfo.data._attachments.hasOwnProperty(key)) {\n        preprocessAttachment(docInfo.data._attachments[key],\n          blobType, processedAttachment);\n      }\n    }\n  });\n\n  function done() {\n    docv++;\n    if (docInfos.length === docv) {\n      if (overallErr) {\n        callback(overallErr);\n      } else {\n        callback();\n      }\n    }\n  }\n}\n\nfunction updateDoc(revLimit, prev, docInfo, results,\n                   i, cb, writeDoc, newEdits) {\n\n  if (revExists(prev.rev_tree, docInfo.metadata.rev)) {\n    results[i] = docInfo;\n    return cb();\n  }\n\n  // sometimes this is pre-calculated. historically not always\n  var previousWinningRev = prev.winningRev || winningRev(prev);\n  var previouslyDeleted = 'deleted' in prev ? prev.deleted :\n    isDeleted(prev, previousWinningRev);\n  var deleted = 'deleted' in docInfo.metadata ? docInfo.metadata.deleted :\n    isDeleted(docInfo.metadata);\n  var isRoot = /^1-/.test(docInfo.metadata.rev);\n\n  if (previouslyDeleted && !deleted && newEdits && isRoot) {\n    var newDoc = docInfo.data;\n    newDoc._rev = previousWinningRev;\n    newDoc._id = docInfo.metadata.id;\n    docInfo = parseDoc(newDoc, newEdits);\n  }\n\n  var merged = merge(prev.rev_tree, docInfo.metadata.rev_tree[0], revLimit);\n\n  var inConflict = newEdits && (((previouslyDeleted && deleted) ||\n    (!previouslyDeleted && merged.conflicts !== 'new_leaf') ||\n    (previouslyDeleted && !deleted && merged.conflicts === 'new_branch')));\n\n  if (inConflict) {\n    var err = createError(REV_CONFLICT);\n    results[i] = err;\n    return cb();\n  }\n\n  var newRev = docInfo.metadata.rev;\n  docInfo.metadata.rev_tree = merged.tree;\n  docInfo.stemmedRevs = merged.stemmedRevs || [];\n  /* istanbul ignore else */\n  if (prev.rev_map) {\n    docInfo.metadata.rev_map = prev.rev_map; // used only by leveldb\n  }\n\n  // recalculate\n  var winningRev$$1 = winningRev(docInfo.metadata);\n  var winningRevIsDeleted = isDeleted(docInfo.metadata, winningRev$$1);\n\n  // calculate the total number of documents that were added/removed,\n  // from the perspective of total_rows/doc_count\n  var delta = (previouslyDeleted === winningRevIsDeleted) ? 0 :\n    previouslyDeleted < winningRevIsDeleted ? -1 : 1;\n\n  var newRevIsDeleted;\n  if (newRev === winningRev$$1) {\n    // if the new rev is the same as the winning rev, we can reuse that value\n    newRevIsDeleted = winningRevIsDeleted;\n  } else {\n    // if they're not the same, then we need to recalculate\n    newRevIsDeleted = isDeleted(docInfo.metadata, newRev);\n  }\n\n  writeDoc(docInfo, winningRev$$1, winningRevIsDeleted, newRevIsDeleted,\n    true, delta, i, cb);\n}\n\nfunction rootIsMissing(docInfo) {\n  return docInfo.metadata.rev_tree[0].ids[1].status === 'missing';\n}\n\nfunction processDocs(revLimit, docInfos, api, fetchedDocs, tx, results,\n                     writeDoc, opts, overallCallback) {\n\n  // Default to 1000 locally\n  revLimit = revLimit || 1000;\n\n  function insertDoc(docInfo, resultsIdx, callback) {\n    // Cant insert new deleted documents\n    var winningRev$$1 = winningRev(docInfo.metadata);\n    var deleted = isDeleted(docInfo.metadata, winningRev$$1);\n    if ('was_delete' in opts && deleted) {\n      results[resultsIdx] = createError(MISSING_DOC, 'deleted');\n      return callback();\n    }\n\n    // 4712 - detect whether a new document was inserted with a _rev\n    var inConflict = newEdits && rootIsMissing(docInfo);\n\n    if (inConflict) {\n      var err = createError(REV_CONFLICT);\n      results[resultsIdx] = err;\n      return callback();\n    }\n\n    var delta = deleted ? 0 : 1;\n\n    writeDoc(docInfo, winningRev$$1, deleted, deleted, false,\n      delta, resultsIdx, callback);\n  }\n\n  var newEdits = opts.new_edits;\n  var idsToDocs = new ExportedMap();\n\n  var docsDone = 0;\n  var docsToDo = docInfos.length;\n\n  function checkAllDocsDone() {\n    if (++docsDone === docsToDo && overallCallback) {\n      overallCallback();\n    }\n  }\n\n  docInfos.forEach(function (currentDoc, resultsIdx) {\n\n    if (currentDoc._id && isLocalId(currentDoc._id)) {\n      var fun = currentDoc._deleted ? '_removeLocal' : '_putLocal';\n      api[fun](currentDoc, {ctx: tx}, function (err, res) {\n        results[resultsIdx] = err || res;\n        checkAllDocsDone();\n      });\n      return;\n    }\n\n    var id = currentDoc.metadata.id;\n    if (idsToDocs.has(id)) {\n      docsToDo--; // duplicate\n      idsToDocs.get(id).push([currentDoc, resultsIdx]);\n    } else {\n      idsToDocs.set(id, [[currentDoc, resultsIdx]]);\n    }\n  });\n\n  // in the case of new_edits, the user can provide multiple docs\n  // with the same id. these need to be processed sequentially\n  idsToDocs.forEach(function (docs, id) {\n    var numDone = 0;\n\n    function docWritten() {\n      if (++numDone < docs.length) {\n        nextDoc();\n      } else {\n        checkAllDocsDone();\n      }\n    }\n    function nextDoc() {\n      var value = docs[numDone];\n      var currentDoc = value[0];\n      var resultsIdx = value[1];\n\n      if (fetchedDocs.has(id)) {\n        updateDoc(revLimit, fetchedDocs.get(id), currentDoc, results,\n          resultsIdx, docWritten, writeDoc, newEdits);\n      } else {\n        // Ensure stemming applies to new writes as well\n        var merged = merge([], currentDoc.metadata.rev_tree[0], revLimit);\n        currentDoc.metadata.rev_tree = merged.tree;\n        currentDoc.stemmedRevs = merged.stemmedRevs || [];\n        insertDoc(currentDoc, resultsIdx, docWritten);\n      }\n    }\n    nextDoc();\n  });\n}\n\n// IndexedDB requires a versioned database structure, so we use the\n// version here to manage migrations.\nvar ADAPTER_VERSION = 5;\n\n// The object stores created for each database\n// DOC_STORE stores the document meta data, its revision history and state\n// Keyed by document id\nvar DOC_STORE = 'document-store';\n// BY_SEQ_STORE stores a particular version of a document, keyed by its\n// sequence id\nvar BY_SEQ_STORE = 'by-sequence';\n// Where we store attachments\nvar ATTACH_STORE = 'attach-store';\n// Where we store many-to-many relations\n// between attachment digests and seqs\nvar ATTACH_AND_SEQ_STORE = 'attach-seq-store';\n\n// Where we store database-wide meta data in a single record\n// keyed by id: META_STORE\nvar META_STORE = 'meta-store';\n// Where we store local documents\nvar LOCAL_STORE = 'local-store';\n// Where we detect blob support\nvar DETECT_BLOB_SUPPORT_STORE = 'detect-blob-support';\n\nfunction safeJsonParse(str) {\n  // This try/catch guards against stack overflow errors.\n  // JSON.parse() is faster than vuvuzela.parse() but vuvuzela\n  // cannot overflow.\n  try {\n    return JSON.parse(str);\n  } catch (e) {\n    /* istanbul ignore next */\n    return vuvuzela.parse(str);\n  }\n}\n\nfunction safeJsonStringify(json) {\n  try {\n    return JSON.stringify(json);\n  } catch (e) {\n    /* istanbul ignore next */\n    return vuvuzela.stringify(json);\n  }\n}\n\nfunction idbError(callback) {\n  return function (evt) {\n    var message = 'unknown_error';\n    if (evt.target && evt.target.error) {\n      message = evt.target.error.name || evt.target.error.message;\n    }\n    callback(createError(IDB_ERROR, message, evt.type));\n  };\n}\n\n// Unfortunately, the metadata has to be stringified\n// when it is put into the database, because otherwise\n// IndexedDB can throw errors for deeply-nested objects.\n// Originally we just used JSON.parse/JSON.stringify; now\n// we use this custom vuvuzela library that avoids recursion.\n// If we could do it all over again, we'd probably use a\n// format for the revision trees other than JSON.\nfunction encodeMetadata(metadata, winningRev, deleted) {\n  return {\n    data: safeJsonStringify(metadata),\n    winningRev: winningRev,\n    deletedOrLocal: deleted ? '1' : '0',\n    seq: metadata.seq, // highest seq for this doc\n    id: metadata.id\n  };\n}\n\nfunction decodeMetadata(storedObject) {\n  if (!storedObject) {\n    return null;\n  }\n  var metadata = safeJsonParse(storedObject.data);\n  metadata.winningRev = storedObject.winningRev;\n  metadata.deleted = storedObject.deletedOrLocal === '1';\n  metadata.seq = storedObject.seq;\n  return metadata;\n}\n\n// read the doc back out from the database. we don't store the\n// _id or _rev because we already have _doc_id_rev.\nfunction decodeDoc(doc) {\n  if (!doc) {\n    return doc;\n  }\n  var idx = doc._doc_id_rev.lastIndexOf(':');\n  doc._id = doc._doc_id_rev.substring(0, idx - 1);\n  doc._rev = doc._doc_id_rev.substring(idx + 1);\n  delete doc._doc_id_rev;\n  return doc;\n}\n\n// Read a blob from the database, encoding as necessary\n// and translating from base64 if the IDB doesn't support\n// native Blobs\nfunction readBlobData(body, type, asBlob, callback) {\n  if (asBlob) {\n    if (!body) {\n      callback(createBlob([''], {type: type}));\n    } else if (typeof body !== 'string') { // we have blob support\n      callback(body);\n    } else { // no blob support\n      callback(b64ToBluffer(body, type));\n    }\n  } else { // as base64 string\n    if (!body) {\n      callback('');\n    } else if (typeof body !== 'string') { // we have blob support\n      readAsBinaryString(body, function (binary) {\n        callback(thisBtoa(binary));\n      });\n    } else { // no blob support\n      callback(body);\n    }\n  }\n}\n\nfunction fetchAttachmentsIfNecessary(doc, opts, txn, cb) {\n  var attachments = Object.keys(doc._attachments || {});\n  if (!attachments.length) {\n    return cb && cb();\n  }\n  var numDone = 0;\n\n  function checkDone() {\n    if (++numDone === attachments.length && cb) {\n      cb();\n    }\n  }\n\n  function fetchAttachment(doc, att) {\n    var attObj = doc._attachments[att];\n    var digest = attObj.digest;\n    var req = txn.objectStore(ATTACH_STORE).get(digest);\n    req.onsuccess = function (e) {\n      attObj.body = e.target.result.body;\n      checkDone();\n    };\n  }\n\n  attachments.forEach(function (att) {\n    if (opts.attachments && opts.include_docs) {\n      fetchAttachment(doc, att);\n    } else {\n      doc._attachments[att].stub = true;\n      checkDone();\n    }\n  });\n}\n\n// IDB-specific postprocessing necessary because\n// we don't know whether we stored a true Blob or\n// a base64-encoded string, and if it's a Blob it\n// needs to be read outside of the transaction context\nfunction postProcessAttachments(results, asBlob) {\n  return PouchPromise$1.all(results.map(function (row) {\n    if (row.doc && row.doc._attachments) {\n      var attNames = Object.keys(row.doc._attachments);\n      return PouchPromise$1.all(attNames.map(function (att) {\n        var attObj = row.doc._attachments[att];\n        if (!('body' in attObj)) { // already processed\n          return;\n        }\n        var body = attObj.body;\n        var type = attObj.content_type;\n        return new PouchPromise$1(function (resolve) {\n          readBlobData(body, type, asBlob, function (data) {\n            row.doc._attachments[att] = assign$1(\n              pick(attObj, ['digest', 'content_type']),\n              {data: data}\n            );\n            resolve();\n          });\n        });\n      }));\n    }\n  }));\n}\n\nfunction compactRevs(revs, docId, txn) {\n\n  var possiblyOrphanedDigests = [];\n  var seqStore = txn.objectStore(BY_SEQ_STORE);\n  var attStore = txn.objectStore(ATTACH_STORE);\n  var attAndSeqStore = txn.objectStore(ATTACH_AND_SEQ_STORE);\n  var count = revs.length;\n\n  function checkDone() {\n    count--;\n    if (!count) { // done processing all revs\n      deleteOrphanedAttachments();\n    }\n  }\n\n  function deleteOrphanedAttachments() {\n    if (!possiblyOrphanedDigests.length) {\n      return;\n    }\n    possiblyOrphanedDigests.forEach(function (digest) {\n      var countReq = attAndSeqStore.index('digestSeq').count(\n        IDBKeyRange.bound(\n          digest + '::', digest + '::\\uffff', false, false));\n      countReq.onsuccess = function (e) {\n        var count = e.target.result;\n        if (!count) {\n          // orphaned\n          attStore.delete(digest);\n        }\n      };\n    });\n  }\n\n  revs.forEach(function (rev) {\n    var index = seqStore.index('_doc_id_rev');\n    var key = docId + \"::\" + rev;\n    index.getKey(key).onsuccess = function (e) {\n      var seq = e.target.result;\n      if (typeof seq !== 'number') {\n        return checkDone();\n      }\n      seqStore.delete(seq);\n\n      var cursor = attAndSeqStore.index('seq')\n        .openCursor(IDBKeyRange.only(seq));\n\n      cursor.onsuccess = function (event) {\n        var cursor = event.target.result;\n        if (cursor) {\n          var digest = cursor.value.digestSeq.split('::')[0];\n          possiblyOrphanedDigests.push(digest);\n          attAndSeqStore.delete(cursor.primaryKey);\n          cursor.continue();\n        } else { // done\n          checkDone();\n        }\n      };\n    };\n  });\n}\n\nfunction openTransactionSafely(idb, stores, mode) {\n  try {\n    return {\n      txn: idb.transaction(stores, mode)\n    };\n  } catch (err) {\n    return {\n      error: err\n    };\n  }\n}\n\nvar changesHandler$$1 = new Changes();\n\nfunction idbBulkDocs(dbOpts, req, opts, api, idb, callback) {\n  var docInfos = req.docs;\n  var txn;\n  var docStore;\n  var bySeqStore;\n  var attachStore;\n  var attachAndSeqStore;\n  var metaStore;\n  var docInfoError;\n  var metaDoc;\n\n  for (var i = 0, len = docInfos.length; i < len; i++) {\n    var doc = docInfos[i];\n    if (doc._id && isLocalId(doc._id)) {\n      continue;\n    }\n    doc = docInfos[i] = parseDoc(doc, opts.new_edits);\n    if (doc.error && !docInfoError) {\n      docInfoError = doc;\n    }\n  }\n\n  if (docInfoError) {\n    return callback(docInfoError);\n  }\n\n  var allDocsProcessed = false;\n  var docCountDelta = 0;\n  var results = new Array(docInfos.length);\n  var fetchedDocs = new ExportedMap();\n  var preconditionErrored = false;\n  var blobType = api._meta.blobSupport ? 'blob' : 'base64';\n\n  preprocessAttachments(docInfos, blobType, function (err) {\n    if (err) {\n      return callback(err);\n    }\n    startTransaction();\n  });\n\n  function startTransaction() {\n\n    var stores = [\n      DOC_STORE, BY_SEQ_STORE,\n      ATTACH_STORE,\n      LOCAL_STORE, ATTACH_AND_SEQ_STORE,\n      META_STORE\n    ];\n    var txnResult = openTransactionSafely(idb, stores, 'readwrite');\n    if (txnResult.error) {\n      return callback(txnResult.error);\n    }\n    txn = txnResult.txn;\n    txn.onabort = idbError(callback);\n    txn.ontimeout = idbError(callback);\n    txn.oncomplete = complete;\n    docStore = txn.objectStore(DOC_STORE);\n    bySeqStore = txn.objectStore(BY_SEQ_STORE);\n    attachStore = txn.objectStore(ATTACH_STORE);\n    attachAndSeqStore = txn.objectStore(ATTACH_AND_SEQ_STORE);\n    metaStore = txn.objectStore(META_STORE);\n\n    metaStore.get(META_STORE).onsuccess = function (e) {\n      metaDoc = e.target.result;\n      updateDocCountIfReady();\n    };\n\n    verifyAttachments(function (err) {\n      if (err) {\n        preconditionErrored = true;\n        return callback(err);\n      }\n      fetchExistingDocs();\n    });\n  }\n\n  function onAllDocsProcessed() {\n    allDocsProcessed = true;\n    updateDocCountIfReady();\n  }\n\n  function idbProcessDocs() {\n    processDocs(dbOpts.revs_limit, docInfos, api, fetchedDocs,\n                txn, results, writeDoc, opts, onAllDocsProcessed);\n  }\n\n  function updateDocCountIfReady() {\n    if (!metaDoc || !allDocsProcessed) {\n      return;\n    }\n    // caching the docCount saves a lot of time in allDocs() and\n    // info(), which is why we go to all the trouble of doing this\n    metaDoc.docCount += docCountDelta;\n    metaStore.put(metaDoc);\n  }\n\n  function fetchExistingDocs() {\n\n    if (!docInfos.length) {\n      return;\n    }\n\n    var numFetched = 0;\n\n    function checkDone() {\n      if (++numFetched === docInfos.length) {\n        idbProcessDocs();\n      }\n    }\n\n    function readMetadata(event) {\n      var metadata = decodeMetadata(event.target.result);\n\n      if (metadata) {\n        fetchedDocs.set(metadata.id, metadata);\n      }\n      checkDone();\n    }\n\n    for (var i = 0, len = docInfos.length; i < len; i++) {\n      var docInfo = docInfos[i];\n      if (docInfo._id && isLocalId(docInfo._id)) {\n        checkDone(); // skip local docs\n        continue;\n      }\n      var req = docStore.get(docInfo.metadata.id);\n      req.onsuccess = readMetadata;\n    }\n  }\n\n  function complete() {\n    if (preconditionErrored) {\n      return;\n    }\n\n    changesHandler$$1.notify(api._meta.name);\n    callback(null, results);\n  }\n\n  function verifyAttachment(digest, callback) {\n\n    var req = attachStore.get(digest);\n    req.onsuccess = function (e) {\n      if (!e.target.result) {\n        var err = createError(MISSING_STUB,\n          'unknown stub attachment with digest ' +\n          digest);\n        err.status = 412;\n        callback(err);\n      } else {\n        callback();\n      }\n    };\n  }\n\n  function verifyAttachments(finish) {\n\n\n    var digests = [];\n    docInfos.forEach(function (docInfo) {\n      if (docInfo.data && docInfo.data._attachments) {\n        Object.keys(docInfo.data._attachments).forEach(function (filename) {\n          var att = docInfo.data._attachments[filename];\n          if (att.stub) {\n            digests.push(att.digest);\n          }\n        });\n      }\n    });\n    if (!digests.length) {\n      return finish();\n    }\n    var numDone = 0;\n    var err;\n\n    function checkDone() {\n      if (++numDone === digests.length) {\n        finish(err);\n      }\n    }\n    digests.forEach(function (digest) {\n      verifyAttachment(digest, function (attErr) {\n        if (attErr && !err) {\n          err = attErr;\n        }\n        checkDone();\n      });\n    });\n  }\n\n  function writeDoc(docInfo, winningRev$$1, winningRevIsDeleted, newRevIsDeleted,\n                    isUpdate, delta, resultsIdx, callback) {\n\n    docInfo.metadata.winningRev = winningRev$$1;\n    docInfo.metadata.deleted = winningRevIsDeleted;\n\n    var doc = docInfo.data;\n    doc._id = docInfo.metadata.id;\n    doc._rev = docInfo.metadata.rev;\n\n    if (newRevIsDeleted) {\n      doc._deleted = true;\n    }\n\n    var hasAttachments = doc._attachments &&\n      Object.keys(doc._attachments).length;\n    if (hasAttachments) {\n      return writeAttachments(docInfo, winningRev$$1, winningRevIsDeleted,\n        isUpdate, resultsIdx, callback);\n    }\n\n    docCountDelta += delta;\n    updateDocCountIfReady();\n\n    finishDoc(docInfo, winningRev$$1, winningRevIsDeleted,\n      isUpdate, resultsIdx, callback);\n  }\n\n  function finishDoc(docInfo, winningRev$$1, winningRevIsDeleted,\n                     isUpdate, resultsIdx, callback) {\n\n    var doc = docInfo.data;\n    var metadata = docInfo.metadata;\n\n    doc._doc_id_rev = metadata.id + '::' + metadata.rev;\n    delete doc._id;\n    delete doc._rev;\n\n    function afterPutDoc(e) {\n      var revsToDelete = docInfo.stemmedRevs || [];\n\n      if (isUpdate && api.auto_compaction) {\n        revsToDelete = revsToDelete.concat(compactTree(docInfo.metadata));\n      }\n\n      if (revsToDelete && revsToDelete.length) {\n        compactRevs(revsToDelete, docInfo.metadata.id, txn);\n      }\n\n      metadata.seq = e.target.result;\n      // Current _rev is calculated from _rev_tree on read\n      // delete metadata.rev;\n      var metadataToStore = encodeMetadata(metadata, winningRev$$1,\n        winningRevIsDeleted);\n      var metaDataReq = docStore.put(metadataToStore);\n      metaDataReq.onsuccess = afterPutMetadata;\n    }\n\n    function afterPutDocError(e) {\n      // ConstraintError, need to update, not put (see #1638 for details)\n      e.preventDefault(); // avoid transaction abort\n      e.stopPropagation(); // avoid transaction onerror\n      var index = bySeqStore.index('_doc_id_rev');\n      var getKeyReq = index.getKey(doc._doc_id_rev);\n      getKeyReq.onsuccess = function (e) {\n        var putReq = bySeqStore.put(doc, e.target.result);\n        putReq.onsuccess = afterPutDoc;\n      };\n    }\n\n    function afterPutMetadata() {\n      results[resultsIdx] = {\n        ok: true,\n        id: metadata.id,\n        rev: metadata.rev\n      };\n      fetchedDocs.set(docInfo.metadata.id, docInfo.metadata);\n      insertAttachmentMappings(docInfo, metadata.seq, callback);\n    }\n\n    var putReq = bySeqStore.put(doc);\n\n    putReq.onsuccess = afterPutDoc;\n    putReq.onerror = afterPutDocError;\n  }\n\n  function writeAttachments(docInfo, winningRev$$1, winningRevIsDeleted,\n                            isUpdate, resultsIdx, callback) {\n\n\n    var doc = docInfo.data;\n\n    var numDone = 0;\n    var attachments = Object.keys(doc._attachments);\n\n    function collectResults() {\n      if (numDone === attachments.length) {\n        finishDoc(docInfo, winningRev$$1, winningRevIsDeleted,\n          isUpdate, resultsIdx, callback);\n      }\n    }\n\n    function attachmentSaved() {\n      numDone++;\n      collectResults();\n    }\n\n    attachments.forEach(function (key) {\n      var att = docInfo.data._attachments[key];\n      if (!att.stub) {\n        var data = att.data;\n        delete att.data;\n        att.revpos = parseInt(winningRev$$1, 10);\n        var digest = att.digest;\n        saveAttachment(digest, data, attachmentSaved);\n      } else {\n        numDone++;\n        collectResults();\n      }\n    });\n  }\n\n  // map seqs to attachment digests, which\n  // we will need later during compaction\n  function insertAttachmentMappings(docInfo, seq, callback) {\n\n    var attsAdded = 0;\n    var attsToAdd = Object.keys(docInfo.data._attachments || {});\n\n    if (!attsToAdd.length) {\n      return callback();\n    }\n\n    function checkDone() {\n      if (++attsAdded === attsToAdd.length) {\n        callback();\n      }\n    }\n\n    function add(att) {\n      var digest = docInfo.data._attachments[att].digest;\n      var req = attachAndSeqStore.put({\n        seq: seq,\n        digestSeq: digest + '::' + seq\n      });\n\n      req.onsuccess = checkDone;\n      req.onerror = function (e) {\n        // this callback is for a constaint error, which we ignore\n        // because this docid/rev has already been associated with\n        // the digest (e.g. when new_edits == false)\n        e.preventDefault(); // avoid transaction abort\n        e.stopPropagation(); // avoid transaction onerror\n        checkDone();\n      };\n    }\n    for (var i = 0; i < attsToAdd.length; i++) {\n      add(attsToAdd[i]); // do in parallel\n    }\n  }\n\n  function saveAttachment(digest, data, callback) {\n\n\n    var getKeyReq = attachStore.count(digest);\n    getKeyReq.onsuccess = function (e) {\n      var count = e.target.result;\n      if (count) {\n        return callback(); // already exists\n      }\n      var newAtt = {\n        digest: digest,\n        body: data\n      };\n      var putReq = attachStore.put(newAtt);\n      putReq.onsuccess = callback;\n    };\n  }\n}\n\n// Abstraction over IDBCursor and getAll()/getAllKeys() that allows us to batch our operations\n// while falling back to a normal IDBCursor operation on browsers that don't support getAll() or\n// getAllKeys(). This allows for a much faster implementation than just straight-up cursors, because\n// we're not processing each document one-at-a-time.\nfunction runBatchedCursor(objectStore, keyRange, descending, batchSize, onBatch) {\n\n  // Bail out of getAll()/getAllKeys() in the following cases:\n  // 1) either method is unsupported - we need both\n  // 2) batchSize is 1 (might as well use IDBCursor), or batchSize is -1 (i.e. batchSize unlimited,\n  //    not really clear the user wants a batched approach where the entire DB is read into memory,\n  //    perhaps they are filtering on a per-doc basis)\n  // 3) descending  no real way to do this via getAll()/getAllKeys()\n\n  var useGetAll = typeof objectStore.getAll === 'function' &&\n    typeof objectStore.getAllKeys === 'function' &&\n    batchSize > 1 && !descending;\n\n  var keysBatch;\n  var valuesBatch;\n  var pseudoCursor;\n\n  function onGetAll(e) {\n    valuesBatch = e.target.result;\n    if (keysBatch) {\n      onBatch(keysBatch, valuesBatch, pseudoCursor);\n    }\n  }\n\n  function onGetAllKeys(e) {\n    keysBatch = e.target.result;\n    if (valuesBatch) {\n      onBatch(keysBatch, valuesBatch, pseudoCursor);\n    }\n  }\n\n  function continuePseudoCursor() {\n    if (!keysBatch.length) { // no more results\n      return onBatch();\n    }\n    // fetch next batch, exclusive start\n    var lastKey = keysBatch[keysBatch.length - 1];\n    var newKeyRange;\n    if (keyRange && keyRange.upper) {\n      try {\n        newKeyRange = IDBKeyRange.bound(lastKey, keyRange.upper,\n          true, keyRange.upperOpen);\n      } catch (e) {\n        if (e.name === \"DataError\" && e.code === 0) {\n          return onBatch(); // we're done, startkey and endkey are equal\n        }\n      }\n    } else {\n      newKeyRange = IDBKeyRange.lowerBound(lastKey, true);\n    }\n    keyRange = newKeyRange;\n    keysBatch = null;\n    valuesBatch = null;\n    objectStore.getAll(keyRange, batchSize).onsuccess = onGetAll;\n    objectStore.getAllKeys(keyRange, batchSize).onsuccess = onGetAllKeys;\n  }\n\n  function onCursor(e) {\n    var cursor = e.target.result;\n    if (!cursor) { // done\n      return onBatch();\n    }\n    // regular IDBCursor acts like a batch where batch size is always 1\n    onBatch([cursor.key], [cursor.value], cursor);\n  }\n\n  if (useGetAll) {\n    pseudoCursor = {\"continue\": continuePseudoCursor};\n    objectStore.getAll(keyRange, batchSize).onsuccess = onGetAll;\n    objectStore.getAllKeys(keyRange, batchSize).onsuccess = onGetAllKeys;\n  } else if (descending) {\n    objectStore.openCursor(keyRange, 'prev').onsuccess = onCursor;\n  } else {\n    objectStore.openCursor(keyRange).onsuccess = onCursor;\n  }\n}\n\n// simple shim for objectStore.getAll(), falling back to IDBCursor\nfunction getAll(objectStore, keyRange, onSuccess) {\n  if (typeof objectStore.getAll === 'function') {\n    // use native getAll\n    objectStore.getAll(keyRange).onsuccess = onSuccess;\n    return;\n  }\n  // fall back to cursors\n  var values = [];\n\n  function onCursor(e) {\n    var cursor = e.target.result;\n    if (cursor) {\n      values.push(cursor.value);\n      cursor.continue();\n    } else {\n      onSuccess({\n        target: {\n          result: values\n        }\n      });\n    }\n  }\n\n  objectStore.openCursor(keyRange).onsuccess = onCursor;\n}\n\nfunction createKeyRange(start, end, inclusiveEnd, key, descending) {\n  try {\n    if (start && end) {\n      if (descending) {\n        return IDBKeyRange.bound(end, start, !inclusiveEnd, false);\n      } else {\n        return IDBKeyRange.bound(start, end, false, !inclusiveEnd);\n      }\n    } else if (start) {\n      if (descending) {\n        return IDBKeyRange.upperBound(start);\n      } else {\n        return IDBKeyRange.lowerBound(start);\n      }\n    } else if (end) {\n      if (descending) {\n        return IDBKeyRange.lowerBound(end, !inclusiveEnd);\n      } else {\n        return IDBKeyRange.upperBound(end, !inclusiveEnd);\n      }\n    } else if (key) {\n      return IDBKeyRange.only(key);\n    }\n  } catch (e) {\n    return {error: e};\n  }\n  return null;\n}\n\nfunction idbAllDocs(opts, idb, callback) {\n  var start = 'startkey' in opts ? opts.startkey : false;\n  var end = 'endkey' in opts ? opts.endkey : false;\n  var key = 'key' in opts ? opts.key : false;\n  var skip = opts.skip || 0;\n  var limit = typeof opts.limit === 'number' ? opts.limit : -1;\n  var inclusiveEnd = opts.inclusive_end !== false;\n\n  var keyRange = createKeyRange(start, end, inclusiveEnd, key, opts.descending);\n  var keyRangeError = keyRange && keyRange.error;\n  if (keyRangeError && !(keyRangeError.name === \"DataError\" &&\n      keyRangeError.code === 0)) {\n    // DataError with error code 0 indicates start is less than end, so\n    // can just do an empty query. Else need to throw\n    return callback(createError(IDB_ERROR,\n      keyRangeError.name, keyRangeError.message));\n  }\n\n  var stores = [DOC_STORE, BY_SEQ_STORE, META_STORE];\n\n  if (opts.attachments) {\n    stores.push(ATTACH_STORE);\n  }\n  var txnResult = openTransactionSafely(idb, stores, 'readonly');\n  if (txnResult.error) {\n    return callback(txnResult.error);\n  }\n  var txn = txnResult.txn;\n  txn.oncomplete = onTxnComplete;\n  txn.onabort = idbError(callback);\n  var docStore = txn.objectStore(DOC_STORE);\n  var seqStore = txn.objectStore(BY_SEQ_STORE);\n  var metaStore = txn.objectStore(META_STORE);\n  var docIdRevIndex = seqStore.index('_doc_id_rev');\n  var results = [];\n  var docCount;\n\n  metaStore.get(META_STORE).onsuccess = function (e) {\n    docCount = e.target.result.docCount;\n  };\n\n  // if the user specifies include_docs=true, then we don't\n  // want to block the main cursor while we're fetching the doc\n  function fetchDocAsynchronously(metadata, row, winningRev$$1) {\n    var key = metadata.id + \"::\" + winningRev$$1;\n    docIdRevIndex.get(key).onsuccess =  function onGetDoc(e) {\n      row.doc = decodeDoc(e.target.result);\n      if (opts.conflicts) {\n        var conflicts = collectConflicts(metadata);\n        if (conflicts.length) {\n          row.doc._conflicts = conflicts;\n        }\n      }\n      fetchAttachmentsIfNecessary(row.doc, opts, txn);\n    };\n  }\n\n  function allDocsInner(winningRev$$1, metadata) {\n    var row = {\n      id: metadata.id,\n      key: metadata.id,\n      value: {\n        rev: winningRev$$1\n      }\n    };\n    var deleted = metadata.deleted;\n    if (opts.deleted === 'ok') {\n      results.push(row);\n      // deleted docs are okay with \"keys\" requests\n      if (deleted) {\n        row.value.deleted = true;\n        row.doc = null;\n      } else if (opts.include_docs) {\n        fetchDocAsynchronously(metadata, row, winningRev$$1);\n      }\n    } else if (!deleted && skip-- <= 0) {\n      results.push(row);\n      if (opts.include_docs) {\n        fetchDocAsynchronously(metadata, row, winningRev$$1);\n      }\n    }\n  }\n\n  function processBatch(batchValues) {\n    for (var i = 0, len = batchValues.length; i < len; i++) {\n      if (results.length === limit) {\n        break;\n      }\n      var batchValue = batchValues[i];\n      var metadata = decodeMetadata(batchValue);\n      var winningRev$$1 = metadata.winningRev;\n      allDocsInner(winningRev$$1, metadata);\n    }\n  }\n\n  function onBatch(batchKeys, batchValues, cursor) {\n    if (!cursor) {\n      return;\n    }\n    processBatch(batchValues);\n    if (results.length < limit) {\n      cursor.continue();\n    }\n  }\n\n  function onGetAll(e) {\n    var values = e.target.result;\n    if (opts.descending) {\n      values = values.reverse();\n    }\n    processBatch(values);\n  }\n\n  function onResultsReady() {\n    callback(null, {\n      total_rows: docCount,\n      offset: opts.skip,\n      rows: results\n    });\n  }\n\n  function onTxnComplete() {\n    if (opts.attachments) {\n      postProcessAttachments(results, opts.binary).then(onResultsReady);\n    } else {\n      onResultsReady();\n    }\n  }\n\n  // don't bother doing any requests if start > end or limit === 0\n  if (keyRangeError || limit === 0) {\n    return;\n  }\n  if (limit === -1) { // just fetch everything\n    return getAll(docStore, keyRange, onGetAll);\n  }\n  // else do a cursor\n  // choose a batch size based on the skip, since we'll need to skip that many\n  runBatchedCursor(docStore, keyRange, opts.descending, limit + skip, onBatch);\n}\n\n//\n// Blobs are not supported in all versions of IndexedDB, notably\n// Chrome <37 and Android <5. In those versions, storing a blob will throw.\n//\n// Various other blob bugs exist in Chrome v37-42 (inclusive).\n// Detecting them is expensive and confusing to users, and Chrome 37-42\n// is at very low usage worldwide, so we do a hacky userAgent check instead.\n//\n// content-type bug: https://code.google.com/p/chromium/issues/detail?id=408120\n// 404 bug: https://code.google.com/p/chromium/issues/detail?id=447916\n// FileReader bug: https://code.google.com/p/chromium/issues/detail?id=447836\n//\nfunction checkBlobSupport(txn) {\n  return new PouchPromise$1(function (resolve) {\n    var blob$$1 = createBlob(['']);\n    var req = txn.objectStore(DETECT_BLOB_SUPPORT_STORE).put(blob$$1, 'key');\n\n    req.onsuccess = function () {\n      var matchedChrome = navigator.userAgent.match(/Chrome\\/(\\d+)/);\n      var matchedEdge = navigator.userAgent.match(/Edge\\//);\n      // MS Edge pretends to be Chrome 42:\n      // https://msdn.microsoft.com/en-us/library/hh869301%28v=vs.85%29.aspx\n      resolve(matchedEdge || !matchedChrome ||\n        parseInt(matchedChrome[1], 10) >= 43);\n    };\n\n    txn.onabort = function (e) {\n      // If the transaction aborts now its due to not being able to\n      // write to the database, likely due to the disk being full\n      e.preventDefault();\n      e.stopPropagation();\n      resolve(false);\n    };\n  }).catch(function () {\n    return false; // error, so assume unsupported\n  });\n}\n\nfunction countDocs(txn, cb) {\n  var index = txn.objectStore(DOC_STORE).index('deletedOrLocal');\n  index.count(IDBKeyRange.only('0')).onsuccess = function (e) {\n    cb(e.target.result);\n  };\n}\n\n// This task queue ensures that IDB open calls are done in their own tick\n// and sequentially - i.e. we wait for the async IDB open to *fully* complete\n// before calling the next one. This works around IE/Edge race conditions in IDB.\n\nvar running = false;\nvar queue = [];\n\nfunction tryCode(fun, err, res, PouchDB) {\n  try {\n    fun(err, res);\n  } catch (err) {\n    // Shouldn't happen, but in some odd cases\n    // IndexedDB implementations might throw a sync\n    // error, in which case this will at least log it.\n    PouchDB.emit('error', err);\n  }\n}\n\nfunction applyNext() {\n  if (running || !queue.length) {\n    return;\n  }\n  running = true;\n  queue.shift()();\n}\n\nfunction enqueueTask(action, callback, PouchDB) {\n  queue.push(function runAction() {\n    action(function runCallback(err, res) {\n      tryCode(callback, err, res, PouchDB);\n      running = false;\n      nextTick(function runNext() {\n        applyNext(PouchDB);\n      });\n    });\n  });\n  applyNext();\n}\n\nfunction changes(opts, api, dbName, idb) {\n  opts = clone(opts);\n\n  if (opts.continuous) {\n    var id = dbName + ':' + uuid();\n    changesHandler$$1.addListener(dbName, id, api, opts);\n    changesHandler$$1.notify(dbName);\n    return {\n      cancel: function () {\n        changesHandler$$1.removeListener(dbName, id);\n      }\n    };\n  }\n\n  var docIds = opts.doc_ids && new ExportedSet(opts.doc_ids);\n\n  opts.since = opts.since || 0;\n  var lastSeq = opts.since;\n\n  var limit = 'limit' in opts ? opts.limit : -1;\n  if (limit === 0) {\n    limit = 1; // per CouchDB _changes spec\n  }\n  var returnDocs;\n  if ('return_docs' in opts) {\n    returnDocs = opts.return_docs;\n  } else if ('returnDocs' in opts) {\n    // TODO: Remove 'returnDocs' in favor of 'return_docs' in a future release\n    returnDocs = opts.returnDocs;\n  } else {\n    returnDocs = true;\n  }\n\n  var results = [];\n  var numResults = 0;\n  var filter = filterChange(opts);\n  var docIdsToMetadata = new ExportedMap();\n\n  var txn;\n  var bySeqStore;\n  var docStore;\n  var docIdRevIndex;\n\n  function onBatch(batchKeys, batchValues, cursor) {\n    if (!cursor || !batchKeys.length) { // done\n      return;\n    }\n\n    var winningDocs = new Array(batchKeys.length);\n    var metadatas = new Array(batchKeys.length);\n\n    function processMetadataAndWinningDoc(metadata, winningDoc) {\n      var change = opts.processChange(winningDoc, metadata, opts);\n      lastSeq = change.seq = metadata.seq;\n\n      var filtered = filter(change);\n      if (typeof filtered === 'object') { // anything but true/false indicates error\n        return opts.complete(filtered);\n      }\n\n      if (filtered) {\n        numResults++;\n        if (returnDocs) {\n          results.push(change);\n        }\n        // process the attachment immediately\n        // for the benefit of live listeners\n        if (opts.attachments && opts.include_docs) {\n          fetchAttachmentsIfNecessary(winningDoc, opts, txn, function () {\n            postProcessAttachments([change], opts.binary).then(function () {\n              opts.onChange(change);\n            });\n          });\n        } else {\n          opts.onChange(change);\n        }\n      }\n    }\n\n    function onBatchDone() {\n      for (var i = 0, len = winningDocs.length; i < len; i++) {\n        if (numResults === limit) {\n          break;\n        }\n        var winningDoc = winningDocs[i];\n        if (!winningDoc) {\n          continue;\n        }\n        var metadata = metadatas[i];\n        processMetadataAndWinningDoc(metadata, winningDoc);\n      }\n\n      if (numResults !== limit) {\n        cursor.continue();\n      }\n    }\n\n    // Fetch all metadatas/winningdocs from this batch in parallel, then process\n    // them all only once all data has been collected. This is done in parallel\n    // because it's faster than doing it one-at-a-time.\n    var numDone = 0;\n    batchValues.forEach(function (value, i) {\n      var doc = decodeDoc(value);\n      var seq = batchKeys[i];\n      fetchWinningDocAndMetadata(doc, seq, function (metadata, winningDoc) {\n        metadatas[i] = metadata;\n        winningDocs[i] = winningDoc;\n        if (++numDone === batchKeys.length) {\n          onBatchDone();\n        }\n      });\n    });\n  }\n\n  function onGetMetadata(doc, seq, metadata, cb) {\n    if (metadata.seq !== seq) {\n      // some other seq is later\n      return cb();\n    }\n\n    if (metadata.winningRev === doc._rev) {\n      // this is the winning doc\n      return cb(metadata, doc);\n    }\n\n    // fetch winning doc in separate request\n    var docIdRev = doc._id + '::' + metadata.winningRev;\n    var req = docIdRevIndex.get(docIdRev);\n    req.onsuccess = function (e) {\n      cb(metadata, decodeDoc(e.target.result));\n    };\n  }\n\n  function fetchWinningDocAndMetadata(doc, seq, cb) {\n    if (docIds && !docIds.has(doc._id)) {\n      return cb();\n    }\n\n    var metadata = docIdsToMetadata.get(doc._id);\n    if (metadata) { // cached\n      return onGetMetadata(doc, seq, metadata, cb);\n    }\n    // metadata not cached, have to go fetch it\n    docStore.get(doc._id).onsuccess = function (e) {\n      metadata = decodeMetadata(e.target.result);\n      docIdsToMetadata.set(doc._id, metadata);\n      onGetMetadata(doc, seq, metadata, cb);\n    };\n  }\n\n  function finish() {\n    opts.complete(null, {\n      results: results,\n      last_seq: lastSeq\n    });\n  }\n\n  function onTxnComplete() {\n    if (!opts.continuous && opts.attachments) {\n      // cannot guarantee that postProcessing was already done,\n      // so do it again\n      postProcessAttachments(results).then(finish);\n    } else {\n      finish();\n    }\n  }\n\n  var objectStores = [DOC_STORE, BY_SEQ_STORE];\n  if (opts.attachments) {\n    objectStores.push(ATTACH_STORE);\n  }\n  var txnResult = openTransactionSafely(idb, objectStores, 'readonly');\n  if (txnResult.error) {\n    return opts.complete(txnResult.error);\n  }\n  txn = txnResult.txn;\n  txn.onabort = idbError(opts.complete);\n  txn.oncomplete = onTxnComplete;\n\n  bySeqStore = txn.objectStore(BY_SEQ_STORE);\n  docStore = txn.objectStore(DOC_STORE);\n  docIdRevIndex = bySeqStore.index('_doc_id_rev');\n\n  var keyRange = (opts.since && !opts.descending) ?\n    IDBKeyRange.lowerBound(opts.since, true) : null;\n\n  runBatchedCursor(bySeqStore, keyRange, opts.descending, limit, onBatch);\n}\n\nvar cachedDBs = new ExportedMap();\nvar blobSupportPromise;\nvar openReqList = new ExportedMap();\n\nfunction IdbPouch(opts, callback) {\n  var api = this;\n\n  enqueueTask(function (thisCallback) {\n    init(api, opts, thisCallback);\n  }, callback, api.constructor);\n}\n\nfunction init(api, opts, callback) {\n\n  var dbName = opts.name;\n\n  var idb = null;\n  api._meta = null;\n\n  // called when creating a fresh new database\n  function createSchema(db) {\n    var docStore = db.createObjectStore(DOC_STORE, {keyPath : 'id'});\n    db.createObjectStore(BY_SEQ_STORE, {autoIncrement: true})\n      .createIndex('_doc_id_rev', '_doc_id_rev', {unique: true});\n    db.createObjectStore(ATTACH_STORE, {keyPath: 'digest'});\n    db.createObjectStore(META_STORE, {keyPath: 'id', autoIncrement: false});\n    db.createObjectStore(DETECT_BLOB_SUPPORT_STORE);\n\n    // added in v2\n    docStore.createIndex('deletedOrLocal', 'deletedOrLocal', {unique : false});\n\n    // added in v3\n    db.createObjectStore(LOCAL_STORE, {keyPath: '_id'});\n\n    // added in v4\n    var attAndSeqStore = db.createObjectStore(ATTACH_AND_SEQ_STORE,\n      {autoIncrement: true});\n    attAndSeqStore.createIndex('seq', 'seq');\n    attAndSeqStore.createIndex('digestSeq', 'digestSeq', {unique: true});\n  }\n\n  // migration to version 2\n  // unfortunately \"deletedOrLocal\" is a misnomer now that we no longer\n  // store local docs in the main doc-store, but whaddyagonnado\n  function addDeletedOrLocalIndex(txn, callback) {\n    var docStore = txn.objectStore(DOC_STORE);\n    docStore.createIndex('deletedOrLocal', 'deletedOrLocal', {unique : false});\n\n    docStore.openCursor().onsuccess = function (event) {\n      var cursor = event.target.result;\n      if (cursor) {\n        var metadata = cursor.value;\n        var deleted = isDeleted(metadata);\n        metadata.deletedOrLocal = deleted ? \"1\" : \"0\";\n        docStore.put(metadata);\n        cursor.continue();\n      } else {\n        callback();\n      }\n    };\n  }\n\n  // migration to version 3 (part 1)\n  function createLocalStoreSchema(db) {\n    db.createObjectStore(LOCAL_STORE, {keyPath: '_id'})\n      .createIndex('_doc_id_rev', '_doc_id_rev', {unique: true});\n  }\n\n  // migration to version 3 (part 2)\n  function migrateLocalStore(txn, cb) {\n    var localStore = txn.objectStore(LOCAL_STORE);\n    var docStore = txn.objectStore(DOC_STORE);\n    var seqStore = txn.objectStore(BY_SEQ_STORE);\n\n    var cursor = docStore.openCursor();\n    cursor.onsuccess = function (event) {\n      var cursor = event.target.result;\n      if (cursor) {\n        var metadata = cursor.value;\n        var docId = metadata.id;\n        var local = isLocalId(docId);\n        var rev = winningRev(metadata);\n        if (local) {\n          var docIdRev = docId + \"::\" + rev;\n          // remove all seq entries\n          // associated with this docId\n          var start = docId + \"::\";\n          var end = docId + \"::~\";\n          var index = seqStore.index('_doc_id_rev');\n          var range = IDBKeyRange.bound(start, end, false, false);\n          var seqCursor = index.openCursor(range);\n          seqCursor.onsuccess = function (e) {\n            seqCursor = e.target.result;\n            if (!seqCursor) {\n              // done\n              docStore.delete(cursor.primaryKey);\n              cursor.continue();\n            } else {\n              var data = seqCursor.value;\n              if (data._doc_id_rev === docIdRev) {\n                localStore.put(data);\n              }\n              seqStore.delete(seqCursor.primaryKey);\n              seqCursor.continue();\n            }\n          };\n        } else {\n          cursor.continue();\n        }\n      } else if (cb) {\n        cb();\n      }\n    };\n  }\n\n  // migration to version 4 (part 1)\n  function addAttachAndSeqStore(db) {\n    var attAndSeqStore = db.createObjectStore(ATTACH_AND_SEQ_STORE,\n      {autoIncrement: true});\n    attAndSeqStore.createIndex('seq', 'seq');\n    attAndSeqStore.createIndex('digestSeq', 'digestSeq', {unique: true});\n  }\n\n  // migration to version 4 (part 2)\n  function migrateAttsAndSeqs(txn, callback) {\n    var seqStore = txn.objectStore(BY_SEQ_STORE);\n    var attStore = txn.objectStore(ATTACH_STORE);\n    var attAndSeqStore = txn.objectStore(ATTACH_AND_SEQ_STORE);\n\n    // need to actually populate the table. this is the expensive part,\n    // so as an optimization, check first that this database even\n    // contains attachments\n    var req = attStore.count();\n    req.onsuccess = function (e) {\n      var count = e.target.result;\n      if (!count) {\n        return callback(); // done\n      }\n\n      seqStore.openCursor().onsuccess = function (e) {\n        var cursor = e.target.result;\n        if (!cursor) {\n          return callback(); // done\n        }\n        var doc = cursor.value;\n        var seq = cursor.primaryKey;\n        var atts = Object.keys(doc._attachments || {});\n        var digestMap = {};\n        for (var j = 0; j < atts.length; j++) {\n          var att = doc._attachments[atts[j]];\n          digestMap[att.digest] = true; // uniq digests, just in case\n        }\n        var digests = Object.keys(digestMap);\n        for (j = 0; j < digests.length; j++) {\n          var digest = digests[j];\n          attAndSeqStore.put({\n            seq: seq,\n            digestSeq: digest + '::' + seq\n          });\n        }\n        cursor.continue();\n      };\n    };\n  }\n\n  // migration to version 5\n  // Instead of relying on on-the-fly migration of metadata,\n  // this brings the doc-store to its modern form:\n  // - metadata.winningrev\n  // - metadata.seq\n  // - stringify the metadata when storing it\n  function migrateMetadata(txn) {\n\n    function decodeMetadataCompat(storedObject) {\n      if (!storedObject.data) {\n        // old format, when we didn't store it stringified\n        storedObject.deleted = storedObject.deletedOrLocal === '1';\n        return storedObject;\n      }\n      return decodeMetadata(storedObject);\n    }\n\n    // ensure that every metadata has a winningRev and seq,\n    // which was previously created on-the-fly but better to migrate\n    var bySeqStore = txn.objectStore(BY_SEQ_STORE);\n    var docStore = txn.objectStore(DOC_STORE);\n    var cursor = docStore.openCursor();\n    cursor.onsuccess = function (e) {\n      var cursor = e.target.result;\n      if (!cursor) {\n        return; // done\n      }\n      var metadata = decodeMetadataCompat(cursor.value);\n\n      metadata.winningRev = metadata.winningRev ||\n        winningRev(metadata);\n\n      function fetchMetadataSeq() {\n        // metadata.seq was added post-3.2.0, so if it's missing,\n        // we need to fetch it manually\n        var start = metadata.id + '::';\n        var end = metadata.id + '::\\uffff';\n        var req = bySeqStore.index('_doc_id_rev').openCursor(\n          IDBKeyRange.bound(start, end));\n\n        var metadataSeq = 0;\n        req.onsuccess = function (e) {\n          var cursor = e.target.result;\n          if (!cursor) {\n            metadata.seq = metadataSeq;\n            return onGetMetadataSeq();\n          }\n          var seq = cursor.primaryKey;\n          if (seq > metadataSeq) {\n            metadataSeq = seq;\n          }\n          cursor.continue();\n        };\n      }\n\n      function onGetMetadataSeq() {\n        var metadataToStore = encodeMetadata(metadata,\n          metadata.winningRev, metadata.deleted);\n\n        var req = docStore.put(metadataToStore);\n        req.onsuccess = function () {\n          cursor.continue();\n        };\n      }\n\n      if (metadata.seq) {\n        return onGetMetadataSeq();\n      }\n\n      fetchMetadataSeq();\n    };\n\n  }\n\n  api.type = function () {\n    return 'idb';\n  };\n\n  api._id = toPromise(function (callback) {\n    callback(null, api._meta.instanceId);\n  });\n\n  api._bulkDocs = function idb_bulkDocs(req, reqOpts, callback) {\n    idbBulkDocs(opts, req, reqOpts, api, idb, callback);\n  };\n\n  // First we look up the metadata in the ids database, then we fetch the\n  // current revision(s) from the by sequence store\n  api._get = function idb_get(id, opts, callback) {\n    var doc;\n    var metadata;\n    var err;\n    var txn = opts.ctx;\n    if (!txn) {\n      var txnResult = openTransactionSafely(idb,\n        [DOC_STORE, BY_SEQ_STORE, ATTACH_STORE], 'readonly');\n      if (txnResult.error) {\n        return callback(txnResult.error);\n      }\n      txn = txnResult.txn;\n    }\n\n    function finish() {\n      callback(err, {doc: doc, metadata: metadata, ctx: txn});\n    }\n\n    txn.objectStore(DOC_STORE).get(id).onsuccess = function (e) {\n      metadata = decodeMetadata(e.target.result);\n      // we can determine the result here if:\n      // 1. there is no such document\n      // 2. the document is deleted and we don't ask about specific rev\n      // When we ask with opts.rev we expect the answer to be either\n      // doc (possibly with _deleted=true) or missing error\n      if (!metadata) {\n        err = createError(MISSING_DOC, 'missing');\n        return finish();\n      }\n\n      var rev;\n      if(!opts.rev) {\n        rev = metadata.winningRev;\n        var deleted = isDeleted(metadata);\n        if (deleted) {\n          err = createError(MISSING_DOC, \"deleted\");\n          return finish();\n        }\n      } else {\n        rev = opts.latest ? latest(opts.rev, metadata) : opts.rev;\n      }\n\n      var objectStore = txn.objectStore(BY_SEQ_STORE);\n      var key = metadata.id + '::' + rev;\n\n      objectStore.index('_doc_id_rev').get(key).onsuccess = function (e) {\n        doc = e.target.result;\n        if (doc) {\n          doc = decodeDoc(doc);\n        }\n        if (!doc) {\n          err = createError(MISSING_DOC, 'missing');\n          return finish();\n        }\n        finish();\n      };\n    };\n  };\n\n  api._getAttachment = function (docId, attachId, attachment, opts, callback) {\n    var txn;\n    if (opts.ctx) {\n      txn = opts.ctx;\n    } else {\n      var txnResult = openTransactionSafely(idb,\n        [DOC_STORE, BY_SEQ_STORE, ATTACH_STORE], 'readonly');\n      if (txnResult.error) {\n        return callback(txnResult.error);\n      }\n      txn = txnResult.txn;\n    }\n    var digest = attachment.digest;\n    var type = attachment.content_type;\n\n    txn.objectStore(ATTACH_STORE).get(digest).onsuccess = function (e) {\n      var body = e.target.result.body;\n      readBlobData(body, type, opts.binary, function (blobData) {\n        callback(null, blobData);\n      });\n    };\n  };\n\n  api._info = function idb_info(callback) {\n    var updateSeq;\n    var docCount;\n\n    var txnResult = openTransactionSafely(idb, [META_STORE, BY_SEQ_STORE], 'readonly');\n    if (txnResult.error) {\n      return callback(txnResult.error);\n    }\n    var txn = txnResult.txn;\n    txn.objectStore(META_STORE).get(META_STORE).onsuccess = function (e) {\n      docCount = e.target.result.docCount;\n    };\n    txn.objectStore(BY_SEQ_STORE).openCursor(null, 'prev').onsuccess = function (e) {\n      var cursor = e.target.result;\n      updateSeq = cursor ? cursor.key : 0;\n    };\n\n    txn.oncomplete = function () {\n      callback(null, {\n        doc_count: docCount,\n        update_seq: updateSeq,\n        // for debugging\n        idb_attachment_format: (api._meta.blobSupport ? 'binary' : 'base64')\n      });\n    };\n  };\n\n  api._allDocs = function idb_allDocs(opts, callback) {\n    idbAllDocs(opts, idb, callback);\n  };\n\n  api._changes = function idbChanges(opts) {\n    changes(opts, api, dbName, idb);\n  };\n\n  api._close = function (callback) {\n    // https://developer.mozilla.org/en-US/docs/IndexedDB/IDBDatabase#close\n    // \"Returns immediately and closes the connection in a separate thread...\"\n    idb.close();\n    cachedDBs.delete(dbName);\n    callback();\n  };\n\n  api._getRevisionTree = function (docId, callback) {\n    var txnResult = openTransactionSafely(idb, [DOC_STORE], 'readonly');\n    if (txnResult.error) {\n      return callback(txnResult.error);\n    }\n    var txn = txnResult.txn;\n    var req = txn.objectStore(DOC_STORE).get(docId);\n    req.onsuccess = function (event) {\n      var doc = decodeMetadata(event.target.result);\n      if (!doc) {\n        callback(createError(MISSING_DOC));\n      } else {\n        callback(null, doc.rev_tree);\n      }\n    };\n  };\n\n  // This function removes revisions of document docId\n  // which are listed in revs and sets this document\n  // revision to to rev_tree\n  api._doCompaction = function (docId, revs, callback) {\n    var stores = [\n      DOC_STORE,\n      BY_SEQ_STORE,\n      ATTACH_STORE,\n      ATTACH_AND_SEQ_STORE\n    ];\n    var txnResult = openTransactionSafely(idb, stores, 'readwrite');\n    if (txnResult.error) {\n      return callback(txnResult.error);\n    }\n    var txn = txnResult.txn;\n\n    var docStore = txn.objectStore(DOC_STORE);\n\n    docStore.get(docId).onsuccess = function (event) {\n      var metadata = decodeMetadata(event.target.result);\n      traverseRevTree(metadata.rev_tree, function (isLeaf, pos,\n                                                         revHash, ctx, opts) {\n        var rev = pos + '-' + revHash;\n        if (revs.indexOf(rev) !== -1) {\n          opts.status = 'missing';\n        }\n      });\n      compactRevs(revs, docId, txn);\n      var winningRev$$1 = metadata.winningRev;\n      var deleted = metadata.deleted;\n      txn.objectStore(DOC_STORE).put(\n        encodeMetadata(metadata, winningRev$$1, deleted));\n    };\n    txn.onabort = idbError(callback);\n    txn.oncomplete = function () {\n      callback();\n    };\n  };\n\n\n  api._getLocal = function (id, callback) {\n    var txnResult = openTransactionSafely(idb, [LOCAL_STORE], 'readonly');\n    if (txnResult.error) {\n      return callback(txnResult.error);\n    }\n    var tx = txnResult.txn;\n    var req = tx.objectStore(LOCAL_STORE).get(id);\n\n    req.onerror = idbError(callback);\n    req.onsuccess = function (e) {\n      var doc = e.target.result;\n      if (!doc) {\n        callback(createError(MISSING_DOC));\n      } else {\n        delete doc['_doc_id_rev']; // for backwards compat\n        callback(null, doc);\n      }\n    };\n  };\n\n  api._putLocal = function (doc, opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    delete doc._revisions; // ignore this, trust the rev\n    var oldRev = doc._rev;\n    var id = doc._id;\n    if (!oldRev) {\n      doc._rev = '0-1';\n    } else {\n      doc._rev = '0-' + (parseInt(oldRev.split('-')[1], 10) + 1);\n    }\n\n    var tx = opts.ctx;\n    var ret;\n    if (!tx) {\n      var txnResult = openTransactionSafely(idb, [LOCAL_STORE], 'readwrite');\n      if (txnResult.error) {\n        return callback(txnResult.error);\n      }\n      tx = txnResult.txn;\n      tx.onerror = idbError(callback);\n      tx.oncomplete = function () {\n        if (ret) {\n          callback(null, ret);\n        }\n      };\n    }\n\n    var oStore = tx.objectStore(LOCAL_STORE);\n    var req;\n    if (oldRev) {\n      req = oStore.get(id);\n      req.onsuccess = function (e) {\n        var oldDoc = e.target.result;\n        if (!oldDoc || oldDoc._rev !== oldRev) {\n          callback(createError(REV_CONFLICT));\n        } else { // update\n          var req = oStore.put(doc);\n          req.onsuccess = function () {\n            ret = {ok: true, id: doc._id, rev: doc._rev};\n            if (opts.ctx) { // return immediately\n              callback(null, ret);\n            }\n          };\n        }\n      };\n    } else { // new doc\n      req = oStore.add(doc);\n      req.onerror = function (e) {\n        // constraint error, already exists\n        callback(createError(REV_CONFLICT));\n        e.preventDefault(); // avoid transaction abort\n        e.stopPropagation(); // avoid transaction onerror\n      };\n      req.onsuccess = function () {\n        ret = {ok: true, id: doc._id, rev: doc._rev};\n        if (opts.ctx) { // return immediately\n          callback(null, ret);\n        }\n      };\n    }\n  };\n\n  api._removeLocal = function (doc, opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    var tx = opts.ctx;\n    if (!tx) {\n      var txnResult = openTransactionSafely(idb, [LOCAL_STORE], 'readwrite');\n      if (txnResult.error) {\n        return callback(txnResult.error);\n      }\n      tx = txnResult.txn;\n      tx.oncomplete = function () {\n        if (ret) {\n          callback(null, ret);\n        }\n      };\n    }\n    var ret;\n    var id = doc._id;\n    var oStore = tx.objectStore(LOCAL_STORE);\n    var req = oStore.get(id);\n\n    req.onerror = idbError(callback);\n    req.onsuccess = function (e) {\n      var oldDoc = e.target.result;\n      if (!oldDoc || oldDoc._rev !== doc._rev) {\n        callback(createError(MISSING_DOC));\n      } else {\n        oStore.delete(id);\n        ret = {ok: true, id: id, rev: '0-0'};\n        if (opts.ctx) { // return immediately\n          callback(null, ret);\n        }\n      }\n    };\n  };\n\n  api._destroy = function (opts, callback) {\n    changesHandler$$1.removeAllListeners(dbName);\n\n    //Close open request for \"dbName\" database to fix ie delay.\n    var openReq = openReqList.get(dbName);\n    if (openReq && openReq.result) {\n      openReq.result.close();\n      cachedDBs.delete(dbName);\n    }\n    var req = indexedDB.deleteDatabase(dbName);\n\n    req.onsuccess = function () {\n      //Remove open request from the list.\n      openReqList.delete(dbName);\n      if (hasLocalStorage() && (dbName in localStorage)) {\n        delete localStorage[dbName];\n      }\n      callback(null, { 'ok': true });\n    };\n\n    req.onerror = idbError(callback);\n  };\n\n  var cached = cachedDBs.get(dbName);\n\n  if (cached) {\n    idb = cached.idb;\n    api._meta = cached.global;\n    return nextTick(function () {\n      callback(null, api);\n    });\n  }\n\n  var req;\n  if (opts.storage) {\n    req = tryStorageOption(dbName, opts.storage);\n  } else {\n    req = indexedDB.open(dbName, ADAPTER_VERSION);\n  }\n\n  openReqList.set(dbName, req);\n\n  req.onupgradeneeded = function (e) {\n    var db = e.target.result;\n    if (e.oldVersion < 1) {\n      return createSchema(db); // new db, initial schema\n    }\n    // do migrations\n\n    var txn = e.currentTarget.transaction;\n    // these migrations have to be done in this function, before\n    // control is returned to the event loop, because IndexedDB\n\n    if (e.oldVersion < 3) {\n      createLocalStoreSchema(db); // v2 -> v3\n    }\n    if (e.oldVersion < 4) {\n      addAttachAndSeqStore(db); // v3 -> v4\n    }\n\n    var migrations = [\n      addDeletedOrLocalIndex, // v1 -> v2\n      migrateLocalStore,      // v2 -> v3\n      migrateAttsAndSeqs,     // v3 -> v4\n      migrateMetadata         // v4 -> v5\n    ];\n\n    var i = e.oldVersion;\n\n    function next() {\n      var migration = migrations[i - 1];\n      i++;\n      if (migration) {\n        migration(txn, next);\n      }\n    }\n\n    next();\n  };\n\n  req.onsuccess = function (e) {\n\n    idb = e.target.result;\n\n    idb.onversionchange = function () {\n      idb.close();\n      cachedDBs.delete(dbName);\n    };\n\n    idb.onabort = function (e) {\n      guardedConsole('error', 'Database has a global failure', e.target.error);\n      idb.close();\n      cachedDBs.delete(dbName);\n    };\n\n    // Do a few setup operations (in parallel as much as possible):\n    // 1. Fetch meta doc\n    // 2. Check blob support\n    // 3. Calculate docCount\n    // 4. Generate an instanceId if necessary\n    // 5. Store docCount and instanceId on meta doc\n\n    var txn = idb.transaction([\n      META_STORE,\n      DETECT_BLOB_SUPPORT_STORE,\n      DOC_STORE\n    ], 'readwrite');\n\n    var storedMetaDoc = false;\n    var metaDoc;\n    var docCount;\n    var blobSupport;\n    var instanceId;\n\n    function completeSetup() {\n      if (typeof blobSupport === 'undefined' || !storedMetaDoc) {\n        return;\n      }\n      api._meta = {\n        name: dbName,\n        instanceId: instanceId,\n        blobSupport: blobSupport\n      };\n\n      cachedDBs.set(dbName, {\n        idb: idb,\n        global: api._meta\n      });\n      callback(null, api);\n    }\n\n    function storeMetaDocIfReady() {\n      if (typeof docCount === 'undefined' || typeof metaDoc === 'undefined') {\n        return;\n      }\n      var instanceKey = dbName + '_id';\n      if (instanceKey in metaDoc) {\n        instanceId = metaDoc[instanceKey];\n      } else {\n        metaDoc[instanceKey] = instanceId = uuid();\n      }\n      metaDoc.docCount = docCount;\n      txn.objectStore(META_STORE).put(metaDoc);\n    }\n\n    //\n    // fetch or generate the instanceId\n    //\n    txn.objectStore(META_STORE).get(META_STORE).onsuccess = function (e) {\n      metaDoc = e.target.result || { id: META_STORE };\n      storeMetaDocIfReady();\n    };\n\n    //\n    // countDocs\n    //\n    countDocs(txn, function (count) {\n      docCount = count;\n      storeMetaDocIfReady();\n    });\n\n    //\n    // check blob support\n    //\n    if (!blobSupportPromise) {\n      // make sure blob support is only checked once\n      blobSupportPromise = checkBlobSupport(txn);\n    }\n\n    blobSupportPromise.then(function (val) {\n      blobSupport = val;\n      completeSetup();\n    });\n\n    // only when the metadata put transaction has completed,\n    // consider the setup done\n    txn.oncomplete = function () {\n      storedMetaDoc = true;\n      completeSetup();\n    };\n  };\n\n  req.onerror = function () {\n    var msg = 'Failed to open indexedDB, are you in private browsing mode?';\n    guardedConsole('error', msg);\n    callback(createError(IDB_ERROR, msg));\n  };\n}\n\nIdbPouch.valid = function () {\n  // Issue #2533, we finally gave up on doing bug\n  // detection instead of browser sniffing. Safari brought us\n  // to our knees.\n  var isSafari = typeof openDatabase !== 'undefined' &&\n    /(Safari|iPhone|iPad|iPod)/.test(navigator.userAgent) &&\n    !/Chrome/.test(navigator.userAgent) &&\n    !/BlackBerry/.test(navigator.platform);\n\n  // some outdated implementations of IDB that appear on Samsung\n  // and HTC Android devices <4.4 are missing IDBKeyRange\n  return !isSafari && typeof indexedDB !== 'undefined' &&\n    typeof IDBKeyRange !== 'undefined';\n};\n\nfunction tryStorageOption(dbName, storage) {\n  try { // option only available in Firefox 26+\n    return indexedDB.open(dbName, {\n      version: ADAPTER_VERSION,\n      storage: storage\n    });\n  } catch(err) {\n      return indexedDB.open(dbName, ADAPTER_VERSION);\n  }\n}\n\nvar IDBPouch = function (PouchDB) {\n  PouchDB.adapter('idb', IdbPouch, true);\n};\n\n//\n// Parsing hex strings. Yeah.\n//\n// So basically we need this because of a bug in WebSQL:\n// https://code.google.com/p/chromium/issues/detail?id=422690\n// https://bugs.webkit.org/show_bug.cgi?id=137637\n//\n// UTF-8 and UTF-16 are provided as separate functions\n// for meager performance improvements\n//\n\nfunction decodeUtf8(str) {\n  return decodeURIComponent(escape(str));\n}\n\nfunction hexToInt(charCode) {\n  // '0'-'9' is 48-57\n  // 'A'-'F' is 65-70\n  // SQLite will only give us uppercase hex\n  return charCode < 65 ? (charCode - 48) : (charCode - 55);\n}\n\n\n// Example:\n// pragma encoding=utf8;\n// select hex('A');\n// returns '41'\nfunction parseHexUtf8(str, start, end) {\n  var result = '';\n  while (start < end) {\n    result += String.fromCharCode(\n      (hexToInt(str.charCodeAt(start++)) << 4) |\n        hexToInt(str.charCodeAt(start++)));\n  }\n  return result;\n}\n\n// Example:\n// pragma encoding=utf16;\n// select hex('A');\n// returns '4100'\n// notice that the 00 comes after the 41 (i.e. it's swizzled)\nfunction parseHexUtf16(str, start, end) {\n  var result = '';\n  while (start < end) {\n    // UTF-16, so swizzle the bytes\n    result += String.fromCharCode(\n      (hexToInt(str.charCodeAt(start + 2)) << 12) |\n        (hexToInt(str.charCodeAt(start + 3)) << 8) |\n        (hexToInt(str.charCodeAt(start)) << 4) |\n        hexToInt(str.charCodeAt(start + 1)));\n    start += 4;\n  }\n  return result;\n}\n\nfunction parseHexString(str, encoding) {\n  if (encoding === 'UTF-8') {\n    return decodeUtf8(parseHexUtf8(str, 0, str.length));\n  } else {\n    return parseHexUtf16(str, 0, str.length);\n  }\n}\n\nfunction quote(str) {\n  return \"'\" + str + \"'\";\n}\n\nvar ADAPTER_VERSION$1 = 7; // used to manage migrations\n\n// The object stores created for each database\n// DOC_STORE stores the document meta data, its revision history and state\nvar DOC_STORE$1 = quote('document-store');\n// BY_SEQ_STORE stores a particular version of a document, keyed by its\n// sequence id\nvar BY_SEQ_STORE$1 = quote('by-sequence');\n// Where we store attachments\nvar ATTACH_STORE$1 = quote('attach-store');\nvar LOCAL_STORE$1 = quote('local-store');\nvar META_STORE$1 = quote('metadata-store');\n// where we store many-to-many relations between attachment\n// digests and seqs\nvar ATTACH_AND_SEQ_STORE$1 = quote('attach-seq-store');\n\n// escapeBlob and unescapeBlob are workarounds for a websql bug:\n// https://code.google.com/p/chromium/issues/detail?id=422690\n// https://bugs.webkit.org/show_bug.cgi?id=137637\n// The goal is to never actually insert the \\u0000 character\n// in the database.\nfunction escapeBlob(str) {\n  return str\n    .replace(/\\u0002/g, '\\u0002\\u0002')\n    .replace(/\\u0001/g, '\\u0001\\u0002')\n    .replace(/\\u0000/g, '\\u0001\\u0001');\n}\n\nfunction unescapeBlob(str) {\n  return str\n    .replace(/\\u0001\\u0001/g, '\\u0000')\n    .replace(/\\u0001\\u0002/g, '\\u0001')\n    .replace(/\\u0002\\u0002/g, '\\u0002');\n}\n\nfunction stringifyDoc(doc) {\n  // don't bother storing the id/rev. it uses lots of space,\n  // in persistent map/reduce especially\n  delete doc._id;\n  delete doc._rev;\n  return JSON.stringify(doc);\n}\n\nfunction unstringifyDoc(doc, id, rev) {\n  doc = JSON.parse(doc);\n  doc._id = id;\n  doc._rev = rev;\n  return doc;\n}\n\n// question mark groups IN queries, e.g. 3 -> '(?,?,?)'\nfunction qMarks(num) {\n  var s = '(';\n  while (num--) {\n    s += '?';\n    if (num) {\n      s += ',';\n    }\n  }\n  return s + ')';\n}\n\nfunction select(selector, table, joiner, where, orderBy) {\n  return 'SELECT ' + selector + ' FROM ' +\n    (typeof table === 'string' ? table : table.join(' JOIN ')) +\n    (joiner ? (' ON ' + joiner) : '') +\n    (where ? (' WHERE ' +\n    (typeof where === 'string' ? where : where.join(' AND '))) : '') +\n    (orderBy ? (' ORDER BY ' + orderBy) : '');\n}\n\nfunction compactRevs$1(revs, docId, tx) {\n\n  if (!revs.length) {\n    return;\n  }\n\n  var numDone = 0;\n  var seqs = [];\n\n  function checkDone() {\n    if (++numDone === revs.length) { // done\n      deleteOrphans();\n    }\n  }\n\n  function deleteOrphans() {\n    // find orphaned attachment digests\n\n    if (!seqs.length) {\n      return;\n    }\n\n    var sql = 'SELECT DISTINCT digest AS digest FROM ' +\n      ATTACH_AND_SEQ_STORE$1 + ' WHERE seq IN ' + qMarks(seqs.length);\n\n    tx.executeSql(sql, seqs, function (tx, res) {\n\n      var digestsToCheck = [];\n      for (var i = 0; i < res.rows.length; i++) {\n        digestsToCheck.push(res.rows.item(i).digest);\n      }\n      if (!digestsToCheck.length) {\n        return;\n      }\n\n      var sql = 'DELETE FROM ' + ATTACH_AND_SEQ_STORE$1 +\n        ' WHERE seq IN (' +\n        seqs.map(function () { return '?'; }).join(',') +\n        ')';\n      tx.executeSql(sql, seqs, function (tx) {\n\n        var sql = 'SELECT digest FROM ' + ATTACH_AND_SEQ_STORE$1 +\n          ' WHERE digest IN (' +\n          digestsToCheck.map(function () { return '?'; }).join(',') +\n          ')';\n        tx.executeSql(sql, digestsToCheck, function (tx, res) {\n          var nonOrphanedDigests = new ExportedSet();\n          for (var i = 0; i < res.rows.length; i++) {\n            nonOrphanedDigests.add(res.rows.item(i).digest);\n          }\n          digestsToCheck.forEach(function (digest) {\n            if (nonOrphanedDigests.has(digest)) {\n              return;\n            }\n            tx.executeSql(\n              'DELETE FROM ' + ATTACH_AND_SEQ_STORE$1 + ' WHERE digest=?',\n              [digest]);\n            tx.executeSql(\n              'DELETE FROM ' + ATTACH_STORE$1 + ' WHERE digest=?', [digest]);\n          });\n        });\n      });\n    });\n  }\n\n  // update by-seq and attach stores in parallel\n  revs.forEach(function (rev) {\n    var sql = 'SELECT seq FROM ' + BY_SEQ_STORE$1 +\n      ' WHERE doc_id=? AND rev=?';\n\n    tx.executeSql(sql, [docId, rev], function (tx, res) {\n      if (!res.rows.length) { // already deleted\n        return checkDone();\n      }\n      var seq = res.rows.item(0).seq;\n      seqs.push(seq);\n\n      tx.executeSql(\n        'DELETE FROM ' + BY_SEQ_STORE$1 + ' WHERE seq=?', [seq], checkDone);\n    });\n  });\n}\n\nfunction websqlError(callback) {\n  return function (event) {\n    guardedConsole('error', 'WebSQL threw an error', event);\n    // event may actually be a SQLError object, so report is as such\n    var errorNameMatch = event && event.constructor.toString()\n        .match(/function ([^\\(]+)/);\n    var errorName = (errorNameMatch && errorNameMatch[1]) || event.type;\n    var errorReason = event.target || event.message;\n    callback(createError(WSQ_ERROR, errorReason, errorName));\n  };\n}\n\nfunction getSize(opts) {\n  if ('size' in opts) {\n    // triggers immediate popup in iOS, fixes #2347\n    // e.g. 5000001 asks for 5 MB, 10000001 asks for 10 MB,\n    return opts.size * 1000000;\n  }\n  // In iOS, doesn't matter as long as it's <= 5000000.\n  // Except that if you request too much, our tests fail\n  // because of the native \"do you accept?\" popup.\n  // In Android <=4.3, this value is actually used as an\n  // honest-to-god ceiling for data, so we need to\n  // set it to a decently high number.\n  var isAndroid = typeof navigator !== 'undefined' &&\n    /Android/.test(navigator.userAgent);\n  return isAndroid ? 5000000 : 1; // in PhantomJS, if you use 0 it will crash\n}\n\nfunction websqlBulkDocs(dbOpts, req, opts, api, db, websqlChanges, callback) {\n  var newEdits = opts.new_edits;\n  var userDocs = req.docs;\n\n  // Parse the docs, give them a sequence number for the result\n  var docInfos = userDocs.map(function (doc) {\n    if (doc._id && isLocalId(doc._id)) {\n      return doc;\n    }\n    var newDoc = parseDoc(doc, newEdits);\n    return newDoc;\n  });\n\n  var docInfoErrors = docInfos.filter(function (docInfo) {\n    return docInfo.error;\n  });\n  if (docInfoErrors.length) {\n    return callback(docInfoErrors[0]);\n  }\n\n  var tx;\n  var results = new Array(docInfos.length);\n  var fetchedDocs = new ExportedMap();\n\n  var preconditionErrored;\n  function complete() {\n    if (preconditionErrored) {\n      return callback(preconditionErrored);\n    }\n    websqlChanges.notify(api._name);\n    callback(null, results);\n  }\n\n  function verifyAttachment(digest, callback) {\n    var sql = 'SELECT count(*) as cnt FROM ' + ATTACH_STORE$1 +\n      ' WHERE digest=?';\n    tx.executeSql(sql, [digest], function (tx, result) {\n      if (result.rows.item(0).cnt === 0) {\n        var err = createError(MISSING_STUB,\n          'unknown stub attachment with digest ' +\n          digest);\n        callback(err);\n      } else {\n        callback();\n      }\n    });\n  }\n\n  function verifyAttachments(finish) {\n    var digests = [];\n    docInfos.forEach(function (docInfo) {\n      if (docInfo.data && docInfo.data._attachments) {\n        Object.keys(docInfo.data._attachments).forEach(function (filename) {\n          var att = docInfo.data._attachments[filename];\n          if (att.stub) {\n            digests.push(att.digest);\n          }\n        });\n      }\n    });\n    if (!digests.length) {\n      return finish();\n    }\n    var numDone = 0;\n    var err;\n\n    function checkDone() {\n      if (++numDone === digests.length) {\n        finish(err);\n      }\n    }\n    digests.forEach(function (digest) {\n      verifyAttachment(digest, function (attErr) {\n        if (attErr && !err) {\n          err = attErr;\n        }\n        checkDone();\n      });\n    });\n  }\n\n  function writeDoc(docInfo, winningRev$$1, winningRevIsDeleted, newRevIsDeleted,\n                    isUpdate, delta, resultsIdx, callback) {\n\n    function finish() {\n      var data = docInfo.data;\n      var deletedInt = newRevIsDeleted ? 1 : 0;\n\n      var id = data._id;\n      var rev = data._rev;\n      var json = stringifyDoc(data);\n      var sql = 'INSERT INTO ' + BY_SEQ_STORE$1 +\n        ' (doc_id, rev, json, deleted) VALUES (?, ?, ?, ?);';\n      var sqlArgs = [id, rev, json, deletedInt];\n\n      // map seqs to attachment digests, which\n      // we will need later during compaction\n      function insertAttachmentMappings(seq, callback) {\n        var attsAdded = 0;\n        var attsToAdd = Object.keys(data._attachments || {});\n\n        if (!attsToAdd.length) {\n          return callback();\n        }\n        function checkDone() {\n          if (++attsAdded === attsToAdd.length) {\n            callback();\n          }\n          return false; // ack handling a constraint error\n        }\n        function add(att) {\n          var sql = 'INSERT INTO ' + ATTACH_AND_SEQ_STORE$1 +\n            ' (digest, seq) VALUES (?,?)';\n          var sqlArgs = [data._attachments[att].digest, seq];\n          tx.executeSql(sql, sqlArgs, checkDone, checkDone);\n          // second callback is for a constaint error, which we ignore\n          // because this docid/rev has already been associated with\n          // the digest (e.g. when new_edits == false)\n        }\n        for (var i = 0; i < attsToAdd.length; i++) {\n          add(attsToAdd[i]); // do in parallel\n        }\n      }\n\n      tx.executeSql(sql, sqlArgs, function (tx, result) {\n        var seq = result.insertId;\n        insertAttachmentMappings(seq, function () {\n          dataWritten(tx, seq);\n        });\n      }, function () {\n        // constraint error, recover by updating instead (see #1638)\n        var fetchSql = select('seq', BY_SEQ_STORE$1, null,\n          'doc_id=? AND rev=?');\n        tx.executeSql(fetchSql, [id, rev], function (tx, res) {\n          var seq = res.rows.item(0).seq;\n          var sql = 'UPDATE ' + BY_SEQ_STORE$1 +\n            ' SET json=?, deleted=? WHERE doc_id=? AND rev=?;';\n          var sqlArgs = [json, deletedInt, id, rev];\n          tx.executeSql(sql, sqlArgs, function (tx) {\n            insertAttachmentMappings(seq, function () {\n              dataWritten(tx, seq);\n            });\n          });\n        });\n        return false; // ack that we've handled the error\n      });\n    }\n\n    function collectResults(attachmentErr) {\n      if (!err) {\n        if (attachmentErr) {\n          err = attachmentErr;\n          callback(err);\n        } else if (recv === attachments.length) {\n          finish();\n        }\n      }\n    }\n\n    var err = null;\n    var recv = 0;\n\n    docInfo.data._id = docInfo.metadata.id;\n    docInfo.data._rev = docInfo.metadata.rev;\n    var attachments = Object.keys(docInfo.data._attachments || {});\n\n\n    if (newRevIsDeleted) {\n      docInfo.data._deleted = true;\n    }\n\n    function attachmentSaved(err) {\n      recv++;\n      collectResults(err);\n    }\n\n    attachments.forEach(function (key) {\n      var att = docInfo.data._attachments[key];\n      if (!att.stub) {\n        var data = att.data;\n        delete att.data;\n        att.revpos = parseInt(winningRev$$1, 10);\n        var digest = att.digest;\n        saveAttachment(digest, data, attachmentSaved);\n      } else {\n        recv++;\n        collectResults();\n      }\n    });\n\n    if (!attachments.length) {\n      finish();\n    }\n\n    function dataWritten(tx, seq) {\n      var id = docInfo.metadata.id;\n\n      var revsToCompact = docInfo.stemmedRevs || [];\n      if (isUpdate && api.auto_compaction) {\n        revsToCompact = compactTree(docInfo.metadata).concat(revsToCompact);\n      }\n      if (revsToCompact.length) {\n        compactRevs$1(revsToCompact, id, tx);\n      }\n\n      docInfo.metadata.seq = seq;\n      var rev = docInfo.metadata.rev;\n      delete docInfo.metadata.rev;\n\n      var sql = isUpdate ?\n      'UPDATE ' + DOC_STORE$1 +\n      ' SET json=?, max_seq=?, winningseq=' +\n      '(SELECT seq FROM ' + BY_SEQ_STORE$1 +\n      ' WHERE doc_id=' + DOC_STORE$1 + '.id AND rev=?) WHERE id=?'\n        : 'INSERT INTO ' + DOC_STORE$1 +\n      ' (id, winningseq, max_seq, json) VALUES (?,?,?,?);';\n      var metadataStr = safeJsonStringify(docInfo.metadata);\n      var params = isUpdate ?\n        [metadataStr, seq, winningRev$$1, id] :\n        [id, seq, seq, metadataStr];\n      tx.executeSql(sql, params, function () {\n        results[resultsIdx] = {\n          ok: true,\n          id: docInfo.metadata.id,\n          rev: rev\n        };\n        fetchedDocs.set(id, docInfo.metadata);\n        callback();\n      });\n    }\n  }\n\n  function websqlProcessDocs() {\n    processDocs(dbOpts.revs_limit, docInfos, api, fetchedDocs, tx,\n                results, writeDoc, opts);\n  }\n\n  function fetchExistingDocs(callback) {\n    if (!docInfos.length) {\n      return callback();\n    }\n\n    var numFetched = 0;\n\n    function checkDone() {\n      if (++numFetched === docInfos.length) {\n        callback();\n      }\n    }\n\n    docInfos.forEach(function (docInfo) {\n      if (docInfo._id && isLocalId(docInfo._id)) {\n        return checkDone(); // skip local docs\n      }\n      var id = docInfo.metadata.id;\n      tx.executeSql('SELECT json FROM ' + DOC_STORE$1 +\n      ' WHERE id = ?', [id], function (tx, result) {\n        if (result.rows.length) {\n          var metadata = safeJsonParse(result.rows.item(0).json);\n          fetchedDocs.set(id, metadata);\n        }\n        checkDone();\n      });\n    });\n  }\n\n  function saveAttachment(digest, data, callback) {\n    var sql = 'SELECT digest FROM ' + ATTACH_STORE$1 + ' WHERE digest=?';\n    tx.executeSql(sql, [digest], function (tx, result) {\n      if (result.rows.length) { // attachment already exists\n        return callback();\n      }\n      // we could just insert before selecting and catch the error,\n      // but my hunch is that it's cheaper not to serialize the blob\n      // from JS to C if we don't have to (TODO: confirm this)\n      sql = 'INSERT INTO ' + ATTACH_STORE$1 +\n      ' (digest, body, escaped) VALUES (?,?,1)';\n      tx.executeSql(sql, [digest, escapeBlob(data)], function () {\n        callback();\n      }, function () {\n        // ignore constaint errors, means it already exists\n        callback();\n        return false; // ack we handled the error\n      });\n    });\n  }\n\n  preprocessAttachments(docInfos, 'binary', function (err) {\n    if (err) {\n      return callback(err);\n    }\n    db.transaction(function (txn) {\n      tx = txn;\n      verifyAttachments(function (err) {\n        if (err) {\n          preconditionErrored = err;\n        } else {\n          fetchExistingDocs(websqlProcessDocs);\n        }\n      });\n    }, websqlError(callback), complete);\n  });\n}\n\nvar cachedDatabases = new ExportedMap();\n\n// openDatabase passed in through opts (e.g. for node-websql)\nfunction openDatabaseWithOpts(opts) {\n  return opts.websql(opts.name, opts.version, opts.description, opts.size);\n}\n\nfunction openDBSafely(opts) {\n  try {\n    return {\n      db: openDatabaseWithOpts(opts)\n    };\n  } catch (err) {\n    return {\n      error: err\n    };\n  }\n}\n\nfunction openDB$1(opts) {\n  var cachedResult = cachedDatabases.get(opts.name);\n  if (!cachedResult) {\n    cachedResult = openDBSafely(opts);\n    cachedDatabases.set(opts.name, cachedResult);\n  }\n  return cachedResult;\n}\n\nvar websqlChanges = new Changes();\n\nfunction fetchAttachmentsIfNecessary$1(doc, opts, api, txn, cb) {\n  var attachments = Object.keys(doc._attachments || {});\n  if (!attachments.length) {\n    return cb && cb();\n  }\n  var numDone = 0;\n\n  function checkDone() {\n    if (++numDone === attachments.length && cb) {\n      cb();\n    }\n  }\n\n  function fetchAttachment(doc, att) {\n    var attObj = doc._attachments[att];\n    var attOpts = {binary: opts.binary, ctx: txn};\n    api._getAttachment(doc._id, att, attObj, attOpts, function (_, data) {\n      doc._attachments[att] = assign$1(\n        pick(attObj, ['digest', 'content_type']),\n        { data: data }\n      );\n      checkDone();\n    });\n  }\n\n  attachments.forEach(function (att) {\n    if (opts.attachments && opts.include_docs) {\n      fetchAttachment(doc, att);\n    } else {\n      doc._attachments[att].stub = true;\n      checkDone();\n    }\n  });\n}\n\nvar POUCH_VERSION = 1;\n\n// these indexes cover the ground for most allDocs queries\nvar BY_SEQ_STORE_DELETED_INDEX_SQL =\n  'CREATE INDEX IF NOT EXISTS \\'by-seq-deleted-idx\\' ON ' +\n  BY_SEQ_STORE$1 + ' (seq, deleted)';\nvar BY_SEQ_STORE_DOC_ID_REV_INDEX_SQL =\n  'CREATE UNIQUE INDEX IF NOT EXISTS \\'by-seq-doc-id-rev\\' ON ' +\n    BY_SEQ_STORE$1 + ' (doc_id, rev)';\nvar DOC_STORE_WINNINGSEQ_INDEX_SQL =\n  'CREATE INDEX IF NOT EXISTS \\'doc-winningseq-idx\\' ON ' +\n  DOC_STORE$1 + ' (winningseq)';\nvar ATTACH_AND_SEQ_STORE_SEQ_INDEX_SQL =\n  'CREATE INDEX IF NOT EXISTS \\'attach-seq-seq-idx\\' ON ' +\n    ATTACH_AND_SEQ_STORE$1 + ' (seq)';\nvar ATTACH_AND_SEQ_STORE_ATTACH_INDEX_SQL =\n  'CREATE UNIQUE INDEX IF NOT EXISTS \\'attach-seq-digest-idx\\' ON ' +\n    ATTACH_AND_SEQ_STORE$1 + ' (digest, seq)';\n\nvar DOC_STORE_AND_BY_SEQ_JOINER = BY_SEQ_STORE$1 +\n  '.seq = ' + DOC_STORE$1 + '.winningseq';\n\nvar SELECT_DOCS = BY_SEQ_STORE$1 + '.seq AS seq, ' +\n  BY_SEQ_STORE$1 + '.deleted AS deleted, ' +\n  BY_SEQ_STORE$1 + '.json AS data, ' +\n  BY_SEQ_STORE$1 + '.rev AS rev, ' +\n  DOC_STORE$1 + '.json AS metadata';\n\nfunction WebSqlPouch$1(opts, callback) {\n  var api = this;\n  var instanceId = null;\n  var size = getSize(opts);\n  var idRequests = [];\n  var encoding;\n\n  api._name = opts.name;\n\n  // extend the options here, because sqlite plugin has a ton of options\n  // and they are constantly changing, so it's more prudent to allow anything\n  var websqlOpts = assign$1({}, opts, {\n    version: POUCH_VERSION,\n    description: opts.name,\n    size: size\n  });\n  var openDBResult = openDB$1(websqlOpts);\n  if (openDBResult.error) {\n    return websqlError(callback)(openDBResult.error);\n  }\n  var db = openDBResult.db;\n  if (typeof db.readTransaction !== 'function') {\n    // doesn't exist in sqlite plugin\n    db.readTransaction = db.transaction;\n  }\n\n  function dbCreated() {\n    // note the db name in case the browser upgrades to idb\n    if (hasLocalStorage()) {\n      window.localStorage['_pouch__websqldb_' + api._name] = true;\n    }\n    callback(null, api);\n  }\n\n  // In this migration, we added the 'deleted' and 'local' columns to the\n  // by-seq and doc store tables.\n  // To preserve existing user data, we re-process all the existing JSON\n  // and add these values.\n  // Called migration2 because it corresponds to adapter version (db_version) #2\n  function runMigration2(tx, callback) {\n    // index used for the join in the allDocs query\n    tx.executeSql(DOC_STORE_WINNINGSEQ_INDEX_SQL);\n\n    tx.executeSql('ALTER TABLE ' + BY_SEQ_STORE$1 +\n      ' ADD COLUMN deleted TINYINT(1) DEFAULT 0', [], function () {\n      tx.executeSql(BY_SEQ_STORE_DELETED_INDEX_SQL);\n      tx.executeSql('ALTER TABLE ' + DOC_STORE$1 +\n        ' ADD COLUMN local TINYINT(1) DEFAULT 0', [], function () {\n        tx.executeSql('CREATE INDEX IF NOT EXISTS \\'doc-store-local-idx\\' ON ' +\n          DOC_STORE$1 + ' (local, id)');\n\n        var sql = 'SELECT ' + DOC_STORE$1 + '.winningseq AS seq, ' + DOC_STORE$1 +\n          '.json AS metadata FROM ' + BY_SEQ_STORE$1 + ' JOIN ' + DOC_STORE$1 +\n          ' ON ' + BY_SEQ_STORE$1 + '.seq = ' + DOC_STORE$1 + '.winningseq';\n\n        tx.executeSql(sql, [], function (tx, result) {\n\n          var deleted = [];\n          var local = [];\n\n          for (var i = 0; i < result.rows.length; i++) {\n            var item = result.rows.item(i);\n            var seq = item.seq;\n            var metadata = JSON.parse(item.metadata);\n            if (isDeleted(metadata)) {\n              deleted.push(seq);\n            }\n            if (isLocalId(metadata.id)) {\n              local.push(metadata.id);\n            }\n          }\n          tx.executeSql('UPDATE ' + DOC_STORE$1 + 'SET local = 1 WHERE id IN ' +\n            qMarks(local.length), local, function () {\n            tx.executeSql('UPDATE ' + BY_SEQ_STORE$1 +\n              ' SET deleted = 1 WHERE seq IN ' +\n              qMarks(deleted.length), deleted, callback);\n          });\n        });\n      });\n    });\n  }\n\n  // in this migration, we make all the local docs unversioned\n  function runMigration3(tx, callback) {\n    var local = 'CREATE TABLE IF NOT EXISTS ' + LOCAL_STORE$1 +\n      ' (id UNIQUE, rev, json)';\n    tx.executeSql(local, [], function () {\n      var sql = 'SELECT ' + DOC_STORE$1 + '.id AS id, ' +\n        BY_SEQ_STORE$1 + '.json AS data ' +\n        'FROM ' + BY_SEQ_STORE$1 + ' JOIN ' +\n        DOC_STORE$1 + ' ON ' + BY_SEQ_STORE$1 + '.seq = ' +\n        DOC_STORE$1 + '.winningseq WHERE local = 1';\n      tx.executeSql(sql, [], function (tx, res) {\n        var rows = [];\n        for (var i = 0; i < res.rows.length; i++) {\n          rows.push(res.rows.item(i));\n        }\n        function doNext() {\n          if (!rows.length) {\n            return callback(tx);\n          }\n          var row = rows.shift();\n          var rev = JSON.parse(row.data)._rev;\n          tx.executeSql('INSERT INTO ' + LOCAL_STORE$1 +\n              ' (id, rev, json) VALUES (?,?,?)',\n              [row.id, rev, row.data], function (tx) {\n            tx.executeSql('DELETE FROM ' + DOC_STORE$1 + ' WHERE id=?',\n                [row.id], function (tx) {\n              tx.executeSql('DELETE FROM ' + BY_SEQ_STORE$1 + ' WHERE seq=?',\n                  [row.seq], function () {\n                doNext();\n              });\n            });\n          });\n        }\n        doNext();\n      });\n    });\n  }\n\n  // in this migration, we remove doc_id_rev and just use rev\n  function runMigration4(tx, callback) {\n\n    function updateRows(rows) {\n      function doNext() {\n        if (!rows.length) {\n          return callback(tx);\n        }\n        var row = rows.shift();\n        var doc_id_rev = parseHexString(row.hex, encoding);\n        var idx = doc_id_rev.lastIndexOf('::');\n        var doc_id = doc_id_rev.substring(0, idx);\n        var rev = doc_id_rev.substring(idx + 2);\n        var sql = 'UPDATE ' + BY_SEQ_STORE$1 +\n          ' SET doc_id=?, rev=? WHERE doc_id_rev=?';\n        tx.executeSql(sql, [doc_id, rev, doc_id_rev], function () {\n          doNext();\n        });\n      }\n      doNext();\n    }\n\n    var sql = 'ALTER TABLE ' + BY_SEQ_STORE$1 + ' ADD COLUMN doc_id';\n    tx.executeSql(sql, [], function (tx) {\n      var sql = 'ALTER TABLE ' + BY_SEQ_STORE$1 + ' ADD COLUMN rev';\n      tx.executeSql(sql, [], function (tx) {\n        tx.executeSql(BY_SEQ_STORE_DOC_ID_REV_INDEX_SQL, [], function (tx) {\n          var sql = 'SELECT hex(doc_id_rev) as hex FROM ' + BY_SEQ_STORE$1;\n          tx.executeSql(sql, [], function (tx, res) {\n            var rows = [];\n            for (var i = 0; i < res.rows.length; i++) {\n              rows.push(res.rows.item(i));\n            }\n            updateRows(rows);\n          });\n        });\n      });\n    });\n  }\n\n  // in this migration, we add the attach_and_seq table\n  // for issue #2818\n  function runMigration5(tx, callback) {\n\n    function migrateAttsAndSeqs(tx) {\n      // need to actually populate the table. this is the expensive part,\n      // so as an optimization, check first that this database even\n      // contains attachments\n      var sql = 'SELECT COUNT(*) AS cnt FROM ' + ATTACH_STORE$1;\n      tx.executeSql(sql, [], function (tx, res) {\n        var count = res.rows.item(0).cnt;\n        if (!count) {\n          return callback(tx);\n        }\n\n        var offset = 0;\n        var pageSize = 10;\n        function nextPage() {\n          var sql = select(\n            SELECT_DOCS + ', ' + DOC_STORE$1 + '.id AS id',\n            [DOC_STORE$1, BY_SEQ_STORE$1],\n            DOC_STORE_AND_BY_SEQ_JOINER,\n            null,\n            DOC_STORE$1 + '.id '\n          );\n          sql += ' LIMIT ' + pageSize + ' OFFSET ' + offset;\n          offset += pageSize;\n          tx.executeSql(sql, [], function (tx, res) {\n            if (!res.rows.length) {\n              return callback(tx);\n            }\n            var digestSeqs = {};\n            function addDigestSeq(digest, seq) {\n              // uniq digest/seq pairs, just in case there are dups\n              var seqs = digestSeqs[digest] = (digestSeqs[digest] || []);\n              if (seqs.indexOf(seq) === -1) {\n                seqs.push(seq);\n              }\n            }\n            for (var i = 0; i < res.rows.length; i++) {\n              var row = res.rows.item(i);\n              var doc = unstringifyDoc(row.data, row.id, row.rev);\n              var atts = Object.keys(doc._attachments || {});\n              for (var j = 0; j < atts.length; j++) {\n                var att = doc._attachments[atts[j]];\n                addDigestSeq(att.digest, row.seq);\n              }\n            }\n            var digestSeqPairs = [];\n            Object.keys(digestSeqs).forEach(function (digest) {\n              var seqs = digestSeqs[digest];\n              seqs.forEach(function (seq) {\n                digestSeqPairs.push([digest, seq]);\n              });\n            });\n            if (!digestSeqPairs.length) {\n              return nextPage();\n            }\n            var numDone = 0;\n            digestSeqPairs.forEach(function (pair) {\n              var sql = 'INSERT INTO ' + ATTACH_AND_SEQ_STORE$1 +\n                ' (digest, seq) VALUES (?,?)';\n              tx.executeSql(sql, pair, function () {\n                if (++numDone === digestSeqPairs.length) {\n                  nextPage();\n                }\n              });\n            });\n          });\n        }\n        nextPage();\n      });\n    }\n\n    var attachAndRev = 'CREATE TABLE IF NOT EXISTS ' +\n      ATTACH_AND_SEQ_STORE$1 + ' (digest, seq INTEGER)';\n    tx.executeSql(attachAndRev, [], function (tx) {\n      tx.executeSql(\n        ATTACH_AND_SEQ_STORE_ATTACH_INDEX_SQL, [], function (tx) {\n          tx.executeSql(\n            ATTACH_AND_SEQ_STORE_SEQ_INDEX_SQL, [],\n            migrateAttsAndSeqs);\n        });\n    });\n  }\n\n  // in this migration, we use escapeBlob() and unescapeBlob()\n  // instead of reading out the binary as HEX, which is slow\n  function runMigration6(tx, callback) {\n    var sql = 'ALTER TABLE ' + ATTACH_STORE$1 +\n      ' ADD COLUMN escaped TINYINT(1) DEFAULT 0';\n    tx.executeSql(sql, [], callback);\n  }\n\n  // issue #3136, in this migration we need a \"latest seq\" as well\n  // as the \"winning seq\" in the doc store\n  function runMigration7(tx, callback) {\n    var sql = 'ALTER TABLE ' + DOC_STORE$1 +\n      ' ADD COLUMN max_seq INTEGER';\n    tx.executeSql(sql, [], function (tx) {\n      var sql = 'UPDATE ' + DOC_STORE$1 + ' SET max_seq=(SELECT MAX(seq) FROM ' +\n        BY_SEQ_STORE$1 + ' WHERE doc_id=id)';\n      tx.executeSql(sql, [], function (tx) {\n        // add unique index after filling, else we'll get a constraint\n        // error when we do the ALTER TABLE\n        var sql =\n          'CREATE UNIQUE INDEX IF NOT EXISTS \\'doc-max-seq-idx\\' ON ' +\n          DOC_STORE$1 + ' (max_seq)';\n        tx.executeSql(sql, [], callback);\n      });\n    });\n  }\n\n  function checkEncoding(tx, cb) {\n    // UTF-8 on chrome/android, UTF-16 on safari < 7.1\n    tx.executeSql('SELECT HEX(\"a\") AS hex', [], function (tx, res) {\n        var hex = res.rows.item(0).hex;\n        encoding = hex.length === 2 ? 'UTF-8' : 'UTF-16';\n        cb();\n      }\n    );\n  }\n\n  function onGetInstanceId() {\n    while (idRequests.length > 0) {\n      var idCallback = idRequests.pop();\n      idCallback(null, instanceId);\n    }\n  }\n\n  function onGetVersion(tx, dbVersion) {\n    if (dbVersion === 0) {\n      // initial schema\n\n      var meta = 'CREATE TABLE IF NOT EXISTS ' + META_STORE$1 +\n        ' (dbid, db_version INTEGER)';\n      var attach = 'CREATE TABLE IF NOT EXISTS ' + ATTACH_STORE$1 +\n        ' (digest UNIQUE, escaped TINYINT(1), body BLOB)';\n      var attachAndRev = 'CREATE TABLE IF NOT EXISTS ' +\n        ATTACH_AND_SEQ_STORE$1 + ' (digest, seq INTEGER)';\n      // TODO: migrate winningseq to INTEGER\n      var doc = 'CREATE TABLE IF NOT EXISTS ' + DOC_STORE$1 +\n        ' (id unique, json, winningseq, max_seq INTEGER UNIQUE)';\n      var seq = 'CREATE TABLE IF NOT EXISTS ' + BY_SEQ_STORE$1 +\n        ' (seq INTEGER NOT NULL PRIMARY KEY AUTOINCREMENT, ' +\n        'json, deleted TINYINT(1), doc_id, rev)';\n      var local = 'CREATE TABLE IF NOT EXISTS ' + LOCAL_STORE$1 +\n        ' (id UNIQUE, rev, json)';\n\n      // creates\n      tx.executeSql(attach);\n      tx.executeSql(local);\n      tx.executeSql(attachAndRev, [], function () {\n        tx.executeSql(ATTACH_AND_SEQ_STORE_SEQ_INDEX_SQL);\n        tx.executeSql(ATTACH_AND_SEQ_STORE_ATTACH_INDEX_SQL);\n      });\n      tx.executeSql(doc, [], function () {\n        tx.executeSql(DOC_STORE_WINNINGSEQ_INDEX_SQL);\n        tx.executeSql(seq, [], function () {\n          tx.executeSql(BY_SEQ_STORE_DELETED_INDEX_SQL);\n          tx.executeSql(BY_SEQ_STORE_DOC_ID_REV_INDEX_SQL);\n          tx.executeSql(meta, [], function () {\n            // mark the db version, and new dbid\n            var initSeq = 'INSERT INTO ' + META_STORE$1 +\n              ' (db_version, dbid) VALUES (?,?)';\n            instanceId = uuid();\n            var initSeqArgs = [ADAPTER_VERSION$1, instanceId];\n            tx.executeSql(initSeq, initSeqArgs, function () {\n              onGetInstanceId();\n            });\n          });\n        });\n      });\n    } else { // version > 0\n\n      var setupDone = function () {\n        var migrated = dbVersion < ADAPTER_VERSION$1;\n        if (migrated) {\n          // update the db version within this transaction\n          tx.executeSql('UPDATE ' + META_STORE$1 + ' SET db_version = ' +\n            ADAPTER_VERSION$1);\n        }\n        // notify db.id() callers\n        var sql = 'SELECT dbid FROM ' + META_STORE$1;\n        tx.executeSql(sql, [], function (tx, result) {\n          instanceId = result.rows.item(0).dbid;\n          onGetInstanceId();\n        });\n      };\n\n      // would love to use promises here, but then websql\n      // ends the transaction early\n      var tasks = [\n        runMigration2,\n        runMigration3,\n        runMigration4,\n        runMigration5,\n        runMigration6,\n        runMigration7,\n        setupDone\n      ];\n\n      // run each migration sequentially\n      var i = dbVersion;\n      var nextMigration = function (tx) {\n        tasks[i - 1](tx, nextMigration);\n        i++;\n      };\n      nextMigration(tx);\n    }\n  }\n\n  function setup() {\n    db.transaction(function (tx) {\n      // first check the encoding\n      checkEncoding(tx, function () {\n        // then get the version\n        fetchVersion(tx);\n      });\n    }, websqlError(callback), dbCreated);\n  }\n\n  function fetchVersion(tx) {\n    var sql = 'SELECT sql FROM sqlite_master WHERE tbl_name = ' + META_STORE$1;\n    tx.executeSql(sql, [], function (tx, result) {\n      if (!result.rows.length) {\n        // database hasn't even been created yet (version 0)\n        onGetVersion(tx, 0);\n      } else if (!/db_version/.test(result.rows.item(0).sql)) {\n        // table was created, but without the new db_version column,\n        // so add it.\n        tx.executeSql('ALTER TABLE ' + META_STORE$1 +\n          ' ADD COLUMN db_version INTEGER', [], function () {\n          // before version 2, this column didn't even exist\n          onGetVersion(tx, 1);\n        });\n      } else { // column exists, we can safely get it\n        tx.executeSql('SELECT db_version FROM ' + META_STORE$1,\n          [], function (tx, result) {\n          var dbVersion = result.rows.item(0).db_version;\n          onGetVersion(tx, dbVersion);\n        });\n      }\n    });\n  }\n\n  setup();\n\n  function getMaxSeq(tx, callback) {\n    var sql = 'SELECT MAX(seq) AS seq FROM ' + BY_SEQ_STORE$1;\n    tx.executeSql(sql, [], function (tx, res) {\n      var updateSeq = res.rows.item(0).seq || 0;\n      callback(updateSeq);\n    });\n  }\n\n  function countDocs(tx, callback) {\n    // count the total rows\n    var sql = select(\n      'COUNT(' + DOC_STORE$1 + '.id) AS \\'num\\'',\n      [DOC_STORE$1, BY_SEQ_STORE$1],\n      DOC_STORE_AND_BY_SEQ_JOINER,\n      BY_SEQ_STORE$1 + '.deleted=0');\n\n    tx.executeSql(sql, [], function (tx, result) {\n      callback(result.rows.item(0).num);\n    });\n  }\n\n  api.type = function () {\n    return 'websql';\n  };\n\n  api._id = toPromise(function (callback) {\n    callback(null, instanceId);\n  });\n\n  api._info = function (callback) {\n    var seq;\n    var docCount;\n    db.readTransaction(function (tx) {\n      getMaxSeq(tx, function (theSeq) {\n        seq = theSeq;\n      });\n      countDocs(tx, function (theDocCount) {\n        docCount = theDocCount;\n      });\n    }, websqlError(callback), function () {\n      callback(null, {\n        doc_count: docCount,\n        update_seq: seq,\n        websql_encoding: encoding\n      });\n    });\n  };\n\n  api._bulkDocs = function (req, reqOpts, callback) {\n    websqlBulkDocs(opts, req, reqOpts, api, db, websqlChanges, callback);\n  };\n\n  function latest$$1(tx, id, rev, callback, finish) {\n    var sql = select(\n        SELECT_DOCS,\n        [DOC_STORE$1, BY_SEQ_STORE$1],\n        DOC_STORE_AND_BY_SEQ_JOINER,\n        DOC_STORE$1 + '.id=?');\n    var sqlArgs = [id];\n\n    tx.executeSql(sql, sqlArgs, function (a, results) {\n      if (!results.rows.length) {\n        var err = createError(MISSING_DOC, 'missing');\n        return finish(err);\n      }\n      var item = results.rows.item(0);\n      var metadata = safeJsonParse(item.metadata);\n      callback(latest(rev, metadata));\n    });\n  }\n\n  api._get = function (id, opts, callback) {\n    var doc;\n    var metadata;\n    var tx = opts.ctx;\n    if (!tx) {\n      return db.readTransaction(function (txn) {\n        api._get(id, assign$1({ctx: txn}, opts), callback);\n      });\n    }\n\n    function finish(err) {\n      callback(err, {doc: doc, metadata: metadata, ctx: tx});\n    }\n\n    var sql;\n    var sqlArgs;\n\n    if(!opts.rev) {\n      sql = select(\n        SELECT_DOCS,\n        [DOC_STORE$1, BY_SEQ_STORE$1],\n        DOC_STORE_AND_BY_SEQ_JOINER,\n        DOC_STORE$1 + '.id=?');\n      sqlArgs = [id];\n    } else if (opts.latest) {\n      latest$$1(tx, id, opts.rev, function (latestRev) {\n        opts.latest = false;\n        opts.rev = latestRev;\n        api._get(id, opts, callback);\n      }, finish);\n      return;\n    } else {\n      sql = select(\n        SELECT_DOCS,\n        [DOC_STORE$1, BY_SEQ_STORE$1],\n        DOC_STORE$1 + '.id=' + BY_SEQ_STORE$1 + '.doc_id',\n        [BY_SEQ_STORE$1 + '.doc_id=?', BY_SEQ_STORE$1 + '.rev=?']);\n      sqlArgs = [id, opts.rev];\n    }\n\n    tx.executeSql(sql, sqlArgs, function (a, results) {\n      if (!results.rows.length) {\n        var missingErr = createError(MISSING_DOC, 'missing');\n        return finish(missingErr);\n      }\n      var item = results.rows.item(0);\n      metadata = safeJsonParse(item.metadata);\n      if (item.deleted && !opts.rev) {\n        var deletedErr = createError(MISSING_DOC, 'deleted');\n        return finish(deletedErr);\n      }\n      doc = unstringifyDoc(item.data, metadata.id, item.rev);\n      finish();\n    });\n  };\n\n  api._allDocs = function (opts, callback) {\n    var results = [];\n    var totalRows;\n\n    var start = 'startkey' in opts ? opts.startkey : false;\n    var end = 'endkey' in opts ? opts.endkey : false;\n    var key = 'key' in opts ? opts.key : false;\n    var descending = 'descending' in opts ? opts.descending : false;\n    var limit = 'limit' in opts ? opts.limit : -1;\n    var offset = 'skip' in opts ? opts.skip : 0;\n    var inclusiveEnd = opts.inclusive_end !== false;\n\n    var sqlArgs = [];\n    var criteria = [];\n\n    if (key !== false) {\n      criteria.push(DOC_STORE$1 + '.id = ?');\n      sqlArgs.push(key);\n    } else if (start !== false || end !== false) {\n      if (start !== false) {\n        criteria.push(DOC_STORE$1 + '.id ' + (descending ? '<=' : '>=') + ' ?');\n        sqlArgs.push(start);\n      }\n      if (end !== false) {\n        var comparator = descending ? '>' : '<';\n        if (inclusiveEnd) {\n          comparator += '=';\n        }\n        criteria.push(DOC_STORE$1 + '.id ' + comparator + ' ?');\n        sqlArgs.push(end);\n      }\n      if (key !== false) {\n        criteria.push(DOC_STORE$1 + '.id = ?');\n        sqlArgs.push(key);\n      }\n    }\n\n    if (opts.deleted !== 'ok') {\n      // report deleted if keys are specified\n      criteria.push(BY_SEQ_STORE$1 + '.deleted = 0');\n    }\n\n    db.readTransaction(function (tx) {\n      // count the docs in parallel to other operations\n      countDocs(tx, function (docCount) {\n        totalRows = docCount;\n      });\n\n      if (limit === 0) {\n        return;\n      }\n\n      // do a single query to fetch the documents\n      var sql = select(\n        SELECT_DOCS,\n        [DOC_STORE$1, BY_SEQ_STORE$1],\n        DOC_STORE_AND_BY_SEQ_JOINER,\n        criteria,\n        DOC_STORE$1 + '.id ' + (descending ? 'DESC' : 'ASC')\n        );\n      sql += ' LIMIT ' + limit + ' OFFSET ' + offset;\n\n      tx.executeSql(sql, sqlArgs, function (tx, result) {\n        for (var i = 0, l = result.rows.length; i < l; i++) {\n          var item = result.rows.item(i);\n          var metadata = safeJsonParse(item.metadata);\n          var id = metadata.id;\n          var data = unstringifyDoc(item.data, id, item.rev);\n          var winningRev$$1 = data._rev;\n          var doc = {\n            id: id,\n            key: id,\n            value: {rev: winningRev$$1}\n          };\n          if (opts.include_docs) {\n            doc.doc = data;\n            doc.doc._rev = winningRev$$1;\n            if (opts.conflicts) {\n              var conflicts = collectConflicts(metadata);\n              if (conflicts.length) {\n                doc.doc._conflicts = conflicts;\n              }\n            }\n            fetchAttachmentsIfNecessary$1(doc.doc, opts, api, tx);\n          }\n          if (item.deleted) {\n            if (opts.deleted === 'ok') {\n              doc.value.deleted = true;\n              doc.doc = null;\n            } else {\n              continue;\n            }\n          }\n          results.push(doc);\n        }\n      });\n    }, websqlError(callback), function () {\n      callback(null, {\n        total_rows: totalRows,\n        offset: opts.skip,\n        rows: results\n      });\n    });\n  };\n\n  api._changes = function (opts) {\n    opts = clone(opts);\n\n    if (opts.continuous) {\n      var id = api._name + ':' + uuid();\n      websqlChanges.addListener(api._name, id, api, opts);\n      websqlChanges.notify(api._name);\n      return {\n        cancel: function () {\n          websqlChanges.removeListener(api._name, id);\n        }\n      };\n    }\n\n    var descending = opts.descending;\n\n    // Ignore the `since` parameter when `descending` is true\n    opts.since = opts.since && !descending ? opts.since : 0;\n\n    var limit = 'limit' in opts ? opts.limit : -1;\n    if (limit === 0) {\n      limit = 1; // per CouchDB _changes spec\n    }\n\n    var returnDocs;\n    if ('return_docs' in opts) {\n      returnDocs = opts.return_docs;\n    } else if ('returnDocs' in opts) {\n      // TODO: Remove 'returnDocs' in favor of 'return_docs' in a future release\n      returnDocs = opts.returnDocs;\n    } else {\n      returnDocs = true;\n    }\n    var results = [];\n    var numResults = 0;\n\n    function fetchChanges() {\n\n      var selectStmt =\n        DOC_STORE$1 + '.json AS metadata, ' +\n        DOC_STORE$1 + '.max_seq AS maxSeq, ' +\n        BY_SEQ_STORE$1 + '.json AS winningDoc, ' +\n        BY_SEQ_STORE$1 + '.rev AS winningRev ';\n\n      var from = DOC_STORE$1 + ' JOIN ' + BY_SEQ_STORE$1;\n\n      var joiner = DOC_STORE$1 + '.id=' + BY_SEQ_STORE$1 + '.doc_id' +\n        ' AND ' + DOC_STORE$1 + '.winningseq=' + BY_SEQ_STORE$1 + '.seq';\n\n      var criteria = ['maxSeq > ?'];\n      var sqlArgs = [opts.since];\n\n      if (opts.doc_ids) {\n        criteria.push(DOC_STORE$1 + '.id IN ' + qMarks(opts.doc_ids.length));\n        sqlArgs = sqlArgs.concat(opts.doc_ids);\n      }\n\n      var orderBy = 'maxSeq ' + (descending ? 'DESC' : 'ASC');\n\n      var sql = select(selectStmt, from, joiner, criteria, orderBy);\n\n      var filter = filterChange(opts);\n      if (!opts.view && !opts.filter) {\n        // we can just limit in the query\n        sql += ' LIMIT ' + limit;\n      }\n\n      var lastSeq = opts.since || 0;\n      db.readTransaction(function (tx) {\n        tx.executeSql(sql, sqlArgs, function (tx, result) {\n          function reportChange(change) {\n            return function () {\n              opts.onChange(change);\n            };\n          }\n          for (var i = 0, l = result.rows.length; i < l; i++) {\n            var item = result.rows.item(i);\n            var metadata = safeJsonParse(item.metadata);\n            lastSeq = item.maxSeq;\n\n            var doc = unstringifyDoc(item.winningDoc, metadata.id,\n              item.winningRev);\n            var change = opts.processChange(doc, metadata, opts);\n            change.seq = item.maxSeq;\n\n            var filtered = filter(change);\n            if (typeof filtered === 'object') {\n              return opts.complete(filtered);\n            }\n\n            if (filtered) {\n              numResults++;\n              if (returnDocs) {\n                results.push(change);\n              }\n              // process the attachment immediately\n              // for the benefit of live listeners\n              if (opts.attachments && opts.include_docs) {\n                fetchAttachmentsIfNecessary$1(doc, opts, api, tx,\n                  reportChange(change));\n              } else {\n                reportChange(change)();\n              }\n            }\n            if (numResults === limit) {\n              break;\n            }\n          }\n        });\n      }, websqlError(opts.complete), function () {\n        if (!opts.continuous) {\n          opts.complete(null, {\n            results: results,\n            last_seq: lastSeq\n          });\n        }\n      });\n    }\n\n    fetchChanges();\n  };\n\n  api._close = function (callback) {\n    //WebSQL databases do not need to be closed\n    callback();\n  };\n\n  api._getAttachment = function (docId, attachId, attachment, opts, callback) {\n    var res;\n    var tx = opts.ctx;\n    var digest = attachment.digest;\n    var type = attachment.content_type;\n    var sql = 'SELECT escaped, ' +\n      'CASE WHEN escaped = 1 THEN body ELSE HEX(body) END AS body FROM ' +\n      ATTACH_STORE$1 + ' WHERE digest=?';\n    tx.executeSql(sql, [digest], function (tx, result) {\n      // websql has a bug where \\u0000 causes early truncation in strings\n      // and blobs. to work around this, we used to use the hex() function,\n      // but that's not performant. after migration 6, we remove \\u0000\n      // and add it back in afterwards\n      var item = result.rows.item(0);\n      var data = item.escaped ? unescapeBlob(item.body) :\n        parseHexString(item.body, encoding);\n      if (opts.binary) {\n        res = binStringToBluffer(data, type);\n      } else {\n        res = thisBtoa(data);\n      }\n      callback(null, res);\n    });\n  };\n\n  api._getRevisionTree = function (docId, callback) {\n    db.readTransaction(function (tx) {\n      var sql = 'SELECT json AS metadata FROM ' + DOC_STORE$1 + ' WHERE id = ?';\n      tx.executeSql(sql, [docId], function (tx, result) {\n        if (!result.rows.length) {\n          callback(createError(MISSING_DOC));\n        } else {\n          var data = safeJsonParse(result.rows.item(0).metadata);\n          callback(null, data.rev_tree);\n        }\n      });\n    });\n  };\n\n  api._doCompaction = function (docId, revs, callback) {\n    if (!revs.length) {\n      return callback();\n    }\n    db.transaction(function (tx) {\n\n      // update doc store\n      var sql = 'SELECT json AS metadata FROM ' + DOC_STORE$1 + ' WHERE id = ?';\n      tx.executeSql(sql, [docId], function (tx, result) {\n        var metadata = safeJsonParse(result.rows.item(0).metadata);\n        traverseRevTree(metadata.rev_tree, function (isLeaf, pos,\n                                                           revHash, ctx, opts) {\n          var rev = pos + '-' + revHash;\n          if (revs.indexOf(rev) !== -1) {\n            opts.status = 'missing';\n          }\n        });\n\n        var sql = 'UPDATE ' + DOC_STORE$1 + ' SET json = ? WHERE id = ?';\n        tx.executeSql(sql, [safeJsonStringify(metadata), docId]);\n      });\n\n      compactRevs$1(revs, docId, tx);\n    }, websqlError(callback), function () {\n      callback();\n    });\n  };\n\n  api._getLocal = function (id, callback) {\n    db.readTransaction(function (tx) {\n      var sql = 'SELECT json, rev FROM ' + LOCAL_STORE$1 + ' WHERE id=?';\n      tx.executeSql(sql, [id], function (tx, res) {\n        if (res.rows.length) {\n          var item = res.rows.item(0);\n          var doc = unstringifyDoc(item.json, id, item.rev);\n          callback(null, doc);\n        } else {\n          callback(createError(MISSING_DOC));\n        }\n      });\n    });\n  };\n\n  api._putLocal = function (doc, opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    delete doc._revisions; // ignore this, trust the rev\n    var oldRev = doc._rev;\n    var id = doc._id;\n    var newRev;\n    if (!oldRev) {\n      newRev = doc._rev = '0-1';\n    } else {\n      newRev = doc._rev = '0-' + (parseInt(oldRev.split('-')[1], 10) + 1);\n    }\n    var json = stringifyDoc(doc);\n\n    var ret;\n    function putLocal(tx) {\n      var sql;\n      var values;\n      if (oldRev) {\n        sql = 'UPDATE ' + LOCAL_STORE$1 + ' SET rev=?, json=? ' +\n          'WHERE id=? AND rev=?';\n        values = [newRev, json, id, oldRev];\n      } else {\n        sql = 'INSERT INTO ' + LOCAL_STORE$1 + ' (id, rev, json) VALUES (?,?,?)';\n        values = [id, newRev, json];\n      }\n      tx.executeSql(sql, values, function (tx, res) {\n        if (res.rowsAffected) {\n          ret = {ok: true, id: id, rev: newRev};\n          if (opts.ctx) { // return immediately\n            callback(null, ret);\n          }\n        } else {\n          callback(createError(REV_CONFLICT));\n        }\n      }, function () {\n        callback(createError(REV_CONFLICT));\n        return false; // ack that we handled the error\n      });\n    }\n\n    if (opts.ctx) {\n      putLocal(opts.ctx);\n    } else {\n      db.transaction(putLocal, websqlError(callback), function () {\n        if (ret) {\n          callback(null, ret);\n        }\n      });\n    }\n  };\n\n  api._removeLocal = function (doc, opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    var ret;\n\n    function removeLocal(tx) {\n      var sql = 'DELETE FROM ' + LOCAL_STORE$1 + ' WHERE id=? AND rev=?';\n      var params = [doc._id, doc._rev];\n      tx.executeSql(sql, params, function (tx, res) {\n        if (!res.rowsAffected) {\n          return callback(createError(MISSING_DOC));\n        }\n        ret = {ok: true, id: doc._id, rev: '0-0'};\n        if (opts.ctx) { // return immediately\n          callback(null, ret);\n        }\n      });\n    }\n\n    if (opts.ctx) {\n      removeLocal(opts.ctx);\n    } else {\n      db.transaction(removeLocal, websqlError(callback), function () {\n        if (ret) {\n          callback(null, ret);\n        }\n      });\n    }\n  };\n\n  api._destroy = function (opts, callback) {\n    websqlChanges.removeAllListeners(api._name);\n    db.transaction(function (tx) {\n      var stores = [DOC_STORE$1, BY_SEQ_STORE$1, ATTACH_STORE$1, META_STORE$1,\n        LOCAL_STORE$1, ATTACH_AND_SEQ_STORE$1];\n      stores.forEach(function (store) {\n        tx.executeSql('DROP TABLE IF EXISTS ' + store, []);\n      });\n    }, websqlError(callback), function () {\n      if (hasLocalStorage()) {\n        delete window.localStorage['_pouch__websqldb_' + api._name];\n        delete window.localStorage[api._name];\n      }\n      callback(null, {'ok': true});\n    });\n  };\n}\n\nfunction canOpenTestDB() {\n  try {\n    openDatabase('_pouch_validate_websql', 1, '', 1);\n    return true;\n  } catch (err) {\n    return false;\n  }\n}\n\n// WKWebView had a bug where WebSQL would throw a DOM Exception 18\n// (see https://bugs.webkit.org/show_bug.cgi?id=137760 and\n// https://github.com/pouchdb/pouchdb/issues/5079)\n// This has been fixed in latest WebKit, so we try to detect it here.\nfunction isValidWebSQL() {\n  // WKWebView UA:\n  //   Mozilla/5.0 (iPhone; CPU iPhone OS 9_2 like Mac OS X)\n  //   AppleWebKit/601.1.46 (KHTML, like Gecko) Mobile/13C75\n  // Chrome for iOS UA:\n  //   Mozilla/5.0 (iPhone; U; CPU iPhone OS 5_1_1 like Mac OS X; en)\n  //   AppleWebKit/534.46.0 (KHTML, like Gecko) CriOS/19.0.1084.60\n  //   Mobile/9B206 Safari/7534.48.3\n  // Firefox for iOS UA:\n  //   Mozilla/5.0 (iPhone; CPU iPhone OS 8_3 like Mac OS X) AppleWebKit/600.1.4\n  //   (KHTML, like Gecko) FxiOS/1.0 Mobile/12F69 Safari/600.1.4\n\n  // indexedDB is null on some UIWebViews and undefined in others\n  // see: https://bugs.webkit.org/show_bug.cgi?id=137034\n  if (typeof indexedDB === 'undefined' || indexedDB === null ||\n      !/iP(hone|od|ad)/.test(navigator.userAgent)) {\n    // definitely not WKWebView, avoid creating an unnecessary database\n    return true;\n  }\n  // Cache the result in LocalStorage. Reason we do this is because if we\n  // call openDatabase() too many times, Safari craps out in SauceLabs and\n  // starts throwing DOM Exception 14s.\n  var hasLS = hasLocalStorage();\n  // Include user agent in the hash, so that if Safari is upgraded, we don't\n  // continually think it's broken.\n  var localStorageKey = '_pouch__websqldb_valid_' + navigator.userAgent;\n  if (hasLS && localStorage[localStorageKey]) {\n    return localStorage[localStorageKey] === '1';\n  }\n  var openedTestDB = canOpenTestDB();\n  if (hasLS) {\n    localStorage[localStorageKey] = openedTestDB ? '1' : '0';\n  }\n  return openedTestDB;\n}\n\nfunction valid() {\n  if (typeof openDatabase !== 'function') {\n    return false;\n  }\n  return isValidWebSQL();\n}\n\nfunction openDB(name, version, description, size) {\n  // Traditional WebSQL API\n  return openDatabase(name, version, description, size);\n}\n\nfunction WebSQLPouch(opts, callback) {\n  var _opts = assign$1({\n    websql: openDB\n  }, opts);\n\n  WebSqlPouch$1.call(this, _opts, callback);\n}\n\nWebSQLPouch.valid = valid;\n\nWebSQLPouch.use_prefix = true;\n\nvar WebSqlPouch = function (PouchDB) {\n  PouchDB.adapter('websql', WebSQLPouch, true);\n};\n\n/* global fetch */\n/* global Headers */\nfunction wrappedFetch() {\n  var wrappedPromise = {};\n\n  var promise = new PouchPromise$1(function (resolve, reject) {\n    wrappedPromise.resolve = resolve;\n    wrappedPromise.reject = reject;\n  });\n\n  var args = new Array(arguments.length);\n\n  for (var i = 0; i < args.length; i++) {\n    args[i] = arguments[i];\n  }\n\n  wrappedPromise.promise = promise;\n\n  PouchPromise$1.resolve().then(function () {\n    return fetch.apply(null, args);\n  }).then(function (response) {\n    wrappedPromise.resolve(response);\n  }).catch(function (error) {\n    wrappedPromise.reject(error);\n  });\n\n  return wrappedPromise;\n}\n\nfunction fetchRequest(options, callback) {\n  var wrappedPromise, timer, response;\n\n  var headers = new Headers();\n\n  var fetchOptions = {\n    method: options.method,\n    credentials: 'include',\n    headers: headers\n  };\n\n  if (options.json) {\n    headers.set('Accept', 'application/json');\n    headers.set('Content-Type', options.headers['Content-Type'] ||\n      'application/json');\n  }\n\n  if (options.body &&\n      options.processData &&\n      typeof options.body !== 'string') {\n    fetchOptions.body = JSON.stringify(options.body);\n  } else if ('body' in options) {\n    fetchOptions.body = options.body;\n  } else {\n    fetchOptions.body = null;\n  }\n\n  Object.keys(options.headers).forEach(function (key) {\n    if (options.headers.hasOwnProperty(key)) {\n      headers.set(key, options.headers[key]);\n    }\n  });\n\n  wrappedPromise = wrappedFetch(options.url, fetchOptions);\n\n  if (options.timeout > 0) {\n    timer = setTimeout(function () {\n      wrappedPromise.reject(new Error('Load timeout for resource: ' +\n        options.url));\n    }, options.timeout);\n  }\n\n  wrappedPromise.promise.then(function (fetchResponse) {\n    response = {\n      statusCode: fetchResponse.status\n    };\n\n    if (options.timeout > 0) {\n      clearTimeout(timer);\n    }\n\n    if (response.statusCode >= 200 && response.statusCode < 300) {\n      return options.binary ? fetchResponse.blob() : fetchResponse.text();\n    }\n\n    return fetchResponse.json();\n  }).then(function (result) {\n    if (response.statusCode >= 200 && response.statusCode < 300) {\n      callback(null, response, result);\n    } else {\n      result.status = response.statusCode;\n      callback(result);\n    }\n  }).catch(function (error) {\n    if (!error) {\n      // this happens when the listener is canceled\n      error = new Error('canceled');\n    }\n    callback(error);\n  });\n\n  return {abort: wrappedPromise.reject};\n}\n\nfunction xhRequest(options, callback) {\n\n  var xhr, timer;\n  var timedout = false;\n\n  var abortReq = function () {\n    xhr.abort();\n    cleanUp();\n  };\n\n  var timeoutReq = function () {\n    timedout = true;\n    xhr.abort();\n    cleanUp();\n  };\n\n  var ret = {abort: abortReq};\n\n  var cleanUp = function () {\n    clearTimeout(timer);\n    ret.abort = function () {};\n    if (xhr) {\n      xhr.onprogress = undefined;\n      if (xhr.upload) {\n        xhr.upload.onprogress = undefined;\n      }\n      xhr.onreadystatechange = undefined;\n      xhr = undefined;\n    }\n  };\n\n  if (options.xhr) {\n    xhr = new options.xhr();\n  } else {\n    xhr = new XMLHttpRequest();\n  }\n\n  try {\n    xhr.open(options.method, options.url);\n  } catch (exception) {\n    return callback(new Error(exception.name || 'Url is invalid'));\n  }\n\n  xhr.withCredentials = ('withCredentials' in options) ?\n    options.withCredentials : true;\n\n  if (options.method === 'GET') {\n    delete options.headers['Content-Type'];\n  } else if (options.json) {\n    options.headers.Accept = 'application/json';\n    options.headers['Content-Type'] = options.headers['Content-Type'] ||\n      'application/json';\n    if (options.body &&\n        options.processData &&\n        typeof options.body !== \"string\") {\n      options.body = JSON.stringify(options.body);\n    }\n  }\n\n  if (options.binary) {\n    xhr.responseType = 'arraybuffer';\n  }\n\n  if (!('body' in options)) {\n    options.body = null;\n  }\n\n  for (var key in options.headers) {\n    if (options.headers.hasOwnProperty(key)) {\n      xhr.setRequestHeader(key, options.headers[key]);\n    }\n  }\n\n  if (options.timeout > 0) {\n    timer = setTimeout(timeoutReq, options.timeout);\n    xhr.onprogress = function () {\n      clearTimeout(timer);\n      if(xhr.readyState !== 4) {\n        timer = setTimeout(timeoutReq, options.timeout);\n      }\n    };\n    if (typeof xhr.upload !== 'undefined') { // does not exist in ie9\n      xhr.upload.onprogress = xhr.onprogress;\n    }\n  }\n\n  xhr.onreadystatechange = function () {\n    if (xhr.readyState !== 4) {\n      return;\n    }\n\n    var response = {\n      statusCode: xhr.status\n    };\n\n    if (xhr.status >= 200 && xhr.status < 300) {\n      var data;\n      if (options.binary) {\n        data = createBlob([xhr.response || ''], {\n          type: xhr.getResponseHeader('Content-Type')\n        });\n      } else {\n        data = xhr.responseText;\n      }\n      callback(null, response, data);\n    } else {\n      var err = {};\n      if (timedout) {\n        err = new Error('ETIMEDOUT');\n        err.code = 'ETIMEDOUT';\n      } else if (typeof xhr.response === 'string') {\n        try {\n          err = JSON.parse(xhr.response);\n        } catch(e) {}\n      }\n      err.status = xhr.status;\n      callback(err);\n    }\n    cleanUp();\n  };\n\n  if (options.body && (options.body instanceof Blob)) {\n    readAsArrayBuffer(options.body, function (arrayBuffer) {\n      xhr.send(arrayBuffer);\n    });\n  } else {\n    xhr.send(options.body);\n  }\n\n  return ret;\n}\n\nfunction testXhr() {\n  try {\n    new XMLHttpRequest();\n    return true;\n  } catch (err) {\n    return false;\n  }\n}\n\nvar hasXhr = testXhr();\n\nfunction ajax$1(options, callback) {\n  if (!false && (hasXhr || options.xhr)) {\n    return xhRequest(options, callback);\n  } else {\n    return fetchRequest(options, callback);\n  }\n}\n\n// the blob already has a type; do nothing\nvar res$2 = function () {};\n\nfunction defaultBody() {\n  return '';\n}\n\nfunction ajaxCore$1(options, callback) {\n\n  options = clone(options);\n\n  var defaultOptions = {\n    method : \"GET\",\n    headers: {},\n    json: true,\n    processData: true,\n    timeout: 10000,\n    cache: false\n  };\n\n  options = assign$1(defaultOptions, options);\n\n  function onSuccess(obj, resp, cb) {\n    if (!options.binary && options.json && typeof obj === 'string') {\n      /* istanbul ignore next */\n      try {\n        obj = JSON.parse(obj);\n      } catch (e) {\n        // Probably a malformed JSON from server\n        return cb(e);\n      }\n    }\n    if (Array.isArray(obj)) {\n      obj = obj.map(function (v) {\n        if (v.error || v.missing) {\n          return generateErrorFromResponse(v);\n        } else {\n          return v;\n        }\n      });\n    }\n    if (options.binary) {\n      res$2(obj, resp);\n    }\n    cb(null, obj, resp);\n  }\n\n  if (options.json) {\n    if (!options.binary) {\n      options.headers.Accept = 'application/json';\n    }\n    options.headers['Content-Type'] = options.headers['Content-Type'] ||\n      'application/json';\n  }\n\n  if (options.binary) {\n    options.encoding = null;\n    options.json = false;\n  }\n\n  if (!options.processData) {\n    options.json = false;\n  }\n\n  return ajax$1(options, function (err, response, body) {\n\n    if (err) {\n      return callback(generateErrorFromResponse(err));\n    }\n\n    var error;\n    var content_type = response.headers && response.headers['content-type'];\n    var data = body || defaultBody();\n\n    // CouchDB doesn't always return the right content-type for JSON data, so\n    // we check for ^{ and }$ (ignoring leading/trailing whitespace)\n    if (!options.binary && (options.json || !options.processData) &&\n        typeof data !== 'object' &&\n        (/json/.test(content_type) ||\n         (/^[\\s]*\\{/.test(data) && /\\}[\\s]*$/.test(data)))) {\n      try {\n        data = JSON.parse(data.toString());\n      } catch (e) {}\n    }\n\n    if (response.statusCode >= 200 && response.statusCode < 300) {\n      onSuccess(data, response, callback);\n    } else {\n      error = generateErrorFromResponse(data);\n      error.status = response.statusCode;\n      callback(error);\n    }\n  });\n}\n\nfunction ajax(opts, callback) {\n\n  // cache-buster, specifically designed to work around IE's aggressive caching\n  // see http://www.dashbay.com/2011/05/internet-explorer-caches-ajax/\n  // Also Safari caches POSTs, so we need to cache-bust those too.\n  var ua = (navigator && navigator.userAgent) ?\n    navigator.userAgent.toLowerCase() : '';\n\n  var isSafari = ua.indexOf('safari') !== -1 && ua.indexOf('chrome') === -1;\n  var isIE = ua.indexOf('msie') !== -1;\n  var isEdge = ua.indexOf('edge') !== -1;\n\n  // it appears the new version of safari also caches GETs,\n  // see https://github.com/pouchdb/pouchdb/issues/5010\n  var shouldCacheBust = (isSafari ||\n    ((isIE || isEdge) && opts.method === 'GET'));\n\n  var cache = 'cache' in opts ? opts.cache : true;\n\n  var isBlobUrl = /^blob:/.test(opts.url); // don't append nonces for blob URLs\n\n  if (!isBlobUrl && (shouldCacheBust || !cache)) {\n    var hasArgs = opts.url.indexOf('?') !== -1;\n    opts.url += (hasArgs ? '&' : '?') + '_nonce=' + Date.now();\n  }\n\n  return ajaxCore$1(opts, callback);\n}\n\n// dead simple promise pool, inspired by https://github.com/timdp/es6-promise-pool\n// but much smaller in code size. limits the number of concurrent promises that are executed\n\nfunction pool(promiseFactories, limit) {\n  return new PouchPromise$1(function (resolve, reject) {\n    var running = 0;\n    var current = 0;\n    var done = 0;\n    var len = promiseFactories.length;\n    var err;\n\n    function runNext() {\n      running++;\n      promiseFactories[current++]().then(onSuccess, onError);\n    }\n\n    function doNext() {\n      if (++done === len) {\n        /* istanbul ignore if */\n        if (err) {\n          reject(err);\n        } else {\n          resolve();\n        }\n      } else {\n        runNextBatch();\n      }\n    }\n\n    function onSuccess() {\n      running--;\n      doNext();\n    }\n\n    /* istanbul ignore next */\n    function onError(thisErr) {\n      running--;\n      err = err || thisErr;\n      doNext();\n    }\n\n    function runNextBatch() {\n      while (running < limit && current < len) {\n        runNext();\n      }\n    }\n\n    runNextBatch();\n  });\n}\n\nvar CHANGES_BATCH_SIZE = 25;\nvar MAX_SIMULTANEOUS_REVS = 50;\n\nvar supportsBulkGetMap = {};\n\nvar log$1 = debug('pouchdb:http');\n\nfunction readAttachmentsAsBlobOrBuffer(row) {\n  var atts = row.doc && row.doc._attachments;\n  if (!atts) {\n    return;\n  }\n  Object.keys(atts).forEach(function (filename) {\n    var att = atts[filename];\n    att.data = b64ToBluffer(att.data, att.content_type);\n  });\n}\n\nfunction encodeDocId(id) {\n  if (/^_design/.test(id)) {\n    return '_design/' + encodeURIComponent(id.slice(8));\n  }\n  if (/^_local/.test(id)) {\n    return '_local/' + encodeURIComponent(id.slice(7));\n  }\n  return encodeURIComponent(id);\n}\n\nfunction preprocessAttachments$2(doc) {\n  if (!doc._attachments || !Object.keys(doc._attachments)) {\n    return PouchPromise$1.resolve();\n  }\n\n  return PouchPromise$1.all(Object.keys(doc._attachments).map(function (key) {\n    var attachment = doc._attachments[key];\n    if (attachment.data && typeof attachment.data !== 'string') {\n      return new PouchPromise$1(function (resolve) {\n        blobToBase64(attachment.data, resolve);\n      }).then(function (b64) {\n        attachment.data = b64;\n      });\n    }\n  }));\n}\n\nfunction hasUrlPrefix(opts) {\n  if (!opts.prefix) {\n    return false;\n  }\n\n  var protocol = parseUri(opts.prefix).protocol;\n\n  return protocol === 'http' || protocol === 'https';\n}\n\n// Get all the information you possibly can about the URI given by name and\n// return it as a suitable object.\nfunction getHost(name, opts) {\n\n  // encode db name if opts.prefix is a url (#5574)\n  if (hasUrlPrefix(opts)) {\n    var dbName = opts.name.substr(opts.prefix.length);\n    name = opts.prefix + encodeURIComponent(dbName);\n  }\n\n  // Prase the URI into all its little bits\n  var uri = parseUri(name);\n\n  // Store the user and password as a separate auth object\n  if (uri.user || uri.password) {\n    uri.auth = {username: uri.user, password: uri.password};\n  }\n\n  // Split the path part of the URI into parts using '/' as the delimiter\n  // after removing any leading '/' and any trailing '/'\n  var parts = uri.path.replace(/(^\\/|\\/$)/g, '').split('/');\n\n  // Store the first part as the database name and remove it from the parts\n  // array\n  uri.db = parts.pop();\n  // Prevent double encoding of URI component\n  if (uri.db.indexOf('%') === -1) {\n    uri.db = encodeURIComponent(uri.db);\n  }\n\n  // Restore the path by joining all the remaining parts (all the parts\n  // except for the database name) with '/'s\n  uri.path = parts.join('/');\n\n  return uri;\n}\n\n// Generate a URL with the host data given by opts and the given path\nfunction genDBUrl(opts, path) {\n  return genUrl(opts, opts.db + '/' + path);\n}\n\n// Generate a URL with the host data given by opts and the given path\nfunction genUrl(opts, path) {\n  // If the host already has a path, then we need to have a path delimiter\n  // Otherwise, the path delimiter is the empty string\n  var pathDel = !opts.path ? '' : '/';\n\n  // If the host already has a path, then we need to have a path delimiter\n  // Otherwise, the path delimiter is the empty string\n  return opts.protocol + '://' + opts.host +\n         (opts.port ? (':' + opts.port) : '') +\n         '/' + opts.path + pathDel + path;\n}\n\nfunction paramsToStr(params) {\n  return '?' + Object.keys(params).map(function (k) {\n    return k + '=' + encodeURIComponent(params[k]);\n  }).join('&');\n}\n\n// Implements the PouchDB API for dealing with CouchDB instances over HTTP\nfunction HttpPouch(opts, callback) {\n\n  // The functions that will be publicly available for HttpPouch\n  var api = this;\n\n  var host = getHost(opts.name, opts);\n  var dbUrl = genDBUrl(host, '');\n\n  opts = clone(opts);\n  var ajaxOpts = opts.ajax || {};\n\n  if (opts.auth || host.auth) {\n    var nAuth = opts.auth || host.auth;\n    var str = nAuth.username + ':' + nAuth.password;\n    var token = thisBtoa(unescape(encodeURIComponent(str)));\n    ajaxOpts.headers = ajaxOpts.headers || {};\n    ajaxOpts.headers.Authorization = 'Basic ' + token;\n  }\n\n  // Not strictly necessary, but we do this because numerous tests\n  // rely on swapping ajax in and out.\n  api._ajax = ajax;\n\n  function ajax$$1(userOpts, options, callback) {\n    var reqAjax = userOpts.ajax || {};\n    var reqOpts = assign$1(clone(ajaxOpts), reqAjax, options);\n    log$1(reqOpts.method + ' ' + reqOpts.url);\n    return api._ajax(reqOpts, callback);\n  }\n\n  function ajaxPromise(userOpts, opts) {\n    return new PouchPromise$1(function (resolve, reject) {\n      ajax$$1(userOpts, opts, function (err, res) {\n        /* istanbul ignore if */\n        if (err) {\n          return reject(err);\n        }\n        resolve(res);\n      });\n    });\n  }\n\n  function adapterFun$$1(name, fun) {\n    return adapterFun(name, getArguments(function (args) {\n      setup().then(function () {\n        return fun.apply(this, args);\n      }).catch(function (e) {\n        var callback = args.pop();\n        callback(e);\n      });\n    }));\n  }\n\n  var setupPromise;\n\n  function setup() {\n    // TODO: Remove `skipSetup` in favor of `skip_setup` in a future release\n    if (opts.skipSetup || opts.skip_setup) {\n      return PouchPromise$1.resolve();\n    }\n\n    // If there is a setup in process or previous successful setup\n    // done then we will use that\n    // If previous setups have been rejected we will try again\n    if (setupPromise) {\n      return setupPromise;\n    }\n\n    var checkExists = {method: 'GET', url: dbUrl};\n    setupPromise = ajaxPromise({}, checkExists).catch(function (err) {\n      if (err && err.status && err.status === 404) {\n        // Doesnt exist, create it\n        explainError(404, 'PouchDB is just detecting if the remote exists.');\n        return ajaxPromise({}, {method: 'PUT', url: dbUrl});\n      } else {\n        return PouchPromise$1.reject(err);\n      }\n    }).catch(function (err) {\n      // If we try to create a database that already exists, skipped in\n      // istanbul since its catching a race condition.\n      /* istanbul ignore if */\n      if (err && err.status && err.status === 412) {\n        return true;\n      }\n      return PouchPromise$1.reject(err);\n    });\n\n    setupPromise.catch(function () {\n      setupPromise = null;\n    });\n\n    return setupPromise;\n  }\n\n  nextTick(function () {\n    callback(null, api);\n  });\n\n  api.type = function () {\n    return 'http';\n  };\n\n  api.id = adapterFun$$1('id', function (callback) {\n    ajax$$1({}, {method: 'GET', url: genUrl(host, '')}, function (err, result) {\n      var uuid$$1 = (result && result.uuid) ?\n        (result.uuid + host.db) : genDBUrl(host, '');\n      callback(null, uuid$$1);\n    });\n  });\n\n  api.request = adapterFun$$1('request', function (options, callback) {\n    options.url = genDBUrl(host, options.url);\n    ajax$$1({}, options, callback);\n  });\n\n  // Sends a POST request to the host calling the couchdb _compact function\n  //    version: The version of CouchDB it is running\n  api.compact = adapterFun$$1('compact', function (opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    opts = clone(opts);\n    ajax$$1(opts, {\n      url: genDBUrl(host, '_compact'),\n      method: 'POST'\n    }, function () {\n      function ping() {\n        api.info(function (err, res) {\n          if (res && !res.compact_running) {\n            callback(null, {ok: true});\n          } else {\n            setTimeout(ping, opts.interval || 200);\n          }\n        });\n      }\n      // Ping the http if it's finished compaction\n      ping();\n    });\n  });\n\n  api.bulkGet = adapterFun('bulkGet', function (opts, callback) {\n    var self = this;\n\n    function doBulkGet(cb) {\n      var params = {};\n      if (opts.revs) {\n        params.revs = true;\n      }\n      if (opts.attachments) {\n        /* istanbul ignore next */\n        params.attachments = true;\n      }\n      if (opts.latest) {\n        params.latest = true;\n      }\n      ajax$$1(opts, {\n        url: genDBUrl(host, '_bulk_get' + paramsToStr(params)),\n        method: 'POST',\n        body: { docs: opts.docs}\n      }, cb);\n    }\n\n    function doBulkGetShim() {\n      // avoid \"url too long error\" by splitting up into multiple requests\n      var batchSize = MAX_SIMULTANEOUS_REVS;\n      var numBatches = Math.ceil(opts.docs.length / batchSize);\n      var numDone = 0;\n      var results = new Array(numBatches);\n\n      function onResult(batchNum) {\n        return function (err, res) {\n          // err is impossible because shim returns a list of errs in that case\n          results[batchNum] = res.results;\n          if (++numDone === numBatches) {\n            callback(null, {results: flatten(results)});\n          }\n        };\n      }\n\n      for (var i = 0; i < numBatches; i++) {\n        var subOpts = pick(opts, ['revs', 'attachments', 'latest']);\n        subOpts.ajax = ajaxOpts;\n        subOpts.docs = opts.docs.slice(i * batchSize,\n          Math.min(opts.docs.length, (i + 1) * batchSize));\n        bulkGet(self, subOpts, onResult(i));\n      }\n    }\n\n    // mark the whole database as either supporting or not supporting _bulk_get\n    var dbUrl = genUrl(host, '');\n    var supportsBulkGet = supportsBulkGetMap[dbUrl];\n\n    if (typeof supportsBulkGet !== 'boolean') {\n      // check if this database supports _bulk_get\n      doBulkGet(function (err, res) {\n        /* istanbul ignore else */\n        if (err) {\n          supportsBulkGetMap[dbUrl] = false;\n          explainError(\n            err.status,\n            'PouchDB is just detecting if the remote ' +\n            'supports the _bulk_get API.'\n          );\n          doBulkGetShim();\n        } else {\n          supportsBulkGetMap[dbUrl] = true;\n          callback(null, res);\n        }\n      });\n    } else if (supportsBulkGet) {\n      /* istanbul ignore next */\n      doBulkGet(callback);\n    } else {\n      doBulkGetShim();\n    }\n  });\n\n  // Calls GET on the host, which gets back a JSON string containing\n  //    couchdb: A welcome string\n  //    version: The version of CouchDB it is running\n  api._info = function (callback) {\n    setup().then(function () {\n      ajax$$1({}, {\n        method: 'GET',\n        url: genDBUrl(host, '')\n      }, function (err, res) {\n        /* istanbul ignore next */\n        if (err) {\n        return callback(err);\n        }\n        res.host = genDBUrl(host, '');\n        callback(null, res);\n      });\n    }).catch(callback);\n  };\n\n  // Get the document with the given id from the database given by host.\n  // The id could be solely the _id in the database, or it may be a\n  // _design/ID or _local/ID path\n  api.get = adapterFun$$1('get', function (id, opts, callback) {\n    // If no options were given, set the callback to the second parameter\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    opts = clone(opts);\n\n    // List of parameters to add to the GET request\n    var params = {};\n\n    if (opts.revs) {\n      params.revs = true;\n    }\n\n    if (opts.revs_info) {\n      params.revs_info = true;\n    }\n\n    if (opts.latest) {\n      params.latest = true;\n    }\n\n    if (opts.open_revs) {\n      if (opts.open_revs !== \"all\") {\n        opts.open_revs = JSON.stringify(opts.open_revs);\n      }\n      params.open_revs = opts.open_revs;\n    }\n\n    if (opts.rev) {\n      params.rev = opts.rev;\n    }\n\n    if (opts.conflicts) {\n      params.conflicts = opts.conflicts;\n    }\n\n    id = encodeDocId(id);\n\n    // Set the options for the ajax call\n    var options = {\n      method: 'GET',\n      url: genDBUrl(host, id + paramsToStr(params))\n    };\n\n    function fetchAttachments(doc) {\n      var atts = doc._attachments;\n      var filenames = atts && Object.keys(atts);\n      if (!atts || !filenames.length) {\n        return;\n      }\n      // we fetch these manually in separate XHRs, because\n      // Sync Gateway would normally send it back as multipart/mixed,\n      // which we cannot parse. Also, this is more efficient than\n      // receiving attachments as base64-encoded strings.\n      function fetch(filename) {\n        var att = atts[filename];\n        var path = encodeDocId(doc._id) + '/' + encodeAttachmentId(filename) +\n          '?rev=' + doc._rev;\n        return ajaxPromise(opts, {\n          method: 'GET',\n          url: genDBUrl(host, path),\n          binary: true\n        }).then(function (blob$$1) {\n          if (opts.binary) {\n            return blob$$1;\n          }\n          return new PouchPromise$1(function (resolve) {\n            blobToBase64(blob$$1, resolve);\n          });\n        }).then(function (data) {\n          delete att.stub;\n          delete att.length;\n          att.data = data;\n        });\n      }\n\n      var promiseFactories = filenames.map(function (filename) {\n        return function () {\n          return fetch(filename);\n        };\n      });\n\n      // This limits the number of parallel xhr requests to 5 any time\n      // to avoid issues with maximum browser request limits\n      return pool(promiseFactories, 5);\n    }\n\n    function fetchAllAttachments(docOrDocs) {\n      if (Array.isArray(docOrDocs)) {\n        return PouchPromise$1.all(docOrDocs.map(function (doc) {\n          if (doc.ok) {\n            return fetchAttachments(doc.ok);\n          }\n        }));\n      }\n      return fetchAttachments(docOrDocs);\n    }\n\n    ajaxPromise(opts, options).then(function (res) {\n      return PouchPromise$1.resolve().then(function () {\n        if (opts.attachments) {\n          return fetchAllAttachments(res);\n        }\n      }).then(function () {\n        callback(null, res);\n      });\n    }).catch(callback);\n  });\n\n  // Delete the document given by doc from the database given by host.\n  api.remove = adapterFun$$1('remove',\n      function (docOrId, optsOrRev, opts, callback) {\n    var doc;\n    if (typeof optsOrRev === 'string') {\n      // id, rev, opts, callback style\n      doc = {\n        _id: docOrId,\n        _rev: optsOrRev\n      };\n      if (typeof opts === 'function') {\n        callback = opts;\n        opts = {};\n      }\n    } else {\n      // doc, opts, callback style\n      doc = docOrId;\n      if (typeof optsOrRev === 'function') {\n        callback = optsOrRev;\n        opts = {};\n      } else {\n        callback = opts;\n        opts = optsOrRev;\n      }\n    }\n\n    var rev = (doc._rev || opts.rev);\n\n    // Delete the document\n    ajax$$1(opts, {\n      method: 'DELETE',\n      url: genDBUrl(host, encodeDocId(doc._id)) + '?rev=' + rev\n    }, callback);\n  });\n\n  function encodeAttachmentId(attachmentId) {\n    return attachmentId.split(\"/\").map(encodeURIComponent).join(\"/\");\n  }\n\n  // Get the attachment\n  api.getAttachment =\n    adapterFun$$1('getAttachment', function (docId, attachmentId, opts,\n                                                callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    var params = opts.rev ? ('?rev=' + opts.rev) : '';\n    var url = genDBUrl(host, encodeDocId(docId)) + '/' +\n      encodeAttachmentId(attachmentId) + params;\n    ajax$$1(opts, {\n      method: 'GET',\n      url: url,\n      binary: true\n    }, callback);\n  });\n\n  // Remove the attachment given by the id and rev\n  api.removeAttachment =\n    adapterFun$$1('removeAttachment', function (docId, attachmentId, rev,\n                                                   callback) {\n\n    var url = genDBUrl(host, encodeDocId(docId) + '/' +\n      encodeAttachmentId(attachmentId)) + '?rev=' + rev;\n\n    ajax$$1({}, {\n      method: 'DELETE',\n      url: url\n    }, callback);\n  });\n\n  // Add the attachment given by blob and its contentType property\n  // to the document with the given id, the revision given by rev, and\n  // add it to the database given by host.\n  api.putAttachment =\n    adapterFun$$1('putAttachment', function (docId, attachmentId, rev, blob$$1,\n                                                type, callback) {\n    if (typeof type === 'function') {\n      callback = type;\n      type = blob$$1;\n      blob$$1 = rev;\n      rev = null;\n    }\n    var id = encodeDocId(docId) + '/' + encodeAttachmentId(attachmentId);\n    var url = genDBUrl(host, id);\n    if (rev) {\n      url += '?rev=' + rev;\n    }\n\n    if (typeof blob$$1 === 'string') {\n      // input is assumed to be a base64 string\n      var binary;\n      try {\n        binary = thisAtob(blob$$1);\n      } catch (err) {\n        return callback(createError(BAD_ARG,\n                        'Attachment is not a valid base64 string'));\n      }\n      blob$$1 = binary ? binStringToBluffer(binary, type) : '';\n    }\n\n    var opts = {\n      headers: {'Content-Type': type},\n      method: 'PUT',\n      url: url,\n      processData: false,\n      body: blob$$1,\n      timeout: ajaxOpts.timeout || 60000\n    };\n    // Add the attachment\n    ajax$$1({}, opts, callback);\n  });\n\n  // Update/create multiple documents given by req in the database\n  // given by host.\n  api._bulkDocs = function (req, opts, callback) {\n    // If new_edits=false then it prevents the database from creating\n    // new revision numbers for the documents. Instead it just uses\n    // the old ones. This is used in database replication.\n    req.new_edits = opts.new_edits;\n\n    setup().then(function () {\n      return PouchPromise$1.all(req.docs.map(preprocessAttachments$2));\n    }).then(function () {\n      // Update/create the documents\n      ajax$$1(opts, {\n        method: 'POST',\n        url: genDBUrl(host, '_bulk_docs'),\n        timeout: opts.timeout,\n        body: req\n      }, function (err, results) {\n        if (err) {\n          return callback(err);\n        }\n        results.forEach(function (result) {\n          result.ok = true; // smooths out cloudant not adding this\n        });\n        callback(null, results);\n      });\n    }).catch(callback);\n  };\n\n\n  // Update/create document\n  api._put = function (doc, opts, callback) {\n    setup().then(function () {\n      return preprocessAttachments$2(doc);\n    }).then(function () {\n      // Update/create the document\n      ajax$$1(opts, {\n        method: 'PUT',\n        url: genDBUrl(host, encodeDocId(doc._id)),\n        body: doc\n      }, function (err, result) {\n        if (err) {\n          return callback(err);\n        }\n        callback(null, result);\n      });\n    }).catch(callback);\n  };\n\n\n  // Get a listing of the documents in the database given\n  // by host and ordered by increasing id.\n  api.allDocs = adapterFun$$1('allDocs', function (opts, callback) {\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n    opts = clone(opts);\n\n    // List of parameters to add to the GET request\n    var params = {};\n    var body;\n    var method = 'GET';\n\n    if (opts.conflicts) {\n      params.conflicts = true;\n    }\n\n    if (opts.descending) {\n      params.descending = true;\n    }\n\n    if (opts.include_docs) {\n      params.include_docs = true;\n    }\n\n    // added in CouchDB 1.6.0\n    if (opts.attachments) {\n      params.attachments = true;\n    }\n\n    if (opts.key) {\n      params.key = JSON.stringify(opts.key);\n    }\n\n    if (opts.start_key) {\n      opts.startkey = opts.start_key;\n    }\n\n    if (opts.startkey) {\n      params.startkey = JSON.stringify(opts.startkey);\n    }\n\n    if (opts.end_key) {\n      opts.endkey = opts.end_key;\n    }\n\n    if (opts.endkey) {\n      params.endkey = JSON.stringify(opts.endkey);\n    }\n\n    if (typeof opts.inclusive_end !== 'undefined') {\n      params.inclusive_end = !!opts.inclusive_end;\n    }\n\n    if (typeof opts.limit !== 'undefined') {\n      params.limit = opts.limit;\n    }\n\n    if (typeof opts.skip !== 'undefined') {\n      params.skip = opts.skip;\n    }\n\n    var paramStr = paramsToStr(params);\n\n    if (typeof opts.keys !== 'undefined') {\n      method = 'POST';\n      body = {keys: opts.keys};\n    }\n\n    // Get the document listing\n    ajaxPromise(opts, {\n      method: method,\n      url: genDBUrl(host, '_all_docs' + paramStr),\n      body: body\n    }).then(function (res) {\n      if (opts.include_docs && opts.attachments && opts.binary) {\n        res.rows.forEach(readAttachmentsAsBlobOrBuffer);\n      }\n      callback(null, res);\n    }).catch(callback);\n  });\n\n  // Get a list of changes made to documents in the database given by host.\n  // TODO According to the README, there should be two other methods here,\n  // api.changes.addListener and api.changes.removeListener.\n  api._changes = function (opts) {\n\n    // We internally page the results of a changes request, this means\n    // if there is a large set of changes to be returned we can start\n    // processing them quicker instead of waiting on the entire\n    // set of changes to return and attempting to process them at once\n    var batchSize = 'batch_size' in opts ? opts.batch_size : CHANGES_BATCH_SIZE;\n\n    opts = clone(opts);\n    opts.timeout = ('timeout' in opts) ? opts.timeout :\n      ('timeout' in ajaxOpts) ? ajaxOpts.timeout :\n      30 * 1000;\n\n    // We give a 5 second buffer for CouchDB changes to respond with\n    // an ok timeout (if a timeout it set)\n    var params = opts.timeout ? {timeout: opts.timeout - (5 * 1000)} : {};\n    var limit = (typeof opts.limit !== 'undefined') ? opts.limit : false;\n    var returnDocs;\n    if ('return_docs' in opts) {\n      returnDocs = opts.return_docs;\n    } else if ('returnDocs' in opts) {\n      // TODO: Remove 'returnDocs' in favor of 'return_docs' in a future release\n      returnDocs = opts.returnDocs;\n    } else {\n      returnDocs = true;\n    }\n    //\n    var leftToFetch = limit;\n\n    if (opts.style) {\n      params.style = opts.style;\n    }\n\n    if (opts.include_docs || opts.filter && typeof opts.filter === 'function') {\n      params.include_docs = true;\n    }\n\n    if (opts.attachments) {\n      params.attachments = true;\n    }\n\n    if (opts.continuous) {\n      params.feed = 'longpoll';\n    }\n\n    if (opts.conflicts) {\n      params.conflicts = true;\n    }\n\n    if (opts.descending) {\n      params.descending = true;\n    }\n\n    if ('heartbeat' in opts) {\n      // If the heartbeat value is false, it disables the default heartbeat\n      if (opts.heartbeat) {\n        params.heartbeat = opts.heartbeat;\n      }\n    } else if (opts.continuous) {\n      // Default heartbeat to 10 seconds\n      params.heartbeat = 10000;\n    }\n\n    if (opts.filter && typeof opts.filter === 'string') {\n      params.filter = opts.filter;\n    }\n\n    if (opts.view && typeof opts.view === 'string') {\n      params.filter = '_view';\n      params.view = opts.view;\n    }\n\n    // If opts.query_params exists, pass it through to the changes request.\n    // These parameters may be used by the filter on the source database.\n    if (opts.query_params && typeof opts.query_params === 'object') {\n      for (var param_name in opts.query_params) {\n        /* istanbul ignore else */\n        if (opts.query_params.hasOwnProperty(param_name)) {\n          params[param_name] = opts.query_params[param_name];\n        }\n      }\n    }\n\n    var method = 'GET';\n    var body;\n\n    if (opts.doc_ids) {\n      // set this automagically for the user; it's annoying that couchdb\n      // requires both a \"filter\" and a \"doc_ids\" param.\n      params.filter = '_doc_ids';\n      method = 'POST';\n      body = {doc_ids: opts.doc_ids };\n    }\n\n    var xhr;\n    var lastFetchedSeq;\n\n    // Get all the changes starting wtih the one immediately after the\n    // sequence number given by since.\n    var fetch = function (since, callback) {\n      if (opts.aborted) {\n        return;\n      }\n      params.since = since;\n      // \"since\" can be any kind of json object in Coudant/CouchDB 2.x\n      /* istanbul ignore next */\n      if (typeof params.since === \"object\") {\n        params.since = JSON.stringify(params.since);\n      }\n\n      if (opts.descending) {\n        if (limit) {\n          params.limit = leftToFetch;\n        }\n      } else {\n        params.limit = (!limit || leftToFetch > batchSize) ?\n          batchSize : leftToFetch;\n      }\n\n      // Set the options for the ajax call\n      var xhrOpts = {\n        method: method,\n        url: genDBUrl(host, '_changes' + paramsToStr(params)),\n        timeout: opts.timeout,\n        body: body\n      };\n      lastFetchedSeq = since;\n\n      /* istanbul ignore if */\n      if (opts.aborted) {\n        return;\n      }\n\n      // Get the changes\n      setup().then(function () {\n        xhr = ajax$$1(opts, xhrOpts, callback);\n      }).catch(callback);\n    };\n\n    // If opts.since exists, get all the changes from the sequence\n    // number given by opts.since. Otherwise, get all the changes\n    // from the sequence number 0.\n    var results = {results: []};\n\n    var fetched = function (err, res) {\n      if (opts.aborted) {\n        return;\n      }\n      var raw_results_length = 0;\n      // If the result of the ajax call (res) contains changes (res.results)\n      if (res && res.results) {\n        raw_results_length = res.results.length;\n        results.last_seq = res.last_seq;\n        // For each change\n        var req = {};\n        req.query = opts.query_params;\n        res.results = res.results.filter(function (c) {\n          leftToFetch--;\n          var ret = filterChange(opts)(c);\n          if (ret) {\n            if (opts.include_docs && opts.attachments && opts.binary) {\n              readAttachmentsAsBlobOrBuffer(c);\n            }\n            if (returnDocs) {\n              results.results.push(c);\n            }\n            opts.onChange(c);\n          }\n          return ret;\n        });\n      } else if (err) {\n        // In case of an error, stop listening for changes and call\n        // opts.complete\n        opts.aborted = true;\n        opts.complete(err);\n        return;\n      }\n\n      // The changes feed may have timed out with no results\n      // if so reuse last update sequence\n      if (res && res.last_seq) {\n        lastFetchedSeq = res.last_seq;\n      }\n\n      var finished = (limit && leftToFetch <= 0) ||\n        (res && raw_results_length < batchSize) ||\n        (opts.descending);\n\n      if ((opts.continuous && !(limit && leftToFetch <= 0)) || !finished) {\n        // Queue a call to fetch again with the newest sequence number\n        nextTick(function () { fetch(lastFetchedSeq, fetched); });\n      } else {\n        // We're done, call the callback\n        opts.complete(null, results);\n      }\n    };\n\n    fetch(opts.since || 0, fetched);\n\n    // Return a method to cancel this method from processing any more\n    return {\n      cancel: function () {\n        opts.aborted = true;\n        if (xhr) {\n          xhr.abort();\n        }\n      }\n    };\n  };\n\n  // Given a set of document/revision IDs (given by req), tets the subset of\n  // those that do NOT correspond to revisions stored in the database.\n  // See http://wiki.apache.org/couchdb/HttpPostRevsDiff\n  api.revsDiff = adapterFun$$1('revsDiff', function (req, opts, callback) {\n    // If no options were given, set the callback to be the second parameter\n    if (typeof opts === 'function') {\n      callback = opts;\n      opts = {};\n    }\n\n    // Get the missing document/revision IDs\n    ajax$$1(opts, {\n      method: 'POST',\n      url: genDBUrl(host, '_revs_diff'),\n      body: req\n    }, callback);\n  });\n\n  api._close = function (callback) {\n    callback();\n  };\n\n  api._destroy = function (options, callback) {\n    ajax$$1(options, {\n      url: genDBUrl(host, ''),\n      method: 'DELETE'\n    }, function (err, resp) {\n      if (err && err.status && err.status !== 404) {\n        return callback(err);\n      }\n      callback(null, resp);\n    });\n  };\n}\n\n// HttpPouch is a valid adapter.\nHttpPouch.valid = function () {\n  return true;\n};\n\nvar HttpPouch$1 = function (PouchDB) {\n  PouchDB.adapter('http', HttpPouch, false);\n  PouchDB.adapter('https', HttpPouch, false);\n};\n\nfunction pad(str, padWith, upToLength) {\n  var padding = '';\n  var targetLength = upToLength - str.length;\n  /* istanbul ignore next */\n  while (padding.length < targetLength) {\n    padding += padWith;\n  }\n  return padding;\n}\n\nfunction padLeft(str, padWith, upToLength) {\n  var padding = pad(str, padWith, upToLength);\n  return padding + str;\n}\n\nvar MIN_MAGNITUDE = -324; // verified by -Number.MIN_VALUE\nvar MAGNITUDE_DIGITS = 3; // ditto\nvar SEP = ''; // set to '_' for easier debugging \n\nfunction collate(a, b) {\n\n  if (a === b) {\n    return 0;\n  }\n\n  a = normalizeKey(a);\n  b = normalizeKey(b);\n\n  var ai = collationIndex(a);\n  var bi = collationIndex(b);\n  if ((ai - bi) !== 0) {\n    return ai - bi;\n  }\n  switch (typeof a) {\n    case 'number':\n      return a - b;\n    case 'boolean':\n      return a < b ? -1 : 1;\n    case 'string':\n      return stringCollate(a, b);\n  }\n  return Array.isArray(a) ? arrayCollate(a, b) : objectCollate(a, b);\n}\n\n// couch considers null/NaN/Infinity/-Infinity === undefined,\n// for the purposes of mapreduce indexes. also, dates get stringified.\nfunction normalizeKey(key) {\n  switch (typeof key) {\n    case 'undefined':\n      return null;\n    case 'number':\n      if (key === Infinity || key === -Infinity || isNaN(key)) {\n        return null;\n      }\n      return key;\n    case 'object':\n      var origKey = key;\n      if (Array.isArray(key)) {\n        var len = key.length;\n        key = new Array(len);\n        for (var i = 0; i < len; i++) {\n          key[i] = normalizeKey(origKey[i]);\n        }\n      /* istanbul ignore next */\n      } else if (key instanceof Date) {\n        return key.toJSON();\n      } else if (key !== null) { // generic object\n        key = {};\n        for (var k in origKey) {\n          if (origKey.hasOwnProperty(k)) {\n            var val = origKey[k];\n            if (typeof val !== 'undefined') {\n              key[k] = normalizeKey(val);\n            }\n          }\n        }\n      }\n  }\n  return key;\n}\n\nfunction indexify(key) {\n  if (key !== null) {\n    switch (typeof key) {\n      case 'boolean':\n        return key ? 1 : 0;\n      case 'number':\n        return numToIndexableString(key);\n      case 'string':\n        // We've to be sure that key does not contain \\u0000\n        // Do order-preserving replacements:\n        // 0 -> 1, 1\n        // 1 -> 1, 2\n        // 2 -> 2, 2\n        return key\n          .replace(/\\u0002/g, '\\u0002\\u0002')\n          .replace(/\\u0001/g, '\\u0001\\u0002')\n          .replace(/\\u0000/g, '\\u0001\\u0001');\n      case 'object':\n        var isArray = Array.isArray(key);\n        var arr = isArray ? key : Object.keys(key);\n        var i = -1;\n        var len = arr.length;\n        var result = '';\n        if (isArray) {\n          while (++i < len) {\n            result += toIndexableString(arr[i]);\n          }\n        } else {\n          while (++i < len) {\n            var objKey = arr[i];\n            result += toIndexableString(objKey) +\n                toIndexableString(key[objKey]);\n          }\n        }\n        return result;\n    }\n  }\n  return '';\n}\n\n// convert the given key to a string that would be appropriate\n// for lexical sorting, e.g. within a database, where the\n// sorting is the same given by the collate() function.\nfunction toIndexableString(key) {\n  var zero = '\\u0000';\n  key = normalizeKey(key);\n  return collationIndex(key) + SEP + indexify(key) + zero;\n}\n\nfunction parseNumber(str, i) {\n  var originalIdx = i;\n  var num;\n  var zero = str[i] === '1';\n  if (zero) {\n    num = 0;\n    i++;\n  } else {\n    var neg = str[i] === '0';\n    i++;\n    var numAsString = '';\n    var magAsString = str.substring(i, i + MAGNITUDE_DIGITS);\n    var magnitude = parseInt(magAsString, 10) + MIN_MAGNITUDE;\n    /* istanbul ignore next */\n    if (neg) {\n      magnitude = -magnitude;\n    }\n    i += MAGNITUDE_DIGITS;\n    while (true) {\n      var ch = str[i];\n      if (ch === '\\u0000') {\n        break;\n      } else {\n        numAsString += ch;\n      }\n      i++;\n    }\n    numAsString = numAsString.split('.');\n    if (numAsString.length === 1) {\n      num = parseInt(numAsString, 10);\n    } else {\n      /* istanbul ignore next */\n      num = parseFloat(numAsString[0] + '.' + numAsString[1]);\n    }\n    /* istanbul ignore next */\n    if (neg) {\n      num = num - 10;\n    }\n    /* istanbul ignore next */\n    if (magnitude !== 0) {\n      // parseFloat is more reliable than pow due to rounding errors\n      // e.g. Number.MAX_VALUE would return Infinity if we did\n      // num * Math.pow(10, magnitude);\n      num = parseFloat(num + 'e' + magnitude);\n    }\n  }\n  return {num: num, length : i - originalIdx};\n}\n\n// move up the stack while parsing\n// this function moved outside of parseIndexableString for performance\nfunction pop(stack, metaStack) {\n  var obj = stack.pop();\n\n  if (metaStack.length) {\n    var lastMetaElement = metaStack[metaStack.length - 1];\n    if (obj === lastMetaElement.element) {\n      // popping a meta-element, e.g. an object whose value is another object\n      metaStack.pop();\n      lastMetaElement = metaStack[metaStack.length - 1];\n    }\n    var element = lastMetaElement.element;\n    var lastElementIndex = lastMetaElement.index;\n    if (Array.isArray(element)) {\n      element.push(obj);\n    } else if (lastElementIndex === stack.length - 2) { // obj with key+value\n      var key = stack.pop();\n      element[key] = obj;\n    } else {\n      stack.push(obj); // obj with key only\n    }\n  }\n}\n\nfunction parseIndexableString(str) {\n  var stack = [];\n  var metaStack = []; // stack for arrays and objects\n  var i = 0;\n\n  /*eslint no-constant-condition: [\"error\", { \"checkLoops\": false }]*/\n  while (true) {\n    var collationIndex = str[i++];\n    if (collationIndex === '\\u0000') {\n      if (stack.length === 1) {\n        return stack.pop();\n      } else {\n        pop(stack, metaStack);\n        continue;\n      }\n    }\n    switch (collationIndex) {\n      case '1':\n        stack.push(null);\n        break;\n      case '2':\n        stack.push(str[i] === '1');\n        i++;\n        break;\n      case '3':\n        var parsedNum = parseNumber(str, i);\n        stack.push(parsedNum.num);\n        i += parsedNum.length;\n        break;\n      case '4':\n        var parsedStr = '';\n        /*eslint no-constant-condition: [\"error\", { \"checkLoops\": false }]*/\n        while (true) {\n          var ch = str[i];\n          if (ch === '\\u0000') {\n            break;\n          }\n          parsedStr += ch;\n          i++;\n        }\n        // perform the reverse of the order-preserving replacement\n        // algorithm (see above)\n        parsedStr = parsedStr.replace(/\\u0001\\u0001/g, '\\u0000')\n          .replace(/\\u0001\\u0002/g, '\\u0001')\n          .replace(/\\u0002\\u0002/g, '\\u0002');\n        stack.push(parsedStr);\n        break;\n      case '5':\n        var arrayElement = { element: [], index: stack.length };\n        stack.push(arrayElement.element);\n        metaStack.push(arrayElement);\n        break;\n      case '6':\n        var objElement = { element: {}, index: stack.length };\n        stack.push(objElement.element);\n        metaStack.push(objElement);\n        break;\n      /* istanbul ignore next */\n      default:\n        throw new Error(\n          'bad collationIndex or unexpectedly reached end of input: ' +\n            collationIndex);\n    }\n  }\n}\n\nfunction arrayCollate(a, b) {\n  var len = Math.min(a.length, b.length);\n  for (var i = 0; i < len; i++) {\n    var sort = collate(a[i], b[i]);\n    if (sort !== 0) {\n      return sort;\n    }\n  }\n  return (a.length === b.length) ? 0 :\n    (a.length > b.length) ? 1 : -1;\n}\nfunction stringCollate(a, b) {\n  // See: https://github.com/daleharvey/pouchdb/issues/40\n  // This is incompatible with the CouchDB implementation, but its the\n  // best we can do for now\n  return (a === b) ? 0 : ((a > b) ? 1 : -1);\n}\nfunction objectCollate(a, b) {\n  var ak = Object.keys(a), bk = Object.keys(b);\n  var len = Math.min(ak.length, bk.length);\n  for (var i = 0; i < len; i++) {\n    // First sort the keys\n    var sort = collate(ak[i], bk[i]);\n    if (sort !== 0) {\n      return sort;\n    }\n    // if the keys are equal sort the values\n    sort = collate(a[ak[i]], b[bk[i]]);\n    if (sort !== 0) {\n      return sort;\n    }\n\n  }\n  return (ak.length === bk.length) ? 0 :\n    (ak.length > bk.length) ? 1 : -1;\n}\n// The collation is defined by erlangs ordered terms\n// the atoms null, true, false come first, then numbers, strings,\n// arrays, then objects\n// null/undefined/NaN/Infinity/-Infinity are all considered null\nfunction collationIndex(x) {\n  var id = ['boolean', 'number', 'string', 'object'];\n  var idx = id.indexOf(typeof x);\n  //false if -1 otherwise true, but fast!!!!1\n  if (~idx) {\n    if (x === null) {\n      return 1;\n    }\n    if (Array.isArray(x)) {\n      return 5;\n    }\n    return idx < 3 ? (idx + 2) : (idx + 3);\n  }\n  /* istanbul ignore next */\n  if (Array.isArray(x)) {\n    return 5;\n  }\n}\n\n// conversion:\n// x yyy zz...zz\n// x = 0 for negative, 1 for 0, 2 for positive\n// y = exponent (for negative numbers negated) moved so that it's >= 0\n// z = mantisse\nfunction numToIndexableString(num) {\n\n  if (num === 0) {\n    return '1';\n  }\n\n  // convert number to exponential format for easier and\n  // more succinct string sorting\n  var expFormat = num.toExponential().split(/e\\+?/);\n  var magnitude = parseInt(expFormat[1], 10);\n\n  var neg = num < 0;\n\n  var result = neg ? '0' : '2';\n\n  // first sort by magnitude\n  // it's easier if all magnitudes are positive\n  var magForComparison = ((neg ? -magnitude : magnitude) - MIN_MAGNITUDE);\n  var magString = padLeft((magForComparison).toString(), '0', MAGNITUDE_DIGITS);\n\n  result += SEP + magString;\n\n  // then sort by the factor\n  var factor = Math.abs(parseFloat(expFormat[0])); // [1..10)\n  /* istanbul ignore next */\n  if (neg) { // for negative reverse ordering\n    factor = 10 - factor;\n  }\n\n  var factorStr = factor.toFixed(20);\n\n  // strip zeros from the end\n  factorStr = factorStr.replace(/\\.?0+$/, '');\n\n  result += SEP + factorStr;\n\n  return result;\n}\n\n/*\n * Simple task queue to sequentialize actions. Assumes\n * callbacks will eventually fire (once).\n */\n\nfunction TaskQueue$2() {\n  this.promise = new PouchPromise$1(function (fulfill) {fulfill(); });\n}\nTaskQueue$2.prototype.add = function (promiseFactory) {\n  this.promise = this.promise.catch(function () {\n    // just recover\n  }).then(function () {\n    return promiseFactory();\n  });\n  return this.promise;\n};\nTaskQueue$2.prototype.finish = function () {\n  return this.promise;\n};\n\nfunction createView(opts) {\n  var sourceDB = opts.db;\n  var viewName = opts.viewName;\n  var mapFun = opts.map;\n  var reduceFun = opts.reduce;\n  var temporary = opts.temporary;\n\n  // the \"undefined\" part is for backwards compatibility\n  var viewSignature = mapFun.toString() + (reduceFun && reduceFun.toString()) +\n    'undefined';\n\n  var cachedViews;\n  if (!temporary) {\n    // cache this to ensure we don't try to update the same view twice\n    cachedViews = sourceDB._cachedViews = sourceDB._cachedViews || {};\n    if (cachedViews[viewSignature]) {\n      return cachedViews[viewSignature];\n    }\n  }\n\n  var promiseForView = sourceDB.info().then(function (info) {\n\n    var depDbName = info.db_name + '-mrview-' +\n      (temporary ? 'temp' : stringMd5(viewSignature));\n\n    // save the view name in the source db so it can be cleaned up if necessary\n    // (e.g. when the _design doc is deleted, remove all associated view data)\n    function diffFunction(doc) {\n      doc.views = doc.views || {};\n      var fullViewName = viewName;\n      if (fullViewName.indexOf('/') === -1) {\n        fullViewName = viewName + '/' + viewName;\n      }\n      var depDbs = doc.views[fullViewName] = doc.views[fullViewName] || {};\n      /* istanbul ignore if */\n      if (depDbs[depDbName]) {\n        return; // no update necessary\n      }\n      depDbs[depDbName] = true;\n      return doc;\n    }\n    return upsert(sourceDB, '_local/mrviews', diffFunction).then(function () {\n      return sourceDB.registerDependentDatabase(depDbName).then(function (res) {\n        var db = res.db;\n        db.auto_compaction = true;\n        var view = {\n          name: depDbName,\n          db: db,\n          sourceDB: sourceDB,\n          adapter: sourceDB.adapter,\n          mapFun: mapFun,\n          reduceFun: reduceFun\n        };\n        return view.db.get('_local/lastSeq').catch(function (err) {\n          /* istanbul ignore if */\n          if (err.status !== 404) {\n            throw err;\n          }\n        }).then(function (lastSeqDoc) {\n          view.seq = lastSeqDoc ? lastSeqDoc.seq : 0;\n          if (cachedViews) {\n            view.db.once('destroyed', function () {\n              delete cachedViews[viewSignature];\n            });\n          }\n          return view;\n        });\n      });\n    });\n  });\n\n  if (cachedViews) {\n    cachedViews[viewSignature] = promiseForView;\n  }\n  return promiseForView;\n}\n\nfunction QueryParseError(message) {\n  this.status = 400;\n  this.name = 'query_parse_error';\n  this.message = message;\n  this.error = true;\n  try {\n    Error.captureStackTrace(this, QueryParseError);\n  } catch (e) {}\n}\n\ninherits(QueryParseError, Error);\n\nfunction NotFoundError(message) {\n  this.status = 404;\n  this.name = 'not_found';\n  this.message = message;\n  this.error = true;\n  try {\n    Error.captureStackTrace(this, NotFoundError);\n  } catch (e) {}\n}\n\ninherits(NotFoundError, Error);\n\nfunction BuiltInError(message) {\n  this.status = 500;\n  this.name = 'invalid_value';\n  this.message = message;\n  this.error = true;\n  try {\n    Error.captureStackTrace(this, BuiltInError);\n  } catch (e) {}\n}\n\ninherits(BuiltInError, Error);\n\nfunction createBuiltInError(name) {\n  var message = 'builtin ' + name +\n    ' function requires map values to be numbers' +\n    ' or number arrays';\n  return new BuiltInError(message);\n}\n\nfunction sum(values) {\n  var result = 0;\n  for (var i = 0, len = values.length; i < len; i++) {\n    var num = values[i];\n    if (typeof num !== 'number') {\n      if (Array.isArray(num)) {\n        // lists of numbers are also allowed, sum them separately\n        result = typeof result === 'number' ? [result] : result;\n        for (var j = 0, jLen = num.length; j < jLen; j++) {\n          var jNum = num[j];\n          if (typeof jNum !== 'number') {\n            throw createBuiltInError('_sum');\n          } else if (typeof result[j] === 'undefined') {\n            result.push(jNum);\n          } else {\n            result[j] += jNum;\n          }\n        }\n      } else { // not array/number\n        throw createBuiltInError('_sum');\n      }\n    } else if (typeof result === 'number') {\n      result += num;\n    } else { // add number to array\n      result[0] += num;\n    }\n  }\n  return result;\n}\n\nvar log$2 = guardedConsole.bind(null, 'log');\nvar isArray = Array.isArray;\nvar toJSON = JSON.parse;\n\nfunction evalFunctionWithEval(func, emit) {\n  return scopedEval(\n    \"return (\" + func.replace(/;\\s*$/, \"\") + \");\",\n    {\n      emit: emit,\n      sum: sum,\n      log: log$2,\n      isArray: isArray,\n      toJSON: toJSON\n    }\n  );\n}\n\nfunction promisedCallback(promise, callback) {\n  if (callback) {\n    promise.then(function (res) {\n      nextTick(function () {\n        callback(null, res);\n      });\n    }, function (reason) {\n      nextTick(function () {\n        callback(reason);\n      });\n    });\n  }\n  return promise;\n}\n\nfunction callbackify(fun) {\n  return getArguments(function (args) {\n    var cb = args.pop();\n    var promise = fun.apply(this, args);\n    if (typeof cb === 'function') {\n      promisedCallback(promise, cb);\n    }\n    return promise;\n  });\n}\n\n// Promise finally util similar to Q.finally\nfunction fin(promise, finalPromiseFactory) {\n  return promise.then(function (res) {\n    return finalPromiseFactory().then(function () {\n      return res;\n    });\n  }, function (reason) {\n    return finalPromiseFactory().then(function () {\n      throw reason;\n    });\n  });\n}\n\nfunction sequentialize(queue, promiseFactory) {\n  return function () {\n    var args = arguments;\n    var that = this;\n    return queue.add(function () {\n      return promiseFactory.apply(that, args);\n    });\n  };\n}\n\n// uniq an array of strings, order not guaranteed\n// similar to underscore/lodash _.uniq\nfunction uniq(arr) {\n  var theSet = new ExportedSet(arr);\n  var result = new Array(theSet.size);\n  var index = -1;\n  theSet.forEach(function (value) {\n    result[++index] = value;\n  });\n  return result;\n}\n\nfunction mapToKeysArray(map) {\n  var result = new Array(map.size);\n  var index = -1;\n  map.forEach(function (value, key) {\n    result[++index] = key;\n  });\n  return result;\n}\n\nvar persistentQueues = {};\nvar tempViewQueue = new TaskQueue$2();\nvar CHANGES_BATCH_SIZE$1 = 50;\n\nfunction parseViewName(name) {\n  // can be either 'ddocname/viewname' or just 'viewname'\n  // (where the ddoc name is the same)\n  return name.indexOf('/') === -1 ? [name, name] : name.split('/');\n}\n\nfunction isGenOne(changes) {\n  // only return true if the current change is 1-\n  // and there are no other leafs\n  return changes.length === 1 && /^1-/.test(changes[0].rev);\n}\n\nfunction emitError(db, e) {\n  try {\n    db.emit('error', e);\n  } catch (err) {\n    guardedConsole('error',\n      'The user\\'s map/reduce function threw an uncaught error.\\n' +\n      'You can debug this error by doing:\\n' +\n      'myDatabase.on(\\'error\\', function (err) { debugger; });\\n' +\n      'Please double-check your map/reduce function.');\n    guardedConsole('error', e);\n  }\n}\nfunction tryMap(db, fun, doc) {\n  // emit an event if there was an error thrown by a map function.\n  // putting try/catches in a single function also avoids deoptimizations.\n  try {\n    fun(doc);\n  } catch (e) {\n    emitError(db, e);\n  }\n}\n\nfunction tryReduce(db, fun, keys, values, rereduce) {\n  // same as above, but returning the result or an error. there are two separate\n  // functions to avoid extra memory allocations since the tryCode() case is used\n  // for custom map functions (common) vs this function, which is only used for\n  // custom reduce functions (rare)\n  try {\n    return {output : fun(keys, values, rereduce)};\n  } catch (e) {\n    emitError(db, e);\n    return {error: e};\n  }\n}\n\nfunction sortByKeyThenValue(x, y) {\n  var keyCompare = collate(x.key, y.key);\n  return keyCompare !== 0 ? keyCompare : collate(x.value, y.value);\n}\n\nfunction sliceResults(results, limit, skip) {\n  skip = skip || 0;\n  if (typeof limit === 'number') {\n    return results.slice(skip, limit + skip);\n  } else if (skip > 0) {\n    return results.slice(skip);\n  }\n  return results;\n}\n\nfunction rowToDocId(row) {\n  var val = row.value;\n  // Users can explicitly specify a joined doc _id, or it\n  // defaults to the doc _id that emitted the key/value.\n  var docId = (val && typeof val === 'object' && val._id) || row.id;\n  return docId;\n}\n\nfunction readAttachmentsAsBlobOrBuffer$1(res) {\n  res.rows.forEach(function (row) {\n    var atts = row.doc && row.doc._attachments;\n    if (!atts) {\n      return;\n    }\n    Object.keys(atts).forEach(function (filename) {\n      var att = atts[filename];\n      atts[filename].data = b64ToBluffer(att.data, att.content_type);\n    });\n  });\n}\n\nfunction postprocessAttachments(opts) {\n  return function (res) {\n    if (opts.include_docs && opts.attachments && opts.binary) {\n      readAttachmentsAsBlobOrBuffer$1(res);\n    }\n    return res;\n  };\n}\n\nvar builtInReduce = {\n  _sum: function (keys, values) {\n    return sum(values);\n  },\n\n  _count: function (keys, values) {\n    return values.length;\n  },\n\n  _stats: function (keys, values) {\n    // no need to implement rereduce=true, because Pouch\n    // will never call it\n    function sumsqr(values) {\n      var _sumsqr = 0;\n      for (var i = 0, len = values.length; i < len; i++) {\n        var num = values[i];\n        _sumsqr += (num * num);\n      }\n      return _sumsqr;\n    }\n    return {\n      sum     : sum(values),\n      min     : Math.min.apply(null, values),\n      max     : Math.max.apply(null, values),\n      count   : values.length,\n      sumsqr : sumsqr(values)\n    };\n  }\n};\n\nfunction addHttpParam(paramName, opts, params, asJson) {\n  // add an http param from opts to params, optionally json-encoded\n  var val = opts[paramName];\n  if (typeof val !== 'undefined') {\n    if (asJson) {\n      val = encodeURIComponent(JSON.stringify(val));\n    }\n    params.push(paramName + '=' + val);\n  }\n}\n\nfunction coerceInteger(integerCandidate) {\n  if (typeof integerCandidate !== 'undefined') {\n    var asNumber = Number(integerCandidate);\n    // prevents e.g. '1foo' or '1.1' being coerced to 1\n    if (!isNaN(asNumber) && asNumber === parseInt(integerCandidate, 10)) {\n      return asNumber;\n    } else {\n      return integerCandidate;\n    }\n  }\n}\n\nfunction coerceOptions(opts) {\n  opts.group_level = coerceInteger(opts.group_level);\n  opts.limit = coerceInteger(opts.limit);\n  opts.skip = coerceInteger(opts.skip);\n  return opts;\n}\n\nfunction checkPositiveInteger(number) {\n  if (number) {\n    if (typeof number !== 'number') {\n      return  new QueryParseError('Invalid value for integer: \"' +\n      number + '\"');\n    }\n    if (number < 0) {\n      return new QueryParseError('Invalid value for positive integer: ' +\n        '\"' + number + '\"');\n    }\n  }\n}\n\nfunction checkQueryParseError(options, fun) {\n  var startkeyName = options.descending ? 'endkey' : 'startkey';\n  var endkeyName = options.descending ? 'startkey' : 'endkey';\n\n  if (typeof options[startkeyName] !== 'undefined' &&\n    typeof options[endkeyName] !== 'undefined' &&\n    collate(options[startkeyName], options[endkeyName]) > 0) {\n    throw new QueryParseError('No rows can match your key range, ' +\n    'reverse your start_key and end_key or set {descending : true}');\n  } else if (fun.reduce && options.reduce !== false) {\n    if (options.include_docs) {\n      throw new QueryParseError('{include_docs:true} is invalid for reduce');\n    } else if (options.keys && options.keys.length > 1 &&\n        !options.group && !options.group_level) {\n      throw new QueryParseError('Multi-key fetches for reduce views must use ' +\n      '{group: true}');\n    }\n  }\n  ['group_level', 'limit', 'skip'].forEach(function (optionName) {\n    var error = checkPositiveInteger(options[optionName]);\n    if (error) {\n      throw error;\n    }\n  });\n}\n\nfunction httpQuery(db, fun, opts) {\n  // List of parameters to add to the PUT request\n  var params = [];\n  var body;\n  var method = 'GET';\n\n  // If opts.reduce exists and is defined, then add it to the list\n  // of parameters.\n  // If reduce=false then the results are that of only the map function\n  // not the final result of map and reduce.\n  addHttpParam('reduce', opts, params);\n  addHttpParam('include_docs', opts, params);\n  addHttpParam('attachments', opts, params);\n  addHttpParam('limit', opts, params);\n  addHttpParam('descending', opts, params);\n  addHttpParam('group', opts, params);\n  addHttpParam('group_level', opts, params);\n  addHttpParam('skip', opts, params);\n  addHttpParam('stale', opts, params);\n  addHttpParam('conflicts', opts, params);\n  addHttpParam('startkey', opts, params, true);\n  addHttpParam('start_key', opts, params, true);\n  addHttpParam('endkey', opts, params, true);\n  addHttpParam('end_key', opts, params, true);\n  addHttpParam('inclusive_end', opts, params);\n  addHttpParam('key', opts, params, true);\n\n  // Format the list of parameters into a valid URI query string\n  params = params.join('&');\n  params = params === '' ? '' : '?' + params;\n\n  // If keys are supplied, issue a POST to circumvent GET query string limits\n  // see http://wiki.apache.org/couchdb/HTTP_view_API#Querying_Options\n  if (typeof opts.keys !== 'undefined') {\n    var MAX_URL_LENGTH = 2000;\n    // according to http://stackoverflow.com/a/417184/680742,\n    // the de facto URL length limit is 2000 characters\n\n    var keysAsString =\n      'keys=' + encodeURIComponent(JSON.stringify(opts.keys));\n    if (keysAsString.length + params.length + 1 <= MAX_URL_LENGTH) {\n      // If the keys are short enough, do a GET. we do this to work around\n      // Safari not understanding 304s on POSTs (see pouchdb/pouchdb#1239)\n      params += (params[0] === '?' ? '&' : '?') + keysAsString;\n    } else {\n      method = 'POST';\n      if (typeof fun === 'string') {\n        body = {keys: opts.keys};\n      } else { // fun is {map : mapfun}, so append to this\n        fun.keys = opts.keys;\n      }\n    }\n  }\n\n  // We are referencing a query defined in the design doc\n  if (typeof fun === 'string') {\n    var parts = parseViewName(fun);\n    return db.request({\n      method: method,\n      url: '_design/' + parts[0] + '/_view/' + parts[1] + params,\n      body: body\n    }).then(postprocessAttachments(opts));\n  }\n\n  // We are using a temporary view, terrible for performance, good for testing\n  body = body || {};\n  Object.keys(fun).forEach(function (key) {\n    if (Array.isArray(fun[key])) {\n      body[key] = fun[key];\n    } else {\n      body[key] = fun[key].toString();\n    }\n  });\n  return db.request({\n    method: 'POST',\n    url: '_temp_view' + params,\n    body: body\n  }).then(postprocessAttachments(opts));\n}\n\n// custom adapters can define their own api._query\n// and override the default behavior\n/* istanbul ignore next */\nfunction customQuery(db, fun, opts) {\n  return new PouchPromise$1(function (resolve, reject) {\n    db._query(fun, opts, function (err, res) {\n      if (err) {\n        return reject(err);\n      }\n      resolve(res);\n    });\n  });\n}\n\n// custom adapters can define their own api._viewCleanup\n// and override the default behavior\n/* istanbul ignore next */\nfunction customViewCleanup(db) {\n  return new PouchPromise$1(function (resolve, reject) {\n    db._viewCleanup(function (err, res) {\n      if (err) {\n        return reject(err);\n      }\n      resolve(res);\n    });\n  });\n}\n\nfunction defaultsTo(value) {\n  return function (reason) {\n    /* istanbul ignore else */\n    if (reason.status === 404) {\n      return value;\n    } else {\n      throw reason;\n    }\n  };\n}\n\n// returns a promise for a list of docs to update, based on the input docId.\n// the order doesn't matter, because post-3.2.0, bulkDocs\n// is an atomic operation in all three adapters.\nfunction getDocsToPersist(docId, view, docIdsToChangesAndEmits) {\n  var metaDocId = '_local/doc_' + docId;\n  var defaultMetaDoc = {_id: metaDocId, keys: []};\n  var docData = docIdsToChangesAndEmits.get(docId);\n  var indexableKeysToKeyValues = docData[0];\n  var changes = docData[1];\n\n  function getMetaDoc() {\n    if (isGenOne(changes)) {\n      // generation 1, so we can safely assume initial state\n      // for performance reasons (avoids unnecessary GETs)\n      return PouchPromise$1.resolve(defaultMetaDoc);\n    }\n    return view.db.get(metaDocId).catch(defaultsTo(defaultMetaDoc));\n  }\n\n  function getKeyValueDocs(metaDoc) {\n    if (!metaDoc.keys.length) {\n      // no keys, no need for a lookup\n      return PouchPromise$1.resolve({rows: []});\n    }\n    return view.db.allDocs({\n      keys: metaDoc.keys,\n      include_docs: true\n    });\n  }\n\n  function processKeyValueDocs(metaDoc, kvDocsRes) {\n    var kvDocs = [];\n    var oldKeys = new ExportedSet();\n\n    for (var i = 0, len = kvDocsRes.rows.length; i < len; i++) {\n      var row = kvDocsRes.rows[i];\n      var doc = row.doc;\n      if (!doc) { // deleted\n        continue;\n      }\n      kvDocs.push(doc);\n      oldKeys.add(doc._id);\n      doc._deleted = !indexableKeysToKeyValues.has(doc._id);\n      if (!doc._deleted) {\n        var keyValue = indexableKeysToKeyValues.get(doc._id);\n        if ('value' in keyValue) {\n          doc.value = keyValue.value;\n        }\n      }\n    }\n    var newKeys = mapToKeysArray(indexableKeysToKeyValues);\n    newKeys.forEach(function (key) {\n      if (!oldKeys.has(key)) {\n        // new doc\n        var kvDoc = {\n          _id: key\n        };\n        var keyValue = indexableKeysToKeyValues.get(key);\n        if ('value' in keyValue) {\n          kvDoc.value = keyValue.value;\n        }\n        kvDocs.push(kvDoc);\n      }\n    });\n    metaDoc.keys = uniq(newKeys.concat(metaDoc.keys));\n    kvDocs.push(metaDoc);\n\n    return kvDocs;\n  }\n\n  return getMetaDoc().then(function (metaDoc) {\n    return getKeyValueDocs(metaDoc).then(function (kvDocsRes) {\n      return processKeyValueDocs(metaDoc, kvDocsRes);\n    });\n  });\n}\n\n// updates all emitted key/value docs and metaDocs in the mrview database\n// for the given batch of documents from the source database\nfunction saveKeyValues(view, docIdsToChangesAndEmits, seq) {\n  var seqDocId = '_local/lastSeq';\n  return view.db.get(seqDocId)\n  .catch(defaultsTo({_id: seqDocId, seq: 0}))\n  .then(function (lastSeqDoc) {\n    var docIds = mapToKeysArray(docIdsToChangesAndEmits);\n    return PouchPromise$1.all(docIds.map(function (docId) {\n      return getDocsToPersist(docId, view, docIdsToChangesAndEmits);\n    })).then(function (listOfDocsToPersist) {\n      var docsToPersist = flatten(listOfDocsToPersist);\n      lastSeqDoc.seq = seq;\n      docsToPersist.push(lastSeqDoc);\n      // write all docs in a single operation, update the seq once\n      return view.db.bulkDocs({docs : docsToPersist});\n    });\n  });\n}\n\nfunction getQueue(view) {\n  var viewName = typeof view === 'string' ? view : view.name;\n  var queue = persistentQueues[viewName];\n  if (!queue) {\n    queue = persistentQueues[viewName] = new TaskQueue$2();\n  }\n  return queue;\n}\n\nfunction updateView(view) {\n  return sequentialize(getQueue(view), function () {\n    return updateViewInQueue(view);\n  })();\n}\n\nfunction updateViewInQueue(view) {\n  // bind the emit function once\n  var mapResults;\n  var doc;\n\n  function emit(key, value) {\n    var output = {id: doc._id, key: normalizeKey(key)};\n    // Don't explicitly store the value unless it's defined and non-null.\n    // This saves on storage space, because often people don't use it.\n    if (typeof value !== 'undefined' && value !== null) {\n      output.value = normalizeKey(value);\n    }\n    mapResults.push(output);\n  }\n\n  var mapFun;\n  // for temp_views one can use emit(doc, emit), see #38\n  if (typeof view.mapFun === \"function\" && view.mapFun.length === 2) {\n    var origMap = view.mapFun;\n    mapFun = function (doc) {\n      return origMap(doc, emit);\n    };\n  } else {\n    mapFun = evalFunctionWithEval(view.mapFun.toString(), emit);\n  }\n\n  var currentSeq = view.seq || 0;\n\n  function processChange(docIdsToChangesAndEmits, seq) {\n    return function () {\n      return saveKeyValues(view, docIdsToChangesAndEmits, seq);\n    };\n  }\n\n  var queue = new TaskQueue$2();\n\n  function processNextBatch() {\n    return view.sourceDB.changes({\n      conflicts: true,\n      include_docs: true,\n      style: 'all_docs',\n      since: currentSeq,\n      limit: CHANGES_BATCH_SIZE$1\n    }).then(processBatch);\n  }\n\n  function processBatch(response) {\n    var results = response.results;\n    if (!results.length) {\n      return;\n    }\n    var docIdsToChangesAndEmits = createDocIdsToChangesAndEmits(results);\n    queue.add(processChange(docIdsToChangesAndEmits, currentSeq));\n    if (results.length < CHANGES_BATCH_SIZE$1) {\n      return;\n    }\n    return processNextBatch();\n  }\n\n  function createDocIdsToChangesAndEmits(results) {\n    var docIdsToChangesAndEmits = new ExportedMap();\n    for (var i = 0, len = results.length; i < len; i++) {\n      var change = results[i];\n      if (change.doc._id[0] !== '_') {\n        mapResults = [];\n        doc = change.doc;\n\n        if (!doc._deleted) {\n          tryMap(view.sourceDB, mapFun, doc);\n        }\n        mapResults.sort(sortByKeyThenValue);\n\n        var indexableKeysToKeyValues = createIndexableKeysToKeyValues(mapResults);\n        docIdsToChangesAndEmits.set(change.doc._id, [\n          indexableKeysToKeyValues,\n          change.changes\n        ]);\n      }\n      currentSeq = change.seq;\n    }\n    return docIdsToChangesAndEmits;\n  }\n\n  function createIndexableKeysToKeyValues(mapResults) {\n    var indexableKeysToKeyValues = new ExportedMap();\n    var lastKey;\n    for (var i = 0, len = mapResults.length; i < len; i++) {\n      var emittedKeyValue = mapResults[i];\n      var complexKey = [emittedKeyValue.key, emittedKeyValue.id];\n      if (i > 0 && collate(emittedKeyValue.key, lastKey) === 0) {\n        complexKey.push(i); // dup key+id, so make it unique\n      }\n      indexableKeysToKeyValues.set(toIndexableString(complexKey), emittedKeyValue);\n      lastKey = emittedKeyValue.key;\n    }\n    return indexableKeysToKeyValues;\n  }\n\n  return processNextBatch().then(function () {\n    return queue.finish();\n  }).then(function () {\n    view.seq = currentSeq;\n  });\n}\n\nfunction reduceView(view, results, options) {\n  if (options.group_level === 0) {\n    delete options.group_level;\n  }\n\n  var shouldGroup = options.group || options.group_level;\n\n  var reduceFun;\n  if (builtInReduce[view.reduceFun]) {\n    reduceFun = builtInReduce[view.reduceFun];\n  } else {\n    reduceFun = evalFunctionWithEval(view.reduceFun.toString());\n  }\n\n  var groups = [];\n  var lvl = isNaN(options.group_level) ? Number.POSITIVE_INFINITY :\n    options.group_level;\n  results.forEach(function (e) {\n    var last = groups[groups.length - 1];\n    var groupKey = shouldGroup ? e.key : null;\n\n    // only set group_level for array keys\n    if (shouldGroup && Array.isArray(groupKey)) {\n      groupKey = groupKey.slice(0, lvl);\n    }\n\n    if (last && collate(last.groupKey, groupKey) === 0) {\n      last.keys.push([e.key, e.id]);\n      last.values.push(e.value);\n      return;\n    }\n    groups.push({\n      keys: [[e.key, e.id]],\n      values: [e.value],\n      groupKey: groupKey\n    });\n  });\n  results = [];\n  for (var i = 0, len = groups.length; i < len; i++) {\n    var e = groups[i];\n    var reduceTry = tryReduce(view.sourceDB, reduceFun, e.keys, e.values, false);\n    if (reduceTry.error && reduceTry.error instanceof BuiltInError) {\n      // CouchDB returns an error if a built-in errors out\n      throw reduceTry.error;\n    }\n    results.push({\n      // CouchDB just sets the value to null if a non-built-in errors out\n      value: reduceTry.error ? null : reduceTry.output,\n      key: e.groupKey\n    });\n  }\n  // no total_rows/offset when reducing\n  return {rows: sliceResults(results, options.limit, options.skip)};\n}\n\nfunction queryView(view, opts) {\n  return sequentialize(getQueue(view), function () {\n    return queryViewInQueue(view, opts);\n  })();\n}\n\nfunction queryViewInQueue(view, opts) {\n  var totalRows;\n  var shouldReduce = view.reduceFun && opts.reduce !== false;\n  var skip = opts.skip || 0;\n  if (typeof opts.keys !== 'undefined' && !opts.keys.length) {\n    // equivalent query\n    opts.limit = 0;\n    delete opts.keys;\n  }\n\n  function fetchFromView(viewOpts) {\n    viewOpts.include_docs = true;\n    return view.db.allDocs(viewOpts).then(function (res) {\n      totalRows = res.total_rows;\n      return res.rows.map(function (result) {\n\n        // implicit migration - in older versions of PouchDB,\n        // we explicitly stored the doc as {id: ..., key: ..., value: ...}\n        // this is tested in a migration test\n        /* istanbul ignore next */\n        if ('value' in result.doc && typeof result.doc.value === 'object' &&\n            result.doc.value !== null) {\n          var keys = Object.keys(result.doc.value).sort();\n          // this detection method is not perfect, but it's unlikely the user\n          // emitted a value which was an object with these 3 exact keys\n          var expectedKeys = ['id', 'key', 'value'];\n          if (!(keys < expectedKeys || keys > expectedKeys)) {\n            return result.doc.value;\n          }\n        }\n\n        var parsedKeyAndDocId = parseIndexableString(result.doc._id);\n        return {\n          key: parsedKeyAndDocId[0],\n          id: parsedKeyAndDocId[1],\n          value: ('value' in result.doc ? result.doc.value : null)\n        };\n      });\n    });\n  }\n\n  function onMapResultsReady(rows) {\n    var finalResults;\n    if (shouldReduce) {\n      finalResults = reduceView(view, rows, opts);\n    } else {\n      finalResults = {\n        total_rows: totalRows,\n        offset: skip,\n        rows: rows\n      };\n    }\n    if (opts.include_docs) {\n      var docIds = uniq(rows.map(rowToDocId));\n\n      return view.sourceDB.allDocs({\n        keys: docIds,\n        include_docs: true,\n        conflicts: opts.conflicts,\n        attachments: opts.attachments,\n        binary: opts.binary\n      }).then(function (allDocsRes) {\n        var docIdsToDocs = new ExportedMap();\n        allDocsRes.rows.forEach(function (row) {\n          docIdsToDocs.set(row.id, row.doc);\n        });\n        rows.forEach(function (row) {\n          var docId = rowToDocId(row);\n          var doc = docIdsToDocs.get(docId);\n          if (doc) {\n            row.doc = doc;\n          }\n        });\n        return finalResults;\n      });\n    } else {\n      return finalResults;\n    }\n  }\n\n  if (typeof opts.keys !== 'undefined') {\n    var keys = opts.keys;\n    var fetchPromises = keys.map(function (key) {\n      var viewOpts = {\n        startkey : toIndexableString([key]),\n        endkey   : toIndexableString([key, {}])\n      };\n      return fetchFromView(viewOpts);\n    });\n    return PouchPromise$1.all(fetchPromises).then(flatten).then(onMapResultsReady);\n  } else { // normal query, no 'keys'\n    var viewOpts = {\n      descending : opts.descending\n    };\n    if (opts.start_key) {\n        opts.startkey = opts.start_key;\n    }\n    if (opts.end_key) {\n        opts.endkey = opts.end_key;\n    }\n    if (typeof opts.startkey !== 'undefined') {\n      viewOpts.startkey = opts.descending ?\n        toIndexableString([opts.startkey, {}]) :\n        toIndexableString([opts.startkey]);\n    }\n    if (typeof opts.endkey !== 'undefined') {\n      var inclusiveEnd = opts.inclusive_end !== false;\n      if (opts.descending) {\n        inclusiveEnd = !inclusiveEnd;\n      }\n\n      viewOpts.endkey = toIndexableString(\n        inclusiveEnd ? [opts.endkey, {}] : [opts.endkey]);\n    }\n    if (typeof opts.key !== 'undefined') {\n      var keyStart = toIndexableString([opts.key]);\n      var keyEnd = toIndexableString([opts.key, {}]);\n      if (viewOpts.descending) {\n        viewOpts.endkey = keyStart;\n        viewOpts.startkey = keyEnd;\n      } else {\n        viewOpts.startkey = keyStart;\n        viewOpts.endkey = keyEnd;\n      }\n    }\n    if (!shouldReduce) {\n      if (typeof opts.limit === 'number') {\n        viewOpts.limit = opts.limit;\n      }\n      viewOpts.skip = skip;\n    }\n    return fetchFromView(viewOpts).then(onMapResultsReady);\n  }\n}\n\nfunction httpViewCleanup(db) {\n  return db.request({\n    method: 'POST',\n    url: '_view_cleanup'\n  });\n}\n\nfunction localViewCleanup(db) {\n  return db.get('_local/mrviews').then(function (metaDoc) {\n    var docsToViews = new ExportedMap();\n    Object.keys(metaDoc.views).forEach(function (fullViewName) {\n      var parts = parseViewName(fullViewName);\n      var designDocName = '_design/' + parts[0];\n      var viewName = parts[1];\n      var views = docsToViews.get(designDocName);\n      if (!views) {\n        views = new ExportedSet();\n        docsToViews.set(designDocName, views);\n      }\n      views.add(viewName);\n    });\n    var opts = {\n      keys : mapToKeysArray(docsToViews),\n      include_docs : true\n    };\n    return db.allDocs(opts).then(function (res) {\n      var viewsToStatus = {};\n      res.rows.forEach(function (row) {\n        var ddocName = row.key.substring(8); // cuts off '_design/'\n        docsToViews.get(row.key).forEach(function (viewName) {\n          var fullViewName = ddocName + '/' + viewName;\n          /* istanbul ignore if */\n          if (!metaDoc.views[fullViewName]) {\n            // new format, without slashes, to support PouchDB 2.2.0\n            // migration test in pouchdb's browser.migration.js verifies this\n            fullViewName = viewName;\n          }\n          var viewDBNames = Object.keys(metaDoc.views[fullViewName]);\n          // design doc deleted, or view function nonexistent\n          var statusIsGood = row.doc && row.doc.views &&\n            row.doc.views[viewName];\n          viewDBNames.forEach(function (viewDBName) {\n            viewsToStatus[viewDBName] =\n              viewsToStatus[viewDBName] || statusIsGood;\n          });\n        });\n      });\n      var dbsToDelete = Object.keys(viewsToStatus).filter(\n        function (viewDBName) { return !viewsToStatus[viewDBName]; });\n      var destroyPromises = dbsToDelete.map(function (viewDBName) {\n        return sequentialize(getQueue(viewDBName), function () {\n          return new db.constructor(viewDBName, db.__opts).destroy();\n        })();\n      });\n      return PouchPromise$1.all(destroyPromises).then(function () {\n        return {ok: true};\n      });\n    });\n  }, defaultsTo({ok: true}));\n}\n\nvar viewCleanup = callbackify(function () {\n  var db = this;\n  if (db.type() === 'http') {\n    return httpViewCleanup(db);\n  }\n  /* istanbul ignore next */\n  if (typeof db._viewCleanup === 'function') {\n    return customViewCleanup(db);\n  }\n  return localViewCleanup(db);\n});\n\nfunction queryPromised(db, fun, opts) {\n  if (db.type() === 'http') {\n    return httpQuery(db, fun, opts);\n  }\n\n  /* istanbul ignore next */\n  if (typeof db._query === 'function') {\n    return customQuery(db, fun, opts);\n  }\n\n  if (typeof fun !== 'string') {\n    // temp_view\n    checkQueryParseError(opts, fun);\n\n    var createViewOpts = {\n      db : db,\n      viewName : 'temp_view/temp_view',\n      map : fun.map,\n      reduce : fun.reduce,\n      temporary : true\n    };\n    tempViewQueue.add(function () {\n      return createView(createViewOpts).then(function (view) {\n        function cleanup() {\n          return view.db.destroy();\n        }\n        return fin(updateView(view).then(function () {\n          return queryView(view, opts);\n        }), cleanup);\n      });\n    });\n    return tempViewQueue.finish();\n  } else {\n    // persistent view\n    var fullViewName = fun;\n    var parts = parseViewName(fullViewName);\n    var designDocName = parts[0];\n    var viewName = parts[1];\n    return db.get('_design/' + designDocName).then(function (doc) {\n      var fun = doc.views && doc.views[viewName];\n\n      if (!fun || typeof fun.map !== 'string') {\n        throw new NotFoundError('ddoc ' + designDocName +\n        ' has no view named ' + viewName);\n      }\n      checkQueryParseError(opts, fun);\n\n      var createViewOpts = {\n        db : db,\n        viewName : fullViewName,\n        map : fun.map,\n        reduce : fun.reduce\n      };\n      return createView(createViewOpts).then(function (view) {\n        if (opts.stale === 'ok' || opts.stale === 'update_after') {\n          if (opts.stale === 'update_after') {\n            nextTick(function () {\n              updateView(view);\n            });\n          }\n          return queryView(view, opts);\n        } else { // stale not ok\n          return updateView(view).then(function () {\n            return queryView(view, opts);\n          });\n        }\n      });\n    });\n  }\n}\n\nvar query = function (fun, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  opts = opts ? coerceOptions(opts) : {};\n\n  if (typeof fun === 'function') {\n    fun = {map : fun};\n  }\n\n  var db = this;\n  var promise = PouchPromise$1.resolve().then(function () {\n    return queryPromised(db, fun, opts);\n  });\n  promisedCallback(promise, callback);\n  return promise;\n};\n\n\nvar mapreduce = {\n  query: query,\n  viewCleanup: viewCleanup\n};\n\nfunction isGenOne$1(rev) {\n  return /^1-/.test(rev);\n}\n\nfunction fileHasChanged(localDoc, remoteDoc, filename) {\n  return !localDoc._attachments ||\n         !localDoc._attachments[filename] ||\n         localDoc._attachments[filename].digest !== remoteDoc._attachments[filename].digest;\n}\n\nfunction getDocAttachments(db, doc) {\n  var filenames = Object.keys(doc._attachments);\n  return PouchPromise$1.all(filenames.map(function (filename) {\n    return db.getAttachment(doc._id, filename, {rev: doc._rev});\n  }));\n}\n\nfunction getDocAttachmentsFromTargetOrSource(target, src, doc) {\n  var doCheckForLocalAttachments = src.type() === 'http' && target.type() !== 'http';\n  var filenames = Object.keys(doc._attachments);\n\n  if (!doCheckForLocalAttachments) {\n    return getDocAttachments(src, doc);\n  }\n\n  return target.get(doc._id).then(function (localDoc) {\n    return PouchPromise$1.all(filenames.map(function (filename) {\n      if (fileHasChanged(localDoc, doc, filename)) {\n        return src.getAttachment(doc._id, filename);\n      }\n\n      return target.getAttachment(localDoc._id, filename);\n    }));\n  }).catch(function (error) {\n    /* istanbul ignore if */\n    if (error.status !== 404) {\n      throw error;\n    }\n\n    return getDocAttachments(src, doc);\n  });\n}\n\nfunction createBulkGetOpts(diffs) {\n  var requests = [];\n  Object.keys(diffs).forEach(function (id) {\n    var missingRevs = diffs[id].missing;\n    missingRevs.forEach(function (missingRev) {\n      requests.push({\n        id: id,\n        rev: missingRev\n      });\n    });\n  });\n\n  return {\n    docs: requests,\n    revs: true,\n    latest: true\n  };\n}\n\n//\n// Fetch all the documents from the src as described in the \"diffs\",\n// which is a mapping of docs IDs to revisions. If the state ever\n// changes to \"cancelled\", then the returned promise will be rejected.\n// Else it will be resolved with a list of fetched documents.\n//\nfunction getDocs(src, target, diffs, state) {\n  diffs = clone(diffs); // we do not need to modify this\n\n  var resultDocs = [],\n      ok = true;\n\n  function getAllDocs() {\n\n    var bulkGetOpts = createBulkGetOpts(diffs);\n\n    if (!bulkGetOpts.docs.length) { // optimization: skip empty requests\n      return;\n    }\n\n    return src.bulkGet(bulkGetOpts).then(function (bulkGetResponse) {\n      /* istanbul ignore if */\n      if (state.cancelled) {\n        throw new Error('cancelled');\n      }\n      return PouchPromise$1.all(bulkGetResponse.results.map(function (bulkGetInfo) {\n        return PouchPromise$1.all(bulkGetInfo.docs.map(function (doc) {\n          var remoteDoc = doc.ok;\n\n          if (doc.error) {\n            // when AUTO_COMPACTION is set, docs can be returned which look\n            // like this: {\"missing\":\"1-7c3ac256b693c462af8442f992b83696\"}\n            ok = false;\n          }\n\n          if (!remoteDoc || !remoteDoc._attachments) {\n            return remoteDoc;\n          }\n\n          return getDocAttachmentsFromTargetOrSource(target, src, remoteDoc).then(function (attachments) {\n            var filenames = Object.keys(remoteDoc._attachments);\n            attachments.forEach(function (attachment, i) {\n              var att = remoteDoc._attachments[filenames[i]];\n              delete att.stub;\n              delete att.length;\n              att.data = attachment;\n            });\n\n            return remoteDoc;\n          });\n        }));\n      }))\n\n      .then(function (results) {\n        resultDocs = resultDocs.concat(flatten(results).filter(Boolean));\n      });\n    });\n  }\n\n  function hasAttachments(doc) {\n    return doc._attachments && Object.keys(doc._attachments).length > 0;\n  }\n\n  function hasConflicts(doc) {\n    return doc._conflicts && doc._conflicts.length > 0;\n  }\n\n  function fetchRevisionOneDocs(ids) {\n    // Optimization: fetch gen-1 docs and attachments in\n    // a single request using _all_docs\n    return src.allDocs({\n      keys: ids,\n      include_docs: true,\n      conflicts: true\n    }).then(function (res) {\n      if (state.cancelled) {\n        throw new Error('cancelled');\n      }\n      res.rows.forEach(function (row) {\n        if (row.deleted || !row.doc || !isGenOne$1(row.value.rev) ||\n            hasAttachments(row.doc) || hasConflicts(row.doc)) {\n          // if any of these conditions apply, we need to fetch using get()\n          return;\n        }\n\n        // strip _conflicts array to appease CSG (#5793)\n        /* istanbul ignore if */\n        if (row.doc._conflicts) {\n          delete row.doc._conflicts;\n        }\n\n        // the doc we got back from allDocs() is sufficient\n        resultDocs.push(row.doc);\n        delete diffs[row.id];\n      });\n    });\n  }\n\n  function getRevisionOneDocs() {\n    // filter out the generation 1 docs and get them\n    // leaving the non-generation one docs to be got otherwise\n    var ids = Object.keys(diffs).filter(function (id) {\n      var missing = diffs[id].missing;\n      return missing.length === 1 && isGenOne$1(missing[0]);\n    });\n    if (ids.length > 0) {\n      return fetchRevisionOneDocs(ids);\n    }\n  }\n\n  function returnResult() {\n    return { ok:ok, docs:resultDocs };\n  }\n\n  return PouchPromise$1.resolve()\n    .then(getRevisionOneDocs)\n    .then(getAllDocs)\n    .then(returnResult);\n}\n\nvar CHECKPOINT_VERSION = 1;\nvar REPLICATOR = \"pouchdb\";\n// This is an arbitrary number to limit the\n// amount of replication history we save in the checkpoint.\n// If we save too much, the checkpoing docs will become very big,\n// if we save fewer, we'll run a greater risk of having to\n// read all the changes from 0 when checkpoint PUTs fail\n// CouchDB 2.0 has a more involved history pruning,\n// but let's go for the simple version for now.\nvar CHECKPOINT_HISTORY_SIZE = 5;\nvar LOWEST_SEQ = 0;\n\nfunction updateCheckpoint(db, id, checkpoint, session, returnValue) {\n  return db.get(id).catch(function (err) {\n    if (err.status === 404) {\n      if (db.type() === 'http') {\n        explainError(\n          404, 'PouchDB is just checking if a remote checkpoint exists.'\n        );\n      }\n      return {\n        session_id: session,\n        _id: id,\n        history: [],\n        replicator: REPLICATOR,\n        version: CHECKPOINT_VERSION\n      };\n    }\n    throw err;\n  }).then(function (doc) {\n    if (returnValue.cancelled) {\n      return;\n    }\n\n    // if the checkpoint has not changed, do not update\n    if (doc.last_seq === checkpoint) {\n      return;\n    }\n\n    // Filter out current entry for this replication\n    doc.history = (doc.history || []).filter(function (item) {\n      return item.session_id !== session;\n    });\n\n    // Add the latest checkpoint to history\n    doc.history.unshift({\n      last_seq: checkpoint,\n      session_id: session\n    });\n\n    // Just take the last pieces in history, to\n    // avoid really big checkpoint docs.\n    // see comment on history size above\n    doc.history = doc.history.slice(0, CHECKPOINT_HISTORY_SIZE);\n\n    doc.version = CHECKPOINT_VERSION;\n    doc.replicator = REPLICATOR;\n\n    doc.session_id = session;\n    doc.last_seq = checkpoint;\n\n    return db.put(doc).catch(function (err) {\n      if (err.status === 409) {\n        // retry; someone is trying to write a checkpoint simultaneously\n        return updateCheckpoint(db, id, checkpoint, session, returnValue);\n      }\n      throw err;\n    });\n  });\n}\n\nfunction Checkpointer(src, target, id, returnValue) {\n  this.src = src;\n  this.target = target;\n  this.id = id;\n  this.returnValue = returnValue;\n}\n\nCheckpointer.prototype.writeCheckpoint = function (checkpoint, session) {\n  var self = this;\n  return this.updateTarget(checkpoint, session).then(function () {\n    return self.updateSource(checkpoint, session);\n  });\n};\n\nCheckpointer.prototype.updateTarget = function (checkpoint, session) {\n  return updateCheckpoint(this.target, this.id, checkpoint,\n    session, this.returnValue);\n};\n\nCheckpointer.prototype.updateSource = function (checkpoint, session) {\n  var self = this;\n  if (this.readOnlySource) {\n    return PouchPromise$1.resolve(true);\n  }\n  return updateCheckpoint(this.src, this.id, checkpoint,\n    session, this.returnValue)\n    .catch(function (err) {\n      if (isForbiddenError(err)) {\n        self.readOnlySource = true;\n        return true;\n      }\n      throw err;\n    });\n};\n\nvar comparisons = {\n  \"undefined\": function (targetDoc, sourceDoc) {\n    // This is the previous comparison function\n    if (collate(targetDoc.last_seq, sourceDoc.last_seq) === 0) {\n      return sourceDoc.last_seq;\n    }\n    /* istanbul ignore next */\n    return 0;\n  },\n  \"1\": function (targetDoc, sourceDoc) {\n    // This is the comparison function ported from CouchDB\n    return compareReplicationLogs(sourceDoc, targetDoc).last_seq;\n  }\n};\n\nCheckpointer.prototype.getCheckpoint = function () {\n  var self = this;\n  return self.target.get(self.id).then(function (targetDoc) {\n    if (self.readOnlySource) {\n      return PouchPromise$1.resolve(targetDoc.last_seq);\n    }\n\n    return self.src.get(self.id).then(function (sourceDoc) {\n      // Since we can't migrate an old version doc to a new one\n      // (no session id), we just go with the lowest seq in this case\n      /* istanbul ignore if */\n      if (targetDoc.version !== sourceDoc.version) {\n        return LOWEST_SEQ;\n      }\n\n      var version;\n      if (targetDoc.version) {\n        version = targetDoc.version.toString();\n      } else {\n        version = \"undefined\";\n      }\n\n      if (version in comparisons) {\n        return comparisons[version](targetDoc, sourceDoc);\n      }\n      /* istanbul ignore next */\n      return LOWEST_SEQ;\n    }, function (err) {\n      if (err.status === 404 && targetDoc.last_seq) {\n        return self.src.put({\n          _id: self.id,\n          last_seq: LOWEST_SEQ\n        }).then(function () {\n          return LOWEST_SEQ;\n        }, function (err) {\n          if (isForbiddenError(err)) {\n            self.readOnlySource = true;\n            return targetDoc.last_seq;\n          }\n          /* istanbul ignore next */\n          return LOWEST_SEQ;\n        });\n      }\n      throw err;\n    });\n  }).catch(function (err) {\n    if (err.status !== 404) {\n      throw err;\n    }\n    return LOWEST_SEQ;\n  });\n};\n// This checkpoint comparison is ported from CouchDBs source\n// they come from here:\n// https://github.com/apache/couchdb-couch-replicator/blob/master/src/couch_replicator.erl#L863-L906\n\nfunction compareReplicationLogs(srcDoc, tgtDoc) {\n  if (srcDoc.session_id === tgtDoc.session_id) {\n    return {\n      last_seq: srcDoc.last_seq,\n      history: srcDoc.history\n    };\n  }\n\n  return compareReplicationHistory(srcDoc.history, tgtDoc.history);\n}\n\nfunction compareReplicationHistory(sourceHistory, targetHistory) {\n  // the erlang loop via function arguments is not so easy to repeat in JS\n  // therefore, doing this as recursion\n  var S = sourceHistory[0];\n  var sourceRest = sourceHistory.slice(1);\n  var T = targetHistory[0];\n  var targetRest = targetHistory.slice(1);\n\n  if (!S || targetHistory.length === 0) {\n    return {\n      last_seq: LOWEST_SEQ,\n      history: []\n    };\n  }\n\n  var sourceId = S.session_id;\n  /* istanbul ignore if */\n  if (hasSessionId(sourceId, targetHistory)) {\n    return {\n      last_seq: S.last_seq,\n      history: sourceHistory\n    };\n  }\n\n  var targetId = T.session_id;\n  if (hasSessionId(targetId, sourceRest)) {\n    return {\n      last_seq: T.last_seq,\n      history: targetRest\n    };\n  }\n\n  return compareReplicationHistory(sourceRest, targetRest);\n}\n\nfunction hasSessionId(sessionId, history) {\n  var props = history[0];\n  var rest = history.slice(1);\n\n  if (!sessionId || history.length === 0) {\n    return false;\n  }\n\n  if (sessionId === props.session_id) {\n    return true;\n  }\n\n  return hasSessionId(sessionId, rest);\n}\n\nfunction isForbiddenError(err) {\n  return typeof err.status === 'number' && Math.floor(err.status / 100) === 4;\n}\n\nvar STARTING_BACK_OFF = 0;\n\nfunction backOff(opts, returnValue, error, callback) {\n  if (opts.retry === false) {\n    returnValue.emit('error', error);\n    returnValue.removeAllListeners();\n    return;\n  }\n  if (typeof opts.back_off_function !== 'function') {\n    opts.back_off_function = defaultBackOff;\n  }\n  returnValue.emit('requestError', error);\n  if (returnValue.state === 'active' || returnValue.state === 'pending') {\n    returnValue.emit('paused', error);\n    returnValue.state = 'stopped';\n    var backOffSet = function backoffTimeSet() {\n      opts.current_back_off = STARTING_BACK_OFF;\n    };\n    var removeBackOffSetter = function removeBackOffTimeSet() {\n      returnValue.removeListener('active', backOffSet);\n    };\n    returnValue.once('paused', removeBackOffSetter);\n    returnValue.once('active', backOffSet);\n  }\n\n  opts.current_back_off = opts.current_back_off || STARTING_BACK_OFF;\n  opts.current_back_off = opts.back_off_function(opts.current_back_off);\n  setTimeout(callback, opts.current_back_off);\n}\n\nfunction sortObjectPropertiesByKey(queryParams) {\n  return Object.keys(queryParams).sort(collate).reduce(function (result, key) {\n    result[key] = queryParams[key];\n    return result;\n  }, {});\n}\n\n// Generate a unique id particular to this replication.\n// Not guaranteed to align perfectly with CouchDB's rep ids.\nfunction generateReplicationId(src, target, opts) {\n  var docIds = opts.doc_ids ? opts.doc_ids.sort(collate) : '';\n  var filterFun = opts.filter ? opts.filter.toString() : '';\n  var queryParams = '';\n  var filterViewName =  '';\n\n  if (opts.filter && opts.query_params) {\n    queryParams = JSON.stringify(sortObjectPropertiesByKey(opts.query_params));\n  }\n\n  if (opts.filter && opts.filter === '_view') {\n    filterViewName = opts.view.toString();\n  }\n\n  return PouchPromise$1.all([src.id(), target.id()]).then(function (res) {\n    var queryData = res[0] + res[1] + filterFun + filterViewName +\n      queryParams + docIds;\n    return new PouchPromise$1(function (resolve) {\n      binaryMd5(queryData, resolve);\n    });\n  }).then(function (md5sum) {\n    // can't use straight-up md5 alphabet, because\n    // the char '/' is interpreted as being for attachments,\n    // and + is also not url-safe\n    md5sum = md5sum.replace(/\\//g, '.').replace(/\\+/g, '_');\n    return '_local/' + md5sum;\n  });\n}\n\nfunction replicate(src, target, opts, returnValue, result) {\n  var batches = [];               // list of batches to be processed\n  var currentBatch;               // the batch currently being processed\n  var pendingBatch = {\n    seq: 0,\n    changes: [],\n    docs: []\n  }; // next batch, not yet ready to be processed\n  var writingCheckpoint = false;  // true while checkpoint is being written\n  var changesCompleted = false;   // true when all changes received\n  var replicationCompleted = false; // true when replication has completed\n  var last_seq = 0;\n  var continuous = opts.continuous || opts.live || false;\n  var batch_size = opts.batch_size || 100;\n  var batches_limit = opts.batches_limit || 10;\n  var changesPending = false;     // true while src.changes is running\n  var doc_ids = opts.doc_ids;\n  var repId;\n  var checkpointer;\n  var changedDocs = [];\n  // Like couchdb, every replication gets a unique session id\n  var session = uuid();\n\n  result = result || {\n    ok: true,\n    start_time: new Date(),\n    docs_read: 0,\n    docs_written: 0,\n    doc_write_failures: 0,\n    errors: []\n  };\n\n  var changesOpts = {};\n  returnValue.ready(src, target);\n\n  function initCheckpointer() {\n    if (checkpointer) {\n      return PouchPromise$1.resolve();\n    }\n    return generateReplicationId(src, target, opts).then(function (res) {\n      repId = res;\n      checkpointer = new Checkpointer(src, target, repId, returnValue);\n    });\n  }\n\n  function writeDocs() {\n    changedDocs = [];\n\n    if (currentBatch.docs.length === 0) {\n      return;\n    }\n    var docs = currentBatch.docs;\n    var bulkOpts = {timeout: opts.timeout};\n    return target.bulkDocs({docs: docs, new_edits: false}, bulkOpts).then(function (res) {\n      /* istanbul ignore if */\n      if (returnValue.cancelled) {\n        completeReplication();\n        throw new Error('cancelled');\n      }\n\n      // `res` doesn't include full documents (which live in `docs`), so we create a map of \n      // (id -> error), and check for errors while iterating over `docs`\n      var errorsById = Object.create(null);\n      res.forEach(function (res) {\n        if (res.error) {\n          errorsById[res.id] = res;\n        }\n      });\n\n      var errorsNo = Object.keys(errorsById).length;\n      result.doc_write_failures += errorsNo;\n      result.docs_written += docs.length - errorsNo;\n\n      docs.forEach(function (doc) {\n        var error = errorsById[doc._id];\n        if (error) {\n          result.errors.push(error);\n          if (error.name === 'unauthorized' || error.name === 'forbidden') {\n            returnValue.emit('denied', clone(error));\n          } else {\n            throw error;\n          }\n        } else {\n          changedDocs.push(doc);\n        }\n      });\n\n    }, function (err) {\n      result.doc_write_failures += docs.length;\n      throw err;\n    });\n  }\n\n  function finishBatch() {\n    if (currentBatch.error) {\n      throw new Error('There was a problem getting docs.');\n    }\n    result.last_seq = last_seq = currentBatch.seq;\n    var outResult = clone(result);\n    if (changedDocs.length) {\n      outResult.docs = changedDocs;\n      returnValue.emit('change', outResult);\n    }\n    writingCheckpoint = true;\n    return checkpointer.writeCheckpoint(currentBatch.seq,\n        session).then(function () {\n      writingCheckpoint = false;\n      /* istanbul ignore if */\n      if (returnValue.cancelled) {\n        completeReplication();\n        throw new Error('cancelled');\n      }\n      currentBatch = undefined;\n      getChanges();\n    }).catch(function (err) {\n      onCheckpointError(err);\n      throw err;\n    });\n  }\n\n  function getDiffs() {\n    var diff = {};\n    currentBatch.changes.forEach(function (change) {\n      // Couchbase Sync Gateway emits these, but we can ignore them\n      /* istanbul ignore if */\n      if (change.id === \"_user/\") {\n        return;\n      }\n      diff[change.id] = change.changes.map(function (x) {\n        return x.rev;\n      });\n    });\n    return target.revsDiff(diff).then(function (diffs) {\n      /* istanbul ignore if */\n      if (returnValue.cancelled) {\n        completeReplication();\n        throw new Error('cancelled');\n      }\n      // currentBatch.diffs elements are deleted as the documents are written\n      currentBatch.diffs = diffs;\n    });\n  }\n\n  function getBatchDocs() {\n    return getDocs(src, target, currentBatch.diffs, returnValue).then(function (got) {\n      currentBatch.error = !got.ok;\n      got.docs.forEach(function (doc) {\n        delete currentBatch.diffs[doc._id];\n        result.docs_read++;\n        currentBatch.docs.push(doc);\n      });\n    });\n  }\n\n  function startNextBatch() {\n    if (returnValue.cancelled || currentBatch) {\n      return;\n    }\n    if (batches.length === 0) {\n      processPendingBatch(true);\n      return;\n    }\n    currentBatch = batches.shift();\n    getDiffs()\n      .then(getBatchDocs)\n      .then(writeDocs)\n      .then(finishBatch)\n      .then(startNextBatch)\n      .catch(function (err) {\n        abortReplication('batch processing terminated with error', err);\n      });\n  }\n\n\n  function processPendingBatch(immediate) {\n    if (pendingBatch.changes.length === 0) {\n      if (batches.length === 0 && !currentBatch) {\n        if ((continuous && changesOpts.live) || changesCompleted) {\n          returnValue.state = 'pending';\n          returnValue.emit('paused');\n        }\n        if (changesCompleted) {\n          completeReplication();\n        }\n      }\n      return;\n    }\n    if (\n      immediate ||\n      changesCompleted ||\n      pendingBatch.changes.length >= batch_size\n    ) {\n      batches.push(pendingBatch);\n      pendingBatch = {\n        seq: 0,\n        changes: [],\n        docs: []\n      };\n      if (returnValue.state === 'pending' || returnValue.state === 'stopped') {\n        returnValue.state = 'active';\n        returnValue.emit('active');\n      }\n      startNextBatch();\n    }\n  }\n\n\n  function abortReplication(reason, err) {\n    if (replicationCompleted) {\n      return;\n    }\n    if (!err.message) {\n      err.message = reason;\n    }\n    result.ok = false;\n    result.status = 'aborting';\n    batches = [];\n    pendingBatch = {\n      seq: 0,\n      changes: [],\n      docs: []\n    };\n    completeReplication(err);\n  }\n\n\n  function completeReplication(fatalError) {\n    if (replicationCompleted) {\n      return;\n    }\n    /* istanbul ignore if */\n    if (returnValue.cancelled) {\n      result.status = 'cancelled';\n      if (writingCheckpoint) {\n        return;\n      }\n    }\n    result.status = result.status || 'complete';\n    result.end_time = new Date();\n    result.last_seq = last_seq;\n    replicationCompleted = true;\n\n    if (fatalError) {\n      fatalError.result = result;\n\n      if (fatalError.name === 'unauthorized' || fatalError.name === 'forbidden') {\n        returnValue.emit('error', fatalError);\n        returnValue.removeAllListeners();\n      } else {\n        backOff(opts, returnValue, fatalError, function () {\n          replicate(src, target, opts, returnValue);\n        });\n      }\n    } else {\n      returnValue.emit('complete', result);\n      returnValue.removeAllListeners();\n    }\n  }\n\n\n  function onChange(change) {\n    /* istanbul ignore if */\n    if (returnValue.cancelled) {\n      return completeReplication();\n    }\n    var filter = filterChange(opts)(change);\n    if (!filter) {\n      return;\n    }\n    pendingBatch.seq = change.seq;\n    pendingBatch.changes.push(change);\n    processPendingBatch(batches.length === 0 && changesOpts.live);\n  }\n\n\n  function onChangesComplete(changes) {\n    changesPending = false;\n    /* istanbul ignore if */\n    if (returnValue.cancelled) {\n      return completeReplication();\n    }\n\n    // if no results were returned then we're done,\n    // else fetch more\n    if (changes.results.length > 0) {\n      changesOpts.since = changes.last_seq;\n      getChanges();\n      processPendingBatch(true);\n    } else {\n\n      var complete = function () {\n        if (continuous) {\n          changesOpts.live = true;\n          getChanges();\n        } else {\n          changesCompleted = true;\n        }\n        processPendingBatch(true);\n      };\n\n      // update the checkpoint so we start from the right seq next time\n      if (!currentBatch && changes.results.length === 0) {\n        writingCheckpoint = true;\n        checkpointer.writeCheckpoint(changes.last_seq,\n            session).then(function () {\n          writingCheckpoint = false;\n          result.last_seq = last_seq = changes.last_seq;\n          complete();\n        })\n        .catch(onCheckpointError);\n      } else {\n        complete();\n      }\n    }\n  }\n\n\n  function onChangesError(err) {\n    changesPending = false;\n    /* istanbul ignore if */\n    if (returnValue.cancelled) {\n      return completeReplication();\n    }\n    abortReplication('changes rejected', err);\n  }\n\n\n  function getChanges() {\n    if (!(\n      !changesPending &&\n      !changesCompleted &&\n      batches.length < batches_limit\n      )) {\n      return;\n    }\n    changesPending = true;\n    function abortChanges() {\n      changes.cancel();\n    }\n    function removeListener() {\n      returnValue.removeListener('cancel', abortChanges);\n    }\n\n    if (returnValue._changes) { // remove old changes() and listeners\n      returnValue.removeListener('cancel', returnValue._abortChanges);\n      returnValue._changes.cancel();\n    }\n    returnValue.once('cancel', abortChanges);\n\n    var changes = src.changes(changesOpts)\n      .on('change', onChange);\n    changes.then(removeListener, removeListener);\n    changes.then(onChangesComplete)\n      .catch(onChangesError);\n\n    if (opts.retry) {\n      // save for later so we can cancel if necessary\n      returnValue._changes = changes;\n      returnValue._abortChanges = abortChanges;\n    }\n  }\n\n\n  function startChanges() {\n    initCheckpointer().then(function () {\n      /* istanbul ignore if */\n      if (returnValue.cancelled) {\n        completeReplication();\n        return;\n      }\n      return checkpointer.getCheckpoint().then(function (checkpoint) {\n        last_seq = checkpoint;\n        changesOpts = {\n          since: last_seq,\n          limit: batch_size,\n          batch_size: batch_size,\n          style: 'all_docs',\n          doc_ids: doc_ids,\n          return_docs: true // required so we know when we're done\n        };\n        if (opts.filter) {\n          if (typeof opts.filter !== 'string') {\n            // required for the client-side filter in onChange\n            changesOpts.include_docs = true;\n          } else { // ddoc filter\n            changesOpts.filter = opts.filter;\n          }\n        }\n        if ('heartbeat' in opts) {\n          changesOpts.heartbeat = opts.heartbeat;\n        }\n        if ('timeout' in opts) {\n          changesOpts.timeout = opts.timeout;\n        }\n        if (opts.query_params) {\n          changesOpts.query_params = opts.query_params;\n        }\n        if (opts.view) {\n          changesOpts.view = opts.view;\n        }\n        getChanges();\n      });\n    }).catch(function (err) {\n      abortReplication('getCheckpoint rejected with ', err);\n    });\n  }\n\n  /* istanbul ignore next */\n  function onCheckpointError(err) {\n    writingCheckpoint = false;\n    abortReplication('writeCheckpoint completed with error', err);\n  }\n\n  /* istanbul ignore if */\n  if (returnValue.cancelled) { // cancelled immediately\n    completeReplication();\n    return;\n  }\n\n  if (!returnValue._addedListeners) {\n    returnValue.once('cancel', completeReplication);\n\n    if (typeof opts.complete === 'function') {\n      returnValue.once('error', opts.complete);\n      returnValue.once('complete', function (result) {\n        opts.complete(null, result);\n      });\n    }\n    returnValue._addedListeners = true;\n  }\n\n  if (typeof opts.since === 'undefined') {\n    startChanges();\n  } else {\n    initCheckpointer().then(function () {\n      writingCheckpoint = true;\n      return checkpointer.writeCheckpoint(opts.since, session);\n    }).then(function () {\n      writingCheckpoint = false;\n      /* istanbul ignore if */\n      if (returnValue.cancelled) {\n        completeReplication();\n        return;\n      }\n      last_seq = opts.since;\n      startChanges();\n    }).catch(onCheckpointError);\n  }\n}\n\n// We create a basic promise so the caller can cancel the replication possibly\n// before we have actually started listening to changes etc\ninherits(Replication, events.EventEmitter);\nfunction Replication() {\n  events.EventEmitter.call(this);\n  this.cancelled = false;\n  this.state = 'pending';\n  var self = this;\n  var promise = new PouchPromise$1(function (fulfill, reject) {\n    self.once('complete', fulfill);\n    self.once('error', reject);\n  });\n  self.then = function (resolve, reject) {\n    return promise.then(resolve, reject);\n  };\n  self.catch = function (reject) {\n    return promise.catch(reject);\n  };\n  // As we allow error handling via \"error\" event as well,\n  // put a stub in here so that rejecting never throws UnhandledError.\n  self.catch(function () {});\n}\n\nReplication.prototype.cancel = function () {\n  this.cancelled = true;\n  this.state = 'cancelled';\n  this.emit('cancel');\n};\n\nReplication.prototype.ready = function (src, target) {\n  var self = this;\n  if (self._readyCalled) {\n    return;\n  }\n  self._readyCalled = true;\n\n  function onDestroy() {\n    self.cancel();\n  }\n  src.once('destroyed', onDestroy);\n  target.once('destroyed', onDestroy);\n  function cleanup() {\n    src.removeListener('destroyed', onDestroy);\n    target.removeListener('destroyed', onDestroy);\n  }\n  self.once('complete', cleanup);\n};\n\nfunction toPouch(db, opts) {\n  var PouchConstructor = opts.PouchConstructor;\n  if (typeof db === 'string') {\n    return new PouchConstructor(db, opts);\n  } else {\n    return db;\n  }\n}\n\nfunction replicateWrapper(src, target, opts, callback) {\n\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  if (typeof opts === 'undefined') {\n    opts = {};\n  }\n\n  if (opts.doc_ids && !Array.isArray(opts.doc_ids)) {\n    throw createError(BAD_REQUEST,\n                       \"`doc_ids` filter parameter is not a list.\");\n  }\n\n  opts.complete = callback;\n  opts = clone(opts);\n  opts.continuous = opts.continuous || opts.live;\n  opts.retry = ('retry' in opts) ? opts.retry : false;\n  /*jshint validthis:true */\n  opts.PouchConstructor = opts.PouchConstructor || this;\n  var replicateRet = new Replication(opts);\n  var srcPouch = toPouch(src, opts);\n  var targetPouch = toPouch(target, opts);\n  replicate(srcPouch, targetPouch, opts, replicateRet);\n  return replicateRet;\n}\n\ninherits(Sync, events.EventEmitter);\nfunction sync$1(src, target, opts, callback) {\n  if (typeof opts === 'function') {\n    callback = opts;\n    opts = {};\n  }\n  if (typeof opts === 'undefined') {\n    opts = {};\n  }\n  opts = clone(opts);\n  /*jshint validthis:true */\n  opts.PouchConstructor = opts.PouchConstructor || this;\n  src = toPouch(src, opts);\n  target = toPouch(target, opts);\n  return new Sync(src, target, opts, callback);\n}\n\nfunction Sync(src, target, opts, callback) {\n  var self = this;\n  this.canceled = false;\n\n  var optsPush = opts.push ? assign$1({}, opts, opts.push) : opts;\n  var optsPull = opts.pull ? assign$1({}, opts, opts.pull) : opts;\n\n  this.push = replicateWrapper(src, target, optsPush);\n  this.pull = replicateWrapper(target, src, optsPull);\n\n  this.pushPaused = true;\n  this.pullPaused = true;\n\n  function pullChange(change) {\n    self.emit('change', {\n      direction: 'pull',\n      change: change\n    });\n  }\n  function pushChange(change) {\n    self.emit('change', {\n      direction: 'push',\n      change: change\n    });\n  }\n  function pushDenied(doc) {\n    self.emit('denied', {\n      direction: 'push',\n      doc: doc\n    });\n  }\n  function pullDenied(doc) {\n    self.emit('denied', {\n      direction: 'pull',\n      doc: doc\n    });\n  }\n  function pushPaused() {\n    self.pushPaused = true;\n    /* istanbul ignore if */\n    if (self.pullPaused) {\n      self.emit('paused');\n    }\n  }\n  function pullPaused() {\n    self.pullPaused = true;\n    /* istanbul ignore if */\n    if (self.pushPaused) {\n      self.emit('paused');\n    }\n  }\n  function pushActive() {\n    self.pushPaused = false;\n    /* istanbul ignore if */\n    if (self.pullPaused) {\n      self.emit('active', {\n        direction: 'push'\n      });\n    }\n  }\n  function pullActive() {\n    self.pullPaused = false;\n    /* istanbul ignore if */\n    if (self.pushPaused) {\n      self.emit('active', {\n        direction: 'pull'\n      });\n    }\n  }\n\n  var removed = {};\n\n  function removeAll(type) { // type is 'push' or 'pull'\n    return function (event, func) {\n      var isChange = event === 'change' &&\n        (func === pullChange || func === pushChange);\n      var isDenied = event === 'denied' &&\n        (func === pullDenied || func === pushDenied);\n      var isPaused = event === 'paused' &&\n        (func === pullPaused || func === pushPaused);\n      var isActive = event === 'active' &&\n        (func === pullActive || func === pushActive);\n\n      if (isChange || isDenied || isPaused || isActive) {\n        if (!(event in removed)) {\n          removed[event] = {};\n        }\n        removed[event][type] = true;\n        if (Object.keys(removed[event]).length === 2) {\n          // both push and pull have asked to be removed\n          self.removeAllListeners(event);\n        }\n      }\n    };\n  }\n\n  if (opts.live) {\n    this.push.on('complete', self.pull.cancel.bind(self.pull));\n    this.pull.on('complete', self.push.cancel.bind(self.push));\n  }\n\n  function addOneListener(ee, event, listener) {\n    if (ee.listeners(event).indexOf(listener) == -1) {\n      ee.on(event, listener);\n    }\n  }\n\n  this.on('newListener', function (event) {\n    if (event === 'change') {\n      addOneListener(self.pull, 'change', pullChange);\n      addOneListener(self.push, 'change', pushChange);\n    } else if (event === 'denied') {\n      addOneListener(self.pull, 'denied', pullDenied);\n      addOneListener(self.push, 'denied', pushDenied);\n    } else if (event === 'active') {\n      addOneListener(self.pull, 'active', pullActive);\n      addOneListener(self.push, 'active', pushActive);\n    } else if (event === 'paused') {\n      addOneListener(self.pull, 'paused', pullPaused);\n      addOneListener(self.push, 'paused', pushPaused);\n    }\n  });\n\n  this.on('removeListener', function (event) {\n    if (event === 'change') {\n      self.pull.removeListener('change', pullChange);\n      self.push.removeListener('change', pushChange);\n    } else if (event === 'denied') {\n      self.pull.removeListener('denied', pullDenied);\n      self.push.removeListener('denied', pushDenied);\n    } else if (event === 'active') {\n      self.pull.removeListener('active', pullActive);\n      self.push.removeListener('active', pushActive);\n    } else if (event === 'paused') {\n      self.pull.removeListener('paused', pullPaused);\n      self.push.removeListener('paused', pushPaused);\n    }\n  });\n\n  this.pull.on('removeListener', removeAll('pull'));\n  this.push.on('removeListener', removeAll('push'));\n\n  var promise = PouchPromise$1.all([\n    this.push,\n    this.pull\n  ]).then(function (resp) {\n    var out = {\n      push: resp[0],\n      pull: resp[1]\n    };\n    self.emit('complete', out);\n    if (callback) {\n      callback(null, out);\n    }\n    self.removeAllListeners();\n    return out;\n  }, function (err) {\n    self.cancel();\n    if (callback) {\n      // if there's a callback, then the callback can receive\n      // the error event\n      callback(err);\n    } else {\n      // if there's no callback, then we're safe to emit an error\n      // event, which would otherwise throw an unhandled error\n      // due to 'error' being a special event in EventEmitters\n      self.emit('error', err);\n    }\n    self.removeAllListeners();\n    if (callback) {\n      // no sense throwing if we're already emitting an 'error' event\n      throw err;\n    }\n  });\n\n  this.then = function (success, err) {\n    return promise.then(success, err);\n  };\n\n  this.catch = function (err) {\n    return promise.catch(err);\n  };\n}\n\nSync.prototype.cancel = function () {\n  if (!this.canceled) {\n    this.canceled = true;\n    this.push.cancel();\n    this.pull.cancel();\n  }\n};\n\nfunction replication(PouchDB) {\n  PouchDB.replicate = replicateWrapper;\n  PouchDB.sync = sync$1;\n\n  Object.defineProperty(PouchDB.prototype, 'replicate', {\n    get: function () {\n      var self = this;\n      return {\n        from: function (other, opts, callback) {\n          return self.constructor.replicate(other, self, opts, callback);\n        },\n        to: function (other, opts, callback) {\n          return self.constructor.replicate(self, other, opts, callback);\n        }\n      };\n    }\n  });\n\n  PouchDB.prototype.sync = function (dbName, opts, callback) {\n    return this.constructor.sync(this, dbName, opts, callback);\n  };\n}\n\nPouchDB$3.plugin(IDBPouch)\n  .plugin(WebSqlPouch)\n  .plugin(HttpPouch$1)\n  .plugin(mapreduce)\n  .plugin(replication);\n\nmodule.exports = PouchDB$3;\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/pouchdb-browser/lib/index.js\n// module id = 4\n// module chunks = 0","'use strict';\n\nmodule.exports = argsArray;\n\nfunction argsArray(fun) {\n  return function () {\n    var len = arguments.length;\n    if (len) {\n      var args = [];\n      var i = -1;\n      while (++i < len) {\n        args[i] = arguments[i];\n      }\n      return fun.call(this, args);\n    } else {\n      return fun.call(this, []);\n    }\n  };\n}\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/argsarray/index.js\n// module id = 5\n// module chunks = 0","/**\n * This is the web browser implementation of `debug()`.\n *\n * Expose `debug()` as the module.\n */\n\nexports = module.exports = require('./debug');\nexports.log = log;\nexports.formatArgs = formatArgs;\nexports.save = save;\nexports.load = load;\nexports.useColors = useColors;\nexports.storage = 'undefined' != typeof chrome\n               && 'undefined' != typeof chrome.storage\n                  ? chrome.storage.local\n                  : localstorage();\n\n/**\n * Colors.\n */\n\nexports.colors = [\n  'lightseagreen',\n  'forestgreen',\n  'goldenrod',\n  'dodgerblue',\n  'darkorchid',\n  'crimson'\n];\n\n/**\n * Currently only WebKit-based Web Inspectors, Firefox >= v31,\n * and the Firebug extension (any Firefox version) are known\n * to support \"%c\" CSS customizations.\n *\n * TODO: add a `localStorage` variable to explicitly enable/disable colors\n */\n\nfunction useColors() {\n  // NB: In an Electron preload script, document will be defined but not fully\n  // initialized. Since we know we're in Chrome, we'll just detect this case\n  // explicitly\n  if (typeof window !== 'undefined' && window && typeof window.process !== 'undefined' && window.process.type === 'renderer') {\n    return true;\n  }\n\n  // is webkit? http://stackoverflow.com/a/16459606/376773\n  // document is undefined in react-native: https://github.com/facebook/react-native/pull/1632\n  return (typeof document !== 'undefined' && document && 'WebkitAppearance' in document.documentElement.style) ||\n    // is firebug? http://stackoverflow.com/a/398120/376773\n    (typeof window !== 'undefined' && window && window.console && (console.firebug || (console.exception && console.table))) ||\n    // is firefox >= v31?\n    // https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages\n    (typeof navigator !== 'undefined' && navigator && navigator.userAgent && navigator.userAgent.toLowerCase().match(/firefox\\/(\\d+)/) && parseInt(RegExp.$1, 10) >= 31) ||\n    // double check webkit in userAgent just in case we are in a worker\n    (typeof navigator !== 'undefined' && navigator && navigator.userAgent && navigator.userAgent.toLowerCase().match(/applewebkit\\/(\\d+)/));\n}\n\n/**\n * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.\n */\n\nexports.formatters.j = function(v) {\n  try {\n    return JSON.stringify(v);\n  } catch (err) {\n    return '[UnexpectedJSONParseError]: ' + err.message;\n  }\n};\n\n\n/**\n * Colorize log arguments if enabled.\n *\n * @api public\n */\n\nfunction formatArgs(args) {\n  var useColors = this.useColors;\n\n  args[0] = (useColors ? '%c' : '')\n    + this.namespace\n    + (useColors ? ' %c' : ' ')\n    + args[0]\n    + (useColors ? '%c ' : ' ')\n    + '+' + exports.humanize(this.diff);\n\n  if (!useColors) return;\n\n  var c = 'color: ' + this.color;\n  args.splice(1, 0, c, 'color: inherit')\n\n  // the final \"%c\" is somewhat tricky, because there could be other\n  // arguments passed either before or after the %c, so we need to\n  // figure out the correct index to insert the CSS into\n  var index = 0;\n  var lastC = 0;\n  args[0].replace(/%[a-zA-Z%]/g, function(match) {\n    if ('%%' === match) return;\n    index++;\n    if ('%c' === match) {\n      // we only are interested in the *last* %c\n      // (the user may have provided their own)\n      lastC = index;\n    }\n  });\n\n  args.splice(lastC, 0, c);\n}\n\n/**\n * Invokes `console.log()` when available.\n * No-op when `console.log` is not a \"function\".\n *\n * @api public\n */\n\nfunction log() {\n  // this hackery is required for IE8/9, where\n  // the `console.log` function doesn't have 'apply'\n  return 'object' === typeof console\n    && console.log\n    && Function.prototype.apply.call(console.log, console, arguments);\n}\n\n/**\n * Save `namespaces`.\n *\n * @param {String} namespaces\n * @api private\n */\n\nfunction save(namespaces) {\n  try {\n    if (null == namespaces) {\n      exports.storage.removeItem('debug');\n    } else {\n      exports.storage.debug = namespaces;\n    }\n  } catch(e) {}\n}\n\n/**\n * Load `namespaces`.\n *\n * @return {String} returns the previously persisted debug modes\n * @api private\n */\n\nfunction load() {\n  try {\n    return exports.storage.debug;\n  } catch(e) {}\n\n  // If debug isn't set in LS, and we're in Electron, try to load $DEBUG\n  if (typeof process !== 'undefined' && 'env' in process) {\n    return process.env.DEBUG;\n  }\n}\n\n/**\n * Enable namespaces listed in `localStorage.debug` initially.\n */\n\nexports.enable(load());\n\n/**\n * Localstorage attempts to return the localstorage.\n *\n * This is necessary because safari throws\n * when a user disables cookies/localstorage\n * and you attempt to access it.\n *\n * @return {LocalStorage}\n * @api private\n */\n\nfunction localstorage() {\n  try {\n    return window.localStorage;\n  } catch (e) {}\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/debug/src/browser.js\n// module id = 6\n// module chunks = 0","\n/**\n * This is the common logic for both the Node.js and web browser\n * implementations of `debug()`.\n *\n * Expose `debug()` as the module.\n */\n\nexports = module.exports = createDebug.debug = createDebug.default = createDebug;\nexports.coerce = coerce;\nexports.disable = disable;\nexports.enable = enable;\nexports.enabled = enabled;\nexports.humanize = require('ms');\n\n/**\n * The currently active debug mode names, and names to skip.\n */\n\nexports.names = [];\nexports.skips = [];\n\n/**\n * Map of special \"%n\" handling functions, for the debug \"format\" argument.\n *\n * Valid key names are a single, lower or upper-case letter, i.e. \"n\" and \"N\".\n */\n\nexports.formatters = {};\n\n/**\n * Previous log timestamp.\n */\n\nvar prevTime;\n\n/**\n * Select a color.\n * @param {String} namespace\n * @return {Number}\n * @api private\n */\n\nfunction selectColor(namespace) {\n  var hash = 0, i;\n\n  for (i in namespace) {\n    hash  = ((hash << 5) - hash) + namespace.charCodeAt(i);\n    hash |= 0; // Convert to 32bit integer\n  }\n\n  return exports.colors[Math.abs(hash) % exports.colors.length];\n}\n\n/**\n * Create a debugger with the given `namespace`.\n *\n * @param {String} namespace\n * @return {Function}\n * @api public\n */\n\nfunction createDebug(namespace) {\n\n  function debug() {\n    // disabled?\n    if (!debug.enabled) return;\n\n    var self = debug;\n\n    // set `diff` timestamp\n    var curr = +new Date();\n    var ms = curr - (prevTime || curr);\n    self.diff = ms;\n    self.prev = prevTime;\n    self.curr = curr;\n    prevTime = curr;\n\n    // turn the `arguments` into a proper Array\n    var args = new Array(arguments.length);\n    for (var i = 0; i < args.length; i++) {\n      args[i] = arguments[i];\n    }\n\n    args[0] = exports.coerce(args[0]);\n\n    if ('string' !== typeof args[0]) {\n      // anything else let's inspect with %O\n      args.unshift('%O');\n    }\n\n    // apply any `formatters` transformations\n    var index = 0;\n    args[0] = args[0].replace(/%([a-zA-Z%])/g, function(match, format) {\n      // if we encounter an escaped % then don't increase the array index\n      if (match === '%%') return match;\n      index++;\n      var formatter = exports.formatters[format];\n      if ('function' === typeof formatter) {\n        var val = args[index];\n        match = formatter.call(self, val);\n\n        // now we need to remove `args[index]` since it's inlined in the `format`\n        args.splice(index, 1);\n        index--;\n      }\n      return match;\n    });\n\n    // apply env-specific formatting (colors, etc.)\n    exports.formatArgs.call(self, args);\n\n    var logFn = debug.log || exports.log || console.log.bind(console);\n    logFn.apply(self, args);\n  }\n\n  debug.namespace = namespace;\n  debug.enabled = exports.enabled(namespace);\n  debug.useColors = exports.useColors();\n  debug.color = selectColor(namespace);\n\n  // env-specific initialization logic for debug instances\n  if ('function' === typeof exports.init) {\n    exports.init(debug);\n  }\n\n  return debug;\n}\n\n/**\n * Enables a debug mode by namespaces. This can include modes\n * separated by a colon and wildcards.\n *\n * @param {String} namespaces\n * @api public\n */\n\nfunction enable(namespaces) {\n  exports.save(namespaces);\n\n  var split = (namespaces || '').split(/[\\s,]+/);\n  var len = split.length;\n\n  for (var i = 0; i < len; i++) {\n    if (!split[i]) continue; // ignore empty strings\n    namespaces = split[i].replace(/\\*/g, '.*?');\n    if (namespaces[0] === '-') {\n      exports.skips.push(new RegExp('^' + namespaces.substr(1) + '$'));\n    } else {\n      exports.names.push(new RegExp('^' + namespaces + '$'));\n    }\n  }\n}\n\n/**\n * Disable debug output.\n *\n * @api public\n */\n\nfunction disable() {\n  exports.enable('');\n}\n\n/**\n * Returns true if the given mode name is enabled, false otherwise.\n *\n * @param {String} name\n * @return {Boolean}\n * @api public\n */\n\nfunction enabled(name) {\n  var i, len;\n  for (i = 0, len = exports.skips.length; i < len; i++) {\n    if (exports.skips[i].test(name)) {\n      return false;\n    }\n  }\n  for (i = 0, len = exports.names.length; i < len; i++) {\n    if (exports.names[i].test(name)) {\n      return true;\n    }\n  }\n  return false;\n}\n\n/**\n * Coerce `val`.\n *\n * @param {Mixed} val\n * @return {Mixed}\n * @api private\n */\n\nfunction coerce(val) {\n  if (val instanceof Error) return val.stack || val.message;\n  return val;\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/debug/src/debug.js\n// module id = 7\n// module chunks = 0","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nfunction EventEmitter() {\n  this._events = this._events || {};\n  this._maxListeners = this._maxListeners || undefined;\n}\nmodule.exports = EventEmitter;\n\n// Backwards-compat with node 0.10.x\nEventEmitter.EventEmitter = EventEmitter;\n\nEventEmitter.prototype._events = undefined;\nEventEmitter.prototype._maxListeners = undefined;\n\n// By default EventEmitters will print a warning if more than 10 listeners are\n// added to it. This is a useful default which helps finding memory leaks.\nEventEmitter.defaultMaxListeners = 10;\n\n// Obviously not all Emitters should be limited to 10. This function allows\n// that to be increased. Set to zero for unlimited.\nEventEmitter.prototype.setMaxListeners = function(n) {\n  if (!isNumber(n) || n < 0 || isNaN(n))\n    throw TypeError('n must be a positive number');\n  this._maxListeners = n;\n  return this;\n};\n\nEventEmitter.prototype.emit = function(type) {\n  var er, handler, len, args, i, listeners;\n\n  if (!this._events)\n    this._events = {};\n\n  // If there is no 'error' event listener then throw.\n  if (type === 'error') {\n    if (!this._events.error ||\n        (isObject(this._events.error) && !this._events.error.length)) {\n      er = arguments[1];\n      if (er instanceof Error) {\n        throw er; // Unhandled 'error' event\n      } else {\n        // At least give some kind of context to the user\n        var err = new Error('Uncaught, unspecified \"error\" event. (' + er + ')');\n        err.context = er;\n        throw err;\n      }\n    }\n  }\n\n  handler = this._events[type];\n\n  if (isUndefined(handler))\n    return false;\n\n  if (isFunction(handler)) {\n    switch (arguments.length) {\n      // fast cases\n      case 1:\n        handler.call(this);\n        break;\n      case 2:\n        handler.call(this, arguments[1]);\n        break;\n      case 3:\n        handler.call(this, arguments[1], arguments[2]);\n        break;\n      // slower\n      default:\n        args = Array.prototype.slice.call(arguments, 1);\n        handler.apply(this, args);\n    }\n  } else if (isObject(handler)) {\n    args = Array.prototype.slice.call(arguments, 1);\n    listeners = handler.slice();\n    len = listeners.length;\n    for (i = 0; i < len; i++)\n      listeners[i].apply(this, args);\n  }\n\n  return true;\n};\n\nEventEmitter.prototype.addListener = function(type, listener) {\n  var m;\n\n  if (!isFunction(listener))\n    throw TypeError('listener must be a function');\n\n  if (!this._events)\n    this._events = {};\n\n  // To avoid recursion in the case that type === \"newListener\"! Before\n  // adding it to the listeners, first emit \"newListener\".\n  if (this._events.newListener)\n    this.emit('newListener', type,\n              isFunction(listener.listener) ?\n              listener.listener : listener);\n\n  if (!this._events[type])\n    // Optimize the case of one listener. Don't need the extra array object.\n    this._events[type] = listener;\n  else if (isObject(this._events[type]))\n    // If we've already got an array, just append.\n    this._events[type].push(listener);\n  else\n    // Adding the second element, need to change to array.\n    this._events[type] = [this._events[type], listener];\n\n  // Check for listener leak\n  if (isObject(this._events[type]) && !this._events[type].warned) {\n    if (!isUndefined(this._maxListeners)) {\n      m = this._maxListeners;\n    } else {\n      m = EventEmitter.defaultMaxListeners;\n    }\n\n    if (m && m > 0 && this._events[type].length > m) {\n      this._events[type].warned = true;\n      console.error('(node) warning: possible EventEmitter memory ' +\n                    'leak detected. %d listeners added. ' +\n                    'Use emitter.setMaxListeners() to increase limit.',\n                    this._events[type].length);\n      if (typeof console.trace === 'function') {\n        // not supported in IE 10\n        console.trace();\n      }\n    }\n  }\n\n  return this;\n};\n\nEventEmitter.prototype.on = EventEmitter.prototype.addListener;\n\nEventEmitter.prototype.once = function(type, listener) {\n  if (!isFunction(listener))\n    throw TypeError('listener must be a function');\n\n  var fired = false;\n\n  function g() {\n    this.removeListener(type, g);\n\n    if (!fired) {\n      fired = true;\n      listener.apply(this, arguments);\n    }\n  }\n\n  g.listener = listener;\n  this.on(type, g);\n\n  return this;\n};\n\n// emits a 'removeListener' event iff the listener was removed\nEventEmitter.prototype.removeListener = function(type, listener) {\n  var list, position, length, i;\n\n  if (!isFunction(listener))\n    throw TypeError('listener must be a function');\n\n  if (!this._events || !this._events[type])\n    return this;\n\n  list = this._events[type];\n  length = list.length;\n  position = -1;\n\n  if (list === listener ||\n      (isFunction(list.listener) && list.listener === listener)) {\n    delete this._events[type];\n    if (this._events.removeListener)\n      this.emit('removeListener', type, listener);\n\n  } else if (isObject(list)) {\n    for (i = length; i-- > 0;) {\n      if (list[i] === listener ||\n          (list[i].listener && list[i].listener === listener)) {\n        position = i;\n        break;\n      }\n    }\n\n    if (position < 0)\n      return this;\n\n    if (list.length === 1) {\n      list.length = 0;\n      delete this._events[type];\n    } else {\n      list.splice(position, 1);\n    }\n\n    if (this._events.removeListener)\n      this.emit('removeListener', type, listener);\n  }\n\n  return this;\n};\n\nEventEmitter.prototype.removeAllListeners = function(type) {\n  var key, listeners;\n\n  if (!this._events)\n    return this;\n\n  // not listening for removeListener, no need to emit\n  if (!this._events.removeListener) {\n    if (arguments.length === 0)\n      this._events = {};\n    else if (this._events[type])\n      delete this._events[type];\n    return this;\n  }\n\n  // emit removeListener for all listeners on all events\n  if (arguments.length === 0) {\n    for (key in this._events) {\n      if (key === 'removeListener') continue;\n      this.removeAllListeners(key);\n    }\n    this.removeAllListeners('removeListener');\n    this._events = {};\n    return this;\n  }\n\n  listeners = this._events[type];\n\n  if (isFunction(listeners)) {\n    this.removeListener(type, listeners);\n  } else if (listeners) {\n    // LIFO order\n    while (listeners.length)\n      this.removeListener(type, listeners[listeners.length - 1]);\n  }\n  delete this._events[type];\n\n  return this;\n};\n\nEventEmitter.prototype.listeners = function(type) {\n  var ret;\n  if (!this._events || !this._events[type])\n    ret = [];\n  else if (isFunction(this._events[type]))\n    ret = [this._events[type]];\n  else\n    ret = this._events[type].slice();\n  return ret;\n};\n\nEventEmitter.prototype.listenerCount = function(type) {\n  if (this._events) {\n    var evlistener = this._events[type];\n\n    if (isFunction(evlistener))\n      return 1;\n    else if (evlistener)\n      return evlistener.length;\n  }\n  return 0;\n};\n\nEventEmitter.listenerCount = function(emitter, type) {\n  return emitter.listenerCount(type);\n};\n\nfunction isFunction(arg) {\n  return typeof arg === 'function';\n}\n\nfunction isNumber(arg) {\n  return typeof arg === 'number';\n}\n\nfunction isObject(arg) {\n  return typeof arg === 'object' && arg !== null;\n}\n\nfunction isUndefined(arg) {\n  return arg === void 0;\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/events/events.js\n// module id = 8\n// module chunks = 0","if (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    ctor.prototype = Object.create(superCtor.prototype, {\n      constructor: {\n        value: ctor,\n        enumerable: false,\n        writable: true,\n        configurable: true\n      }\n    });\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    var TempCtor = function () {}\n    TempCtor.prototype = superCtor.prototype\n    ctor.prototype = new TempCtor()\n    ctor.prototype.constructor = ctor\n  }\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/inherits/inherits_browser.js\n// module id = 9\n// module chunks = 0","'use strict';\nvar immediate = require('immediate');\n\n/* istanbul ignore next */\nfunction INTERNAL() {}\n\nvar handlers = {};\n\nvar REJECTED = ['REJECTED'];\nvar FULFILLED = ['FULFILLED'];\nvar PENDING = ['PENDING'];\n\nmodule.exports = Promise;\n\nfunction Promise(resolver) {\n  if (typeof resolver !== 'function') {\n    throw new TypeError('resolver must be a function');\n  }\n  this.state = PENDING;\n  this.queue = [];\n  this.outcome = void 0;\n  if (resolver !== INTERNAL) {\n    safelyResolveThenable(this, resolver);\n  }\n}\n\nPromise.prototype[\"catch\"] = function (onRejected) {\n  return this.then(null, onRejected);\n};\nPromise.prototype.then = function (onFulfilled, onRejected) {\n  if (typeof onFulfilled !== 'function' && this.state === FULFILLED ||\n    typeof onRejected !== 'function' && this.state === REJECTED) {\n    return this;\n  }\n  var promise = new this.constructor(INTERNAL);\n  if (this.state !== PENDING) {\n    var resolver = this.state === FULFILLED ? onFulfilled : onRejected;\n    unwrap(promise, resolver, this.outcome);\n  } else {\n    this.queue.push(new QueueItem(promise, onFulfilled, onRejected));\n  }\n\n  return promise;\n};\nfunction QueueItem(promise, onFulfilled, onRejected) {\n  this.promise = promise;\n  if (typeof onFulfilled === 'function') {\n    this.onFulfilled = onFulfilled;\n    this.callFulfilled = this.otherCallFulfilled;\n  }\n  if (typeof onRejected === 'function') {\n    this.onRejected = onRejected;\n    this.callRejected = this.otherCallRejected;\n  }\n}\nQueueItem.prototype.callFulfilled = function (value) {\n  handlers.resolve(this.promise, value);\n};\nQueueItem.prototype.otherCallFulfilled = function (value) {\n  unwrap(this.promise, this.onFulfilled, value);\n};\nQueueItem.prototype.callRejected = function (value) {\n  handlers.reject(this.promise, value);\n};\nQueueItem.prototype.otherCallRejected = function (value) {\n  unwrap(this.promise, this.onRejected, value);\n};\n\nfunction unwrap(promise, func, value) {\n  immediate(function () {\n    var returnValue;\n    try {\n      returnValue = func(value);\n    } catch (e) {\n      return handlers.reject(promise, e);\n    }\n    if (returnValue === promise) {\n      handlers.reject(promise, new TypeError('Cannot resolve promise with itself'));\n    } else {\n      handlers.resolve(promise, returnValue);\n    }\n  });\n}\n\nhandlers.resolve = function (self, value) {\n  var result = tryCatch(getThen, value);\n  if (result.status === 'error') {\n    return handlers.reject(self, result.value);\n  }\n  var thenable = result.value;\n\n  if (thenable) {\n    safelyResolveThenable(self, thenable);\n  } else {\n    self.state = FULFILLED;\n    self.outcome = value;\n    var i = -1;\n    var len = self.queue.length;\n    while (++i < len) {\n      self.queue[i].callFulfilled(value);\n    }\n  }\n  return self;\n};\nhandlers.reject = function (self, error) {\n  self.state = REJECTED;\n  self.outcome = error;\n  var i = -1;\n  var len = self.queue.length;\n  while (++i < len) {\n    self.queue[i].callRejected(error);\n  }\n  return self;\n};\n\nfunction getThen(obj) {\n  // Make sure we only access the accessor once as required by the spec\n  var then = obj && obj.then;\n  if (obj && typeof obj === 'object' && typeof then === 'function') {\n    return function appyThen() {\n      then.apply(obj, arguments);\n    };\n  }\n}\n\nfunction safelyResolveThenable(self, thenable) {\n  // Either fulfill, reject or reject with error\n  var called = false;\n  function onError(value) {\n    if (called) {\n      return;\n    }\n    called = true;\n    handlers.reject(self, value);\n  }\n\n  function onSuccess(value) {\n    if (called) {\n      return;\n    }\n    called = true;\n    handlers.resolve(self, value);\n  }\n\n  function tryToUnwrap() {\n    thenable(onSuccess, onError);\n  }\n\n  var result = tryCatch(tryToUnwrap);\n  if (result.status === 'error') {\n    onError(result.value);\n  }\n}\n\nfunction tryCatch(func, value) {\n  var out = {};\n  try {\n    out.value = func(value);\n    out.status = 'success';\n  } catch (e) {\n    out.status = 'error';\n    out.value = e;\n  }\n  return out;\n}\n\nPromise.resolve = resolve;\nfunction resolve(value) {\n  if (value instanceof this) {\n    return value;\n  }\n  return handlers.resolve(new this(INTERNAL), value);\n}\n\nPromise.reject = reject;\nfunction reject(reason) {\n  var promise = new this(INTERNAL);\n  return handlers.reject(promise, reason);\n}\n\nPromise.all = all;\nfunction all(iterable) {\n  var self = this;\n  if (Object.prototype.toString.call(iterable) !== '[object Array]') {\n    return this.reject(new TypeError('must be an array'));\n  }\n\n  var len = iterable.length;\n  var called = false;\n  if (!len) {\n    return this.resolve([]);\n  }\n\n  var values = new Array(len);\n  var resolved = 0;\n  var i = -1;\n  var promise = new this(INTERNAL);\n\n  while (++i < len) {\n    allResolver(iterable[i], i);\n  }\n  return promise;\n  function allResolver(value, i) {\n    self.resolve(value).then(resolveFromAll, function (error) {\n      if (!called) {\n        called = true;\n        handlers.reject(promise, error);\n      }\n    });\n    function resolveFromAll(outValue) {\n      values[i] = outValue;\n      if (++resolved === len && !called) {\n        called = true;\n        handlers.resolve(promise, values);\n      }\n    }\n  }\n}\n\nPromise.race = race;\nfunction race(iterable) {\n  var self = this;\n  if (Object.prototype.toString.call(iterable) !== '[object Array]') {\n    return this.reject(new TypeError('must be an array'));\n  }\n\n  var len = iterable.length;\n  var called = false;\n  if (!len) {\n    return this.resolve([]);\n  }\n\n  var i = -1;\n  var promise = new this(INTERNAL);\n\n  while (++i < len) {\n    resolver(iterable[i]);\n  }\n  return promise;\n  function resolver(value) {\n    self.resolve(value).then(function (response) {\n      if (!called) {\n        called = true;\n        handlers.resolve(promise, response);\n      }\n    }, function (error) {\n      if (!called) {\n        called = true;\n        handlers.reject(promise, error);\n      }\n    });\n  }\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/lie/lib/browser.js\n// module id = 10\n// module chunks = 0","/**\n * Helpers.\n */\n\nvar s = 1000\nvar m = s * 60\nvar h = m * 60\nvar d = h * 24\nvar y = d * 365.25\n\n/**\n * Parse or format the given `val`.\n *\n * Options:\n *\n *  - `long` verbose formatting [false]\n *\n * @param {String|Number} val\n * @param {Object} options\n * @throws {Error} throw an error if val is not a non-empty string or a number\n * @return {String|Number}\n * @api public\n */\n\nmodule.exports = function (val, options) {\n  options = options || {}\n  var type = typeof val\n  if (type === 'string' && val.length > 0) {\n    return parse(val)\n  } else if (type === 'number' && isNaN(val) === false) {\n    return options.long ?\n\t\t\tfmtLong(val) :\n\t\t\tfmtShort(val)\n  }\n  throw new Error('val is not a non-empty string or a valid number. val=' + JSON.stringify(val))\n}\n\n/**\n * Parse the given `str` and return milliseconds.\n *\n * @param {String} str\n * @return {Number}\n * @api private\n */\n\nfunction parse(str) {\n  str = String(str)\n  if (str.length > 10000) {\n    return\n  }\n  var match = /^((?:\\d+)?\\.?\\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|years?|yrs?|y)?$/i.exec(str)\n  if (!match) {\n    return\n  }\n  var n = parseFloat(match[1])\n  var type = (match[2] || 'ms').toLowerCase()\n  switch (type) {\n    case 'years':\n    case 'year':\n    case 'yrs':\n    case 'yr':\n    case 'y':\n      return n * y\n    case 'days':\n    case 'day':\n    case 'd':\n      return n * d\n    case 'hours':\n    case 'hour':\n    case 'hrs':\n    case 'hr':\n    case 'h':\n      return n * h\n    case 'minutes':\n    case 'minute':\n    case 'mins':\n    case 'min':\n    case 'm':\n      return n * m\n    case 'seconds':\n    case 'second':\n    case 'secs':\n    case 'sec':\n    case 's':\n      return n * s\n    case 'milliseconds':\n    case 'millisecond':\n    case 'msecs':\n    case 'msec':\n    case 'ms':\n      return n\n    default:\n      return undefined\n  }\n}\n\n/**\n * Short format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtShort(ms) {\n  if (ms >= d) {\n    return Math.round(ms / d) + 'd'\n  }\n  if (ms >= h) {\n    return Math.round(ms / h) + 'h'\n  }\n  if (ms >= m) {\n    return Math.round(ms / m) + 'm'\n  }\n  if (ms >= s) {\n    return Math.round(ms / s) + 's'\n  }\n  return ms + 'ms'\n}\n\n/**\n * Long format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtLong(ms) {\n  return plural(ms, d, 'day') ||\n    plural(ms, h, 'hour') ||\n    plural(ms, m, 'minute') ||\n    plural(ms, s, 'second') ||\n    ms + ' ms'\n}\n\n/**\n * Pluralization helper.\n */\n\nfunction plural(ms, n, name) {\n  if (ms < n) {\n    return\n  }\n  if (ms < n * 1.5) {\n    return Math.floor(ms / n) + ' ' + name\n  }\n  return Math.ceil(ms / n) + ' ' + name + 's'\n}\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/ms/index.js\n// module id = 11\n// module chunks = 0","// shim for using process in browser\nvar process = module.exports = {};\n\n// cached from whatever global is present so that test runners that stub it\n// don't break things.  But we need to wrap it in a try catch in case it is\n// wrapped in strict mode code which doesn't define any globals.  It's inside a\n// function because try/catches deoptimize in certain engines.\n\nvar cachedSetTimeout;\nvar cachedClearTimeout;\n\nfunction defaultSetTimout() {\n    throw new Error('setTimeout has not been defined');\n}\nfunction defaultClearTimeout () {\n    throw new Error('clearTimeout has not been defined');\n}\n(function () {\n    try {\n        if (typeof setTimeout === 'function') {\n            cachedSetTimeout = setTimeout;\n        } else {\n            cachedSetTimeout = defaultSetTimout;\n        }\n    } catch (e) {\n        cachedSetTimeout = defaultSetTimout;\n    }\n    try {\n        if (typeof clearTimeout === 'function') {\n            cachedClearTimeout = clearTimeout;\n        } else {\n            cachedClearTimeout = defaultClearTimeout;\n        }\n    } catch (e) {\n        cachedClearTimeout = defaultClearTimeout;\n    }\n} ())\nfunction runTimeout(fun) {\n    if (cachedSetTimeout === setTimeout) {\n        //normal enviroments in sane situations\n        return setTimeout(fun, 0);\n    }\n    // if setTimeout wasn't available but was latter defined\n    if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {\n        cachedSetTimeout = setTimeout;\n        return setTimeout(fun, 0);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedSetTimeout(fun, 0);\n    } catch(e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally\n            return cachedSetTimeout.call(null, fun, 0);\n        } catch(e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error\n            return cachedSetTimeout.call(this, fun, 0);\n        }\n    }\n\n\n}\nfunction runClearTimeout(marker) {\n    if (cachedClearTimeout === clearTimeout) {\n        //normal enviroments in sane situations\n        return clearTimeout(marker);\n    }\n    // if clearTimeout wasn't available but was latter defined\n    if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {\n        cachedClearTimeout = clearTimeout;\n        return clearTimeout(marker);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedClearTimeout(marker);\n    } catch (e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally\n            return cachedClearTimeout.call(null, marker);\n        } catch (e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.\n            // Some versions of I.E. have different rules for clearTimeout vs setTimeout\n            return cachedClearTimeout.call(this, marker);\n        }\n    }\n\n\n\n}\nvar queue = [];\nvar draining = false;\nvar currentQueue;\nvar queueIndex = -1;\n\nfunction cleanUpNextTick() {\n    if (!draining || !currentQueue) {\n        return;\n    }\n    draining = false;\n    if (currentQueue.length) {\n        queue = currentQueue.concat(queue);\n    } else {\n        queueIndex = -1;\n    }\n    if (queue.length) {\n        drainQueue();\n    }\n}\n\nfunction drainQueue() {\n    if (draining) {\n        return;\n    }\n    var timeout = runTimeout(cleanUpNextTick);\n    draining = true;\n\n    var len = queue.length;\n    while(len) {\n        currentQueue = queue;\n        queue = [];\n        while (++queueIndex < len) {\n            if (currentQueue) {\n                currentQueue[queueIndex].run();\n            }\n        }\n        queueIndex = -1;\n        len = queue.length;\n    }\n    currentQueue = null;\n    draining = false;\n    runClearTimeout(timeout);\n}\n\nprocess.nextTick = function (fun) {\n    var args = new Array(arguments.length - 1);\n    if (arguments.length > 1) {\n        for (var i = 1; i < arguments.length; i++) {\n            args[i - 1] = arguments[i];\n        }\n    }\n    queue.push(new Item(fun, args));\n    if (queue.length === 1 && !draining) {\n        runTimeout(drainQueue);\n    }\n};\n\n// v8 likes predictible objects\nfunction Item(fun, array) {\n    this.fun = fun;\n    this.array = array;\n}\nItem.prototype.run = function () {\n    this.fun.apply(null, this.array);\n};\nprocess.title = 'browser';\nprocess.browser = true;\nprocess.env = {};\nprocess.argv = [];\nprocess.version = ''; // empty string to avoid regexp issues\nprocess.versions = {};\n\nfunction noop() {}\n\nprocess.on = noop;\nprocess.addListener = noop;\nprocess.once = noop;\nprocess.off = noop;\nprocess.removeListener = noop;\nprocess.removeAllListeners = noop;\nprocess.emit = noop;\n\nprocess.binding = function (name) {\n    throw new Error('process.binding is not supported');\n};\n\nprocess.cwd = function () { return '/' };\nprocess.chdir = function (dir) {\n    throw new Error('process.chdir is not supported');\n};\nprocess.umask = function() { return 0; };\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/process/browser.js\n// module id = 12\n// module chunks = 0","// Generated by CoffeeScript 1.9.2\n(function() {\n  var hasProp = {}.hasOwnProperty,\n    slice = [].slice;\n\n  module.exports = function(source, scope) {\n    var key, keys, value, values;\n    keys = [];\n    values = [];\n    for (key in scope) {\n      if (!hasProp.call(scope, key)) continue;\n      value = scope[key];\n      if (key === 'this') {\n        continue;\n      }\n      keys.push(key);\n      values.push(value);\n    }\n    return Function.apply(null, slice.call(keys).concat([source])).apply(scope[\"this\"], values);\n  };\n\n}).call(this);\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/scope-eval/scope_eval.js\n// module id = 13\n// module chunks = 0","/*\n * Sift 3.x\n *\n * Copryright 2015, Craig Condon\n * Licensed under MIT\n *\n * Filter JavaScript objects with mongodb queries\n */\n\n(function() {\n\n  'use strict';\n\n  /**\n   */\n\n  function isFunction(value) {\n    return typeof value === 'function';\n  }\n\n  /**\n   */\n\n  function isArray(value) {\n    return Object.prototype.toString.call(value) === '[object Array]';\n  }\n\n  /**\n   */\n\n  function comparable(value) {\n    if (value instanceof Date) {\n      return value.getTime();\n    } else if (value instanceof Array) {\n      return value.map(comparable);\n    } else {\n      return value;\n    }\n  }\n\n  function get(obj, key) {\n    if (obj.get) return obj.get(key);\n    return obj[key];\n  }\n\n  /**\n   */\n\n  function or(validator) {\n    return function(a, b) {\n      if (!isArray(b) || !b.length) return validator(a, b);\n      for (var i = 0, n = b.length; i < n; i++) if (validator(a, get(b,i))) return true;\n      return false;\n    }\n  }\n\n  /**\n   */\n\n  function and(validator) {\n    return function(a, b) {\n      if (!isArray(b) || !b.length) return validator(a, b);\n      for (var i = 0, n = b.length; i < n; i++) if (!validator(a, get(b, i))) return false;\n      return true;\n    };\n  }\n\n  function validate(validator, b) {\n    return validator.v(validator.a, b);\n  }\n\n  var operator = {\n\n    /**\n     */\n\n    $eq: or(function(a, b) {\n      return a(b);\n    }),\n\n    /**\n     */\n\n    $ne: and(function(a, b) {\n      return !a(b);\n    }),\n\n    /**\n     */\n\n    $or: function(a, b) {\n      for (var i = 0, n = a.length; i < n; i++) if (validate(get(a, i), b)) return true;\n      return false;\n    },\n\n    /**\n     */\n\n    $gt: or(function(a, b) {\n      return sift.compare(comparable(b), a) > 0;\n    }),\n\n    /**\n     */\n\n    $gte: or(function(a, b) {\n      return sift.compare(comparable(b), a) >= 0;\n    }),\n\n    /**\n     */\n\n    $lt: or(function(a, b) {\n      return sift.compare(comparable(b), a) < 0;\n    }),\n\n    /**\n     */\n\n    $lte: or(function(a, b) {\n      return sift.compare(comparable(b), a) <= 0;\n    }),\n\n    /**\n     */\n\n    $mod: or(function(a, b) {\n      return b % a[0] == a[1];\n    }),\n\n    /**\n     */\n\n    $in: function(a, b) {\n\n      if (b instanceof Array) {\n        for (var i = b.length; i--;) {\n          if (~a.indexOf(comparable(get(b, i)))) return true;\n        }\n      } else {\n        return !!~a.indexOf(comparable(b));\n      }\n\n      return false;\n    },\n\n    /**\n     */\n\n    $nin: function(a, b) {\n      return !operator.$in(a, b);\n    },\n\n    /**\n     */\n\n    $not: function(a, b) {\n      return !validate(a, b);\n    },\n\n    /**\n     */\n\n    $type: function(a, b) {\n      return b != void 0 ? b instanceof a || b.constructor == a : false;\n     },\n\n    /**\n     */\n\n    $all: function(a, b) {\n      return operator.$and(a, b);\n    },\n\n    /**\n     */\n\n    $size: function(a, b) {\n      return b ? a === b.length : false;\n    },\n\n    /**\n     */\n\n    $nor: function(a, b) {\n      // todo - this suffice? return !operator.$in(a)\n      for (var i = 0, n = a.length; i < n; i++) if (validate(get(a, i), b)) return false;\n      return true;\n    },\n\n    /**\n     */\n\n    $and: function(a, b) {\n      if (!b) b = [];\n      for (var i = 0, n = a.length; i < n; i++) if (!validate(get(a, i), b)) return false;\n      return true;\n    },\n\n    /**\n     */\n\n    $regex: or(function(a, b) {\n      return typeof b === 'string' && a.test(b);\n    }),\n\n    /**\n     */\n\n    $where: function(a, b) {\n      return a.call(b, b);\n    },\n\n    /**\n     */\n\n    $elemMatch: function(a, b) {\n      if (isArray(b)) return !!~search(b, a);\n      return validate(a, b);\n    },\n\n    /**\n     */\n\n    $exists: function(a, b) {\n      return (b != void 0) === a;\n    }\n  };\n\n  /**\n   */\n\n  var prepare = {\n\n    /**\n     */\n\n    $eq: function(a) {\n\n      if (a instanceof RegExp) {\n        return function(b) {\n          return typeof b === 'string' && a.test(b);\n        };\n      } else if (a instanceof Function) {\n        return a;\n      } else if (isArray(a) && !a.length) {\n        // Special case of a == []\n        return function(b) {\n          return (isArray(b) && !b.length);\n        };\n      } else if (a === null){\n        return function(b){\n          //will match both null and undefined\n          return b == null;\n        }\n      }\n\n      return function(b) {\n        return sift.compare(comparable(b), a) === 0;\n      };\n    },\n\n    /**\n     */\n\n    $ne: function(a) {\n      return prepare.$eq(a);\n    },\n\n    /**\n     */\n\n    $and: function(a) {\n      return a.map(parse);\n    },\n\n    /**\n     */\n\n    $all: function(a) {\n      return prepare.$and(a);\n    },\n\n    /**\n     */\n\n    $or: function(a) {\n      return a.map(parse);\n    },\n\n    /**\n     */\n\n    $nor: function(a) {\n      return a.map(parse);\n    },\n\n    /**\n     */\n\n    $not: function(a) {\n      return parse(a);\n    },\n\n    /**\n     */\n\n    $regex: function(a, query) {\n      return new RegExp(a, query.$options);\n    },\n\n    /**\n     */\n\n    $where: function(a) {\n      return typeof a === 'string' ? new Function('obj', 'return ' + a) : a;\n    },\n\n    /**\n     */\n\n    $elemMatch: function(a) {\n      return parse(a);\n    },\n\n    /**\n     */\n\n    $exists: function(a) {\n      return !!a;\n    }\n  };\n\n  /**\n   */\n\n  function search(array, validator) {\n\n    for (var i = 0; i < array.length; i++) {\n      if (validate(validator, get(array, i))) {\n        return i;\n      }\n    }\n\n    return -1;\n  }\n\n  /**\n   */\n\n  function createValidator(a, validate) {\n    return { a: a, v: validate };\n  }\n\n  /**\n   */\n\n  function nestedValidator(a, b) {\n    var values  = [];\n    findValues(b, a.k, 0, values);\n\n    if (values.length === 1) {\n      return validate(a.nv, values[0]);\n    }\n\n    return !!~search(values, a.nv);\n  }\n\n  /**\n   */\n\n  function findValues(current, keypath, index, values) {\n\n    if (index === keypath.length || current == void 0) {\n      values.push(current);\n      return;\n    }\n\n    var k = get(keypath, index);\n\n    // ensure that if current is an array, that the current key\n    // is NOT an array index. This sort of thing needs to work:\n    // sift({'foo.0':42}, [{foo: [42]}]);\n    if (isArray(current) && isNaN(Number(k))) {\n      for (var i = 0, n = current.length; i < n; i++) {\n        findValues(get(current, i), keypath, index, values);\n      }\n    } else {\n      findValues(get(current, k), keypath, index + 1, values);\n    }\n  }\n\n  /**\n   */\n\n  function createNestedValidator(keypath, a) {\n    return { a: { k: keypath, nv: a }, v: nestedValidator };\n  }\n\n  /**\n   * flatten the query\n   */\n\n  function parse(query) {\n    query = comparable(query);\n\n    if (!query || (query.constructor.toString() !== 'Object' &&\n        query.constructor.toString().replace(/\\n/g,'').replace(/ /g, '') !== 'functionObject(){[nativecode]}')) { // cross browser support\n      query = { $eq: query };\n    }\n\n    var validators = [];\n\n    for (var key in query) {\n      var a = query[key];\n\n      if (key === '$options') continue;\n\n      if (operator[key]) {\n        if (prepare[key]) a = prepare[key](a, query);\n        validators.push(createValidator(comparable(a), operator[key]));\n      } else {\n\n        if (key.charCodeAt(0) === 36) {\n          throw new Error('Unknown operation ' + key);\n        }\n\n        validators.push(createNestedValidator(key.split('.'), parse(a)));\n      }\n    }\n\n    return validators.length === 1 ? validators[0] : createValidator(validators, operator.$and);\n  }\n\n  /**\n   */\n\n  function createRootValidator(query, getter) {\n    var validator = parse(query);\n    if (getter) {\n      validator = {\n        a: validator,\n        v: function(a, b) {\n          return validate(a, getter(b));\n        }\n      };\n    }\n    return validator;\n  }\n\n  /**\n   */\n\n  function sift(query, array, getter) {\n\n    if (isFunction(array)) {\n      getter = array;\n      array  = void 0;\n    }\n\n    var validator = createRootValidator(query, getter);\n\n    function filter(b) {\n      return validate(validator, b);\n    }\n\n    if (array) {\n      return array.filter(filter);\n    }\n\n    return filter;\n  }\n\n  /**\n   */\n\n  sift.use = function(plugin) {\n    if (isFunction(plugin)) return plugin(sift);\n    for (var key in plugin) {\n      if (key.charCodeAt(0) === 36) operator[key] = plugin[key];\n    }\n  };\n\n  /**\n   */\n\n  sift.indexOf = function(query, array, getter) {\n    return search(array, createRootValidator(query, getter));\n  };\n\n  /**\n   */\n\n  sift.compare = function(a, b) {\n    if(a===b) return 0;\n    if(typeof a === typeof b) {\n      if (a > b) return 1;\n      if (a < b) return -1;\n    }\n  };\n\n  /* istanbul ignore next */\n  if (typeof module !== 'undefined' && typeof module.exports !== 'undefined') {\n    module.exports = sift;\n  }\n\n  if (typeof window !== 'undefined') {\n    window.sift = sift;\n  }\n})();\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/sift/sift.js\n// module id = 14\n// module chunks = 0","(function (factory) {\n    if (typeof exports === 'object') {\n        // Node/CommonJS\n        module.exports = factory();\n    } else if (typeof define === 'function' && define.amd) {\n        // AMD\n        define(factory);\n    } else {\n        // Browser globals (with support for web workers)\n        var glob;\n\n        try {\n            glob = window;\n        } catch (e) {\n            glob = self;\n        }\n\n        glob.SparkMD5 = factory();\n    }\n}(function (undefined) {\n\n    'use strict';\n\n    /*\n     * Fastest md5 implementation around (JKM md5).\n     * Credits: Joseph Myers\n     *\n     * @see http://www.myersdaily.org/joseph/javascript/md5-text.html\n     * @see http://jsperf.com/md5-shootout/7\n     */\n\n    /* this function is much faster,\n      so if possible we use it. Some IEs\n      are the only ones I know of that\n      need the idiotic second function,\n      generated by an if clause.  */\n    var add32 = function (a, b) {\n        return (a + b) & 0xFFFFFFFF;\n    },\n        hex_chr = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f'];\n\n\n    function cmn(q, a, b, x, s, t) {\n        a = add32(add32(a, q), add32(x, t));\n        return add32((a << s) | (a >>> (32 - s)), b);\n    }\n\n    function md5cycle(x, k) {\n        var a = x[0],\n            b = x[1],\n            c = x[2],\n            d = x[3];\n\n        a += (b & c | ~b & d) + k[0] - 680876936 | 0;\n        a  = (a << 7 | a >>> 25) + b | 0;\n        d += (a & b | ~a & c) + k[1] - 389564586 | 0;\n        d  = (d << 12 | d >>> 20) + a | 0;\n        c += (d & a | ~d & b) + k[2] + 606105819 | 0;\n        c  = (c << 17 | c >>> 15) + d | 0;\n        b += (c & d | ~c & a) + k[3] - 1044525330 | 0;\n        b  = (b << 22 | b >>> 10) + c | 0;\n        a += (b & c | ~b & d) + k[4] - 176418897 | 0;\n        a  = (a << 7 | a >>> 25) + b | 0;\n        d += (a & b | ~a & c) + k[5] + 1200080426 | 0;\n        d  = (d << 12 | d >>> 20) + a | 0;\n        c += (d & a | ~d & b) + k[6] - 1473231341 | 0;\n        c  = (c << 17 | c >>> 15) + d | 0;\n        b += (c & d | ~c & a) + k[7] - 45705983 | 0;\n        b  = (b << 22 | b >>> 10) + c | 0;\n        a += (b & c | ~b & d) + k[8] + 1770035416 | 0;\n        a  = (a << 7 | a >>> 25) + b | 0;\n        d += (a & b | ~a & c) + k[9] - 1958414417 | 0;\n        d  = (d << 12 | d >>> 20) + a | 0;\n        c += (d & a | ~d & b) + k[10] - 42063 | 0;\n        c  = (c << 17 | c >>> 15) + d | 0;\n        b += (c & d | ~c & a) + k[11] - 1990404162 | 0;\n        b  = (b << 22 | b >>> 10) + c | 0;\n        a += (b & c | ~b & d) + k[12] + 1804603682 | 0;\n        a  = (a << 7 | a >>> 25) + b | 0;\n        d += (a & b | ~a & c) + k[13] - 40341101 | 0;\n        d  = (d << 12 | d >>> 20) + a | 0;\n        c += (d & a | ~d & b) + k[14] - 1502002290 | 0;\n        c  = (c << 17 | c >>> 15) + d | 0;\n        b += (c & d | ~c & a) + k[15] + 1236535329 | 0;\n        b  = (b << 22 | b >>> 10) + c | 0;\n\n        a += (b & d | c & ~d) + k[1] - 165796510 | 0;\n        a  = (a << 5 | a >>> 27) + b | 0;\n        d += (a & c | b & ~c) + k[6] - 1069501632 | 0;\n        d  = (d << 9 | d >>> 23) + a | 0;\n        c += (d & b | a & ~b) + k[11] + 643717713 | 0;\n        c  = (c << 14 | c >>> 18) + d | 0;\n        b += (c & a | d & ~a) + k[0] - 373897302 | 0;\n        b  = (b << 20 | b >>> 12) + c | 0;\n        a += (b & d | c & ~d) + k[5] - 701558691 | 0;\n        a  = (a << 5 | a >>> 27) + b | 0;\n        d += (a & c | b & ~c) + k[10] + 38016083 | 0;\n        d  = (d << 9 | d >>> 23) + a | 0;\n        c += (d & b | a & ~b) + k[15] - 660478335 | 0;\n        c  = (c << 14 | c >>> 18) + d | 0;\n        b += (c & a | d & ~a) + k[4] - 405537848 | 0;\n        b  = (b << 20 | b >>> 12) + c | 0;\n        a += (b & d | c & ~d) + k[9] + 568446438 | 0;\n        a  = (a << 5 | a >>> 27) + b | 0;\n        d += (a & c | b & ~c) + k[14] - 1019803690 | 0;\n        d  = (d << 9 | d >>> 23) + a | 0;\n        c += (d & b | a & ~b) + k[3] - 187363961 | 0;\n        c  = (c << 14 | c >>> 18) + d | 0;\n        b += (c & a | d & ~a) + k[8] + 1163531501 | 0;\n        b  = (b << 20 | b >>> 12) + c | 0;\n        a += (b & d | c & ~d) + k[13] - 1444681467 | 0;\n        a  = (a << 5 | a >>> 27) + b | 0;\n        d += (a & c | b & ~c) + k[2] - 51403784 | 0;\n        d  = (d << 9 | d >>> 23) + a | 0;\n        c += (d & b | a & ~b) + k[7] + 1735328473 | 0;\n        c  = (c << 14 | c >>> 18) + d | 0;\n        b += (c & a | d & ~a) + k[12] - 1926607734 | 0;\n        b  = (b << 20 | b >>> 12) + c | 0;\n\n        a += (b ^ c ^ d) + k[5] - 378558 | 0;\n        a  = (a << 4 | a >>> 28) + b | 0;\n        d += (a ^ b ^ c) + k[8] - 2022574463 | 0;\n        d  = (d << 11 | d >>> 21) + a | 0;\n        c += (d ^ a ^ b) + k[11] + 1839030562 | 0;\n        c  = (c << 16 | c >>> 16) + d | 0;\n        b += (c ^ d ^ a) + k[14] - 35309556 | 0;\n        b  = (b << 23 | b >>> 9) + c | 0;\n        a += (b ^ c ^ d) + k[1] - 1530992060 | 0;\n        a  = (a << 4 | a >>> 28) + b | 0;\n        d += (a ^ b ^ c) + k[4] + 1272893353 | 0;\n        d  = (d << 11 | d >>> 21) + a | 0;\n        c += (d ^ a ^ b) + k[7] - 155497632 | 0;\n        c  = (c << 16 | c >>> 16) + d | 0;\n        b += (c ^ d ^ a) + k[10] - 1094730640 | 0;\n        b  = (b << 23 | b >>> 9) + c | 0;\n        a += (b ^ c ^ d) + k[13] + 681279174 | 0;\n        a  = (a << 4 | a >>> 28) + b | 0;\n        d += (a ^ b ^ c) + k[0] - 358537222 | 0;\n        d  = (d << 11 | d >>> 21) + a | 0;\n        c += (d ^ a ^ b) + k[3] - 722521979 | 0;\n        c  = (c << 16 | c >>> 16) + d | 0;\n        b += (c ^ d ^ a) + k[6] + 76029189 | 0;\n        b  = (b << 23 | b >>> 9) + c | 0;\n        a += (b ^ c ^ d) + k[9] - 640364487 | 0;\n        a  = (a << 4 | a >>> 28) + b | 0;\n        d += (a ^ b ^ c) + k[12] - 421815835 | 0;\n        d  = (d << 11 | d >>> 21) + a | 0;\n        c += (d ^ a ^ b) + k[15] + 530742520 | 0;\n        c  = (c << 16 | c >>> 16) + d | 0;\n        b += (c ^ d ^ a) + k[2] - 995338651 | 0;\n        b  = (b << 23 | b >>> 9) + c | 0;\n\n        a += (c ^ (b | ~d)) + k[0] - 198630844 | 0;\n        a  = (a << 6 | a >>> 26) + b | 0;\n        d += (b ^ (a | ~c)) + k[7] + 1126891415 | 0;\n        d  = (d << 10 | d >>> 22) + a | 0;\n        c += (a ^ (d | ~b)) + k[14] - 1416354905 | 0;\n        c  = (c << 15 | c >>> 17) + d | 0;\n        b += (d ^ (c | ~a)) + k[5] - 57434055 | 0;\n        b  = (b << 21 |b >>> 11) + c | 0;\n        a += (c ^ (b | ~d)) + k[12] + 1700485571 | 0;\n        a  = (a << 6 | a >>> 26) + b | 0;\n        d += (b ^ (a | ~c)) + k[3] - 1894986606 | 0;\n        d  = (d << 10 | d >>> 22) + a | 0;\n        c += (a ^ (d | ~b)) + k[10] - 1051523 | 0;\n        c  = (c << 15 | c >>> 17) + d | 0;\n        b += (d ^ (c | ~a)) + k[1] - 2054922799 | 0;\n        b  = (b << 21 |b >>> 11) + c | 0;\n        a += (c ^ (b | ~d)) + k[8] + 1873313359 | 0;\n        a  = (a << 6 | a >>> 26) + b | 0;\n        d += (b ^ (a | ~c)) + k[15] - 30611744 | 0;\n        d  = (d << 10 | d >>> 22) + a | 0;\n        c += (a ^ (d | ~b)) + k[6] - 1560198380 | 0;\n        c  = (c << 15 | c >>> 17) + d | 0;\n        b += (d ^ (c | ~a)) + k[13] + 1309151649 | 0;\n        b  = (b << 21 |b >>> 11) + c | 0;\n        a += (c ^ (b | ~d)) + k[4] - 145523070 | 0;\n        a  = (a << 6 | a >>> 26) + b | 0;\n        d += (b ^ (a | ~c)) + k[11] - 1120210379 | 0;\n        d  = (d << 10 | d >>> 22) + a | 0;\n        c += (a ^ (d | ~b)) + k[2] + 718787259 | 0;\n        c  = (c << 15 | c >>> 17) + d | 0;\n        b += (d ^ (c | ~a)) + k[9] - 343485551 | 0;\n        b  = (b << 21 | b >>> 11) + c | 0;\n\n        x[0] = a + x[0] | 0;\n        x[1] = b + x[1] | 0;\n        x[2] = c + x[2] | 0;\n        x[3] = d + x[3] | 0;\n    }\n\n    function md5blk(s) {\n        var md5blks = [],\n            i; /* Andy King said do it this way. */\n\n        for (i = 0; i < 64; i += 4) {\n            md5blks[i >> 2] = s.charCodeAt(i) + (s.charCodeAt(i + 1) << 8) + (s.charCodeAt(i + 2) << 16) + (s.charCodeAt(i + 3) << 24);\n        }\n        return md5blks;\n    }\n\n    function md5blk_array(a) {\n        var md5blks = [],\n            i; /* Andy King said do it this way. */\n\n        for (i = 0; i < 64; i += 4) {\n            md5blks[i >> 2] = a[i] + (a[i + 1] << 8) + (a[i + 2] << 16) + (a[i + 3] << 24);\n        }\n        return md5blks;\n    }\n\n    function md51(s) {\n        var n = s.length,\n            state = [1732584193, -271733879, -1732584194, 271733878],\n            i,\n            length,\n            tail,\n            tmp,\n            lo,\n            hi;\n\n        for (i = 64; i <= n; i += 64) {\n            md5cycle(state, md5blk(s.substring(i - 64, i)));\n        }\n        s = s.substring(i - 64);\n        length = s.length;\n        tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];\n        for (i = 0; i < length; i += 1) {\n            tail[i >> 2] |= s.charCodeAt(i) << ((i % 4) << 3);\n        }\n        tail[i >> 2] |= 0x80 << ((i % 4) << 3);\n        if (i > 55) {\n            md5cycle(state, tail);\n            for (i = 0; i < 16; i += 1) {\n                tail[i] = 0;\n            }\n        }\n\n        // Beware that the final length might not fit in 32 bits so we take care of that\n        tmp = n * 8;\n        tmp = tmp.toString(16).match(/(.*?)(.{0,8})$/);\n        lo = parseInt(tmp[2], 16);\n        hi = parseInt(tmp[1], 16) || 0;\n\n        tail[14] = lo;\n        tail[15] = hi;\n\n        md5cycle(state, tail);\n        return state;\n    }\n\n    function md51_array(a) {\n        var n = a.length,\n            state = [1732584193, -271733879, -1732584194, 271733878],\n            i,\n            length,\n            tail,\n            tmp,\n            lo,\n            hi;\n\n        for (i = 64; i <= n; i += 64) {\n            md5cycle(state, md5blk_array(a.subarray(i - 64, i)));\n        }\n\n        // Not sure if it is a bug, however IE10 will always produce a sub array of length 1\n        // containing the last element of the parent array if the sub array specified starts\n        // beyond the length of the parent array - weird.\n        // https://connect.microsoft.com/IE/feedback/details/771452/typed-array-subarray-issue\n        a = (i - 64) < n ? a.subarray(i - 64) : new Uint8Array(0);\n\n        length = a.length;\n        tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0];\n        for (i = 0; i < length; i += 1) {\n            tail[i >> 2] |= a[i] << ((i % 4) << 3);\n        }\n\n        tail[i >> 2] |= 0x80 << ((i % 4) << 3);\n        if (i > 55) {\n            md5cycle(state, tail);\n            for (i = 0; i < 16; i += 1) {\n                tail[i] = 0;\n            }\n        }\n\n        // Beware that the final length might not fit in 32 bits so we take care of that\n        tmp = n * 8;\n        tmp = tmp.toString(16).match(/(.*?)(.{0,8})$/);\n        lo = parseInt(tmp[2], 16);\n        hi = parseInt(tmp[1], 16) || 0;\n\n        tail[14] = lo;\n        tail[15] = hi;\n\n        md5cycle(state, tail);\n\n        return state;\n    }\n\n    function rhex(n) {\n        var s = '',\n            j;\n        for (j = 0; j < 4; j += 1) {\n            s += hex_chr[(n >> (j * 8 + 4)) & 0x0F] + hex_chr[(n >> (j * 8)) & 0x0F];\n        }\n        return s;\n    }\n\n    function hex(x) {\n        var i;\n        for (i = 0; i < x.length; i += 1) {\n            x[i] = rhex(x[i]);\n        }\n        return x.join('');\n    }\n\n    // In some cases the fast add32 function cannot be used..\n    if (hex(md51('hello')) !== '5d41402abc4b2a76b9719d911017c592') {\n        add32 = function (x, y) {\n            var lsw = (x & 0xFFFF) + (y & 0xFFFF),\n                msw = (x >> 16) + (y >> 16) + (lsw >> 16);\n            return (msw << 16) | (lsw & 0xFFFF);\n        };\n    }\n\n    // ---------------------------------------------------\n\n    /**\n     * ArrayBuffer slice polyfill.\n     *\n     * @see https://github.com/ttaubert/node-arraybuffer-slice\n     */\n\n    if (typeof ArrayBuffer !== 'undefined' && !ArrayBuffer.prototype.slice) {\n        (function () {\n            function clamp(val, length) {\n                val = (val | 0) || 0;\n\n                if (val < 0) {\n                    return Math.max(val + length, 0);\n                }\n\n                return Math.min(val, length);\n            }\n\n            ArrayBuffer.prototype.slice = function (from, to) {\n                var length = this.byteLength,\n                    begin = clamp(from, length),\n                    end = length,\n                    num,\n                    target,\n                    targetArray,\n                    sourceArray;\n\n                if (to !== undefined) {\n                    end = clamp(to, length);\n                }\n\n                if (begin > end) {\n                    return new ArrayBuffer(0);\n                }\n\n                num = end - begin;\n                target = new ArrayBuffer(num);\n                targetArray = new Uint8Array(target);\n\n                sourceArray = new Uint8Array(this, begin, num);\n                targetArray.set(sourceArray);\n\n                return target;\n            };\n        })();\n    }\n\n    // ---------------------------------------------------\n\n    /**\n     * Helpers.\n     */\n\n    function toUtf8(str) {\n        if (/[\\u0080-\\uFFFF]/.test(str)) {\n            str = unescape(encodeURIComponent(str));\n        }\n\n        return str;\n    }\n\n    function utf8Str2ArrayBuffer(str, returnUInt8Array) {\n        var length = str.length,\n           buff = new ArrayBuffer(length),\n           arr = new Uint8Array(buff),\n           i;\n\n        for (i = 0; i < length; i += 1) {\n            arr[i] = str.charCodeAt(i);\n        }\n\n        return returnUInt8Array ? arr : buff;\n    }\n\n    function arrayBuffer2Utf8Str(buff) {\n        return String.fromCharCode.apply(null, new Uint8Array(buff));\n    }\n\n    function concatenateArrayBuffers(first, second, returnUInt8Array) {\n        var result = new Uint8Array(first.byteLength + second.byteLength);\n\n        result.set(new Uint8Array(first));\n        result.set(new Uint8Array(second), first.byteLength);\n\n        return returnUInt8Array ? result : result.buffer;\n    }\n\n    function hexToBinaryString(hex) {\n        var bytes = [],\n            length = hex.length,\n            x;\n\n        for (x = 0; x < length - 1; x += 2) {\n            bytes.push(parseInt(hex.substr(x, 2), 16));\n        }\n\n        return String.fromCharCode.apply(String, bytes);\n    }\n\n    // ---------------------------------------------------\n\n    /**\n     * SparkMD5 OOP implementation.\n     *\n     * Use this class to perform an incremental md5, otherwise use the\n     * static methods instead.\n     */\n\n    function SparkMD5() {\n        // call reset to init the instance\n        this.reset();\n    }\n\n    /**\n     * Appends a string.\n     * A conversion will be applied if an utf8 string is detected.\n     *\n     * @param {String} str The string to be appended\n     *\n     * @return {SparkMD5} The instance itself\n     */\n    SparkMD5.prototype.append = function (str) {\n        // Converts the string to utf8 bytes if necessary\n        // Then append as binary\n        this.appendBinary(toUtf8(str));\n\n        return this;\n    };\n\n    /**\n     * Appends a binary string.\n     *\n     * @param {String} contents The binary string to be appended\n     *\n     * @return {SparkMD5} The instance itself\n     */\n    SparkMD5.prototype.appendBinary = function (contents) {\n        this._buff += contents;\n        this._length += contents.length;\n\n        var length = this._buff.length,\n            i;\n\n        for (i = 64; i <= length; i += 64) {\n            md5cycle(this._hash, md5blk(this._buff.substring(i - 64, i)));\n        }\n\n        this._buff = this._buff.substring(i - 64);\n\n        return this;\n    };\n\n    /**\n     * Finishes the incremental computation, reseting the internal state and\n     * returning the result.\n     *\n     * @param {Boolean} raw True to get the raw string, false to get the hex string\n     *\n     * @return {String} The result\n     */\n    SparkMD5.prototype.end = function (raw) {\n        var buff = this._buff,\n            length = buff.length,\n            i,\n            tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            ret;\n\n        for (i = 0; i < length; i += 1) {\n            tail[i >> 2] |= buff.charCodeAt(i) << ((i % 4) << 3);\n        }\n\n        this._finish(tail, length);\n        ret = hex(this._hash);\n\n        if (raw) {\n            ret = hexToBinaryString(ret);\n        }\n\n        this.reset();\n\n        return ret;\n    };\n\n    /**\n     * Resets the internal state of the computation.\n     *\n     * @return {SparkMD5} The instance itself\n     */\n    SparkMD5.prototype.reset = function () {\n        this._buff = '';\n        this._length = 0;\n        this._hash = [1732584193, -271733879, -1732584194, 271733878];\n\n        return this;\n    };\n\n    /**\n     * Gets the internal state of the computation.\n     *\n     * @return {Object} The state\n     */\n    SparkMD5.prototype.getState = function () {\n        return {\n            buff: this._buff,\n            length: this._length,\n            hash: this._hash\n        };\n    };\n\n    /**\n     * Gets the internal state of the computation.\n     *\n     * @param {Object} state The state\n     *\n     * @return {SparkMD5} The instance itself\n     */\n    SparkMD5.prototype.setState = function (state) {\n        this._buff = state.buff;\n        this._length = state.length;\n        this._hash = state.hash;\n\n        return this;\n    };\n\n    /**\n     * Releases memory used by the incremental buffer and other additional\n     * resources. If you plan to use the instance again, use reset instead.\n     */\n    SparkMD5.prototype.destroy = function () {\n        delete this._hash;\n        delete this._buff;\n        delete this._length;\n    };\n\n    /**\n     * Finish the final calculation based on the tail.\n     *\n     * @param {Array}  tail   The tail (will be modified)\n     * @param {Number} length The length of the remaining buffer\n     */\n    SparkMD5.prototype._finish = function (tail, length) {\n        var i = length,\n            tmp,\n            lo,\n            hi;\n\n        tail[i >> 2] |= 0x80 << ((i % 4) << 3);\n        if (i > 55) {\n            md5cycle(this._hash, tail);\n            for (i = 0; i < 16; i += 1) {\n                tail[i] = 0;\n            }\n        }\n\n        // Do the final computation based on the tail and length\n        // Beware that the final length may not fit in 32 bits so we take care of that\n        tmp = this._length * 8;\n        tmp = tmp.toString(16).match(/(.*?)(.{0,8})$/);\n        lo = parseInt(tmp[2], 16);\n        hi = parseInt(tmp[1], 16) || 0;\n\n        tail[14] = lo;\n        tail[15] = hi;\n        md5cycle(this._hash, tail);\n    };\n\n    /**\n     * Performs the md5 hash on a string.\n     * A conversion will be applied if utf8 string is detected.\n     *\n     * @param {String}  str The string\n     * @param {Boolean} raw True to get the raw string, false to get the hex string\n     *\n     * @return {String} The result\n     */\n    SparkMD5.hash = function (str, raw) {\n        // Converts the string to utf8 bytes if necessary\n        // Then compute it using the binary function\n        return SparkMD5.hashBinary(toUtf8(str), raw);\n    };\n\n    /**\n     * Performs the md5 hash on a binary string.\n     *\n     * @param {String}  content The binary string\n     * @param {Boolean} raw     True to get the raw string, false to get the hex string\n     *\n     * @return {String} The result\n     */\n    SparkMD5.hashBinary = function (content, raw) {\n        var hash = md51(content),\n            ret = hex(hash);\n\n        return raw ? hexToBinaryString(ret) : ret;\n    };\n\n    // ---------------------------------------------------\n\n    /**\n     * SparkMD5 OOP implementation for array buffers.\n     *\n     * Use this class to perform an incremental md5 ONLY for array buffers.\n     */\n    SparkMD5.ArrayBuffer = function () {\n        // call reset to init the instance\n        this.reset();\n    };\n\n    /**\n     * Appends an array buffer.\n     *\n     * @param {ArrayBuffer} arr The array to be appended\n     *\n     * @return {SparkMD5.ArrayBuffer} The instance itself\n     */\n    SparkMD5.ArrayBuffer.prototype.append = function (arr) {\n        var buff = concatenateArrayBuffers(this._buff.buffer, arr, true),\n            length = buff.length,\n            i;\n\n        this._length += arr.byteLength;\n\n        for (i = 64; i <= length; i += 64) {\n            md5cycle(this._hash, md5blk_array(buff.subarray(i - 64, i)));\n        }\n\n        this._buff = (i - 64) < length ? new Uint8Array(buff.buffer.slice(i - 64)) : new Uint8Array(0);\n\n        return this;\n    };\n\n    /**\n     * Finishes the incremental computation, reseting the internal state and\n     * returning the result.\n     *\n     * @param {Boolean} raw True to get the raw string, false to get the hex string\n     *\n     * @return {String} The result\n     */\n    SparkMD5.ArrayBuffer.prototype.end = function (raw) {\n        var buff = this._buff,\n            length = buff.length,\n            tail = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n            i,\n            ret;\n\n        for (i = 0; i < length; i += 1) {\n            tail[i >> 2] |= buff[i] << ((i % 4) << 3);\n        }\n\n        this._finish(tail, length);\n        ret = hex(this._hash);\n\n        if (raw) {\n            ret = hexToBinaryString(ret);\n        }\n\n        this.reset();\n\n        return ret;\n    };\n\n    /**\n     * Resets the internal state of the computation.\n     *\n     * @return {SparkMD5.ArrayBuffer} The instance itself\n     */\n    SparkMD5.ArrayBuffer.prototype.reset = function () {\n        this._buff = new Uint8Array(0);\n        this._length = 0;\n        this._hash = [1732584193, -271733879, -1732584194, 271733878];\n\n        return this;\n    };\n\n    /**\n     * Gets the internal state of the computation.\n     *\n     * @return {Object} The state\n     */\n    SparkMD5.ArrayBuffer.prototype.getState = function () {\n        var state = SparkMD5.prototype.getState.call(this);\n\n        // Convert buffer to a string\n        state.buff = arrayBuffer2Utf8Str(state.buff);\n\n        return state;\n    };\n\n    /**\n     * Gets the internal state of the computation.\n     *\n     * @param {Object} state The state\n     *\n     * @return {SparkMD5.ArrayBuffer} The instance itself\n     */\n    SparkMD5.ArrayBuffer.prototype.setState = function (state) {\n        // Convert string to buffer\n        state.buff = utf8Str2ArrayBuffer(state.buff, true);\n\n        return SparkMD5.prototype.setState.call(this, state);\n    };\n\n    SparkMD5.ArrayBuffer.prototype.destroy = SparkMD5.prototype.destroy;\n\n    SparkMD5.ArrayBuffer.prototype._finish = SparkMD5.prototype._finish;\n\n    /**\n     * Performs the md5 hash on an array buffer.\n     *\n     * @param {ArrayBuffer} arr The array buffer\n     * @param {Boolean}     raw True to get the raw string, false to get the hex one\n     *\n     * @return {String} The result\n     */\n    SparkMD5.ArrayBuffer.hash = function (arr, raw) {\n        var hash = md51_array(new Uint8Array(arr)),\n            ret = hex(hash);\n\n        return raw ? hexToBinaryString(ret) : ret;\n    };\n\n    return SparkMD5;\n}));\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/spark-md5/spark-md5.js\n// module id = 15\n// module chunks = 0","'use strict';\n\n/**\n * Stringify/parse functions that don't operate\n * recursively, so they avoid call stack exceeded\n * errors.\n */\nexports.stringify = function stringify(input) {\n  var queue = [];\n  queue.push({obj: input});\n\n  var res = '';\n  var next, obj, prefix, val, i, arrayPrefix, keys, k, key, value, objPrefix;\n  while ((next = queue.pop())) {\n    obj = next.obj;\n    prefix = next.prefix || '';\n    val = next.val || '';\n    res += prefix;\n    if (val) {\n      res += val;\n    } else if (typeof obj !== 'object') {\n      res += typeof obj === 'undefined' ? null : JSON.stringify(obj);\n    } else if (obj === null) {\n      res += 'null';\n    } else if (Array.isArray(obj)) {\n      queue.push({val: ']'});\n      for (i = obj.length - 1; i >= 0; i--) {\n        arrayPrefix = i === 0 ? '' : ',';\n        queue.push({obj: obj[i], prefix: arrayPrefix});\n      }\n      queue.push({val: '['});\n    } else { // object\n      keys = [];\n      for (k in obj) {\n        if (obj.hasOwnProperty(k)) {\n          keys.push(k);\n        }\n      }\n      queue.push({val: '}'});\n      for (i = keys.length - 1; i >= 0; i--) {\n        key = keys[i];\n        value = obj[key];\n        objPrefix = (i > 0 ? ',' : '');\n        objPrefix += JSON.stringify(key) + ':';\n        queue.push({obj: value, prefix: objPrefix});\n      }\n      queue.push({val: '{'});\n    }\n  }\n  return res;\n};\n\n// Convenience function for the parse function.\n// This pop function is basically copied from\n// pouchCollate.parseIndexableString\nfunction pop(obj, stack, metaStack) {\n  var lastMetaElement = metaStack[metaStack.length - 1];\n  if (obj === lastMetaElement.element) {\n    // popping a meta-element, e.g. an object whose value is another object\n    metaStack.pop();\n    lastMetaElement = metaStack[metaStack.length - 1];\n  }\n  var element = lastMetaElement.element;\n  var lastElementIndex = lastMetaElement.index;\n  if (Array.isArray(element)) {\n    element.push(obj);\n  } else if (lastElementIndex === stack.length - 2) { // obj with key+value\n    var key = stack.pop();\n    element[key] = obj;\n  } else {\n    stack.push(obj); // obj with key only\n  }\n}\n\nexports.parse = function (str) {\n  var stack = [];\n  var metaStack = []; // stack for arrays and objects\n  var i = 0;\n  var collationIndex,parsedNum,numChar;\n  var parsedString,lastCh,numConsecutiveSlashes,ch;\n  var arrayElement, objElement;\n  while (true) {\n    collationIndex = str[i++];\n    if (collationIndex === '}' ||\n        collationIndex === ']' ||\n        typeof collationIndex === 'undefined') {\n      if (stack.length === 1) {\n        return stack.pop();\n      } else {\n        pop(stack.pop(), stack, metaStack);\n        continue;\n      }\n    }\n    switch (collationIndex) {\n      case ' ':\n      case '\\t':\n      case '\\n':\n      case ':':\n      case ',':\n        break;\n      case 'n':\n        i += 3; // 'ull'\n        pop(null, stack, metaStack);\n        break;\n      case 't':\n        i += 3; // 'rue'\n        pop(true, stack, metaStack);\n        break;\n      case 'f':\n        i += 4; // 'alse'\n        pop(false, stack, metaStack);\n        break;\n      case '0':\n      case '1':\n      case '2':\n      case '3':\n      case '4':\n      case '5':\n      case '6':\n      case '7':\n      case '8':\n      case '9':\n      case '-':\n        parsedNum = '';\n        i--;\n        while (true) {\n          numChar = str[i++];\n          if (/[\\d\\.\\-e\\+]/.test(numChar)) {\n            parsedNum += numChar;\n          } else {\n            i--;\n            break;\n          }\n        }\n        pop(parseFloat(parsedNum), stack, metaStack);\n        break;\n      case '\"':\n        parsedString = '';\n        lastCh = void 0;\n        numConsecutiveSlashes = 0;\n        while (true) {\n          ch = str[i++];\n          if (ch !== '\"' || (lastCh === '\\\\' &&\n              numConsecutiveSlashes % 2 === 1)) {\n            parsedString += ch;\n            lastCh = ch;\n            if (lastCh === '\\\\') {\n              numConsecutiveSlashes++;\n            } else {\n              numConsecutiveSlashes = 0;\n            }\n          } else {\n            break;\n          }\n        }\n        pop(JSON.parse('\"' + parsedString + '\"'), stack, metaStack);\n        break;\n      case '[':\n        arrayElement = { element: [], index: stack.length };\n        stack.push(arrayElement.element);\n        metaStack.push(arrayElement);\n        break;\n      case '{':\n        objElement = { element: {}, index: stack.length };\n        stack.push(objElement.element);\n        metaStack.push(objElement);\n        break;\n      default:\n        throw new Error(\n          'unexpectedly reached end of input: ' + collationIndex);\n    }\n  }\n};\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// ./~/vuvuzela/index.js\n// module id = 16\n// module chunks = 0","module.exports = function(module) {\r\n\tif(!module.webpackPolyfill) {\r\n\t\tmodule.deprecate = function() {};\r\n\t\tmodule.paths = [];\r\n\t\t// module.parent = undefined by default\r\n\t\tif(!module.children) module.children = [];\r\n\t\tObject.defineProperty(module, \"loaded\", {\r\n\t\t\tenumerable: true,\r\n\t\t\tget: function() {\r\n\t\t\t\treturn module.l;\r\n\t\t\t}\r\n\t\t});\r\n\t\tObject.defineProperty(module, \"id\", {\r\n\t\t\tenumerable: true,\r\n\t\t\tget: function() {\r\n\t\t\t\treturn module.i;\r\n\t\t\t}\r\n\t\t});\r\n\t\tmodule.webpackPolyfill = 1;\r\n\t}\r\n\treturn module;\r\n};\r\n\n\n\n//////////////////\n// WEBPACK FOOTER\n// (webpack)/buildin/module.js\n// module id = 17\n// module chunks = 0","/**\n * Importing\n */\nimport PouchDB from 'pouchdb-browser';\n\n/**\n * Utilities\n */\nimport merge from 'lodash.merge';\nimport {\n  noop,\n  binarySearch,\n  expand,\n  mapQueries\n} from './utils';\n\n/**\n * Internal Global Vue reference\n */\nlet Vue;\n\n/**\n * Bucket Class\n */\nclass Bucket {\n\n  /**\n   * Creating internal state for Bucket\n   * @param schema\n   */\n  constructor(schema = {}) {\n\n    // Ignore Schema Keys\n    const ignoredKeys = [\n      'config',\n      'plugins',\n      'actions'\n    ];\n\n    // Internal Config reference\n    this._config = schema.config;\n\n    // Internal State\n    this._dbs   = {};\n    this._watch = {};\n    this._state = {};\n\n    // Throw Error if Global Config not defined\n    if (!schema.config) {\n      throw new Error('[VuePouch]: Global Config is not declared in the upper level!');\n    }\n\n    // Referencing Actions to the $bucket\n    if (schema.actions) {\n      merge(this, schema.actions);\n    }\n\n    // Init PouchDB plugins\n    if ((schema.plugins.constructor === Array) && (schema.plugins.length > 0)) {\n      for (let i = 0; i < schema.plugins.length; i += 1) {\n        PouchDB.plugin(schema.plugins[i]);\n      }\n    }\n\n    // Initializing DBs that are declared in the schema{}\n    Object.keys(schema).forEach((dbname) => {\n      // If is ignored Key, skip!\n      if (ignoredKeys.indexOf(dbname) !== -1)  return null;\n\n      // Initialize the DB\n      return this._initDB(dbname, merge(\n        {},\n        schema.config,\n        schema[dbname]\n      ));\n    });\n  }\n\n  // Delete Object from _state\n  _deleted(dbname, docID) {\n    const index = binarySearch(this._state[dbname], docID);\n    const doc   = this._state[dbname][index];\n\n    // Delete\n    if (doc && doc._id === docID) {\n      this._state[dbname].splice(index, 1);\n    }\n  }\n\n  // Update or insert state in object\n  _upsert(dbname, newDoc) {\n    const index = binarySearch(this._state[dbname], newDoc._id);\n    const doc   = this._state[dbname][index];\n\n    // Update\n    if (doc && doc._id === newDoc._id) {\n      // Make Reactive\n      Vue.set(this._state[dbname], index, newDoc);\n    } else {\n      // Insert an Empty object to reserve the index\n      this._state[dbname].splice(index, 0, {});\n      // Set the reactive data\n      Vue.set(this._state[dbname], index, newDoc);\n    }\n  }\n\n  /**\n   * Relax, and send the request to CouchDB\n   * @param options\n   * @private\n   */\n  _relax(options) {\n    return fetch(`${this._config.remote}/${options.url}`,\n      merge({\n        credentials: 'include',\n        headers: { 'Content-Type': 'application/json' }\n      }, options, { body: JSON.stringify(options.body) }\n    )).then(response => response.json());\n  }\n\n  /**\n   * Init Database\n   * @param dbname\n   * @param config\n   * @returns {*}\n   * @private\n   */\n  _initDB(dbname, config = {}) {\n    // If DB Exists return it\n    if (this._dbs[dbname]) {\n      return this._dbs[dbname];\n    }\n\n    // Init only remote\n    if (config.remoteOnly) {\n      this._dbs[dbname] = new PouchDB(\n        `${config.remote}/${dbname}`,\n        config.options\n      );\n      return this._dbs[dbname];\n    }\n\n    // Init DB\n    this._dbs[dbname] = new PouchDB(dbname, config.options);\n\n    // Populate state with data\n    this._dbs[dbname].allDocs(config.allDocs).then((data) => {\n      return Vue.set(this._state, dbname, data.rows.map((row) => row.doc));\n    });\n\n    // Sync DB\n    PouchDB.sync(\n      dbname,\n      `${config.remote}/${dbname}`,\n      config.sync\n    );\n\n    // Start detecting changes\n    this._initChanges(dbname, config);\n\n    // Return instance\n    return this._dbs[dbname];\n  }\n\n  _initChanges(dbname, config) {\n    // Detect Changes and update the _state tree\n    const dbChanges = this._dbs[dbname].changes(config.changes).on('change', (change) => {\n      if (change.deleted) {\n        this._deleted(dbname, change.id);\n      } else {\n        this._upsert(dbname, change.doc);\n      }\n      return config.onChanges && config.onChanges(change);\n    }).on('complete', (complete) => {\n      if (complete.results) {\n        complete.results.forEach((change) => {\n          if (change.deleted) {\n            this._deleted(dbname, change.id);\n          } else {\n            this._upsert(dbname, change.doc);\n          }\n        });\n      }\n      return config.onComplete || config.onComplete(complete);\n    }).on('error', config.onError || noop)\n    .on('paused', config.onPaused || noop)\n    .on('active', config.onActive || noop)\n    .on('denied', config.onDenied || noop);\n\n    // Calling the Cancel function\n    config.cancel && config.cancel(dbChanges.cancel);\n\n    // Reference all Subscriptions\n    this._watch[dbname] = dbChanges;\n\n    // Returing the Watch\n    return this._watch[dbname];\n  }\n\n  /**\n   * Reference internal state\n   */\n  get state() {\n    return this._state;\n  }\n\n  /**\n   * Don't let the state be overwritten from outside\n   */\n  set state(value) {\n    console.error(\n      `[VuePouch]: Do not replace the entire state! \n       VuePouch takes care of the updates internally, \n       change the DB instead!`\n    );\n    // Return Undefined\n    return undefined;\n  }\n\n  /**\n   * DB Accessor\n   * @param dbname\n   * @param config\n   * @returns {*}\n   */\n  db(dbname, config = {}) {\n    return this._initDB(dbname, merge({}, this._config, config));\n  }\n\n  /**\n   * Closing the DB and removing all the change watchers and state.\n   * @param dbname\n   * @returns {Promise}\n   */\n  closedb(dbname) {\n    // If db does not exist, skip.\n    if (!this._dbs[dbname]) return null;\n    // If the DB is already closed, simply skip.\n    if (this._dbs[dbname]._closed) return null;\n    // Close the DB and return Promise\n    return new Promise((resolve, reject) => {\n      // Closing the DB\n      this._dbs[dbname].close().then((response) => {\n        // Canceling the Change Event\n        this._watch[dbname].cancel();\n        // Deleting internal db reference\n        delete this._dbs[dbname];\n        // Removing the State of the DB\n        Vue.delete(this._state, dbname);\n        // Deleting internal watch reference\n        delete this._watch[dbname];\n        // Resolving Promise\n        return resolve(response);\n      }).catch(reject);\n    });\n  }\n}\n\n/**\n * Exporting public utility functions\n */\nexport {\n  mapQueries\n};\n\n/**\n * Exporting\n **/\nexport default {\n  // Bucket Class\n  Bucket,\n\n  // Install Plugin\n  install($Vue) {\n\n    // Checking if Vue is Installed\n    if (Vue) {\n      throw new Error(\n        '[VuePouch] already installed. Vue.use(VuePouch) should be called only once.'\n      );\n    }\n\n    // Making Vue globally available\n    Vue = $Vue;\n\n    // Get Util Functions\n    const { defineReactive } = Vue.util;\n\n    // Check Version Number\n    const version = Number(Vue.version.split('.')[0]);\n\n    /**\n     * Setup the internal $dbsetup object\n     * @param dbsetup\n     */\n    function $dbsetup() {\n      // If dbsetup does not exist, terminate!\n      if (!this.$options.dbsetup) return null;\n      // Getting DB Setup\n      const { dbsetup } = this.$options;\n      // Compile the Object and assign it to the instance\n      return merge(this, {\n        $dbsetup: Object.keys(dbsetup).reduce((db, prop) => merge(db, {\n          [prop]: expand(dbsetup[prop] || {}, this)\n        }), {})\n      });\n    }\n\n    /**\n     * Vuex init hook, injected into each instances init hooks list.\n     */\n    function bucketInit () {\n      // Getting Options\n      const options = this.$options;\n      // Bucket injection\n      if (options.bucket) {\n        // Getting the core $bucket\n        this.$bucket = options.bucket;\n        // Define Reactive state\n        defineReactive(this.$bucket, '_state', options.bucket._state);\n      } else if (options.parent && options.parent.$bucket) {\n        // Getting parent bucket\n        this.$bucket = options.parent.$bucket;\n      }\n    }\n\n    /**\n     * Based on dbsetup object, configure the Database\n     */\n    function dbCreated() {\n      // Compiling this.$options.dbsetup to have local component variables\n      $dbsetup.call(this);\n      // If dbsetup does not exist, terminate!\n      if (!this.$dbsetup) return null;\n      // Setting up the database\n      return this.$bucket.db(this.$dbsetup.name, this.$dbsetup.options);\n    }\n\n    /**\n     * Close DB connections when component gets Destroyed\n     */\n    function dbDestroy() {\n      // If dbsetup does not exist, terminate!\n      if (!this.$dbsetup) return null;\n      // Closing the DB Connection on component destroy\n      return this.$bucket.closedb(this.$dbsetup.name);\n    }\n\n    // Check Version\n    if (version >= 2) {\n      const usesInit = Vue.config._lifecycleHooks.indexOf('init') > -1;\n      Vue.mixin(usesInit ? {\n        init:          bucketInit,\n        created:       dbCreated,\n        beforeDestroy: dbDestroy\n      } : {\n        beforeCreate:  bucketInit,\n        created:       dbCreated,\n        activated:     dbCreated,\n        deactivated:   dbDestroy,\n        beforeDestroy: dbDestroy\n      });\n    } else {\n      // override init and inject VuePouch init procedure\n      // for 1.x backwards compatibility.\n      const _init = Vue.prototype._init;\n      // Initializing the bucket\n      Vue.prototype._init = function VueInit(options = {}) {\n        options.init = options.init\n          ? [bucketInit].concat(options.init)\n          : bucketInit;\n        _init.call(this, options);\n      };\n    }\n  }\n};\n\n/**\n * Making PouchDB Available for Debugging\n */\nif (process.env.NODE_ENV !== 'production') {\n  window.PouchDB = PouchDB;\n}\n\n\n\n// WEBPACK FOOTER //\n// ./src/index.js"],"sourceRoot":""}